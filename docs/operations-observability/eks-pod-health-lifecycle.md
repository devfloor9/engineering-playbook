---
title: "EKS Pod í—¬ìŠ¤ì²´í¬ & ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬"
sidebar_label: "5. Pod í—¬ìŠ¤ì²´í¬ & ë¼ì´í”„ì‚¬ì´í´"
description: "Kubernetes Probe ì„¤ì • ì „ëµ, Graceful Shutdown íŒ¨í„´, Pod ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬ ëª¨ë²” ì‚¬ë¡€"
tags: [eks, kubernetes, probes, health-check, graceful-shutdown, lifecycle, best-practices]
category: "operations"
last_update:
  date: 2026-02-12
  author: devfloor9
sidebar_position: 5
---

# EKS Pod í—¬ìŠ¤ì²´í¬ & ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬

> ğŸ“… **ì‘ì„±ì¼**: 2026-02-12 | â±ï¸ **ì½ëŠ” ì‹œê°„**: ì•½ 18ë¶„

> **ğŸ“Œ ê¸°ì¤€ í™˜ê²½**: EKS 1.30+, Kubernetes 1.30+, AWS Load Balancer Controller v2.7+

## 1. ê°œìš”

Podì˜ í—¬ìŠ¤ì²´í¬ì™€ ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬ëŠ” ì„œë¹„ìŠ¤ ì•ˆì •ì„±ê³¼ ê°€ìš©ì„±ì˜ í•µì‹¬ì…ë‹ˆë‹¤. ì ì ˆí•œ Probe ì„¤ì •ê³¼ Graceful Shutdown êµ¬í˜„ì€ ë‹¤ìŒì„ ë³´ì¥í•©ë‹ˆë‹¤:

- **ë¬´ì¤‘ë‹¨ ë°°í¬**: ë¡¤ë§ ì—…ë°ì´íŠ¸ ì‹œ íŠ¸ë˜í”½ ìœ ì‹¤ ë°©ì§€
- **ë¹ ë¥¸ ì¥ì•  ê°ì§€**: ë¹„ì •ìƒ Pod ìë™ ê²©ë¦¬ ë° ì¬ì‹œì‘
- **ë¦¬ì†ŒìŠ¤ ìµœì í™”**: ëŠë¦° ì‹œì‘ ì•±ì˜ ì¡°ê¸° ì¬ì‹œì‘ ë°©ì§€
- **ë°ì´í„° ë¬´ê²°ì„±**: ì¢…ë£Œ ì‹œ ì§„í–‰ ì¤‘ì¸ ìš”ì²­ ì•ˆì „í•˜ê²Œ ì™„ë£Œ

ë³¸ ë¬¸ì„œëŠ” Kubernetes Probeì˜ ë™ì‘ ì›ë¦¬ë¶€í„° ì–¸ì–´ë³„ Graceful Shutdown êµ¬í˜„, Init Container í™œìš©, ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ìµœì í™”ê¹Œì§€ Pod ë¼ì´í”„ì‚¬ì´í´ ì „ì²´ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤.

:::info ê´€ë ¨ ë¬¸ì„œ ì°¸ì¡°
- **Probe ë””ë²„ê¹…**: [EKS ì¥ì•  ì§„ë‹¨ ë° ëŒ€ì‘ ê°€ì´ë“œ](/docs/operations-observability/eks-debugging-guide)ì˜ "Probe ë””ë²„ê¹… ë° Best Practices" ì„¹ì…˜
- **ê³ ê°€ìš©ì„± ì„¤ê³„**: [EKS ê³ ê°€ìš©ì„± ì•„í‚¤í…ì²˜ ê°€ì´ë“œ](/docs/operations-observability/eks-resiliency-guide)ì˜ "Graceful Shutdown", "PDB", "Pod Readiness Gates" ì„¹ì…˜
:::

---

## 2. Kubernetes Probe ì‹¬ì¸µ ê°€ì´ë“œ

### 2.1 ì„¸ ê°€ì§€ Probe ìœ í˜•ê³¼ ë™ì‘ ì›ë¦¬

KubernetesëŠ” ì„¸ ê°€ì§€ ìœ í˜•ì˜ Probeë¥¼ ì œê³µí•˜ì—¬ Podì˜ ìƒíƒœë¥¼ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤.

| Probe ìœ í˜• | ëª©ì  | ì‹¤íŒ¨ ì‹œ ë™ì‘ | í™œì„±í™” íƒ€ì´ë° |
|-----------|------|-------------|-------------|
| **Startup Probe** | ì• í”Œë¦¬ì¼€ì´ì…˜ ì´ˆê¸°í™” ì™„ë£Œ í™•ì¸ | Pod ì¬ì‹œì‘ (failureThreshold ë„ë‹¬ ì‹œ) | Pod ì‹œì‘ ì§í›„ |
| **Liveness Probe** | ì• í”Œë¦¬ì¼€ì´ì…˜ ë°ë“œë½/êµì°© ìƒíƒœ ê°ì§€ | ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘ | Startup Probe ì„±ê³µ í›„ |
| **Readiness Probe** | íŠ¸ë˜í”½ ìˆ˜ì‹  ì¤€ë¹„ ìƒíƒœ í™•ì¸ | Service Endpointì—ì„œ ì œê±° (ì¬ì‹œì‘ ì—†ìŒ) | Startup Probe ì„±ê³µ í›„ |

#### Startup Probe: ëŠë¦° ì‹œì‘ ì•± ë³´í˜¸

Startup ProbeëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì™„ì „íˆ ì‹œì‘ë  ë•Œê¹Œì§€ Liveness/Readiness Probeì˜ ì‹¤í–‰ì„ ì§€ì—°ì‹œí‚µë‹ˆë‹¤. Spring Boot, JVM ì• í”Œë¦¬ì¼€ì´ì…˜, ML ëª¨ë¸ ë¡œë”© ë“± ì‹œì‘ì´ ëŠë¦° ì•±ì— í•„ìˆ˜ì…ë‹ˆë‹¤.

**ë™ì‘ ì›ë¦¬:**
- Startup Probeê°€ ì‹¤í–‰ ì¤‘ì¼ ë•ŒëŠ” Liveness/Readiness Probeê°€ ë¹„í™œì„±í™”ë¨
- Startup Probe ì„±ê³µ ì‹œ â†’ Liveness/Readiness Probe í™œì„±í™”
- Startup Probe ì‹¤íŒ¨ (failureThreshold ë„ë‹¬) â†’ ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘

#### Liveness Probe: ë°ë“œë½ ê°ì§€

Liveness ProbeëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì‚´ì•„ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤. ì‹¤íŒ¨ ì‹œ kubeletì´ ì»¨í…Œì´ë„ˆë¥¼ ì¬ì‹œì‘í•©ë‹ˆë‹¤.

**ì‚¬ìš© ì‚¬ë¡€:**
- ë¬´í•œ ë£¨í”„, ë°ë“œë½ ìƒíƒœ ê°ì§€
- ë³µêµ¬ ë¶ˆê°€ëŠ¥í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ì—ëŸ¬
- ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ë¡œ ì¸í•œ ì‘ë‹µ ë¶ˆê°€ ìƒíƒœ

**ì£¼ì˜ì‚¬í•­:**
- Liveness Probeì— **ì™¸ë¶€ ì˜ì¡´ì„±ì„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”** (DB, Redis ë“±)
- ì™¸ë¶€ ì„œë¹„ìŠ¤ ì¥ì•  ì‹œ ì „ì²´ Podì´ ì¬ì‹œì‘ë˜ëŠ” cascading failure ë°œìƒ

#### Readiness Probe: íŠ¸ë˜í”½ ìˆ˜ì‹  ì œì–´

Readiness ProbeëŠ” Podì´ íŠ¸ë˜í”½ì„ ë°›ì„ ì¤€ë¹„ê°€ ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤. ì‹¤íŒ¨ ì‹œ Serviceì˜ Endpointsì—ì„œ Podì´ ì œê±°ë˜ì§€ë§Œ, ì»¨í…Œì´ë„ˆëŠ” ì¬ì‹œì‘ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

**ì‚¬ìš© ì‚¬ë¡€:**
- ì˜ì¡´ ì„œë¹„ìŠ¤ ì—°ê²° í™•ì¸ (DB, ìºì‹œ)
- ì´ˆê¸° ë°ì´í„° ë¡œë”© ì™„ë£Œ í™•ì¸
- ë°°í¬ ì¤‘ ë‹¨ê³„ì  íŠ¸ë˜í”½ ìˆ˜ì‹ 

```mermaid
flowchart TB
    subgraph "Pod ë¼ì´í”„ì‚¬ì´í´ & Probe ë™ì‘"
        START[Pod ìƒì„±] --> INIT[Init Container ì‹¤í–‰]
        INIT --> MAIN[ë©”ì¸ ì»¨í…Œì´ë„ˆ ì‹œì‘]
        MAIN --> STARTUP{Startup Probe<br/>ì‹¤í–‰ ì¤‘}

        STARTUP -->|ì‹¤íŒ¨| STARTUP_FAIL[failureThreshold ë„ë‹¬]
        STARTUP_FAIL --> RESTART[ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘]
        RESTART --> MAIN

        STARTUP -->|ì„±ê³µ| PROBES_ACTIVE[Liveness/Readiness<br/>Probe í™œì„±í™”]

        PROBES_ACTIVE --> LIVENESS{Liveness Probe}
        PROBES_ACTIVE --> READINESS{Readiness Probe}

        LIVENESS -->|ì‹¤íŒ¨| LIVENESS_FAIL[ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘]
        LIVENESS_FAIL --> MAIN
        LIVENESS -->|ì„±ê³µ| RUNNING[ì •ìƒ ë™ì‘]

        READINESS -->|ì‹¤íŒ¨| EP_REMOVE[Service Endpoint<br/>ì œê±°]
        READINESS -->|ì„±ê³µ| EP_ADD[Service Endpoint<br/>ì¶”ê°€]
        EP_REMOVE -.-> READINESS
        EP_ADD --> RUNNING

        RUNNING --> TERM[Pod ì¢…ë£Œ ìš”ì²­]
        TERM --> PRESTOP[preStop Hook]
        PRESTOP --> SIGTERM[SIGTERM ì „ì†¡]
        SIGTERM --> GRACE[Graceful Shutdown]
        GRACE --> STOPPED[ì»¨í…Œì´ë„ˆ ì¢…ë£Œ]
    end

    style START fill:#4286f4,stroke:#2a6acf,color:#fff
    style STARTUP fill:#fbbc04,stroke:#c99603,color:#000
    style PROBES_ACTIVE fill:#34a853,stroke:#2a8642,color:#fff
    style RESTART fill:#ff4444,stroke:#cc3636,color:#fff
    style RUNNING fill:#34a853,stroke:#2a8642,color:#fff
    style TERM fill:#ff9900,stroke:#cc7a00,color:#fff
```

### 2.2 Probe ë©”ì»¤ë‹ˆì¦˜

KubernetesëŠ” ë„¤ ê°€ì§€ Probe ë©”ì»¤ë‹ˆì¦˜ì„ ì§€ì›í•©ë‹ˆë‹¤.

| ë©”ì»¤ë‹ˆì¦˜ | ì„¤ëª… | ì¥ì  | ë‹¨ì  | ì í•©í•œ ìƒí™© |
|----------|------|------|------|------------|
| **httpGet** | HTTP GET ìš”ì²­, 200-399 ì‘ë‹µ ì½”ë“œ í™•ì¸ | í‘œì¤€ì , êµ¬í˜„ ê°„ë‹¨ | HTTP ì„œë²„ í•„ìš” | REST API, ì›¹ ì„œë¹„ìŠ¤ |
| **tcpSocket** | TCP í¬íŠ¸ ì—°ê²° ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ | ê°€ë³ê³  ë¹ ë¦„ | ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œì§ ê²€ì¦ ë¶ˆê°€ | gRPC, ë°ì´í„°ë² ì´ìŠ¤ |
| **exec** | ì»¨í…Œì´ë„ˆ ë‚´ ëª…ë ¹ ì‹¤í–‰, exit code 0 í™•ì¸ | ìœ ì—°í•¨, ì»¤ìŠ¤í…€ ë¡œì§ ê°€ëŠ¥ | ì˜¤ë²„í—¤ë“œ ë†’ìŒ | ë°°ì¹˜ ì›Œì»¤, íŒŒì¼ ê¸°ë°˜ í™•ì¸ |
| **grpc** | gRPC Health Check Protocol ì‚¬ìš© (K8s 1.27+ GA) | ë„¤ì´í‹°ë¸Œ gRPC ì§€ì› | gRPC ì•±ë§Œ ì‚¬ìš© ê°€ëŠ¥ | gRPC ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ |

#### httpGet ì˜ˆì‹œ

```yaml
livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
    httpHeaders:
    - name: X-Custom-Header
      value: HealthCheck
    scheme: HTTP  # ë˜ëŠ” HTTPS
  initialDelaySeconds: 30
  periodSeconds: 10
```

#### tcpSocket ì˜ˆì‹œ

```yaml
livenessProbe:
  tcpSocket:
    port: 5432  # PostgreSQL
  initialDelaySeconds: 15
  periodSeconds: 10
```

#### exec ì˜ˆì‹œ

```yaml
livenessProbe:
  exec:
    command:
    - /bin/sh
    - -c
    - test -f /tmp/healthy
  initialDelaySeconds: 5
  periodSeconds: 5
```

#### grpc ì˜ˆì‹œ (Kubernetes 1.27+)

```yaml
livenessProbe:
  grpc:
    port: 9090
    service: myservice  # ì„ íƒ ì‚¬í•­
  initialDelaySeconds: 10
  periodSeconds: 5
```

:::tip gRPC Health Check Protocol
gRPC ì„œë¹„ìŠ¤ëŠ” [gRPC Health Checking Protocol](https://github.com/grpc/grpc/blob/master/doc/health-checking.md)ì„ êµ¬í˜„í•´ì•¼ í•©ë‹ˆë‹¤. GoëŠ” `google.golang.org/grpc/health`, JavaëŠ” `grpc-health-check` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
:::

### 2.3 Probe íƒ€ì´ë° ì„¤ê³„

Probeì˜ íƒ€ì´ë° íŒŒë¼ë¯¸í„°ëŠ” ì¥ì•  ê°ì§€ ì†ë„ì™€ ì•ˆì •ì„± ê°„ì˜ ê· í˜•ì„ ê²°ì •í•©ë‹ˆë‹¤.

| íŒŒë¼ë¯¸í„° | ì„¤ëª… | ê¸°ë³¸ê°’ | ê¶Œì¥ ë²”ìœ„ |
|----------|------|--------|----------|
| `initialDelaySeconds` | ì»¨í…Œì´ë„ˆ ì‹œì‘ í›„ ì²« Probeê¹Œì§€ ëŒ€ê¸° ì‹œê°„ | 0 | 10-30s (Startup Probe ì‚¬ìš© ì‹œ 0 ê°€ëŠ¥) |
| `periodSeconds` | Probe ì‹¤í–‰ ê°„ê²© | 10 | 5-15s |
| `timeoutSeconds` | Probe ì‘ë‹µ ëŒ€ê¸° ì‹œê°„ | 1 | 3-10s |
| `failureThreshold` | ì‹¤íŒ¨ íŒì •ê¹Œì§€ ì—°ì† ì‹¤íŒ¨ íšŸìˆ˜ | 3 | Liveness: 3, Readiness: 1-3, Startup: 30+ |
| `successThreshold` | ì„±ê³µ íŒì •ê¹Œì§€ ì—°ì† ì„±ê³µ íšŸìˆ˜ (Readinessë§Œ 1 ì´ìƒ ê°€ëŠ¥) | 1 | 1-2 |

#### íƒ€ì´ë° ì„¤ê³„ ê³µì‹

```
ìµœëŒ€ ê°ì§€ ì‹œê°„ = failureThreshold Ã— periodSeconds
ìµœì†Œ ë³µêµ¬ ì‹œê°„ = successThreshold Ã— periodSeconds
```

**ì˜ˆì‹œ:**
- `failureThreshold: 3, periodSeconds: 10` â†’ ìµœëŒ€ 30ì´ˆ í›„ ì¥ì•  ê°ì§€
- `successThreshold: 2, periodSeconds: 5` â†’ ìµœì†Œ 10ì´ˆ í›„ ë³µêµ¬ íŒì • (Readinessë§Œ)

#### ì›Œí¬ë¡œë“œë³„ ê¶Œì¥ íƒ€ì´ë°

| ì›Œí¬ë¡œë“œ ìœ í˜• | initialDelaySeconds | periodSeconds | failureThreshold | ì´ìœ  |
|--------------|-------------------|---------------|-----------------|------|
| ì›¹ ì„œë¹„ìŠ¤ (Node.js, Python) | 10 | 5 | 3 | ë¹ ë¥¸ ì‹œì‘, ë¹ ë¥¸ ê°ì§€ í•„ìš” |
| JVM ì•± (Spring Boot) | 0 (Startup Probe ì‚¬ìš©) | 10 | 3 | ì‹œì‘ ëŠë¦¼, Startupìœ¼ë¡œ ë³´í˜¸ |
| ë°ì´í„°ë² ì´ìŠ¤ (PostgreSQL) | 30 | 10 | 5 | ì´ˆê¸°í™” ì‹œê°„ ê¸¸ìŒ |
| ë°°ì¹˜ ì›Œì»¤ | 5 | 15 | 2 | ì£¼ê¸°ì  ì‘ì—…, ëŠìŠ¨í•œ ê°ì§€ |
| ML ì¶”ë¡  ì„œë¹„ìŠ¤ | 0 (Startup: 60) | 10 | 3 | ëª¨ë¸ ë¡œë”© ì‹œê°„ ê¸º |

### 2.4 ì›Œí¬ë¡œë“œë³„ Probe íŒ¨í„´

#### íŒ¨í„´ 1: ì›¹ ì„œë¹„ìŠ¤ (REST API)

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: rest-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: rest-api
  template:
    metadata:
      labels:
        app: rest-api
    spec:
      containers:
      - name: api
        image: myapp/rest-api:v1.2.3
        ports:
        - containerPort: 8080
          protocol: TCP
        resources:
          requests:
            cpu: 200m
            memory: 256Mi
          limits:
            cpu: 500m
            memory: 512Mi
        # Startup Probe: 30ì´ˆ ì´ë‚´ ì‹œì‘ ì™„ë£Œ í™•ì¸
        startupProbe:
          httpGet:
            path: /healthz
            port: 8080
          failureThreshold: 6
          periodSeconds: 5
        # Liveness Probe: ë‚´ë¶€ í—¬ìŠ¤ì²´í¬ë§Œ (ì™¸ë¶€ ì˜ì¡´ì„± ì œì™¸)
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        # Readiness Probe: ì™¸ë¶€ ì˜ì¡´ì„± í¬í•¨ ê°€ëŠ¥
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 2
          successThreshold: 1
        lifecycle:
          preStop:
            exec:
              command:
              - /bin/sh
              - -c
              - sleep 5 && kill -TERM 1
      terminationGracePeriodSeconds: 60
```

**í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„ (Node.js/Express):**

```javascript
// /healthz - Liveness: ì• í”Œë¦¬ì¼€ì´ì…˜ ìì²´ ìƒíƒœë§Œ í™•ì¸
app.get('/healthz', (req, res) => {
  // ë‚´ë¶€ ìƒíƒœë§Œ í™•ì¸ (ë©”ëª¨ë¦¬, CPU ë“±)
  const memUsage = process.memoryUsage();
  if (memUsage.heapUsed / memUsage.heapTotal > 0.95) {
    return res.status(500).json({ status: 'unhealthy', reason: 'memory_pressure' });
  }
  res.status(200).json({ status: 'ok' });
});

// /ready - Readiness: ì™¸ë¶€ ì˜ì¡´ì„± í¬í•¨ í™•ì¸
app.get('/ready', async (req, res) => {
  try {
    // DB ì—°ê²° í™•ì¸
    await db.ping();
    // Redis ì—°ê²° í™•ì¸
    await redis.ping();
    res.status(200).json({ status: 'ready' });
  } catch (err) {
    res.status(503).json({ status: 'not_ready', reason: err.message });
  }
});
```

#### íŒ¨í„´ 2: gRPC ì„œë¹„ìŠ¤

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grpc-service
spec:
  replicas: 3
  selector:
    matchLabels:
      app: grpc-service
  template:
    metadata:
      labels:
        app: grpc-service
    spec:
      containers:
      - name: grpc-server
        image: myapp/grpc-service:v2.1.0
        ports:
        - containerPort: 9090
          name: grpc
        resources:
          requests:
            cpu: 300m
            memory: 512Mi
          limits:
            cpu: 1
            memory: 1Gi
        # gRPC native probe (K8s 1.27+)
        startupProbe:
          grpc:
            port: 9090
            service: myapp.HealthService  # ì„ íƒ ì‚¬í•­
          failureThreshold: 30
          periodSeconds: 10
        livenessProbe:
          grpc:
            port: 9090
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        readinessProbe:
          grpc:
            port: 9090
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 2
      terminationGracePeriodSeconds: 45
```

**gRPC Health Check êµ¬í˜„ (Go):**

```go
package main

import (
    "context"
    "google.golang.org/grpc"
    "google.golang.org/grpc/health"
    "google.golang.org/grpc/health/grpc_health_v1"
)

func main() {
    server := grpc.NewServer()

    // Health ì„œë¹„ìŠ¤ ë“±ë¡
    healthServer := health.NewServer()
    grpc_health_v1.RegisterHealthServer(server, healthServer)

    // ì„œë¹„ìŠ¤ë¥¼ SERVING ìƒíƒœë¡œ ì„¤ì •
    healthServer.SetServingStatus("myapp.HealthService", grpc_health_v1.HealthCheckResponse_SERVING)

    // ì˜ì¡´ì„± ì²´í¬ í›„ NOT_SERVINGìœ¼ë¡œ ë³€ê²½ ê°€ëŠ¥
    // healthServer.SetServingStatus("myapp.HealthService", grpc_health_v1.HealthCheckResponse_NOT_SERVING)

    // gRPC ì„œë²„ ì‹œì‘
    lis, _ := net.Listen("tcp", ":9090")
    server.Serve(lis)
}
```

#### íŒ¨í„´ 3: ì›Œì»¤/ë°°ì¹˜ ì²˜ë¦¬

ë°°ì¹˜ ì›Œì»¤ëŠ” HTTP ì„œë²„ê°€ ì—†ìœ¼ë¯€ë¡œ `exec` Probeë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: batch-worker
spec:
  replicas: 2
  selector:
    matchLabels:
      app: batch-worker
  template:
    metadata:
      labels:
        app: batch-worker
    spec:
      containers:
      - name: worker
        image: myapp/batch-worker:v3.0.1
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 2
            memory: 4Gi
        # Startup Probe: ì›Œì»¤ ì´ˆê¸°í™” í™•ì¸
        startupProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - test -f /tmp/worker-ready
          failureThreshold: 12
          periodSeconds: 5
        # Liveness Probe: í•˜íŠ¸ë¹„íŠ¸ íŒŒì¼ í™•ì¸
        livenessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - find /tmp/heartbeat -mmin -2 | grep -q heartbeat
          initialDelaySeconds: 10
          periodSeconds: 30
          failureThreshold: 3
        # Readiness Probe: ì‘ì—… í ì—°ê²° í™•ì¸
        readinessProbe:
          exec:
            command:
            - /app/check-queue-connection.sh
          periodSeconds: 10
          failureThreshold: 3
      terminationGracePeriodSeconds: 120
```

**ì›Œì»¤ ì• í”Œë¦¬ì¼€ì´ì…˜ (Python):**

```python
import os
import time
from pathlib import Path

HEARTBEAT_FILE = Path("/tmp/heartbeat")
READY_FILE = Path("/tmp/worker-ready")

def worker_loop():
    # ì´ˆê¸°í™” ì™„ë£Œ ì‹œê·¸ë„
    READY_FILE.touch()

    while True:
        # ì£¼ê¸°ì ìœ¼ë¡œ í•˜íŠ¸ë¹„íŠ¸ ì—…ë°ì´íŠ¸
        HEARTBEAT_FILE.touch()

        # ì‘ì—… ì²˜ë¦¬
        process_jobs()
        time.sleep(5)

def process_jobs():
    # ì‹¤ì œ ì‘ì—… ë¡œì§
    pass

if __name__ == "__main__":
    worker_loop()
```

#### íŒ¨í„´ 4: ëŠë¦° ì‹œì‘ ì•± (Spring Boot, JVM)

JVM ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ì‹œì‘ ì‹œê°„ì´ 30ì´ˆ ì´ìƒ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Startup Probeë¡œ ë³´í˜¸í•©ë‹ˆë‹¤.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spring-boot-app
spec:
  replicas: 4
  selector:
    matchLabels:
      app: spring-boot
  template:
    metadata:
      labels:
        app: spring-boot
    spec:
      containers:
      - name: app
        image: myapp/spring-boot:v2.7.0
        ports:
        - containerPort: 8080
        resources:
          requests:
            cpu: 1
            memory: 2Gi
          limits:
            cpu: 2
            memory: 4Gi
        env:
        - name: JAVA_OPTS
          value: "-Xms1g -Xmx3g"
        # Startup Probe: ìµœëŒ€ 5ë¶„(30 x 10s) ëŒ€ê¸°
        startupProbe:
          httpGet:
            path: /actuator/health/liveness
            port: 8080
          failureThreshold: 30
          periodSeconds: 10
        # Liveness Probe: Startup ì„±ê³µ í›„ í™œì„±í™”
        livenessProbe:
          httpGet:
            path: /actuator/health/liveness
            port: 8080
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        # Readiness Probe: ì™¸ë¶€ ì˜ì¡´ì„± í¬í•¨
        readinessProbe:
          httpGet:
            path: /actuator/health/readiness
            port: 8080
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 2
      terminationGracePeriodSeconds: 60
```

**Spring Boot Actuator ì„¤ì •:**

```yaml
# application.yml
management:
  endpoints:
    web:
      exposure:
        include: health
  health:
    livenessState:
      enabled: true
    readinessState:
      enabled: true
  endpoint:
    health:
      probes:
        enabled: true
      show-details: when-authorized
```

#### íŒ¨í„´ 5: ì‚¬ì´ë“œì¹´ íŒ¨í„´ (Istio Proxy + ì•±)

ì‚¬ì´ë“œì¹´ íŒ¨í„´ì—ì„œëŠ” ë©”ì¸ ì»¨í…Œì´ë„ˆì™€ ì‚¬ì´ë“œì¹´ ëª¨ë‘ì— Probeë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-with-sidecar
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      # ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ì»¨í…Œì´ë„ˆ
      - name: app
        image: myapp/app:v1.0.0
        ports:
        - containerPort: 8080
        startupProbe:
          httpGet:
            path: /healthz
            port: 8080
          failureThreshold: 10
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8080
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          periodSeconds: 5
      # Istio ì‚¬ì´ë“œì¹´ (ìë™ ì£¼ì… ì‹œ Istioê°€ Probe ì¶”ê°€)
      # ìˆ˜ë™ ì„¤ì • ì˜ˆì‹œ:
      - name: istio-proxy
        image: istio/proxyv2:1.22.0
        ports:
        - containerPort: 15090
          name: http-envoy-prom
        startupProbe:
          httpGet:
            path: /healthz/ready
            port: 15021
          failureThreshold: 30
          periodSeconds: 1
        livenessProbe:
          httpGet:
            path: /healthz/ready
            port: 15021
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /healthz/ready
            port: 15021
          periodSeconds: 2
      terminationGracePeriodSeconds: 90
```

:::tip Istio Sidecar Injection
Istioê°€ ìë™ ì£¼ì…ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš° (`istio-injection=enabled` ë ˆì´ë¸”), Istioê°€ ì‚¬ì´ë“œì¹´ì— ì ì ˆí•œ Probeë¥¼ ìë™ìœ¼ë¡œ ì¶”ê°€í•©ë‹ˆë‹¤. ìˆ˜ë™ ì„¤ì •ì€ ë¶ˆí•„ìš”í•©ë‹ˆë‹¤.
:::

#### 2.4.6 Windows ì»¨í…Œì´ë„ˆ Probe ê³ ë ¤ì‚¬í•­

EKSëŠ” Windows Server 2019/2022 ê¸°ë°˜ Windows ë…¸ë“œë¥¼ ì§€ì›í•˜ë©°, Windows ì»¨í…Œì´ë„ˆëŠ” Linux ì»¨í…Œì´ë„ˆì™€ ë‹¤ë¥¸ Probe ë™ì‘ íŠ¹ì„±ì„ ê°€ì§‘ë‹ˆë‹¤.

##### Windows vs Linux Probe ë™ì‘ ì°¨ì´

| í•­ëª© | Linux ì»¨í…Œì´ë„ˆ | Windows ì»¨í…Œì´ë„ˆ | ì˜í–¥ |
|------|---------------|-----------------|------|
| **ì»¨í…Œì´ë„ˆ ëŸ°íƒ€ì„** | containerd | containerd (1.6+) | ë™ì¼í•œ ëŸ°íƒ€ì„, ë‹¤ë¥¸ OS ë ˆì´ì–´ |
| **exec Probe ì‹¤í–‰** | `/bin/sh -c` | `cmd.exe /c` ë˜ëŠ” `powershell.exe` | ìŠ¤í¬ë¦½íŠ¸ ë¬¸ë²• ì°¨ì´ |
| **httpGet Probe** | ë™ì¼ | ë™ì¼ | ì°¨ì´ ì—†ìŒ |
| **tcpSocket Probe** | ë™ì¼ | ë™ì¼ | ì°¨ì´ ì—†ìŒ |
| **ì½œë“œ ìŠ¤íƒ€íŠ¸ ì‹œê°„** | ë¹ ë¦„ (ìˆ˜ì´ˆ) | ëŠë¦¼ (10-30ì´ˆ) | Startup Probe failureThreshold ì¦ê°€ í•„ìš” |
| **ë©”ëª¨ë¦¬ ì˜¤ë²„í—¤ë“œ** | ë‚®ìŒ (50-100MB) | ë†’ìŒ (200-500MB) | ë¦¬ì†ŒìŠ¤ ìš”ì²­ ì¦ê°€ í•„ìš” |
| **Probe íƒ€ì„ì•„ì›ƒ** | ì¼ë°˜ì ìœ¼ë¡œ 1-5ì´ˆ | 3-10ì´ˆ ê¶Œì¥ | Windows I/O ì§€ì—° ê³ ë ¤ |

##### Windows ì›Œí¬ë¡œë“œ Probe ì„¤ì • ì˜ˆì‹œ

**IIS/.NET Framework ì•±:**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: iis-app
  namespace: windows-workloads
spec:
  replicas: 2
  selector:
    matchLabels:
      app: iis-app
  template:
    metadata:
      labels:
        app: iis-app
    spec:
      nodeSelector:
        kubernetes.io/os: windows
        kubernetes.io/arch: amd64
      containers:
      - name: iis
        image: mcr.microsoft.com/windows/servercore/iis:windowsservercore-ltsc2022
        ports:
        - containerPort: 80
        resources:
          requests:
            cpu: 500m
            memory: 512Mi
          limits:
            cpu: 2000m
            memory: 2Gi
        # Startup Probe: Windows ì½œë“œ ìŠ¤íƒ€íŠ¸ ê³ ë ¤
        startupProbe:
          httpGet:
            path: /
            port: 80
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 5
          timeoutSeconds: 5
          failureThreshold: 12  # Linux ëŒ€ë¹„ 2ë°° (ìµœëŒ€ 60ì´ˆ)
          successThreshold: 1
        # Liveness Probe: IIS í”„ë¡œì„¸ìŠ¤ ìƒíƒœ
        livenessProbe:
          httpGet:
            path: /healthz
            port: 80
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        # Readiness Probe: ASP.NET ì•± ì¤€ë¹„ ìƒíƒœ
        readinessProbe:
          httpGet:
            path: /ready
            port: 80
          initialDelaySeconds: 15
          periodSeconds: 5
          timeoutSeconds: 5
          failureThreshold: 3
          successThreshold: 1
      terminationGracePeriodSeconds: 60
```

**ASP.NET Core í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„:**

```csharp
// Program.cs (ASP.NET Core 6+)
using Microsoft.AspNetCore.Diagnostics.HealthChecks;
using Microsoft.Extensions.Diagnostics.HealthChecks;

var builder = WebApplication.CreateBuilder(args);

// í—¬ìŠ¤ì²´í¬ ì¶”ê°€
builder.Services.AddHealthChecks()
    .AddCheck("self", () => HealthCheckResult.Healthy())
    .AddSqlServer(
        connectionString: builder.Configuration.GetConnectionString("DefaultConnection"),
        name: "sqlserver",
        tags: new[] { "ready" }
    );

var app = builder.Build();

// /healthz - Liveness: ì• í”Œë¦¬ì¼€ì´ì…˜ ìì²´ë§Œ
app.MapHealthChecks("/healthz", new HealthCheckOptions
{
    Predicate = check => check.Tags.Contains("self") || check.Tags.Count == 0
});

// /ready - Readiness: ì™¸ë¶€ ì˜ì¡´ì„± í¬í•¨
app.MapHealthChecks("/ready", new HealthCheckOptions
{
    Predicate = _ => true  // ëª¨ë“  í—¬ìŠ¤ì²´í¬
});

app.Run();
```

##### Windows ì›Œí¬ë¡œë“œ Probe íƒ€ì„ì•„ì›ƒ ì£¼ì˜ì‚¬í•­

Windows ì»¨í…Œì´ë„ˆëŠ” ë‹¤ìŒ ì´ìœ ë¡œ Probe íƒ€ì„ì•„ì›ƒì´ ê¸¸ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤:

1. **Windows ì»¤ë„ ì˜¤ë²„í—¤ë“œ**: Windowsì˜ ë¬´ê±°ìš´ OS ë ˆì´ì–´ë¡œ ì¸í•œ ì‹œìŠ¤í…œ ì½œ ì§€ì—°
2. **ë””ìŠ¤í¬ I/O ì„±ëŠ¥**: NTFS íŒŒì¼ì‹œìŠ¤í…œì˜ ë©”íƒ€ë°ì´í„° ì˜¤ë²„í—¤ë“œ
3. **.NET Framework ì›Œë°ì—…**: CLR JIT ì»´íŒŒì¼ ë° ì–´ì…ˆë¸”ë¦¬ ë¡œë”© ì‹œê°„
4. **Windows Defender**: ì‹¤ì‹œê°„ ìŠ¤ìº”ìœ¼ë¡œ ì¸í•œ í”„ë¡œì„¸ìŠ¤ ì‹œì‘ ì§€ì—°

**ê¶Œì¥ Probe íƒ€ì´ë° (Windows):**

```yaml
startupProbe:
  timeoutSeconds: 5-10      # Linux: 3-5ì´ˆ
  periodSeconds: 5
  failureThreshold: 12-20   # Linux: 6-10

livenessProbe:
  timeoutSeconds: 5-10      # Linux: 3-5ì´ˆ
  periodSeconds: 10-15      # Linux: 10ì´ˆ
  failureThreshold: 3

readinessProbe:
  timeoutSeconds: 5-10      # Linux: 3-5ì´ˆ
  periodSeconds: 5-10       # Linux: 5ì´ˆ
  failureThreshold: 3
```

##### CloudWatch Container Insights for Windows (2025-08)

AWSëŠ” 2025ë…„ 8ì›”ì— Windows ì›Œí¬ë¡œë“œìš© CloudWatch Container Insights ì§€ì›ì„ ë°œí‘œí–ˆìŠµë‹ˆë‹¤.

**Windows ë…¸ë“œì— Container Insights ì„¤ì¹˜:**

```bash
# CloudWatch Agent ConfigMap (Windows)
kubectl apply -f - <<EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: cwagentconfig-windows
  namespace: amazon-cloudwatch
data:
  cwagentconfig.json: |
    {
      "logs": {
        "metrics_collected": {
          "kubernetes": {
            "cluster_name": "my-eks-cluster",
            "metrics_collection_interval": 60
          }
        }
      },
      "metrics": {
        "namespace": "ContainerInsights",
        "metrics_collected": {
          "statsd": {
            "service_address": ":8125"
          }
        }
      }
    }
EOF

# Windows DaemonSet ë°°í¬
kubectl apply -f https://raw.githubusercontent.com/aws-samples/amazon-cloudwatch-container-insights/latest/k8s-deployment-manifest-templates/deployment-mode/daemonset/container-insights-monitoring/cwagent/cwagent-daemonset-windows.yaml
```

**Container Insights ë©”íŠ¸ë¦­ í™•ì¸:**

```bash
# Windows ë…¸ë“œ ë©”íŠ¸ë¦­
aws cloudwatch get-metric-statistics \
  --namespace ContainerInsights \
  --metric-name node_memory_utilization \
  --dimensions Name=ClusterName,Value=my-eks-cluster Name=NodeName,Value=windows-node-1 \
  --start-time 2026-02-12T00:00:00Z \
  --end-time 2026-02-12T23:59:59Z \
  --period 300 \
  --statistics Average

# Windows Pod ë©”íŠ¸ë¦­
aws cloudwatch get-metric-statistics \
  --namespace ContainerInsights \
  --metric-name pod_cpu_utilization \
  --dimensions Name=ClusterName,Value=my-eks-cluster Name=Namespace,Value=windows-workloads \
  --start-time 2026-02-12T00:00:00Z \
  --end-time 2026-02-12T23:59:59Z \
  --period 60 \
  --statistics Average
```

##### í˜¼í•© í´ëŸ¬ìŠ¤í„° (Linux + Windows) í†µí•© ëª¨ë‹ˆí„°ë§ ì „ëµ

**1. ë…¸ë“œ ì…€ë ‰í„° ê¸°ë°˜ ë¶„ë¦¬:**

```yaml
apiVersion: v1
kind: Service
metadata:
  name: unified-app
spec:
  selector:
    app: unified-app  # OS ë¬´ê´€
  ports:
  - port: 80
    targetPort: 8080
---
# Linux Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: unified-app-linux
spec:
  replicas: 3
  selector:
    matchLabels:
      app: unified-app
      os: linux
  template:
    metadata:
      labels:
        app: unified-app
        os: linux
    spec:
      nodeSelector:
        kubernetes.io/os: linux
      containers:
      - name: app
        image: myapp:linux-v1
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          periodSeconds: 5
          timeoutSeconds: 3
---
# Windows Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: unified-app-windows
spec:
  replicas: 2
  selector:
    matchLabels:
      app: unified-app
      os: windows
  template:
    metadata:
      labels:
        app: unified-app
        os: windows
    spec:
      nodeSelector:
        kubernetes.io/os: windows
      containers:
      - name: app
        image: myapp:windows-v1
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          periodSeconds: 10      # Windows: ë” ê¸´ ê°„ê²©
          timeoutSeconds: 10     # Windows: ë” ê¸´ íƒ€ì„ì•„ì›ƒ
```

**2. CloudWatch Logs Insights í†µí•© ì¿¼ë¦¬:**

```sql
-- Linuxì™€ Windows Pod ë¡œê·¸ë¥¼ ë™ì‹œì— ê²€ìƒ‰
fields @timestamp, kubernetes.namespace_name, kubernetes.pod_name, kubernetes.host, @message
| filter kubernetes.labels.app = "unified-app"
| sort @timestamp desc
| limit 100
```

**3. Grafana ëŒ€ì‹œë³´ë“œ í†µí•©:**

```yaml
# Prometheus Query (í˜¼í•© í´ëŸ¬ìŠ¤í„°)
# Linux + Windows Pod CPU ì‚¬ìš©ë¥ 
sum(rate(container_cpu_usage_seconds_total{namespace="default", pod=~"unified-app-.*"}[5m])) by (pod, node, os)

# OSë³„ ì§‘ê³„
sum(rate(container_cpu_usage_seconds_total{namespace="default", pod=~"unified-app-.*"}[5m])) by (os)
```

:::warning Windows ì»¨í…Œì´ë„ˆ ì œì•½ì‚¬í•­
- **ì´ë¯¸ì§€ í¬ê¸°**: Windows ì´ë¯¸ì§€ëŠ” ìˆ˜ GB (LinuxëŠ” ìˆ˜ì‹­ MB)
- **ë¼ì´ì„ ìŠ¤ ë¹„ìš©**: Windows Server ë¼ì´ì„ ìŠ¤ ë¹„ìš© ë°œìƒ (EC2 ì¸ìŠ¤í„´ìŠ¤ ë¹„ìš©ì— í¬í•¨)
- **ë…¸ë“œ ë¶€íŒ… ì‹œê°„**: Windows ë…¸ë“œëŠ” ë¶€íŒ…ì´ ëŠë¦¼ (5-10ë¶„)
- **íŠ¹ê¶Œ ì»¨í…Œì´ë„ˆ**: WindowsëŠ” Linuxì˜ `privileged` ëª¨ë“œ ë¯¸ì§€ì›
- **HostProcess ì»¨í…Œì´ë„ˆ**: Windows Server 2022 (1.22+)ë¶€í„° ì§€ì›
:::

:::info ì°¸ê³  ìë£Œ
- [AWS Blog: CloudWatch Container Insights for Windows](https://aws.amazon.com/blogs/mt/announcing-amazon-cloudwatch-container-insights-for-amazon-eks-windows-workloads-monitoring)
- [EKS Windows ì»¨í…Œì´ë„ˆ ê³µì‹ ë¬¸ì„œ](https://docs.aws.amazon.com/eks/latest/userguide/windows-support.html)
- [Kubernetes Windows ì»¨í…Œì´ë„ˆ ê°€ì´ë“œ](https://kubernetes.io/docs/concepts/windows/)
:::

### 2.5 Probe ì•ˆí‹°íŒ¨í„´ê³¼ í•¨ì •

#### âŒ ì•ˆí‹°íŒ¨í„´ 1: Liveness Probeì— ì™¸ë¶€ ì˜ì¡´ì„± í¬í•¨

**ë¬¸ì œ:**

```yaml
livenessProbe:
  httpGet:
    path: /health  # DB, Redis ì—°ê²° í™•ì¸ í¬í•¨
    port: 8080
```

**ê²°ê³¼:**
- DB ì¥ì•  ì‹œ ëª¨ë“  Podì´ ë™ì‹œ ì¬ì‹œì‘ â†’ Cascading Failure
- ì¼ì‹œì ì¸ ë„¤íŠ¸ì›Œí¬ ì§€ì—°ìœ¼ë¡œë„ Pod ì¬ì‹œì‘

**ì˜¬ë°”ë¥¸ ì„¤ì •:**

```yaml
# Liveness: ì• í”Œë¦¬ì¼€ì´ì…˜ ìì²´ ìƒíƒœë§Œ
livenessProbe:
  httpGet:
    path: /healthz  # ë‚´ë¶€ ìƒíƒœë§Œ í™•ì¸
    port: 8080

# Readiness: ì™¸ë¶€ ì˜ì¡´ì„± í¬í•¨
readinessProbe:
  httpGet:
    path: /ready  # DB, Redis ë“± í™•ì¸
    port: 8080
```

#### âŒ ì•ˆí‹°íŒ¨í„´ 2: Startup Probe ì—†ì´ ë†’ì€ initialDelaySeconds

**ë¬¸ì œ:**

```yaml
livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
  initialDelaySeconds: 120  # 2ë¶„ ëŒ€ê¸°
  periodSeconds: 10
```

**ê²°ê³¼:**
- ì•±ì´ 30ì´ˆì— ì‹œì‘ ì™„ë£Œí•´ë„ 90ì´ˆ ë™ì•ˆ í—¬ìŠ¤ì²´í¬ ì—†ìŒ
- ì‹œì‘ ì¤‘ í¬ë˜ì‹œê°€ ë°œìƒí•´ë„ 2ë¶„ê¹Œì§€ ê°ì§€ ë¶ˆê°€

**ì˜¬ë°”ë¥¸ ì„¤ì •:**

```yaml
# Startup Probeë¡œ ì‹œì‘ ë³´í˜¸
startupProbe:
  httpGet:
    path: /healthz
    port: 8080
  failureThreshold: 12  # ìµœëŒ€ 120ì´ˆ ëŒ€ê¸°
  periodSeconds: 10

# LivenessëŠ” Startup ì„±ê³µ í›„ ì¦‰ì‹œ í™œì„±í™”
livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
  initialDelaySeconds: 0  # Startup ì„±ê³µ í›„ ë°”ë¡œ ì‹œì‘
  periodSeconds: 10
```

#### âŒ ì•ˆí‹°íŒ¨í„´ 3: Livenessì™€ Readinessì— ê°™ì€ ì—”ë“œí¬ì¸íŠ¸

**ë¬¸ì œ:**

```yaml
livenessProbe:
  httpGet:
    path: /health
    port: 8080

readinessProbe:
  httpGet:
    path: /health  # ë™ì¼í•œ ì—”ë“œí¬ì¸íŠ¸
    port: 8080
```

**ê²°ê³¼:**
- `/health`ê°€ ì™¸ë¶€ ì˜ì¡´ì„±ì„ í™•ì¸í•˜ë©´ Livenessê°€ ì‹¤íŒ¨í•˜ì—¬ ë¶ˆí•„ìš”í•œ ì¬ì‹œì‘
- ì—­í•  êµ¬ë¶„ì´ ëª¨í˜¸í•˜ì—¬ ë””ë²„ê¹… ì–´ë ¤ì›€

**ì˜¬ë°”ë¥¸ ì„¤ì •:**

```yaml
livenessProbe:
  httpGet:
    path: /healthz  # ë‚´ë¶€ ìƒíƒœë§Œ
    port: 8080

readinessProbe:
  httpGet:
    path: /ready  # ì™¸ë¶€ ì˜ì¡´ì„± í¬í•¨
    port: 8080
```

#### âŒ ì•ˆí‹°íŒ¨í„´ 4: ë„ˆë¬´ ê³µê²©ì ì¸ failureThreshold

**ë¬¸ì œ:**

```yaml
livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
  periodSeconds: 5
  failureThreshold: 1  # ë‹¨ 1ë²ˆ ì‹¤íŒ¨ë¡œ ì¬ì‹œì‘
```

**ê²°ê³¼:**
- ì¼ì‹œì ì¸ ë„¤íŠ¸ì›Œí¬ ì§€ì—°, GC pause ë“±ìœ¼ë¡œ ë¶ˆí•„ìš”í•œ ì¬ì‹œì‘
- ì¬ì‹œì‘ ë£¨í”„ ë°œìƒ ê°€ëŠ¥

**ì˜¬ë°”ë¥¸ ì„¤ì •:**

```yaml
livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
  periodSeconds: 10
  failureThreshold: 3  # 30ì´ˆ(3 x 10s) í›„ ì¬ì‹œì‘
  timeoutSeconds: 5
```

#### âŒ ì•ˆí‹°íŒ¨í„´ 5: ê³¼ë„í•˜ê²Œ ê¸´ timeoutSeconds

**ë¬¸ì œ:**

```yaml
livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
  timeoutSeconds: 30  # 30ì´ˆ ëŒ€ê¸°
  periodSeconds: 10
```

**ê²°ê³¼:**
- Probeê°€ 30ì´ˆ ë™ì•ˆ blockingë˜ì–´ ë‹¤ìŒ Probe ì‹¤í–‰ ì§€ì—°
- ì¥ì•  ê°ì§€ê°€ ëŠë ¤ì§

**ì˜¬ë°”ë¥¸ ì„¤ì •:**

```yaml
livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
  timeoutSeconds: 5  # 5ì´ˆ ì´ë‚´ ì‘ë‹µ í•„ìš”
  periodSeconds: 10
  failureThreshold: 3
```

### 2.6 ALB/NLB í—¬ìŠ¤ì²´í¬ì™€ Probe í†µí•©

AWS Load Balancer Controllerë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°, ALB/NLBì˜ í—¬ìŠ¤ì²´í¬ì™€ Kubernetes Readiness Probeë¥¼ ë™ê¸°í™”í•´ì•¼ ë¬´ì¤‘ë‹¨ ë°°í¬ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.

#### ALB Target Group í—¬ìŠ¤ì²´í¬ vs Readiness Probe

| êµ¬ë¶„ | ALB/NLB í—¬ìŠ¤ì²´í¬ | Kubernetes Readiness Probe |
|------|-----------------|---------------------------|
| **ì‹¤í–‰ ì£¼ì²´** | AWS Load Balancer | kubelet |
| **ì²´í¬ ëŒ€ìƒ** | Target Groupì˜ IP:Port | Pod ì»¨í…Œì´ë„ˆ |
| **ì‹¤íŒ¨ ì‹œ ë™ì‘** | Targetì—ì„œ ì œê±° (íŠ¸ë˜í”½ ì°¨ë‹¨) | Service Endpointsì—ì„œ ì œê±° |
| **ê¸°ë³¸ ê°„ê²©** | 30ì´ˆ | 10ì´ˆ |
| **íƒ€ì„ì•„ì›ƒ** | 5ì´ˆ | 1ì´ˆ |

#### í—¬ìŠ¤ì²´í¬ íƒ€ì´ë° ë™ê¸°í™” ì „ëµ

ë¡¤ë§ ì—…ë°ì´íŠ¸ ì‹œ ë‹¤ìŒ ìˆœì„œë¡œ ë™ì‘í•©ë‹ˆë‹¤:

```mermaid
sequenceDiagram
    participant K8s as Kubernetes
    participant Pod as New Pod
    participant LB as ALB/NLB
    participant Old as Old Pod

    K8s->>Pod: Pod ìƒì„±
    Pod->>Pod: startupProbe ì„±ê³µ
    Pod->>Pod: readinessProbe ì„±ê³µ
    K8s->>K8s: Service Endpoints ì¶”ê°€
    LB->>Pod: í—¬ìŠ¤ì²´í¬ ì‹œì‘
    Note over LB,Pod: healthy threshold ë„ë‹¬ ëŒ€ê¸°<br/>(ì˜ˆ: 2íšŒ ì—°ì† ì„±ê³µ)
    LB->>LB: Target Groupì— ì¶”ê°€
    LB->>Pod: íŠ¸ë˜í”½ ì „ì†¡ ì‹œì‘

    K8s->>Old: Pod ì¢…ë£Œ ìš”ì²­
    Old->>Old: preStop Hook
    K8s->>K8s: Service Endpoints ì œê±°
    Old->>Old: SIGTERM ìˆ˜ì‹ 
    LB->>Old: í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨ ê°ì§€
    LB->>LB: Target Groupì—ì„œ ì œê±°
    Old->>Old: Graceful Shutdown
    Old->>K8s: ì¢…ë£Œ ì™„ë£Œ
```

**ê¶Œì¥ ì„¤ì •:**

```yaml
apiVersion: v1
kind: Service
metadata:
  name: myapp
  annotations:
    # ALB í—¬ìŠ¤ì²´í¬ ì„¤ì •
    alb.ingress.kubernetes.io/healthcheck-path: /ready
    alb.ingress.kubernetes.io/healthcheck-interval-seconds: "10"
    alb.ingress.kubernetes.io/healthcheck-timeout-seconds: "5"
    alb.ingress.kubernetes.io/healthy-threshold-count: "2"
    alb.ingress.kubernetes.io/unhealthy-threshold-count: "2"
spec:
  type: NodePort
  ports:
  - port: 80
    targetPort: 8080
  selector:
    app: myapp
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: app
        image: myapp:v1
        ports:
        - containerPort: 8080
        readinessProbe:
          httpGet:
            path: /ready  # ALBì™€ ë™ì¼í•œ ê²½ë¡œ
            port: 8080
          periodSeconds: 5  # ALBë³´ë‹¤ ì§§ì€ ê°„ê²©
          failureThreshold: 2
          successThreshold: 1
      terminationGracePeriodSeconds: 60
```

#### Pod Readiness Gates (ë¬´ì¤‘ë‹¨ ë°°í¬ ë³´ì¥)

AWS Load Balancer Controller v2.5+ëŠ” Pod Readiness Gatesë¥¼ ì§€ì›í•˜ì—¬, Podì´ ALB/NLB íƒ€ê²Ÿìœ¼ë¡œ ë“±ë¡ë˜ê³  í—¬ìŠ¤ì²´í¬ë¥¼ í†µê³¼í•  ë•Œê¹Œì§€ `Ready` ìƒíƒœ ì „í™˜ì„ ì§€ì—°ì‹œí‚µë‹ˆë‹¤.

**í™œì„±í™” ë°©ë²•:**

```yaml
# Namespaceì— ë ˆì´ë¸” ì¶”ê°€ë¡œ ìë™ ì£¼ì… í™œì„±í™”
apiVersion: v1
kind: Namespace
metadata:
  name: production
  labels:
    elbv2.k8s.aws/pod-readiness-gate-inject: enabled
```

**ë™ì‘ í™•ì¸:**

```bash
# Podì˜ Readiness Gates í™•ì¸
kubectl get pod myapp-xyz -o yaml | grep -A 10 readinessGates

# ì¶œë ¥ ì˜ˆì‹œ:
# readinessGates:
# - conditionType: target-health.alb.ingress.k8s.aws/my-target-group-hash

# Pod Conditions í™•ì¸
kubectl get pod myapp-xyz -o jsonpath='{.status.conditions}' | jq
```

**ì¥ì :**
- ë¡¤ë§ ì—…ë°ì´íŠ¸ ì‹œ Old Podì´ íƒ€ê²Ÿì—ì„œ ì œê±°ë˜ê¸° ì „ê¹Œì§€ ìœ ì§€ë¨
- New Podì´ ALB í—¬ìŠ¤ì²´í¬ í†µê³¼ í›„ì—ë§Œ íŠ¸ë˜í”½ ìˆ˜ì‹ 
- íŠ¸ë˜í”½ ìœ ì‹¤ ì—†ëŠ” ì™„ì „í•œ ë¬´ì¤‘ë‹¨ ë°°í¬

:::info ìƒì„¸ ì •ë³´
Pod Readiness Gatesì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ [EKS ê³ ê°€ìš©ì„± ì•„í‚¤í…ì²˜ ê°€ì´ë“œ](/docs/operations-observability/eks-resiliency-guide)ì˜ "Pod Readiness Gates" ì„¹ì…˜ì„ ì°¸ì¡°í•˜ì„¸ìš”.
:::

#### 2.6.4 Gateway API í—¬ìŠ¤ì²´í¬ í†µí•© (ALB Controller v2.14+)

AWS Load Balancer Controller v2.14+ëŠ” Kubernetes Gateway API v1.4ì™€ ë„¤ì´í‹°ë¸Œ í†µí•©í•˜ì—¬, Ingressë³´ë‹¤ í–¥ìƒëœ ê²½ë¡œë³„ í—¬ìŠ¤ì²´í¬ ë§¤í•‘ì„ ì œê³µí•©ë‹ˆë‹¤.

##### Gateway API vs Ingress í—¬ìŠ¤ì²´í¬ ë¹„êµ

| êµ¬ë¶„ | Ingress | Gateway API |
|------|---------|-------------|
| **í—¬ìŠ¤ì²´í¬ ì„¤ì • ìœ„ì¹˜** | Service/Ingress annotation | HealthCheckPolicy CRD |
| **ê²½ë¡œë³„ í—¬ìŠ¤ì²´í¬** | ì œí•œì  (annotation ê¸°ë°˜) | ë„¤ì´í‹°ë¸Œ ì§€ì› (HTTPRoute/GRPCRouteë³„) |
| **L4/L7 í”„ë¡œí† ì½œ ì§€ì›** | HTTP/HTTPSë§Œ | TCP/UDP/TLS/HTTP/GRPC ëª¨ë‘ ì§€ì› |
| **ë©€í‹° í…Œë„ŒíŠ¸ ì—­í•  ë¶„ë¦¬** | ë‹¨ì¼ Ingress ì˜¤ë¸Œì íŠ¸ | Gateway(ì¸í”„ë¼)/Route(ì•±) ë¶„ë¦¬ |
| **ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì¹´ë‚˜ë¦¬** | ì–´ë µê±°ë‚˜ ë¶ˆê°€ëŠ¥ | HTTPRoute ë„¤ì´í‹°ë¸Œ ì§€ì› |

##### Gateway API ì•„í‚¤í…ì²˜ì™€ í—¬ìŠ¤ì²´í¬

```mermaid
flowchart TB
    subgraph "Gateway API ì•„í‚¤í…ì²˜"
        Client[Client] --> Gateway[Gateway<br/>ALB/NLB]
        Gateway --> HTTPRoute1[HTTPRoute<br/>/api/v1]
        Gateway --> HTTPRoute2[HTTPRoute<br/>/api/v2]
        Gateway --> GRPCRoute[GRPCRoute<br/>/grpc]

        HTTPRoute1 --> Service1[Service: api-v1]
        HTTPRoute2 --> Service2[Service: api-v2]
        GRPCRoute --> Service3[Service: grpc-svc]

        Service1 --> Pod1[Pods]
        Service2 --> Pod2[Pods]
        Service3 --> Pod3[Pods]

        Policy[HealthCheckPolicy] -.->|ì ìš©| HTTPRoute1
        Policy -.->|ì ìš©| HTTPRoute2
    end

    style Gateway fill:#ff9900,stroke:#cc7a00,color:#fff
    style Policy fill:#34a853,stroke:#2a8642,color:#fff
```

##### L7 í—¬ìŠ¤ì²´í¬: HTTPRoute/GRPCRoute with ALB

**HealthCheckPolicy CRD ì˜ˆì‹œ:**

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: prod-gateway
  namespace: production
spec:
  gatewayClassName: alb
  listeners:
  - name: http
    protocol: HTTP
    port: 80
---
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: api-v1-route
  namespace: production
spec:
  parentRefs:
  - name: prod-gateway
  hostnames:
  - api.example.com
  rules:
  - matches:
    - path:
        type: PathPrefix
        value: /api/v1
    backendRefs:
    - name: api-v1-service
      port: 8080
---
# HealthCheckPolicy (AWS Load Balancer Controller v2.14+)
apiVersion: elbv2.k8s.aws/v1beta1
kind: HealthCheckPolicy
metadata:
  name: api-v1-healthcheck
  namespace: production
spec:
  targetGroupARN: arn:aws:elasticloadbalancing:region:account:targetgroup/name/id
  healthCheckConfig:
    protocol: HTTP
    path: /api/v1/healthz  # ê²½ë¡œë³„ í—¬ìŠ¤ì²´í¬
    port: 8080
    intervalSeconds: 10
    timeoutSeconds: 5
    healthyThresholdCount: 2
    unhealthyThresholdCount: 2
    matcher:
      httpCode: "200-299"
```

**GRPCRoute í—¬ìŠ¤ì²´í¬ ì˜ˆì‹œ:**

```yaml
apiVersion: gateway.networking.k8s.io/v1alpha2
kind: GRPCRoute
metadata:
  name: grpc-service-route
  namespace: production
spec:
  parentRefs:
  - name: prod-gateway
  hostnames:
  - grpc.example.com
  rules:
  - matches:
    - method:
        service: myservice.v1.MyService
    backendRefs:
    - name: grpc-backend
      port: 9090
---
apiVersion: elbv2.k8s.aws/v1beta1
kind: HealthCheckPolicy
metadata:
  name: grpc-healthcheck
  namespace: production
spec:
  targetGroupARN: arn:aws:elasticloadbalancing:region:account:targetgroup/grpc/id
  healthCheckConfig:
    protocol: HTTP  # gRPC í—¬ìŠ¤ì²´í¬ëŠ” HTTP/2 ê¸°ë°˜
    path: /grpc.health.v1.Health/Check
    port: 9090
    intervalSeconds: 10
    timeoutSeconds: 5
    healthyThresholdCount: 2
    unhealthyThresholdCount: 2
    matcher:
      grpcCode: "0"  # gRPC OK status
```

##### L4 í—¬ìŠ¤ì²´í¬: TCPRoute/UDPRoute with NLB

```yaml
apiVersion: gateway.networking.k8s.io/v1alpha2
kind: TCPRoute
metadata:
  name: tcp-service-route
  namespace: production
spec:
  parentRefs:
  - name: nlb-gateway
    sectionName: tcp-listener
  rules:
  - backendRefs:
    - name: tcp-backend
      port: 5432
---
apiVersion: elbv2.k8s.aws/v1beta1
kind: HealthCheckPolicy
metadata:
  name: tcp-healthcheck
  namespace: production
spec:
  targetGroupARN: arn:aws:elasticloadbalancing:region:account:targetgroup/tcp/id
  healthCheckConfig:
    protocol: TCP  # TCP ì—°ê²°ë§Œ í™•ì¸
    port: 5432
    intervalSeconds: 30
    timeoutSeconds: 10
    healthyThresholdCount: 3
    unhealthyThresholdCount: 3
```

##### Gateway API Pod Readiness Gates

Gateway APIëŠ” Ingressì™€ ë™ì¼í•˜ê²Œ Pod Readiness Gatesë¥¼ ì§€ì›í•©ë‹ˆë‹¤:

```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: production
  labels:
    elbv2.k8s.aws/pod-readiness-gate-inject: enabled
```

**ë™ì‘ í™•ì¸:**

```bash
# Gateway ìƒíƒœ í™•ì¸
kubectl get gateway prod-gateway -n production

# HTTPRoute ìƒíƒœ í™•ì¸
kubectl get httproute api-v1-route -n production -o yaml

# Podì˜ Readiness Gates í™•ì¸
kubectl get pod -n production -l app=api-v1 \
  -o jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.status.conditions[?(@.type=="target-health.gateway.networking.k8s.io")].status}{"\n"}{end}'
```

##### Ingressì—ì„œ Gateway APIë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œ í—¬ìŠ¤ì²´í¬ ì „í™˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

| ë‹¨ê³„ | Ingress | Gateway API | í™•ì¸ í•­ëª© |
|------|---------|-------------|----------|
| 1. í—¬ìŠ¤ì²´í¬ ê²½ë¡œ ë§¤í•‘ | Annotation ê¸°ë°˜ | HealthCheckPolicy CRD | ê²½ë¡œë³„ ì •ì±… ë¶„ë¦¬ |
| 2. í”„ë¡œí† ì½œ ì„¤ì • | HTTP/HTTPSë§Œ | HTTP/HTTPS/GRPC/TCP/UDP | í”„ë¡œí† ì½œ íƒ€ì… í™•ì¸ |
| 3. Pod Readiness Gates | Namespace ë ˆì´ë¸” | Namespace ë ˆì´ë¸” (ë™ì¼) | ë¬´ì¤‘ë‹¨ ë°°í¬ ë³´ì¥ |
| 4. í—¬ìŠ¤ì²´í¬ íƒ€ì´ë° | Service annotation | HealthCheckPolicy | interval/timeout ê²€ì¦ |
| 5. ë©€í‹° ê²½ë¡œ í—¬ìŠ¤ì²´í¬ | ë‹¨ì¼ ê²½ë¡œë§Œ | ê²½ë¡œë³„ ë…ë¦½ ì„¤ì • | ê° ê²½ë¡œ ê²€ì¦ |

**ë§ˆì´ê·¸ë ˆì´ì…˜ ì˜ˆì‹œ (Ingress â†’ Gateway API):**

```yaml
# Before (Ingress)
apiVersion: v1
kind: Service
metadata:
  name: myapp
  annotations:
    alb.ingress.kubernetes.io/healthcheck-path: /healthz
    alb.ingress.kubernetes.io/healthcheck-interval-seconds: "10"
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: myapp-ingress
spec:
  rules:
  - host: api.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: myapp
            port:
              number: 8080
```

```yaml
# After (Gateway API)
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: myapp-route
spec:
  parentRefs:
  - name: prod-gateway
  hostnames:
  - api.example.com
  rules:
  - matches:
    - path:
        type: PathPrefix
        value: /
    backendRefs:
    - name: myapp
      port: 8080
---
apiVersion: elbv2.k8s.aws/v1beta1
kind: HealthCheckPolicy
metadata:
  name: myapp-healthcheck
spec:
  targetGroupARN: <auto-discovered-or-explicit>
  healthCheckConfig:
    protocol: HTTP
    path: /healthz
    port: 8080
    intervalSeconds: 10
    timeoutSeconds: 5
    healthyThresholdCount: 2
    unhealthyThresholdCount: 2
```

:::tip Gateway API ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ëµ
- **ë‹¨ê³„ì  ë§ˆì´ê·¸ë ˆì´ì…˜**: ë™ì¼í•œ ALBì—ì„œ Ingressì™€ Gateway APIë¥¼ ë™ì‹œì— ì‚¬ìš© ê°€ëŠ¥ (ë¦¬ìŠ¤ë„ˆ ë¶„ë¦¬)
- **ì¹´ë‚˜ë¦¬ ë°°í¬**: HTTPRouteì˜ ê°€ì¤‘ì¹˜ ê¸°ë°˜ íŠ¸ë˜í”½ ë¶„í• ë¡œ ì•ˆì „í•œ ì „í™˜
- **ë¡¤ë°± ê³„íš**: Ingress ì˜¤ë¸Œì íŠ¸ëŠ” ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ í›„ ì¼ì • ê¸°ê°„ ìœ ì§€
:::

:::info ì°¸ê³  ìë£Œ
- [Kubernetes Gateway API v1.4 Release](https://kubernetes.io/blog/2025/11/06/gateway-api-v1-4/)
- [AWS Load Balancer Controller Gateway API ê°€ì´ë“œ](https://kubernetes-sigs.github.io/aws-load-balancer-controller/latest/guide/gateway/gateway/)
- [Gateway API ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤ì „ ê°€ì´ë“œ](https://medium.com/@gudiwada.chaithu/zero-downtime-migration-from-kubernetes-ingress-to-gateway-api-on-aws-eks-642f3432d394)
:::

### 2.7 2025-2026 EKS ì‹ ê·œ ê¸°ëŠ¥ê³¼ Probe í†µí•©

AWS re:Invent 2025ì—ì„œ ë°œí‘œëœ EKSì˜ ìƒˆë¡œìš´ ê´€ì°°ì„± ë° ì œì–´ ê¸°ëŠ¥ì€ Probe ê¸°ë°˜ í—¬ìŠ¤ì²´í¬ë¥¼ ë”ìš± ê°•í™”í•©ë‹ˆë‹¤. ì´ ì„¹ì…˜ì—ì„œëŠ” ìµœì‹  EKS ê¸°ëŠ¥ê³¼ Probeë¥¼ í†µí•©í•˜ì—¬ ë” ì •í™•í•˜ê³  ì„ ì œì ì¸ í—¬ìŠ¤ ëª¨ë‹ˆí„°ë§ì„ êµ¬í˜„í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤.

#### 2.7.1 Container Network Observabilityë¡œ Probe ì—°ê²°ì„± ê²€ì¦

**ê°œìš”:**

Container Network Observability(2025ë…„ 11ì›” ë°œí‘œ)ëŠ” Pod ê°„ ë„¤íŠ¸ì›Œí¬ í†µì‹  íŒ¨í„´, ì§€ì—° ì‹œê°„, íŒ¨í‚· ì†ì‹¤ ë“± ì„¸ë°€í•œ ë„¤íŠ¸ì›Œí¬ ë©”íŠ¸ë¦­ì„ ì œê³µí•©ë‹ˆë‹¤. Probe ì‹¤íŒ¨ê°€ ë„¤íŠ¸ì›Œí¬ ë¬¸ì œë¡œ ì¸í•œ ê²ƒì¸ì§€, ì• í”Œë¦¬ì¼€ì´ì…˜ ìì²´ ë¬¸ì œì¸ì§€ ëª…í™•íˆ êµ¬ë¶„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ì£¼ìš” ê¸°ëŠ¥:**
- Pod-to-Pod í†µì‹  ê²½ë¡œ ì‹œê°í™”
- ë„¤íŠ¸ì›Œí¬ ì§€ì—°(latency), íŒ¨í‚· ì†ì‹¤(packet loss), ì¬ì „ì†¡ë¥  ëª¨ë‹ˆí„°ë§
- ì‹¤ì‹œê°„ ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ ì´ìƒ íƒì§€
- CloudWatch Container Insightsì™€ì˜ í†µí•©

**í™œì„±í™” ë°©ë²•:**

```bash
# VPC CNIì—ì„œ ë„¤íŠ¸ì›Œí¬ ê´€ì°°ì„± í™œì„±í™”
kubectl set env daemonset aws-node \
  -n kube-system \
  ENABLE_NETWORK_OBSERVABILITY=true

# ë˜ëŠ” ConfigMapìœ¼ë¡œ ì„¤ì •
kubectl apply -f - <<EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: amazon-vpc-cni
  namespace: kube-system
data:
  enable-network-observability: "true"
EOF
```

**Probe ì—°ê²°ì„± ê²€ì¦ ì˜ˆì‹œ:**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-gateway
  annotations:
    # ë„¤íŠ¸ì›Œí¬ ê´€ì°°ì„± ë©”íŠ¸ë¦­ ìˆ˜ì§‘ í™œì„±í™”
    network-observability.amazonaws.com/enabled: "true"
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: gateway
        image: myapp/gateway:v2
        ports:
        - containerPort: 8080
        # Readiness Probe: ì™¸ë¶€ DB ì—°ê²° í™•ì¸
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          periodSeconds: 5
          failureThreshold: 2
          timeoutSeconds: 3
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8080
          periodSeconds: 10
          failureThreshold: 3
```

**CloudWatch Insights ì¿¼ë¦¬ - Probe ì‹¤íŒ¨ì™€ ë„¤íŠ¸ì›Œí¬ ì§€ì—° ìƒê´€ ë¶„ì„:**

```sql
-- Probe ì‹¤íŒ¨ ì‹œì ì˜ ë„¤íŠ¸ì›Œí¬ ì§€ì—° í™•ì¸
fields @timestamp, pod_name, probe_type, network_latency_ms, packet_loss_percent
| filter namespace = "production"
| filter probe_result = "failed"
| filter network_latency_ms > 100 or packet_loss_percent > 1
| sort @timestamp desc
| limit 100
```

**ì•Œë¦¼ ì„¤ì • ì˜ˆì‹œ:**

```yaml
# CloudWatch Alarm: Probe ì‹¤íŒ¨ì™€ ë„¤íŠ¸ì›Œí¬ ì´ìƒ ë™ì‹œ ë°œìƒ
apiVersion: v1
kind: ConfigMap
metadata:
  name: probe-network-alert
  namespace: monitoring
data:
  alarm-config: |
    {
      "AlarmName": "ProbeFailureWithNetworkIssue",
      "MetricName": "ReadinessProbeFailure",
      "Namespace": "ContainerInsights",
      "Statistic": "Sum",
      "Period": 60,
      "EvaluationPeriods": 2,
      "Threshold": 3,
      "ComparisonOperator": "GreaterThanThreshold",
      "Dimensions": [
        {"Name": "ClusterName", "Value": "production-eks"},
        {"Name": "Namespace", "Value": "production"}
      ],
      "AlarmDescription": "Readiness Probe ì‹¤íŒ¨ ì‹œ ë„¤íŠ¸ì›Œí¬ ì§€ì—° í™•ì¸ í•„ìš”"
    }
```

**ì§„ë‹¨ ì›Œí¬í”Œë¡œìš°:**

```mermaid
flowchart TD
    PROBE_FAIL[Readiness Probe ì‹¤íŒ¨ ê°ì§€]
    PROBE_FAIL --> CHECK_NET[ë„¤íŠ¸ì›Œí¬ ê´€ì°°ì„± ë©”íŠ¸ë¦­ í™•ì¸]
    CHECK_NET --> NET_OK{ë„¤íŠ¸ì›Œí¬<br/>ì •ìƒ?}

    NET_OK -->|ì§€ì—°/ì†ì‹¤ ë†’ìŒ| NET_ISSUE[ë„¤íŠ¸ì›Œí¬ ë¬¸ì œ]
    NET_ISSUE --> CHECK_CNI[CNI í”ŒëŸ¬ê·¸ì¸ ìƒíƒœ í™•ì¸]
    NET_ISSUE --> CHECK_SG[ë³´ì•ˆ ê·¸ë£¹ ê·œì¹™ ê²€ì¦]
    NET_ISSUE --> CHECK_AZ[AZ ê°„ íŠ¸ë˜í”½ íŒ¨í„´ ë¶„ì„]

    NET_OK -->|ì •ìƒ| APP_ISSUE[ì• í”Œë¦¬ì¼€ì´ì…˜ ë¬¸ì œ]
    APP_ISSUE --> CHECK_LOGS[Pod ë¡œê·¸ ë¶„ì„]
    APP_ISSUE --> CHECK_METRICS[CPU/ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  í™•ì¸]
    APP_ISSUE --> CHECK_DEPS[ì™¸ë¶€ ì˜ì¡´ì„± ìƒíƒœ ê²€ì¦]

    style PROBE_FAIL fill:#ff4444,stroke:#cc3636,color:#fff
    style NET_ISSUE fill:#fbbc04,stroke:#c99603,color:#000
    style APP_ISSUE fill:#fbbc04,stroke:#c99603,color:#000
```

:::tip Pod-to-Pod ê²½ë¡œ ì‹œê°í™”
Container Network ObservabilityëŠ” CloudWatch Logs Insightsì™€ í†µí•©ë˜ì–´ Probe ìš”ì²­ì˜ ì „ì²´ ë„¤íŠ¸ì›Œí¬ ê²½ë¡œë¥¼ ì¶”ì í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Readiness Probeê°€ ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ í™•ì¸í•˜ëŠ” ê²½ìš°, Pod â†’ Service â†’ Endpoint â†’ DB Podì˜ ì „ì²´ ê²½ë¡œì—ì„œ ë³‘ëª© êµ¬ê°„ì„ ì‹ë³„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
:::

---

#### 2.7.2 CloudWatch Observability Operator + Control Plane ë©”íŠ¸ë¦­

**ê°œìš”:**

CloudWatch Observability Operator(2025ë…„ 12ì›” ë°œí‘œ)ëŠ” EKS Control Plane ë©”íŠ¸ë¦­ì„ ìë™ìœ¼ë¡œ ìˆ˜ì§‘í•˜ì—¬, API Server ì„±ëŠ¥ ì €í•˜ê°€ Probe ì‘ë‹µì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì‚¬ì „ì— ê°ì§€í•©ë‹ˆë‹¤.

**ì„¤ì¹˜:**

```bash
# CloudWatch Observability Operator ì„¤ì¹˜
kubectl apply -f https://raw.githubusercontent.com/aws-observability/aws-cloudwatch-observability-operator/main/bundle.yaml

# EKS Control Plane ë©”íŠ¸ë¦­ ìˆ˜ì§‘ í™œì„±í™”
kubectl apply -f - <<EOF
apiVersion: cloudwatch.aws.amazon.com/v1alpha1
kind: EKSControlPlaneMetrics
metadata:
  name: production-control-plane
  namespace: amazon-cloudwatch
spec:
  clusterName: production-eks
  region: ap-northeast-2
  metricsCollectionInterval: 60s
  enabledMetrics:
    - apiserver_request_duration_seconds
    - apiserver_request_total
    - apiserver_storage_objects
    - etcd_request_duration_seconds
    - rest_client_requests_total
EOF
```

**ì£¼ìš” Control Plane ë©”íŠ¸ë¦­:**

| ë©”íŠ¸ë¦­ | ì„¤ëª… | Probe ì—°ê´€ì„± | ì„ê³„ê°’ ì˜ˆì‹œ |
|--------|------|-------------|------------|
| `apiserver_request_duration_seconds` | API Server ìš”ì²­ ì§€ì—° ì‹œê°„ | Probe ìš”ì²­ ì²˜ë¦¬ ì†ë„ | p99 < 1ì´ˆ |
| `apiserver_request_total` (code=5xx) | API Server 5xx ì—ëŸ¬ ìˆ˜ | Probe ì‹¤íŒ¨ìœ¨ ìƒìŠ¹ | < 1% |
| `apiserver_storage_objects` | etcd ì €ì¥ ì˜¤ë¸Œì íŠ¸ ìˆ˜ | í´ëŸ¬ìŠ¤í„° ê·œëª¨ í•œê³„ | < 150,000 |
| `etcd_request_duration_seconds` | etcd ì½ê¸°/ì“°ê¸° ì§€ì—° | Pod ìƒíƒœ ì—…ë°ì´íŠ¸ ì§€ì—° | p99 < 100ms |
| `rest_client_requests_total` (code=429) | API Rate Limiting ë°œìƒ | kubelet-apiserver í†µì‹  ì œí•œ | < 10/min |

**Probe íƒ€ì„ì•„ì›ƒ ì˜ˆì¸¡ ì•Œë¦¼:**

```yaml
apiVersion: cloudwatch.amazonaws.com/v1alpha1
kind: Alarm
metadata:
  name: apiserver-slow-probe-risk
spec:
  alarmName: "EKS-APIServer-SlowProbeRisk"
  metrics:
    - id: m1
      metricStat:
        metric:
          namespace: AWS/EKS
          metricName: apiserver_request_duration_seconds
          dimensions:
            - name: ClusterName
              value: production-eks
            - name: verb
              value: GET
        period: 60
        stat: p99
    - id: e1
      expression: "IF(m1 > 0.5, 1, 0)"
      label: "API Server ì‘ë‹µ ì§€ì—° > 500ms"
  evaluationPeriods: 2
  threshold: 1
  comparisonOperator: GreaterThanOrEqualToThreshold
  alarmDescription: "API Server ì„±ëŠ¥ ì €í•˜ë¡œ ì¸í•œ Probe íƒ€ì„ì•„ì›ƒ ìœ„í—˜"
  alarmActions:
    - arn:aws:sns:ap-northeast-2:123456789012:eks-ops-alerts
```

**ëŒ€ê·œëª¨ í´ëŸ¬ìŠ¤í„°ì—ì„œì˜ Probe ì„±ëŠ¥ ë³´ì¥:**

```yaml
# 1000+ ë…¸ë“œ í´ëŸ¬ìŠ¤í„°ì˜ Probe ì„¤ì • ìµœì í™”
apiVersion: apps/v1
kind: Deployment
metadata:
  name: large-scale-api
spec:
  replicas: 100
  template:
    spec:
      containers:
      - name: api
        image: myapp/api:v1
        # Probe íƒ€ì´ë° ì¡°ì •: API Server ë¶€í•˜ ê³ ë ¤
        startupProbe:
          httpGet:
            path: /healthz
            port: 8080
          failureThreshold: 30
          periodSeconds: 5  # ì´ˆê¸° ì‹œì‘ ì‹œê°„ ì—¬ìœ 
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8080
          periodSeconds: 15  # ëŒ€ê·œëª¨ì—ì„œëŠ” ê°„ê²© ì¦ê°€
          failureThreshold: 3
          timeoutSeconds: 5
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          periodSeconds: 10
          failureThreshold: 2
          timeoutSeconds: 3
```

**CloudWatch Dashboard - Control Plane & Probe ìƒê´€ ë¶„ì„:**

```json
{
  "widgets": [
    {
      "type": "metric",
      "properties": {
        "title": "API Server ì§€ì—° vs Probe ì‹¤íŒ¨ìœ¨",
        "metrics": [
          ["AWS/EKS", "apiserver_request_duration_seconds", {"stat": "p99", "label": "API Server p99 ì§€ì—°"}],
          ["ContainerInsights", "ReadinessProbeFailure", {"stat": "Sum", "yAxis": "right"}]
        ],
        "period": 60,
        "region": "ap-northeast-2",
        "yAxis": {
          "left": {"label": "ì§€ì—° ì‹œê°„ (ì´ˆ)", "min": 0},
          "right": {"label": "Probe ì‹¤íŒ¨ ìˆ˜", "min": 0}
        }
      }
    }
  ]
}
```

:::warning ëŒ€ê·œëª¨ í´ëŸ¬ìŠ¤í„°ì˜ API Server ë¶€í•˜
1000ê°œ ì´ìƒì˜ ë…¸ë“œë¥¼ ê°€ì§„ í´ëŸ¬ìŠ¤í„°ì—ì„œëŠ” ëª¨ë“  kubeletì˜ Probe ìš”ì²­ì´ API Serverì— ì§‘ì¤‘ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. `periodSeconds`ë¥¼ 10~15ì´ˆë¡œ ëŠ˜ë¦¬ê³ , `timeoutSeconds`ë¥¼ 5ì´ˆ ì´ìƒìœ¼ë¡œ ì„¤ì •í•˜ì—¬ API Server ë¶€í•˜ë¥¼ ë¶„ì‚°ì‹œí‚¤ì„¸ìš”. Provisioned Control Plane(Section 2.7.3)ì„ ì‚¬ìš©í•˜ë©´ ì´ ë¬¸ì œë¥¼ ê·¼ë³¸ì ìœ¼ë¡œ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
:::

---

#### 2.7.3 Provisioned Control Planeì—ì„œ Probe ì„±ëŠ¥ ë³´ì¥

**ê°œìš”:**

Provisioned Control Plane(2025ë…„ 11ì›” ë°œí‘œ)ì€ ì‚¬ì „ í• ë‹¹ëœ ì œì–´ í”Œë ˆì¸ ìš©ëŸ‰ìœ¼ë¡œ ì˜ˆì¸¡ ê°€ëŠ¥í•œ ê³ ì„±ëŠ¥ Kubernetes ìš´ì˜ì„ ë³´ì¥í•©ë‹ˆë‹¤. ëŒ€ê·œëª¨ í´ëŸ¬ìŠ¤í„°ì—ì„œ Probe ìš”ì²­ì´ API Server ì„±ëŠ¥ ì €í•˜ì˜ ì˜í–¥ì„ ë°›ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.

**í‹°ì–´ë³„ ì„±ëŠ¥ íŠ¹ì„±:**

| í‹°ì–´ | API ë™ì‹œì„± | Pod ìŠ¤ì¼€ì¤„ë§ ì†ë„ | ìµœëŒ€ ë…¸ë“œ ìˆ˜ | Probe ì²˜ë¦¬ ë³´ì¥ | ì í•© ì›Œí¬ë¡œë“œ |
|------|----------|---------------|------------|--------------|-------------|
| **XL** | ë†’ìŒ | ~500 Pods/min | 1,000 | 99.9% < 100ms | AI Training, HPC |
| **2XL** | ë§¤ìš° ë†’ìŒ | ~1,000 Pods/min | 2,500 | 99.9% < 80ms | ëŒ€ê·œëª¨ ë°°ì¹˜ |
| **4XL** | ì´ˆê³ ì† | ~2,000 Pods/min | 5,000 | 99.9% < 50ms | ì´ˆëŒ€ê·œëª¨ ML |

**Standard vs Provisioned Control Plane:**

```mermaid
graph LR
    subgraph "Standard Control Plane"
        STD_LOAD[íŠ¸ë˜í”½ ì¦ê°€]
        STD_LOAD --> STD_SCALE[ë™ì  ìŠ¤ì¼€ì¼ë§]
        STD_SCALE --> STD_DELAY[ì¼ì‹œì  ì§€ì—° ë°œìƒ]
        STD_DELAY -.-> STD_PROBE_FAIL[Probe íƒ€ì„ì•„ì›ƒ ê°€ëŠ¥]
    end

    subgraph "Provisioned Control Plane"
        PROV_LOAD[íŠ¸ë˜í”½ ì¦ê°€]
        PROV_LOAD --> PROV_READY[ì‚¬ì „ í• ë‹¹ëœ ìš©ëŸ‰]
        PROV_READY --> PROV_FAST[ì¦‰ì‹œ ì²˜ë¦¬]
        PROV_FAST --> PROV_PROBE_OK[Probe ì„±ëŠ¥ ë³´ì¥]
    end

    style STD_PROBE_FAIL fill:#ff4444,stroke:#cc3636,color:#fff
    style PROV_PROBE_OK fill:#34a853,stroke:#2a8642,color:#fff
```

**Provisioned Control Plane ìƒì„±:**

```bash
# Provisioned Control Plane í´ëŸ¬ìŠ¤í„° ìƒì„± (AWS CLI)
aws eks create-cluster \
  --name production-provisioned \
  --region ap-northeast-2 \
  --kubernetes-version 1.32 \
  --role-arn arn:aws:iam::123456789012:role/eks-cluster-role \
  --resources-vpc-config subnetIds=subnet-xxx,subnet-yyy,securityGroupIds=sg-zzz \
  --control-plane-type PROVISIONED \
  --control-plane-tier XL
```

**ëŒ€ê·œëª¨ Probe ìµœì í™” ì˜ˆì‹œ:**

```yaml
# AI/ML Training í´ëŸ¬ìŠ¤í„° (1000+ GPU ë…¸ë“œ)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: training-coordinator
  annotations:
    # Provisioned Control Planeì—ì„œ ìµœì í™”ëœ Probe ì„¤ì •
    eks.amazonaws.com/control-plane-tier: "XL"
spec:
  replicas: 50
  template:
    spec:
      containers:
      - name: coordinator
        image: ml-training/coordinator:v3
        resources:
          requests:
            cpu: 4
            memory: 16Gi
        # Provisioned Control Planeì—ì„œëŠ” ì§§ì€ ê°„ê²© ì„¤ì • ê°€ëŠ¥
        startupProbe:
          httpGet:
            path: /healthz
            port: 9090
          failureThreshold: 30
          periodSeconds: 3  # ë¹ ë¥¸ ê°ì§€
        livenessProbe:
          httpGet:
            path: /healthz
            port: 9090
          periodSeconds: 5  # Standardë³´ë‹¤ ì§§ê²Œ
          failureThreshold: 2
          timeoutSeconds: 2
        readinessProbe:
          httpGet:
            path: /ready
            port: 9090
          periodSeconds: 3
          failureThreshold: 1
          timeoutSeconds: 2
```

**ì‚¬ìš© ì‚¬ë¡€: AI/ML Training í´ëŸ¬ìŠ¤í„°**

- **ë¬¸ì œ**: 1,000ê°œì˜ GPU ë…¸ë“œì—ì„œ ë™ì‹œì— ìˆ˜ë°± ê°œì˜ Training Pod ì‹œì‘ ì‹œ, Standard Control Planeì—ì„œ API Server ì‘ë‹µ ì§€ì—° ë°œìƒ
- **í•´ê²°**: Provisioned Control Plane XL í‹°ì–´ ì‚¬ìš©
- **ê²°ê³¼**:
  - Pod ìŠ¤ì¼€ì¤„ë§ ì‹œê°„ 70% ë‹¨ì¶• (í‰ê·  45ì´ˆ â†’ 13ì´ˆ)
  - Readiness Probe íƒ€ì„ì•„ì›ƒ 99.8% ê°ì†Œ
  - Training Job ì‹œì‘ ì•ˆì •ì„± í–¥ìƒ

**Cost vs Performance ê³ ë ¤ì‚¬í•­:**

```yaml
# Provisioned Control Plane ë¹„ìš© ìµœì í™” ì „ëµ
# 1. í‰ìƒì‹œ: Standard Control Plane
# 2. Training ê¸°ê°„: Provisioned Control Plane XLë¡œ ì—…ê·¸ë ˆì´ë“œ
# (í˜„ì¬ëŠ” í´ëŸ¬ìŠ¤í„° ìƒì„± ì‹œ ì„ íƒ, í–¥í›„ ë™ì  ë³€ê²½ ì§€ì› ì˜ˆì •)
```

:::tip HPC ë° ëŒ€ê·œëª¨ ë°°ì¹˜ ì›Œí¬ë¡œë“œ
Provisioned Control Planeì€ ì§§ì€ ì‹œê°„ ë‚´ì— ìˆ˜ì²œ ê°œì˜ Podì„ ë™ì‹œì— ì‹œì‘í•˜ëŠ” ì›Œí¬ë¡œë“œì— ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. AI/ML Training, ê³¼í•™ ì‹œë®¬ë ˆì´ì…˜, ëŒ€ê·œëª¨ ë°ì´í„° ì²˜ë¦¬ ë“±ì—ì„œ Probe ì„±ëŠ¥ì„ ë³´ì¥í•˜ì—¬ Job ì‹œì‘ ì‹œê°„ì„ ë‹¨ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
:::

---

#### 2.7.4 GuardDuty Extended Threat Detection ì—°ê³„

**ê°œìš”:**

GuardDuty Extended Threat Detection(EKS ì§€ì›: 2025ë…„ 6ì›”)ì€ Probe ì—”ë“œí¬ì¸íŠ¸ì˜ ë¹„ì •ìƒ ì ‘ê·¼ íŒ¨í„´ì„ íƒì§€í•˜ì—¬, ì•…ì˜ì ì¸ ì›Œí¬ë¡œë“œê°€ í—¬ìŠ¤ì²´í¬ë¥¼ ìš°íšŒí•˜ê±°ë‚˜ ì¡°ì‘í•˜ëŠ” ê³µê²©ì„ ì‹ë³„í•©ë‹ˆë‹¤.

**ì£¼ìš” ê¸°ëŠ¥:**
- EKS ê°ì‚¬ ë¡œê·¸ + ëŸ°íƒ€ì„ í–‰ë™ + ë§¬ì›¨ì–´ ì‹¤í–‰ + AWS API í™œë™ ìƒê´€ ë¶„ì„
- AI/ML ê¸°ë°˜ ë‹¤ë‹¨ê³„ ê³µê²© ì‹œí€€ìŠ¤ íƒì§€
- Probe ì—”ë“œí¬ì¸íŠ¸ ë¹„ì •ìƒ ì ‘ê·¼ íŒ¨í„´ ì‹ë³„
- í¬ë¦½í† ë§ˆì´ë‹ ë“± ì•…ì˜ì  ì›Œí¬ë¡œë“œ ìë™ íƒì§€

**í™œì„±í™”:**

```bash
# GuardDuty Extended Threat Detection for EKS í™œì„±í™” (AWS CLI)
aws guardduty update-detector \
  --detector-id <detector-id> \
  --features '[
    {
      "Name": "EKS_AUDIT_LOGS",
      "Status": "ENABLED"
    },
    {
      "Name": "EKS_RUNTIME_MONITORING",
      "Status": "ENABLED",
      "AdditionalConfiguration": [
        {
          "Name": "EKS_ADDON_MANAGEMENT",
          "Status": "ENABLED"
        }
      ]
    }
  ]'
```

**Probe ì—”ë“œí¬ì¸íŠ¸ ë³´ì•ˆ íŒ¨í„´:**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: secure-api
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: api
        image: myapp/secure-api:v2
        ports:
        - containerPort: 8080
        # í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8080
            httpHeaders:
            - name: X-Health-Check-Token
              value: "SECRET_TOKEN_FROM_ENV"
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
            httpHeaders:
            - name: X-Health-Check-Token
              value: "SECRET_TOKEN_FROM_ENV"
          periodSeconds: 5
        env:
        - name: HEALTH_CHECK_TOKEN
          valueFrom:
            secretKeyRef:
              name: api-secrets
              key: health-token
```

**GuardDuty íƒì§€ ì‹œë‚˜ë¦¬ì˜¤:**

```mermaid
flowchart TD
    MALICIOUS[ì•…ì˜ì  Pod ë°°í¬]
    MALICIOUS --> PROBE_FAKE[í—¬ìŠ¤ì²´í¬ ìœ„ì¡° ì‹œë„]
    PROBE_FAKE --> GUARDDUTY[GuardDuty íƒì§€]

    GUARDDUTY --> AUDIT[EKS ê°ì‚¬ ë¡œê·¸ ë¶„ì„]
    GUARDDUTY --> RUNTIME[ëŸ°íƒ€ì„ í–‰ë™ ë¶„ì„]
    GUARDDUTY --> API[AWS API í™œë™ ë¶„ì„]

    AUDIT --> FINDING[ë³µí•© íƒì§€ ê²°ê³¼ ìƒì„±]
    RUNTIME --> FINDING
    API --> FINDING

    FINDING --> ALERT[CloudWatch ì•Œë¦¼]
    FINDING --> RESPONSE[ìë™ ëŒ€ì‘]

    RESPONSE --> ISOLATE[Pod ê²©ë¦¬]
    RESPONSE --> TERMINATE[Pod ì¢…ë£Œ]
    RESPONSE --> NOTIFY[ë³´ì•ˆíŒ€ ì•Œë¦¼]

    style MALICIOUS fill:#ff4444,stroke:#cc3636,color:#fff
    style GUARDDUTY fill:#fbbc04,stroke:#c99603,color:#000
    style FINDING fill:#4286f4,stroke:#2a6acf,color:#fff
    style RESPONSE fill:#34a853,stroke:#2a8642,color:#fff
```

**ì‹¤ì œ íƒì§€ ì‚¬ë¡€ - Cryptomining Campaign:**

2025ë…„ 11ì›” 2ì¼ë¶€í„° GuardDutyê°€ íƒì§€í•œ í¬ë¦½í† ë§ˆì´ë‹ ìº í˜ì¸ì—ì„œëŠ” ê³µê²©ìê°€ ë‹¤ìŒê³¼ ê°™ì´ í—¬ìŠ¤ì²´í¬ë¥¼ ìš°íšŒí–ˆìŠµë‹ˆë‹¤:

1. ì •ìƒ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ë¡œ ìœ„ì¥
2. startupProbe ì„±ê³µ í›„ ì•…ì„± ë°”ì´ë„ˆë¦¬ ë‹¤ìš´ë¡œë“œ
3. livenessProbeëŠ” ì •ìƒ ì‘ë‹µ, ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë§ˆì´ë‹ ì‹¤í–‰
4. GuardDutyê°€ ë¹„ì •ìƒì ì¸ ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ + CPU ì‚¬ìš© íŒ¨í„´ íƒì§€

**íƒì§€ í›„ ìë™ ëŒ€ì‘:**

```yaml
# EventBridge Rule: GuardDuty Finding â†’ Lambda â†’ Pod ê²©ë¦¬
apiVersion: v1
kind: ConfigMap
metadata:
  name: guardduty-response
  namespace: security
data:
  eventbridge-rule: |
    {
      "source": ["aws.guardduty"],
      "detail-type": ["GuardDuty Finding"],
      "detail": {
        "service": {
          "serviceName": ["EKS"]
        },
        "severity": [7, 8, 9]  # High, Critical
      }
    }
  lambda-action: |
    import boto3
    eks = boto3.client('eks')

    def isolate_pod(cluster_name, namespace, pod_name):
        # NetworkPolicyë¡œ Pod ê²©ë¦¬
        kubectl_command = f"""
        kubectl apply -f - <<EOF
        apiVersion: networking.k8s.io/v1
        kind: NetworkPolicy
        metadata:
          name: isolate-{pod_name}
          namespace: {namespace}
        spec:
          podSelector:
            matchLabels:
              pod: {pod_name}
          policyTypes:
          - Ingress
          - Egress
        EOF
        """
        # ì‹¤í–‰ ë¡œì§...
```

**ë³´ì•ˆ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ:**

```yaml
# CloudWatch Dashboard: GuardDuty + Probe ìƒíƒœ
apiVersion: cloudwatch.amazonaws.com/v1alpha1
kind: Dashboard
metadata:
  name: security-probe-monitoring
spec:
  widgets:
    - type: metric
      title: "GuardDuty íƒì§€ vs Probe ì‹¤íŒ¨"
      metrics:
        - namespace: AWS/GuardDuty
          metricName: FindingCount
          dimensions:
            - name: ClusterName
              value: production-eks
        - namespace: ContainerInsights
          metricName: ProbeFailure
          dimensions:
            - name: Namespace
              value: production
```

:::warning í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ ë³´ì•ˆ
Probe ì—”ë“œí¬ì¸íŠ¸(`/healthz`, `/ready`)ëŠ” ì¸ì¦ ì—†ì´ ê³µê°œë˜ëŠ” ê²½ìš°ê°€ ë§ì•„ ê³µê²© í‘œë©´ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. GuardDuty Extended Threat Detectionì„ í™œì„±í™”í•˜ê³ , ê°€ëŠ¥í•˜ë©´ í—¬ìŠ¤ì²´í¬ ìš”ì²­ì— ê°„ë‹¨í•œ í† í° í—¤ë”ë¥¼ ì¶”ê°€í•˜ì—¬ ë¬´ë‹¨ ì ‘ê·¼ì„ ì œí•œí•˜ì„¸ìš”.
:::

**ê´€ë ¨ ë¬¸ì„œ:**
- [AWS Blog: GuardDuty Extended Threat Detection for EKS](https://aws.amazon.com/blogs/aws/amazon-guardduty-expands-extended-threat-detection-coverage-to-amazon-eks-clusters/)
- [AWS Blog: Cryptomining Campaign Detection](https://aws.amazon.com/blogs/security/cryptomining-campaign-targeting-amazon-ec2-and-amazon-ecs/)
- [EKS ë³´ì•ˆ Best Practices](https://docs.aws.amazon.com/eks/latest/best-practices/security.html)

---

## 3. Graceful Shutdown ì™„ë²½ ê°€ì´ë“œ

Graceful Shutdownì€ Pod ì¢…ë£Œ ì‹œ ì§„í–‰ ì¤‘ì¸ ìš”ì²­ì„ ì•ˆì „í•˜ê²Œ ì™„ë£Œí•˜ê³ , ìƒˆë¡œìš´ ìš”ì²­ ìˆ˜ì‹ ì„ ì¤‘ë‹¨í•˜ëŠ” íŒ¨í„´ì…ë‹ˆë‹¤. ë¬´ì¤‘ë‹¨ ë°°í¬ì™€ ë°ì´í„° ë¬´ê²°ì„±ì˜ í•µì‹¬ì…ë‹ˆë‹¤.

### 3.1 Pod ì¢…ë£Œ ì‹œí€€ìŠ¤ ìƒì„¸

Kubernetesì—ì„œ Pod ì¢…ë£ŒëŠ” ë‹¤ìŒ ìˆœì„œë¡œ ì§„í–‰ë©ë‹ˆë‹¤.

```mermaid
sequenceDiagram
    participant User as ì‚¬ìš©ì/ì‹œìŠ¤í…œ
    participant API as API Server
    participant EP as Endpoint Controller
    participant Kubelet as kubelet
    participant Container as Container
    participant App as Application

    User->>API: kubectl delete pod
    API->>API: Pod ìƒíƒœ â†’ Terminating

    par Endpoint ì œê±° (ë¹„ë™ê¸°)
        API->>EP: Pod ì‚­ì œ ì´ë²¤íŠ¸
        EP->>EP: Service Endpointsì—ì„œ<br/>Pod IP ì œê±°
        Note over EP: kube-proxyê°€ iptables ì—…ë°ì´íŠ¸<br/>(ìµœëŒ€ ëª‡ ì´ˆ ì†Œìš”)
    and preStop Hook ì‹¤í–‰ (ë¹„ë™ê¸°)
        API->>Kubelet: Pod ì¢…ë£Œ ìš”ì²­
        Kubelet->>Container: preStop Hook ì‹¤í–‰
        Note over Container: sleep 5<br/>(Endpoints ì œê±° ëŒ€ê¸°)
    end

    Container->>App: SIGTERM ì „ì†¡
    App->>App: ìƒˆ ìš”ì²­ ìˆ˜ì‹  ì¤‘ë‹¨
    App->>App: ì§„í–‰ ì¤‘ì¸ ìš”ì²­ ì™„ë£Œ
    Note over App: Graceful Shutdown<br/>(ìµœëŒ€ terminationGracePeriodSeconds - preStop ì‹œê°„)

    alt Graceful ì¢…ë£Œ ì„±ê³µ
        App->>Kubelet: exit 0
        Kubelet->>API: Pod ì¢…ë£Œ ì™„ë£Œ
    else Timeout ì´ˆê³¼
        Kubelet->>Container: SIGKILL (ê°•ì œ ì¢…ë£Œ)
        Container->>API: Pod ê°•ì œ ì¢…ë£Œë¨
    end

    API->>API: Pod ì‚­ì œ
```

**íƒ€ì´ë° ì„¸ë¶€ ì‚¬í•­:**

1. **T+0ì´ˆ**: `kubectl delete pod` ë˜ëŠ” ë¡¤ë§ ì—…ë°ì´íŠ¸ë¡œ Pod ì‚­ì œ ìš”ì²­
2. **T+0ì´ˆ**: API Serverê°€ Pod ìƒíƒœë¥¼ `Terminating`ìœ¼ë¡œ ë³€ê²½
3. **T+0ì´ˆ**: **ë¹„ë™ê¸°ì ìœ¼ë¡œ** ë‘ ì‘ì—… ë™ì‹œ ì‹œì‘:
   - Endpoint Controllerê°€ Service Endpointsì—ì„œ Pod IP ì œê±°
   - kubeletì´ preStop Hook ì‹¤í–‰
4. **T+0~5ì´ˆ**: preStop Hookì˜ `sleep 5` ì‹¤í–‰ (Endpoints ì œê±° ëŒ€ê¸°)
5. **T+5ì´ˆ**: preStop Hookì´ `kill -TERM 1` ì‹¤í–‰ â†’ SIGTERM ì „ì†¡
6. **T+5ì´ˆ**: ì• í”Œë¦¬ì¼€ì´ì…˜ì´ SIGTERM ìˆ˜ì‹ , Graceful Shutdown ì‹œì‘
7. **T+5~60ì´ˆ**: ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì§„í–‰ ì¤‘ì¸ ìš”ì²­ ì™„ë£Œ, ì •ë¦¬ ì‘ì—… ìˆ˜í–‰
8. **T+60ì´ˆ**: `terminationGracePeriodSeconds` ë„ë‹¬ ì‹œ SIGKILL (ê°•ì œ ì¢…ë£Œ)

:::tip preStop sleepì´ í•„ìš”í•œ ì´ìœ 
Endpoint ì œê±°ì™€ preStop Hook ì‹¤í–‰ì€ **ë¹„ë™ê¸°**ë¡œ ë°œìƒí•©ë‹ˆë‹¤. preStopì— 5ì´ˆ sleepì„ ì¶”ê°€í•˜ë©´, Endpoint Controllerì™€ kube-proxyê°€ iptablesë¥¼ ì—…ë°ì´íŠ¸í•˜ì—¬ ìƒˆë¡œìš´ íŠ¸ë˜í”½ì´ ì¢…ë£Œ ì¤‘ì¸ Podìœ¼ë¡œ ìœ ì…ë˜ì§€ ì•Šë„ë¡ ë³´ì¥í•©ë‹ˆë‹¤. ì´ íŒ¨í„´ ì—†ì´ëŠ” ì¢…ë£Œ ì¤‘ì¸ Podìœ¼ë¡œ íŠ¸ë˜í”½ì´ ê³„ì† ì „ì†¡ë˜ì–´ 502/503 ì—ëŸ¬ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
:::

### 3.2 ì–¸ì–´ë³„ SIGTERM ì²˜ë¦¬ íŒ¨í„´

#### Node.js (Express)

```javascript
const express = require('express');
const app = express();
const server = app.listen(8080);

// ìƒíƒœ í”Œë˜ê·¸
let isShuttingDown = false;

// í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸
app.get('/healthz', (req, res) => {
  res.status(200).json({ status: 'ok' });
});

app.get('/ready', (req, res) => {
  if (isShuttingDown) {
    return res.status(503).json({ status: 'shutting_down' });
  }
  res.status(200).json({ status: 'ready' });
});

// ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
app.get('/api/data', (req, res) => {
  if (isShuttingDown) {
    return res.status(503).send('Service Unavailable');
  }
  // ì‹¤ì œ ë¡œì§
  res.json({ data: 'example' });
});

// Graceful Shutdown ì²˜ë¦¬
function gracefulShutdown(signal) {
  console.log(`${signal} received, starting graceful shutdown`);
  isShuttingDown = true;

  // ìƒˆ ì—°ê²° ê±°ë¶€
  server.close(() => {
    console.log('HTTP server closed');

    // DB ì—°ê²° ì¢…ë£Œ
    // db.close();

    // í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
    process.exit(0);
  });

  // Timeout ì„¤ì • (SIGKILL ì „ì— ì™„ë£Œ)
  setTimeout(() => {
    console.error('Graceful shutdown timeout, forcing exit');
    process.exit(1);
  }, 50000); // terminationGracePeriodSeconds - preStop ì‹œê°„ - ì—¬ìœ  5ì´ˆ
}

// SIGTERM, SIGINT ì²˜ë¦¬
process.on('SIGTERM', () => gracefulShutdown('SIGTERM'));
process.on('SIGINT', () => gracefulShutdown('SIGINT'));

console.log('Server started on port 8080');
```

**Deployment ì„¤ì •:**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nodejs-app
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: app
        image: myapp/nodejs:v1
        ports:
        - containerPort: 8080
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          periodSeconds: 5
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh", "-c", "sleep 5"]
      terminationGracePeriodSeconds: 60
```

#### Java/Spring Boot

Spring Boot 2.3+ëŠ” Graceful Shutdownì„ ë„¤ì´í‹°ë¸Œë¡œ ì§€ì›í•©ë‹ˆë‹¤.

**application.yml:**

```yaml
server:
  shutdown: graceful  # Graceful Shutdown í™œì„±í™”

spring:
  lifecycle:
    timeout-per-shutdown-phase: 50s  # ìµœëŒ€ ëŒ€ê¸° ì‹œê°„
management:
  endpoints:
    web:
      exposure:
        include: health
  endpoint:
    health:
      probes:
        enabled: true
  health:
    livenessState:
      enabled: true
    readinessState:
      enabled: true
```

**ì»¤ìŠ¤í…€ ì¢…ë£Œ ë¡œì§ (í•„ìš” ì‹œ):**

```java
import org.springframework.context.event.ContextClosedEvent;
import org.springframework.context.event.EventListener;
import org.springframework.stereotype.Component;

@Component
public class GracefulShutdownListener {

    @EventListener
    public void onApplicationEvent(ContextClosedEvent event) {
        System.out.println("Graceful shutdown initiated");

        // ì»¤ìŠ¤í…€ ì •ë¦¬ ì‘ì—…
        // ì˜ˆ: ë©”ì‹œì§€ í ì •ë¦¬, ë°°ì¹˜ ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
        try {
            // ìµœëŒ€ 50ì´ˆ ëŒ€ê¸°
            cleanupResources();
        } catch (Exception e) {
            System.err.println("Cleanup error: " + e.getMessage());
        }
    }

    private void cleanupResources() throws InterruptedException {
        // ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ë¡œì§
        Thread.sleep(5000); // ì˜ˆì‹œ: 5ì´ˆ ì •ë¦¬ ì‘ì—…
        System.out.println("Cleanup completed");
    }
}
```

**Deployment ì„¤ì •:**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spring-boot-app
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: app
        image: myapp/spring-boot:v2.7
        ports:
        - containerPort: 8080
        env:
        - name: JAVA_OPTS
          value: "-Xms1g -Xmx2g"
        readinessProbe:
          httpGet:
            path: /actuator/health/readiness
            port: 8080
          periodSeconds: 5
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh", "-c", "sleep 5"]
      terminationGracePeriodSeconds: 60
```

#### Go

```go
package main

import (
    "context"
    "fmt"
    "log"
    "net/http"
    "os"
    "os/signal"
    "syscall"
    "time"
)

var isShuttingDown = false

func main() {
    // HTTP ì„œë²„ ì„¤ì •
    mux := http.NewServeMux()

    mux.HandleFunc("/healthz", func(w http.ResponseWriter, r *http.Request) {
        w.WriteHeader(http.StatusOK)
        fmt.Fprintln(w, "ok")
    })

    mux.HandleFunc("/ready", func(w http.ResponseWriter, r *http.Request) {
        if isShuttingDown {
            w.WriteHeader(http.StatusServiceUnavailable)
            fmt.Fprintln(w, "shutting down")
            return
        }
        w.WriteHeader(http.StatusOK)
        fmt.Fprintln(w, "ready")
    })

    mux.HandleFunc("/api/data", func(w http.ResponseWriter, r *http.Request) {
        if isShuttingDown {
            w.WriteHeader(http.StatusServiceUnavailable)
            return
        }
        // ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
        fmt.Fprintln(w, `{"data":"example"}`)
    })

    server := &http.Server{
        Addr:    ":8080",
        Handler: mux,
    }

    // ë³„ë„ ê³ ë£¨í‹´ì—ì„œ ì„œë²„ ì‹œì‘
    go func() {
        log.Println("Server starting on :8080")
        if err := server.ListenAndServe(); err != nil && err != http.ErrServerClosed {
            log.Fatalf("Server error: %v", err)
        }
    }()

    // SIGTERM/SIGINT ëŒ€ê¸°
    quit := make(chan os.Signal, 1)
    signal.Notify(quit, syscall.SIGTERM, syscall.SIGINT)
    <-quit

    log.Println("Graceful shutdown initiated")
    isShuttingDown = true

    // Graceful shutdown with timeout
    ctx, cancel := context.WithTimeout(context.Background(), 50*time.Second)
    defer cancel()

    if err := server.Shutdown(ctx); err != nil {
        log.Fatalf("Server forced to shutdown: %v", err)
    }

    log.Println("Server exited gracefully")
}
```

**Deployment ì„¤ì •:**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: go-app
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: app
        image: myapp/go-app:v1
        ports:
        - containerPort: 8080
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          periodSeconds: 5
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh", "-c", "sleep 5"]
      terminationGracePeriodSeconds: 60
```

#### Python (Flask)

```python
from flask import Flask, jsonify
import signal
import sys
import time
import threading

app = Flask(__name__)
is_shutting_down = False

@app.route('/healthz')
def healthz():
    return jsonify({"status": "ok"}), 200

@app.route('/ready')
def ready():
    if is_shutting_down:
        return jsonify({"status": "shutting_down"}), 503
    return jsonify({"status": "ready"}), 200

@app.route('/api/data')
def api_data():
    if is_shutting_down:
        return jsonify({"error": "service unavailable"}), 503
    return jsonify({"data": "example"}), 200

def graceful_shutdown(signum, frame):
    global is_shutting_down
    print(f"Signal {signum} received, starting graceful shutdown")
    is_shutting_down = True

    # ì •ë¦¬ ì‘ì—… (ì˜ˆ: DB ì—°ê²° ì¢…ë£Œ)
    # db.close()

    print("Graceful shutdown completed")
    sys.exit(0)

# SIGTERM í•¸ë“¤ëŸ¬ ë“±ë¡
signal.signal(signal.SIGTERM, graceful_shutdown)
signal.signal(signal.SIGINT, graceful_shutdown)

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080)
```

**Deployment ì„¤ì •:**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: python-app
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: app
        image: myapp/python-flask:v1
        ports:
        - containerPort: 8080
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          periodSeconds: 5
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh", "-c", "sleep 5"]
      terminationGracePeriodSeconds: 60
```

### 3.3 Connection Draining íŒ¨í„´

Connection Drainingì€ ì¢…ë£Œ ì‹œ ê¸°ì¡´ ì—°ê²°ì„ ì•ˆì „í•˜ê²Œ ì •ë¦¬í•˜ëŠ” íŒ¨í„´ì…ë‹ˆë‹¤.

#### HTTP Keep-Alive ì—°ê²° ì²˜ë¦¬

```javascript
// Node.js Express with Connection Draining
const express = require('express');
const app = express();
const server = app.listen(8080);

let isShuttingDown = false;
const activeConnections = new Set();

// ì—°ê²° ì¶”ì 
server.on('connection', (conn) => {
  activeConnections.add(conn);
  conn.on('close', () => {
    activeConnections.delete(conn);
  });
});

function gracefulShutdown(signal) {
  console.log(`${signal} received`);
  isShuttingDown = true;

  // ìƒˆ ì—°ê²° ê±°ë¶€
  server.close(() => {
    console.log('Server closed, no new connections');
  });

  // ê¸°ì¡´ ì—°ê²° ì¢…ë£Œ
  console.log(`Closing ${activeConnections.size} active connections`);
  activeConnections.forEach((conn) => {
    conn.destroy(); // ê°•ì œ ì¢…ë£Œ (ë˜ëŠ” conn.end()ë¡œ graceful)
  });

  // ì •ë¦¬ ì‘ì—… í›„ ì¢…ë£Œ
  setTimeout(() => {
    console.log('Graceful shutdown complete');
    process.exit(0);
  }, 5000);
}

process.on('SIGTERM', () => gracefulShutdown('SIGTERM'));
```

#### WebSocket ì—°ê²° ì •ë¦¬

```javascript
// WebSocket graceful shutdown
const WebSocket = require('ws');
const wss = new WebSocket.Server({ port: 8080 });

const clients = new Set();

wss.on('connection', (ws) => {
  clients.add(ws);

  ws.on('close', () => {
    clients.delete(ws);
  });

  ws.on('message', (message) => {
    // ë©”ì‹œì§€ ì²˜ë¦¬
  });
});

function gracefulShutdown() {
  console.log(`Closing ${clients.size} WebSocket connections`);

  clients.forEach((ws) => {
    // í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ì¢…ë£Œ ì•Œë¦¼
    ws.send(JSON.stringify({ type: 'server_shutdown' }));
    ws.close(1001, 'Server shutting down');
  });

  wss.close(() => {
    console.log('WebSocket server closed');
    process.exit(0);
  });
}

process.on('SIGTERM', gracefulShutdown);
```

#### gRPC Graceful Shutdown

```go
package main

import (
    "context"
    "log"
    "net"
    "os"
    "os/signal"
    "syscall"
    "time"

    "google.golang.org/grpc"
    pb "myapp/proto"
)

type server struct {
    pb.UnimplementedMyServiceServer
}

func main() {
    lis, err := net.Listen("tcp", ":9090")
    if err != nil {
        log.Fatalf("Failed to listen: %v", err)
    }

    s := grpc.NewServer()
    pb.RegisterMyServiceServer(s, &server{})

    go func() {
        log.Println("gRPC server starting on :9090")
        if err := s.Serve(lis); err != nil {
            log.Fatalf("Failed to serve: %v", err)
        }
    }()

    // SIGTERM ëŒ€ê¸°
    quit := make(chan os.Signal, 1)
    signal.Notify(quit, syscall.SIGTERM, syscall.SIGINT)
    <-quit

    log.Println("Graceful shutdown initiated")

    // GracefulStop: ì§„í–‰ ì¤‘ì¸ RPC ì™„ë£Œ ëŒ€ê¸°
    done := make(chan struct{})
    go func() {
        s.GracefulStop()
        close(done)
    }()

    // Timeout ì²˜ë¦¬
    select {
    case <-done:
        log.Println("gRPC server stopped gracefully")
    case <-time.After(50 * time.Second):
        log.Println("Graceful stop timeout, forcing stop")
        s.Stop() // ê°•ì œ ì¢…ë£Œ
    }
}
```

#### ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ ì •ë¦¬

```python
# Python with psycopg2 connection pool
import psycopg2
from psycopg2 import pool
import signal
import sys

# Connection pool
db_pool = psycopg2.pool.SimpleConnectionPool(
    minconn=1,
    maxconn=10,
    host='db.example.com',
    database='mydb',
    user='user',
    password='password'
)

def graceful_shutdown(signum, frame):
    print("Closing database connections...")

    # ëª¨ë“  ì—°ê²° ì¢…ë£Œ
    db_pool.closeall()

    print("Database connections closed")
    sys.exit(0)

signal.signal(signal.SIGTERM, graceful_shutdown)

# ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œì§
def query_database():
    conn = db_pool.getconn()
    try:
        cur = conn.cursor()
        cur.execute("SELECT * FROM users")
        return cur.fetchall()
    finally:
        db_pool.putconn(conn)
```

### 3.4 Karpenter/Node Drainê³¼ì˜ ìƒí˜¸ì‘ìš©

Karpenterê°€ ë…¸ë“œë¥¼ í†µí•©(consolidation)í•˜ê±°ë‚˜ Spot ì¸ìŠ¤í„´ìŠ¤ê°€ ì¢…ë£Œë  ë•Œ, ë…¸ë“œì˜ ëª¨ë“  Podì´ ì•ˆì „í•˜ê²Œ ì´ë™í•´ì•¼ í•©ë‹ˆë‹¤.

#### Karpenter Disruptionê³¼ Graceful Shutdown

```mermaid
sequenceDiagram
    participant Karpenter
    participant Node as Node (Consolidation)
    participant Kubelet as kubelet
    participant Pod as Pod

    Karpenter->>Karpenter: ë…¸ë“œ í†µí•© í•„ìš” ê°ì§€<br/>(ë¯¸ì‚¬ìš© ë˜ëŠ” ì €ì‚¬ìš©)
    Karpenter->>Node: Node Cordon
    Karpenter->>Node: Node Drain ì‹œì‘
    Node->>Kubelet: Pod ì¢…ë£Œ ìš”ì²­

    Kubelet->>Pod: preStop Hook ì‹¤í–‰
    Note over Pod: sleep 5

    Kubelet->>Pod: SIGTERM ì „ì†¡
    Pod->>Pod: Graceful Shutdown<br/>(ìµœëŒ€ terminationGracePeriodSeconds)

    alt Graceful ì¢…ë£Œ ì„±ê³µ
        Pod->>Kubelet: exit 0
        Kubelet->>Karpenter: Pod ì¢…ë£Œ ì™„ë£Œ
    else Timeout
        Kubelet->>Pod: SIGKILL
        Pod->>Kubelet: ê°•ì œ ì¢…ë£Œ
    end

    Karpenter->>Karpenter: ëª¨ë“  Pod ì´ë™ ì™„ë£Œ
    Karpenter->>Node: ë…¸ë“œ ì¢…ë£Œ
```

**Karpenter NodePool ì„¤ì •:**

```yaml
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: default
spec:
  disruption:
    consolidationPolicy: WhenEmptyOrUnderutilized
    consolidateAfter: 5m
    # Disruption budget: ë™ì‹œ ì¤‘ë‹¨ ë…¸ë“œ ì œí•œ
    budgets:
    - nodes: "20%"
      schedule: "0 9-17 * * MON-FRI"  # ì—…ë¬´ ì‹œê°„ 20%
    - nodes: "50%"
      schedule: "0 0-8,18-23 * * *"   # ë¹„ì—…ë¬´ ì‹œê°„ 50%
```

:::warning PDBì™€ Karpenter ìƒí˜¸ì‘ìš©
PodDisruptionBudgetì´ ë„ˆë¬´ ì—„ê²©í•˜ë©´ (ì˜ˆ: `minAvailable`ì´ replica ìˆ˜ì™€ ê°™ìŒ) Karpenterê°€ ë…¸ë“œë¥¼ drainí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. PDBëŠ” `minAvailable: replica - 1` ë˜ëŠ” `maxUnavailable: 1`ë¡œ ì„¤ì •í•˜ì—¬ ìµœì†Œ 1ê°œ Podì€ ì´ë™ ê°€ëŠ¥í•˜ë„ë¡ í•˜ì„¸ìš”.
:::

#### 3.4.3 ARC + Karpenter í†µí•© AZ ëŒ€í”¼ íŒ¨í„´

**ê°œìš”:**

AWS Application Recovery Controller(ARC)ì™€ Karpenterì˜ í†µí•©(2025ë…„ ë°œí‘œ)ì€ Availability Zone(AZ) ì¥ì•  ì‹œ ìë™ìœ¼ë¡œ ì›Œí¬ë¡œë“œë¥¼ ë‹¤ë¥¸ AZë¡œ ì´ë™ì‹œí‚¤ëŠ” ê³ ê°€ìš©ì„± íŒ¨í„´ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ AZ ì¥ì•  ë˜ëŠ” Gray Failure ìƒí™©ì—ì„œë„ Graceful Shutdownì„ ë³´ì¥í•˜ë©° ì„œë¹„ìŠ¤ ì¤‘ë‹¨ì„ ìµœì†Œí™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ARC Zonal Shiftë€:**

Zonal ShiftëŠ” íŠ¹ì • AZì—ì„œ ë°œìƒí•œ ì¥ì• ë‚˜ ì„±ëŠ¥ ì €í•˜ë¥¼ ê°ì§€í–ˆì„ ë•Œ, í•´ë‹¹ AZì˜ íŠ¸ë˜í”½ì„ ìë™ìœ¼ë¡œ ë‹¤ë¥¸ ì •ìƒ AZë¡œ ì „í™˜í•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤. EKSì™€ í†µí•© ì‹œ Podì˜ ì•ˆì „í•œ ì´ë™ê¹Œì§€ ìë™í™”ë©ë‹ˆë‹¤.

**ì•„í‚¤í…ì²˜ êµ¬ì„± ìš”ì†Œ:**

| ì»´í¬ë„ŒíŠ¸ | ì—­í•  | ë™ì‘ |
|----------|------|------|
| **ARC Zonal Autoshift** | AZ ì¥ì•  ìë™ ê°ì§€ ë° íŠ¸ë˜í”½ ì „í™˜ ê²°ì • | CloudWatch Alarms ê¸°ë°˜ ìë™ Shift |
| **Karpenter** | ìƒˆ AZì— ë…¸ë“œ í”„ë¡œë¹„ì €ë‹ | NodePool ì„¤ì •ì— ë”°ë¼ ì •ìƒ AZì— ë…¸ë“œ ìƒì„± |
| **AWS Load Balancer** | íŠ¸ë˜í”½ ë¼ìš°íŒ… ì œì–´ | ì¥ì•  AZì˜ Target ì œê±° |
| **PodDisruptionBudget** | Pod ì´ë™ ì‹œ ê°€ìš©ì„± ë³´ì¥ | ìµœì†Œ ê°€ìš© Pod ìˆ˜ ìœ ì§€ |

**AZ ëŒ€í”¼ ì‹œí€€ìŠ¤:**

```mermaid
sequenceDiagram
    participant AZ_A as AZ-A (ì¥ì• )
    participant ARC as ARC Zonal Autoshift
    participant Karpenter
    participant AZ_B as AZ-B (ì •ìƒ)
    participant LB as ALB/NLB
    participant Pod_Old as Pod (AZ-A)
    participant Pod_New as Pod (AZ-B)

    Note over AZ_A: AZ ì„±ëŠ¥ ì €í•˜ ê°ì§€<br/>(ë„¤íŠ¸ì›Œí¬ ì§€ì—°, íŒ¨í‚· ì†ì‹¤)

    AZ_A->>ARC: CloudWatch Alarm íŠ¸ë¦¬ê±°
    ARC->>ARC: Zonal Shift ê²°ì •
    ARC->>LB: AZ-A Target ì œê±° ì‹œì‘

    par Karpenter ë…¸ë“œ í”„ë¡œë¹„ì €ë‹
        ARC->>Karpenter: AZ-A ë…¸ë“œ Cordon
        Karpenter->>AZ_B: ìƒˆ ë…¸ë“œ í”„ë¡œë¹„ì €ë‹
        AZ_B->>Karpenter: ë…¸ë“œ Ready
    and Pod ì¬ìŠ¤ì¼€ì¤„ë§
        Karpenter->>Pod_Old: Pod Eviction (Graceful)
        Pod_Old->>Pod_Old: preStop Hook ì‹¤í–‰
        Pod_Old->>Pod_Old: SIGTERM ìˆ˜ì‹ 
        Pod_Old->>Pod_Old: Graceful Shutdown
        Note over Pod_Old: ì§„í–‰ ì¤‘ì¸ ìš”ì²­ ì™„ë£Œ<br/>(terminationGracePeriodSeconds)
    end

    Pod_New->>AZ_B: Pod ì‹œì‘
    Pod_New->>Pod_New: startupProbe ì„±ê³µ
    Pod_New->>Pod_New: readinessProbe ì„±ê³µ
    LB->>Pod_New: Health Check í†µê³¼
    LB->>Pod_New: íŠ¸ë˜í”½ ì „ì†¡ ì‹œì‘

    Pod_Old->>AZ_A: ì•ˆì „ ì¢…ë£Œ
    Karpenter->>AZ_A: ë¹ˆ ë…¸ë“œ ì¢…ë£Œ

    Note over AZ_B: ëª¨ë“  ì›Œí¬ë¡œë“œ AZ-Bë¡œ ì´ë™ ì™„ë£Œ
```

**ì„¤ì • ì˜ˆì‹œ:**

**1. ARC Zonal Autoshift í™œì„±í™”:**

```bash
# Load Balancerì— Zonal Autoshift í™œì„±í™”
aws arc-zonal-shift create-autoshift-observer-notification-configuration \
  --resource-identifier arn:aws:elasticloadbalancing:ap-northeast-2:123456789012:loadbalancer/app/production-alb/1234567890abcdef

# Zonal Autoshift ì„¤ì •
aws arc-zonal-shift update-zonal-autoshift-configuration \
  --resource-identifier arn:aws:elasticloadbalancing:ap-northeast-2:123456789012:loadbalancer/app/production-alb/1234567890abcdef \
  --zonal-autoshift-status ENABLED
```

**2. Karpenter NodePool - AZ ì¸ì‹ ì„¤ì •:**

```yaml
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: default
spec:
  disruption:
    consolidationPolicy: WhenEmptyOrUnderutilized
    consolidateAfter: 30s
    # AZ ì¥ì•  ì‹œ ë¹ ë¥¸ ëŒ€ì‘
    budgets:
    - nodes: "100%"
      reasons:
      - "Drifted"  # AZ Cordon ì‹œ ì¦‰ì‹œ êµì²´
  template:
    spec:
      requirements:
      - key: "topology.kubernetes.io/zone"
        operator: In
        values:
        - ap-northeast-2a
        - ap-northeast-2b
        - ap-northeast-2c
      - key: karpenter.sh/capacity-type
        operator: In
        values:
        - on-demand  # AZ ì¥ì•  ëŒ€ì‘ì€ On-Demand ê¶Œì¥
      nodeClassRef:
        name: default
---
apiVersion: karpenter.k8s.aws/v1
kind: EC2NodeClass
metadata:
  name: default
spec:
  amiFamily: AL2023
  role: "KarpenterNodeRole-production"
  subnetSelectorTerms:
  - tags:
      karpenter.sh/discovery: "production-eks"
  securityGroupSelectorTerms:
  - tags:
      karpenter.sh/discovery: "production-eks"
  # AZ ì¥ì•  ì‹œ ìë™ ê°ì§€
  metadataOptions:
    httpTokens: required
    httpPutResponseHopLimit: 2
```

**3. Deployment with PDB - AZ ë¶„ì‚°:**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: critical-api
spec:
  replicas: 6
  selector:
    matchLabels:
      app: critical-api
  template:
    metadata:
      labels:
        app: critical-api
    spec:
      # AZ ë¶„ì‚° ë³´ì¥
      topologySpreadConstraints:
      - maxSkew: 1
        topologyKey: topology.kubernetes.io/zone
        whenUnsatisfiable: DoNotSchedule
        labelSelector:
          matchLabels:
            app: critical-api
      # ë™ì¼ ë…¸ë“œ ë°°ì¹˜ ë°©ì§€
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchLabels:
                  app: critical-api
              topologyKey: kubernetes.io/hostname
      containers:
      - name: api
        image: myapp/critical-api:v3
        ports:
        - containerPort: 8080
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          periodSeconds: 5
          failureThreshold: 2
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8080
          periodSeconds: 10
        lifecycle:
          preStop:
            exec:
              command:
              - /bin/sh
              - -c
              - sleep 5
      terminationGracePeriodSeconds: 60
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: critical-api-pdb
spec:
  minAvailable: 4  # 6ê°œ ì¤‘ ìµœì†Œ 4ê°œ ìœ ì§€ (AZ ì¥ì•  ì‹œ 2ê°œ AZì—ì„œ ìš´ì˜)
  selector:
    matchLabels:
      app: critical-api
```

**4. CloudWatch Alarm - AZ ì„±ëŠ¥ ì €í•˜ ê°ì§€:**

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: az-health-monitoring
  namespace: monitoring
data:
  cloudwatch-alarm: |
    {
      "AlarmName": "AZ-A-NetworkLatency-High",
      "MetricName": "NetworkLatency",
      "Namespace": "AWS/EC2",
      "Statistic": "Average",
      "Period": 60,
      "EvaluationPeriods": 3,
      "Threshold": 100,
      "ComparisonOperator": "GreaterThanThreshold",
      "Dimensions": [
        {"Name": "AvailabilityZone", "Value": "ap-northeast-2a"}
      ],
      "AlarmDescription": "AZ-A ë„¤íŠ¸ì›Œí¬ ì§€ì—° ì¦ê°€ - Zonal Shift íŠ¸ë¦¬ê±°",
      "AlarmActions": [
        "arn:aws:arc-zonal-shift:ap-northeast-2:123456789012:autoshift-observer-notification"
      ]
    }
```

**Istio ì„œë¹„ìŠ¤ ë©”ì‹œ ê¸°ë°˜ End-to-End AZ ë³µêµ¬:**

Istio ì„œë¹„ìŠ¤ ë©”ì‹œì™€ í†µí•©í•˜ë©´ AZ ëŒ€í”¼ ì‹œ ë”ìš± ì •êµí•œ íŠ¸ë˜í”½ ì œì–´ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤:

```yaml
# Istio DestinationRule: AZ ê¸°ë°˜ íŠ¸ë˜í”½ ë¼ìš°íŒ…
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: critical-api-az-routing
spec:
  host: critical-api.production.svc.cluster.local
  trafficPolicy:
    loadBalancer:
      localityLbSetting:
        enabled: true
        distribute:
        - from: ap-northeast-2a/*
          to:
            "ap-northeast-2b/*": 50
            "ap-northeast-2c/*": 50
        - from: ap-northeast-2b/*
          to:
            "ap-northeast-2a/*": 50
            "ap-northeast-2c/*": 50
        - from: ap-northeast-2c/*
          to:
            "ap-northeast-2a/*": 50
            "ap-northeast-2b/*": 50
    outlierDetection:
      consecutiveErrors: 3
      interval: 10s
      baseEjectionTime: 30s
      maxEjectionPercent: 50
---
# VirtualService: AZ ì¥ì•  ì‹œ ìë™ ì¬ë¼ìš°íŒ…
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: critical-api-failover
spec:
  hosts:
  - critical-api.production.svc.cluster.local
  http:
  - match:
    - sourceLabels:
        topology.kubernetes.io/zone: ap-northeast-2a
    route:
    - destination:
        host: critical-api.production.svc.cluster.local
        subset: az-b
      weight: 50
    - destination:
        host: critical-api.production.svc.cluster.local
        subset: az-c
      weight: 50
    timeout: 3s
    retries:
      attempts: 3
      perTryTimeout: 1s
```

**Gray Failure ì²˜ë¦¬ ì „ëµ:**

Gray FailureëŠ” ì™„ì „í•œ ì¥ì• ê°€ ì•„ë‹Œ ì„±ëŠ¥ ì €í•˜ ìƒíƒœë¡œ, ê°ì§€ê°€ ì–´ë µìŠµë‹ˆë‹¤. ARC + Karpenter + Istio ì¡°í•©ìœ¼ë¡œ ëŒ€ì‘:

| Gray Failure ì¦ìƒ | ê°ì§€ ë°©ë²• | ìë™ ëŒ€ì‘ |
|------------------|----------|----------|
| ë„¤íŠ¸ì›Œí¬ ì§€ì—° ì¦ê°€ (50-200ms) | Container Network Observability | Istio Outlier Detection â†’ íŠ¸ë˜í”½ ìš°íšŒ |
| ê°„í—ì  íŒ¨í‚· ì†ì‹¤ (1-5%) | CloudWatch Network Metrics | ARC Zonal Shift íŠ¸ë¦¬ê±° |
| ë””ìŠ¤í¬ I/O ì €í•˜ | EBS CloudWatch Metrics | Karpenter ë…¸ë“œ êµì²´ |
| API Server ì‘ë‹µ ì§€ì—° | Control Plane Metrics | Provisioned Control Plane ìë™ ìŠ¤ì¼€ì¼ë§ |

**í…ŒìŠ¤íŠ¸ ë° ê²€ì¦:**

```bash
# AZ ì¥ì•  ì‹œë®¬ë ˆì´ì…˜ (Chaos Engineering)
kubectl apply -f - <<EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: az-failure-test
  namespace: chaos
data:
  experiment: |
    # 1. AZ-Aì˜ ëª¨ë“  ë…¸ë“œì— Taint ì¶”ê°€ (AZ ì¥ì•  ì‹œë®¬ë ˆì´ì…˜)
    kubectl taint nodes -l topology.kubernetes.io/zone=ap-northeast-2a \
      az-failure=true:NoSchedule

    # 2. Karpenterê°€ AZ-B, AZ-Cì— ìƒˆ ë…¸ë“œ ìƒì„± í™•ì¸
    kubectl get nodes -l topology.kubernetes.io/zone=ap-northeast-2b,ap-northeast-2c

    # 3. Pod ì´ë™ ëª¨ë‹ˆí„°ë§
    kubectl get pods -o wide --watch

    # 4. PDB ì¤€ìˆ˜ í™•ì¸ (minAvailable ìœ ì§€)
    kubectl get pdb critical-api-pdb

    # 5. Graceful Shutdown ë¡œê·¸ í™•ì¸
    kubectl logs <pod-name> --previous

    # 6. ë³µêµ¬ (Taint ì œê±°)
    kubectl taint nodes -l topology.kubernetes.io/zone=ap-northeast-2a \
      az-failure-
EOF
```

**ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ:**

```yaml
# Grafana Dashboard: AZ í—¬ìŠ¤ ë° ëŒ€í”¼ ìƒíƒœ
apiVersion: v1
kind: ConfigMap
metadata:
  name: az-failover-dashboard
  namespace: monitoring
data:
  dashboard.json: |
    {
      "panels": [
        {
          "title": "AZë³„ Pod ë¶„í¬",
          "targets": [
            {
              "expr": "count(kube_pod_info) by (node, zone)"
            }
          ]
        },
        {
          "title": "AZë³„ ë„¤íŠ¸ì›Œí¬ ì§€ì—°",
          "targets": [
            {
              "expr": "avg(container_network_latency_ms) by (availability_zone)"
            }
          ]
        },
        {
          "title": "Karpenter ë…¸ë“œ í”„ë¡œë¹„ì €ë‹ ì†ë„",
          "targets": [
            {
              "expr": "rate(karpenter_nodes_created_total[5m])"
            }
          ]
        },
        {
          "title": "Graceful Shutdown ì„±ê³µë¥ ",
          "targets": [
            {
              "expr": "rate(pod_termination_graceful_total[5m]) / rate(pod_termination_total[5m])"
            }
          ]
        }
      ]
    }
```

**ê´€ë ¨ ìë£Œ:**
- [AWS Blog: ARC + Karpenter ê³ ê°€ìš©ì„± í†µí•©](https://aws.amazon.com/blogs/containers/enhance-kubernetes-high-availability-with-amazon-application-recovery-controller-and-karpenter-integration/)
- [AWS Blog: Istio ê¸°ë°˜ End-to-end AZ ë³µêµ¬](https://aws.amazon.com/blogs/containers/)
- [AWS re:Invent 2025: Supercharge your Karpenter](https://www.youtube.com/watch?v=kUQ4Q11F4iQ)

:::tip ìš´ì˜ Best Practice
AZ ëŒ€í”¼ëŠ” ìë™í™”ë˜ì§€ë§Œ, ì •ê¸°ì ì¸ Chaos Engineering í…ŒìŠ¤íŠ¸ë¡œ ê²€ì¦í•˜ì„¸ìš”. ë§¤ ë¶„ê¸° 1íšŒ ì´ìƒ AZ ì¥ì•  ì‹œë®¬ë ˆì´ì…˜ì„ ìˆ˜í–‰í•˜ì—¬ PDB, Karpenter, Graceful Shutdownì´ ì˜ˆìƒëŒ€ë¡œ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤. íŠ¹íˆ `terminationGracePeriodSeconds`ê°€ ì‹¤ì œ Shutdown ì‹œê°„ë³´ë‹¤ ì¶©ë¶„íˆ ê¸´ì§€ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì¸¡ì •í•˜ì„¸ìš”.
:::

#### Spot ì¸ìŠ¤í„´ìŠ¤ 2ë¶„ ê²½ê³  ì²˜ë¦¬

AWS Spot ì¸ìŠ¤í„´ìŠ¤ëŠ” ì¢…ë£Œ 2ë¶„ ì „ì— ê²½ê³ ë¥¼ ë³´ëƒ…ë‹ˆë‹¤. ì´ë¥¼ ì²˜ë¦¬í•˜ì—¬ Graceful Shutdownì„ ë³´ì¥í•©ë‹ˆë‹¤.

**AWS Node Termination Handler ì„¤ì¹˜:**

```bash
helm repo add eks https://aws.github.io/eks-charts
helm repo update

helm install aws-node-termination-handler \
  --namespace kube-system \
  eks/aws-node-termination-handler \
  --set enableSpotInterruptionDraining=true \
  --set enableScheduledEventDraining=true
```

**ë™ì‘ ë°©ì‹:**
1. Spot ì¢…ë£Œ 2ë¶„ ê²½ê³  ê°ì§€
2. ë…¸ë“œë¥¼ ì¦‰ì‹œ Cordon (ìƒˆ Pod ìŠ¤ì¼€ì¤„ë§ ì°¨ë‹¨)
3. ë…¸ë“œì˜ ëª¨ë“  Podì„ Drain
4. Podì˜ `terminationGracePeriodSeconds` ë‚´ì— Graceful Shutdown ì™„ë£Œ

**ê¶Œì¥ terminationGracePeriodSeconds:**
- ì¼ë°˜ ì›¹ ì„œë¹„ìŠ¤: 30-60ì´ˆ
- ì¥ê¸° ì‹¤í–‰ ì‘ì—… (ë°°ì¹˜, ML ì¶”ë¡ ): 90-120ì´ˆ
- ìµœëŒ€ 2ë¶„ ì´ë‚´ë¡œ ì„¤ì • (Spot ê²½ê³  ì‹œê°„ ê³ ë ¤)

---

### 3.4.4 Node Readiness Controller â€” ë…¸ë“œ ìˆ˜ì¤€ Readiness ê´€ë¦¬

#### ê°œìš”

Node Readiness Controller(NRC)ëŠ” 2026ë…„ 2ì›” Kubernetes ê³µì‹ ë¸”ë¡œê·¸ì—ì„œ ë°œí‘œëœ ì•ŒíŒŒ ê¸°ëŠ¥(v0.1.1)ìœ¼ë¡œ, ë…¸ë“œ ìˆ˜ì¤€ì˜ ì¸í”„ë¼ ì¤€ë¹„ ìƒíƒœë¥¼ ì„ ì–¸ì ìœ¼ë¡œ ê´€ë¦¬í•˜ëŠ” ìƒˆë¡œìš´ ë©”ì»¤ë‹ˆì¦˜ì…ë‹ˆë‹¤.

ê¸°ì¡´ Kubernetesì˜ ë…¸ë“œ `Ready` ì¡°ê±´ì€ ë‹¨ìˆœí•œ ë°”ì´ë„ˆë¦¬ ìƒíƒœ(Ready/NotReady)ë§Œ ì œê³µí•˜ì—¬, CNI í”ŒëŸ¬ê·¸ì¸ ì´ˆê¸°í™”, GPU ë“œë¼ì´ë²„ ë¡œë”©, ìŠ¤í† ë¦¬ì§€ ë“œë¼ì´ë²„ ì¤€ë¹„ ë“± ë³µì¡í•œ ì¸í”„ë¼ ì˜ì¡´ì„±ì„ ì •í™•íˆ ë°˜ì˜í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. NRCëŠ” ì´ëŸ¬í•œ í•œê³„ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì»¤ìŠ¤í…€ readiness gateë¥¼ ì„ ì–¸ì ìœ¼ë¡œ ì •ì˜í•  ìˆ˜ ìˆëŠ” `NodeReadinessRule` CRDë¥¼ ì œê³µí•©ë‹ˆë‹¤.

**í•µì‹¬ ê°€ì¹˜:**
- **ì„¸ë°€í•œ ë…¸ë“œ ìƒíƒœ ì œì–´**: ì¸í”„ë¼ ì»´í¬ë„ŒíŠ¸ë³„ ì¤€ë¹„ ìƒíƒœë¥¼ ë…ë¦½ì ìœ¼ë¡œ ê´€ë¦¬
- **ìë™í™”ëœ Taint ê´€ë¦¬**: ì¡°ê±´ì´ ì¶©ì¡±ë˜ì§€ ì•Šìœ¼ë©´ ìë™ìœ¼ë¡œ NoSchedule Taint ì ìš©
- **ìœ ì—°í•œ ëª¨ë‹ˆí„°ë§ ëª¨ë“œ**: ë¶€íŠ¸ìŠ¤íŠ¸ë© ì „ìš©, ì§€ì† ëª¨ë‹ˆí„°ë§, Dry-run ëª¨ë“œ ì§€ì›
- **ì„ íƒì  ì ìš©**: nodeSelectorë¡œ íŠ¹ì • ë…¸ë“œ ê·¸ë£¹ì—ë§Œ ê·œì¹™ ì ìš©

**API ì •ë³´:**
- API Group: `readiness.node.x-k8s.io/v1alpha1`
- Kind: `NodeReadinessRule`
- ê³µì‹ ë¬¸ì„œ: https://node-readiness-controller.sigs.k8s.io/

#### í•µì‹¬ ê¸°ëŠ¥

##### 1. Continuous ëª¨ë“œ - ì§€ì† ëª¨ë‹ˆí„°ë§

ë…¸ë“œ ë¼ì´í”„ì‚¬ì´í´ ì „ì²´ì—ì„œ ì§€ì •ëœ ì¡°ê±´ì„ ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤. ì¸í”„ë¼ ì»´í¬ë„ŒíŠ¸ê°€ ëŸ°íƒ€ì„ ì¤‘ ì‹¤íŒ¨í•  ê²½ìš° (ì˜ˆ: GPU ë“œë¼ì´ë²„ í¬ë˜ì‹œ) ì¦‰ì‹œ Taintë¥¼ ì ìš©í•˜ì—¬ ìƒˆë¡œìš´ Pod ìŠ¤ì¼€ì¤„ë§ì„ ì°¨ë‹¨í•©ë‹ˆë‹¤.

**ì‚¬ìš© ì‚¬ë¡€:**
- GPU ë“œë¼ì´ë²„ ìƒíƒœ ëª¨ë‹ˆí„°ë§
- ë„¤íŠ¸ì›Œí¬ í”ŒëŸ¬ê·¸ì¸ ì§€ì† í—¬ìŠ¤ì²´í¬
- ìŠ¤í† ë¦¬ì§€ ë“œë¼ì´ë²„ ê°€ìš©ì„± í™•ì¸

##### 2. Bootstrap-only ëª¨ë“œ - ì´ˆê¸°í™” ì „ìš©

ë…¸ë“œ ì´ˆê¸°í™” ë‹¨ê³„ì—ì„œë§Œ ì¡°ê±´ì„ í™•ì¸í•˜ê³ , ì¡°ê±´ì´ ì¶©ì¡±ë˜ë©´ ëª¨ë‹ˆí„°ë§ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤. ë¶€íŠ¸ìŠ¤íŠ¸ë© ì´í›„ì—ëŠ” ì¡°ê±´ ë³€ê²½ì— ë°˜ì‘í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

**ì‚¬ìš© ì‚¬ë¡€:**
- CNI í”ŒëŸ¬ê·¸ì¸ ì´ˆê¸° ë¶€íŠ¸ìŠ¤íŠ¸ë©
- ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ í”„ë¦¬í’€ ì™„ë£Œ í™•ì¸
- ì´ˆê¸° ë³´ì•ˆ ìŠ¤ìº” ì™„ë£Œ ëŒ€ê¸°

##### 3. Dry-run ëª¨ë“œ - ì•ˆì „í•œ ê²€ì¦

ì‹¤ì œ Taint ì ìš© ì—†ì´ ê·œì¹™ ë™ì‘ì„ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤. í”„ë¡œë•ì…˜ ë°°í¬ ì „ ê·œì¹™ ê²€ì¦ì— ìœ ìš©í•©ë‹ˆë‹¤.

**ì‚¬ìš© ì‚¬ë¡€:**
- ìƒˆë¡œìš´ NodeReadinessRule í…ŒìŠ¤íŠ¸
- ì¡°ê±´ ë³€ê²½ ì˜í–¥ ë¶„ì„
- ë””ë²„ê¹… ë° ë¬¸ì œ ì§„ë‹¨

##### 4. nodeSelector - íƒ€ê²Ÿ ë…¸ë“œ ì„ íƒ

ë¼ë²¨ ê¸°ë°˜ìœ¼ë¡œ íŠ¹ì • ë…¸ë“œ ê·¸ë£¹ì—ë§Œ ê·œì¹™ì„ ì ìš©í•©ë‹ˆë‹¤. GPU ë…¸ë“œì™€ ë²”ìš© ë…¸ë“œì— ì„œë¡œ ë‹¤ë¥¸ readiness ê·œì¹™ì„ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### YAML ì˜ˆì‹œ

##### CNI ë¶€íŠ¸ìŠ¤íŠ¸ë© - Bootstrap-only ëª¨ë“œ

```yaml
apiVersion: readiness.node.x-k8s.io/v1alpha1
kind: NodeReadinessRule
metadata:
  name: network-readiness-rule
  namespace: kube-system
spec:
  # í™•ì¸í•  ë…¸ë“œ ì¡°ê±´
  conditions:
    - type: "cniplugin.example.net/NetworkReady"
      requiredStatus: "True"

  # ì¡°ê±´ ë¯¸ì¶©ì¡± ì‹œ ì ìš©í•  Taint
  taint:
    key: "readiness.k8s.io/acme.com/network-unavailable"
    effect: "NoSchedule"
    value: "pending"

  # ë¶€íŠ¸ìŠ¤íŠ¸ë© ì™„ë£Œ í›„ ëª¨ë‹ˆí„°ë§ ì¤‘ë‹¨
  enforcementMode: "bootstrap-only"

  # ì›Œì»¤ ë…¸ë“œì—ë§Œ ì ìš©
  nodeSelector:
    matchLabels:
      node-role.kubernetes.io/worker: ""
```

**ë™ì‘ íë¦„:**
1. ìƒˆ ë…¸ë“œê°€ í´ëŸ¬ìŠ¤í„°ì— ì¡°ì¸í•˜ë©´ NRCê°€ ìë™ìœ¼ë¡œ Taint ì ìš©
2. CNI í”ŒëŸ¬ê·¸ì¸ì´ ì´ˆê¸°í™” ì™„ë£Œ í›„ `NetworkReady=True` ì¡°ê±´ ì„¤ì •
3. NRCê°€ ì¡°ê±´ í™•ì¸ í›„ Taint ì œê±°
4. Pod ìŠ¤ì¼€ì¤„ë§ ê°€ëŠ¥ (ì´í›„ CNI ìƒíƒœ ë³€ê²½ ë¬´ì‹œ)

##### GPU ë…¸ë“œ Continuous ëª¨ë‹ˆí„°ë§

```yaml
apiVersion: readiness.node.x-k8s.io/v1alpha1
kind: NodeReadinessRule
metadata:
  name: gpu-driver-readiness
  namespace: kube-system
spec:
  conditions:
    - type: "nvidia.com/gpu-driver-ready"
      requiredStatus: "True"

  taint:
    key: "readiness.k8s.io/gpu-unavailable"
    effect: "NoSchedule"
    value: "driver-not-ready"

  # ëŸ°íƒ€ì„ ì¤‘ì—ë„ ì§€ì† ëª¨ë‹ˆí„°ë§
  enforcementMode: "continuous"

  # GPU ë…¸ë“œì—ë§Œ ì ìš©
  nodeSelector:
    matchLabels:
      nvidia.com/gpu.present: "true"
```

**ë™ì‘ íë¦„:**
1. GPU ë…¸ë“œ ì‹œì‘ ì‹œ Taint ìë™ ì ìš©
2. NVIDIA ë“œë¼ì´ë²„ ë°ëª¬ì´ GPU ì´ˆê¸°í™” ì™„ë£Œ í›„ ì¡°ê±´ ì„¤ì •
3. NRCê°€ Taint ì œê±°, AI ì›Œí¬ë¡œë“œ ìŠ¤ì¼€ì¤„ë§ ê°€ëŠ¥
4. **ëŸ°íƒ€ì„ ì¤‘ ë“œë¼ì´ë²„ í¬ë˜ì‹œ ë°œìƒ ì‹œ:**
   - ì¡°ê±´ì´ `False`ë¡œ ë³€ê²½
   - NRCê°€ ì¦‰ì‹œ Taint ì¬ì ìš©
   - ê¸°ì¡´ PodëŠ” ìœ ì§€, ì‹ ê·œ Pod ìŠ¤ì¼€ì¤„ë§ ì°¨ë‹¨

##### EBS CSI ë“œë¼ì´ë²„ ì¤€ë¹„ í™•ì¸

```yaml
apiVersion: readiness.node.x-k8s.io/v1alpha1
kind: NodeReadinessRule
metadata:
  name: ebs-csi-readiness
  namespace: kube-system
spec:
  conditions:
    - type: "ebs.csi.aws.com/VolumeAttachReady"
      requiredStatus: "True"

  taint:
    key: "readiness.k8s.io/storage-unavailable"
    effect: "NoSchedule"
    value: "csi-not-ready"

  enforcementMode: "bootstrap-only"

  # ìŠ¤í† ë¦¬ì§€ ì›Œí¬ë¡œë“œ ì „ìš© ë…¸ë“œì—ë§Œ ì ìš©
  nodeSelector:
    matchLabels:
      workload-type: "stateful"
```

##### Dry-run ëª¨ë“œ - í…ŒìŠ¤íŠ¸ ê·œì¹™

```yaml
apiVersion: readiness.node.x-k8s.io/v1alpha1
kind: NodeReadinessRule
metadata:
  name: test-custom-condition
  namespace: kube-system
spec:
  conditions:
    - type: "example.com/CustomHealthCheck"
      requiredStatus: "True"

  taint:
    key: "readiness.k8s.io/test-condition"
    effect: "NoSchedule"
    value: "testing"

  # Taint ì ìš© ì—†ì´ ë™ì‘ë§Œ ë¡œê¹…
  enforcementMode: "dry-run"

  nodeSelector:
    matchLabels:
      environment: "staging"
```

#### EKS ì ìš© ì‹œë‚˜ë¦¬ì˜¤

##### 1. VPC CNI ì´ˆê¸°í™” ëŒ€ê¸°

**ë¬¸ì œ:**
ë…¸ë“œê°€ í´ëŸ¬ìŠ¤í„°ì— ì¡°ì¸í•œ ì§í›„ VPC CNI í”ŒëŸ¬ê·¸ì¸ì´ ì™„ì „íˆ ì´ˆê¸°í™”ë˜ê¸° ì „ì— Podì´ ìŠ¤ì¼€ì¤„ë§ë˜ë©´ ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì‹¤íŒ¨ê°€ ë°œìƒí•©ë‹ˆë‹¤.

**í•´ê²°:**
```yaml
apiVersion: readiness.node.x-k8s.io/v1alpha1
kind: NodeReadinessRule
metadata:
  name: vpc-cni-readiness
  namespace: kube-system
spec:
  conditions:
    - type: "vpc.amazonaws.com/CNIReady"
      requiredStatus: "True"
  taint:
    key: "node.eks.amazonaws.com/network-unavailable"
    effect: "NoSchedule"
    value: "vpc-cni-initializing"
  enforcementMode: "bootstrap-only"
```

**VPC CNI ë°ëª¬ì…‹ì—ì„œ ì¡°ê±´ ì„¤ì •:**
```yaml
# aws-node DaemonSetì˜ init container
initContainers:
- name: set-node-condition
  image: bitnami/kubectl:latest
  command:
  - /bin/sh
  - -c
  - |
    # CNI ì´ˆê¸°í™” ëŒ€ê¸°
    until [ -f /host/etc/cni/net.d/10-aws.conflist ]; do
      echo "Waiting for CNI config..."
      sleep 2
    done

    # Node Condition ì„¤ì •
    kubectl patch node $NODE_NAME --type=json -p='[
      {
        "op": "add",
        "path": "/status/conditions/-",
        "value": {
          "type": "vpc.amazonaws.com/CNIReady",
          "status": "True",
          "lastTransitionTime": "'$(date -u +"%Y-%m-%dT%H:%M:%SZ")'",
          "reason": "CNIInitialized",
          "message": "VPC CNI is ready"
        }
      }
    ]'
  env:
  - name: NODE_NAME
    valueFrom:
      fieldRef:
        fieldPath: spec.nodeName
```

##### 2. GPU ë…¸ë“œ NVIDIA ë“œë¼ì´ë²„ ì¤€ë¹„

**ë¬¸ì œ:**
GPU ì›Œí¬ë¡œë“œê°€ NVIDIA ë“œë¼ì´ë²„ ë¡œë”© ì™„ë£Œ ì „ì— ìŠ¤ì¼€ì¤„ë§ë˜ë©´ CUDA ì´ˆê¸°í™” ì‹¤íŒ¨ë¡œ Podì´ CrashLoopBackOff ìƒíƒœì— ë¹ ì§‘ë‹ˆë‹¤.

**í•´ê²°:**
```yaml
apiVersion: readiness.node.x-k8s.io/v1alpha1
kind: NodeReadinessRule
metadata:
  name: nvidia-gpu-readiness
  namespace: kube-system
spec:
  conditions:
    - type: "nvidia.com/gpu-driver-ready"
      requiredStatus: "True"
    - type: "nvidia.com/gpu-device-plugin-ready"
      requiredStatus: "True"
  taint:
    key: "nvidia.com/gpu-not-ready"
    effect: "NoSchedule"
    value: "driver-loading"
  enforcementMode: "continuous"
  nodeSelector:
    matchLabels:
      node.kubernetes.io/instance-type: "g5.xlarge"
```

**NVIDIA Device Pluginì—ì„œ ì¡°ê±´ ì„¤ì •:**
```go
// NVIDIA Device Pluginì˜ í—¬ìŠ¤ì²´í¬ ë¡œì§
func updateNodeCondition(nodeName string) error {
    // GPU ë“œë¼ì´ë²„ ìƒíƒœ í™•ì¸
    version, err := nvml.SystemGetDriverVersion()
    if err != nil {
        return setCondition(nodeName, "nvidia.com/gpu-driver-ready", "False")
    }

    // Device Plugin ìƒíƒœ í™•ì¸
    devices, err := nvml.DeviceGetCount()
    if err != nil || devices == 0 {
        return setCondition(nodeName, "nvidia.com/gpu-device-plugin-ready", "False")
    }

    // ëª¨ë‘ ì •ìƒì´ë©´ Trueë¡œ ì„¤ì •
    setCondition(nodeName, "nvidia.com/gpu-driver-ready", "True")
    setCondition(nodeName, "nvidia.com/gpu-device-plugin-ready", "True")
    return nil
}
```

##### 3. Node Problem Detector í†µí•©

**ë¬¸ì œ:**
ë…¸ë“œì—ì„œ í•˜ë“œì›¨ì–´ ì˜¤ë¥˜, ì»¤ë„ ë°ë“œë½, ë„¤íŠ¸ì›Œí¬ ë¬¸ì œ ë“±ì´ ë°œìƒí•´ë„ Kubernetesê°€ ìë™ìœ¼ë¡œ Pod ìŠ¤ì¼€ì¤„ë§ì„ ì°¨ë‹¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

**í•´ê²°:**
```yaml
apiVersion: readiness.node.x-k8s.io/v1alpha1
kind: NodeReadinessRule
metadata:
  name: node-problem-detector-readiness
  namespace: kube-system
spec:
  conditions:
    - type: "KernelDeadlock"
      requiredStatus: "False"  # Falseì´ì–´ì•¼ ì •ìƒ
    - type: "DiskPressure"
      requiredStatus: "False"
    - type: "NetworkUnavailable"
      requiredStatus: "False"
  taint:
    key: "node.kubernetes.io/problem-detected"
    effect: "NoSchedule"
    value: "true"
  enforcementMode: "continuous"
```

#### ì›Œí¬í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨

```mermaid
sequenceDiagram
    participant Node as ìƒˆ ë…¸ë“œ
    participant NRC as Node Readiness<br/>Controller
    participant CNI as CNI Plugin
    participant Scheduler as kube-scheduler
    participant Pod as Pod

    Note over Node: ë…¸ë“œ í´ëŸ¬ìŠ¤í„° ì¡°ì¸

    Node->>NRC: ë…¸ë“œ ë“±ë¡ ì´ë²¤íŠ¸
    NRC->>NRC: NodeReadinessRule í™•ì¸
    NRC->>Node: Taint ìë™ ì ìš©<br/>(network-unavailable=pending:NoSchedule)

    Note over Node,CNI: ì¸í”„ë¼ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì¤‘

    CNI->>CNI: VPC CNI ì´ˆê¸°í™” ì‹œì‘
    CNI->>CNI: ENI í• ë‹¹ ì™„ë£Œ
    CNI->>CNI: IP ì£¼ì†Œ í’€ ì¤€ë¹„
    CNI->>Node: Node Condition ì—…ë°ì´íŠ¸<br/>(CNIReady=True)

    NRC->>Node: Condition ë³€ê²½ ê°ì§€
    NRC->>NRC: requiredStatus í™•ì¸ (True == True)
    NRC->>Node: Taint ì œê±°

    Note over Node: Pod ìŠ¤ì¼€ì¤„ë§ ê°€ëŠ¥ ìƒíƒœ

    Scheduler->>Node: Pod ìŠ¤ì¼€ì¤„ë§ ê°€ëŠ¥ í™•ì¸
    Scheduler->>Pod: Podë¥¼ ë…¸ë“œì— í• ë‹¹
    Pod->>Node: Pod ì‹œì‘ ë° ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì„±ê³µ

    Note over Node,Pod: ì •ìƒ ìš´ì˜ ì¤‘

    alt Continuous ëª¨ë“œì¸ ê²½ìš°
        CNI->>CNI: ëŸ°íƒ€ì„ ì¤‘ ë“œë¼ì´ë²„ í¬ë˜ì‹œ
        CNI->>Node: Condition ë³€ê²½<br/>(CNIReady=False)
        NRC->>Node: Condition ë³€ê²½ ê°ì§€
        NRC->>Node: Taint ì¬ì ìš©
        Note over Scheduler: ì‹ ê·œ Pod ìŠ¤ì¼€ì¤„ë§ ì°¨ë‹¨<br/>(ê¸°ì¡´ PodëŠ” ìœ ì§€)
    else Bootstrap-only ëª¨ë“œì¸ ê²½ìš°
        Note over NRC: Condition ë³€ê²½ ë¬´ì‹œ<br/>(ëª¨ë‹ˆí„°ë§ ì¤‘ë‹¨ë¨)
    end
```

#### Pod Readinessì™€ì˜ ê´€ê³„

Kubernetesì˜ Readiness ë©”ì»¤ë‹ˆì¦˜ì€ ì´ì œ 3ê³„ì¸µ êµ¬ì¡°ë¡œ ì™„ì„±ë©ë‹ˆë‹¤:

| ê³„ì¸µ | ë©”ì»¤ë‹ˆì¦˜ | ë²”ìœ„ | ì‹¤íŒ¨ ì‹œ ë™ì‘ | ì‚¬ìš© ì‚¬ë¡€ |
|------|---------|------|-------------|----------|
| **1. ì»¨í…Œì´ë„ˆ** | Readiness Probe | ì»¨í…Œì´ë„ˆ ë‚´ë¶€ í—¬ìŠ¤ì²´í¬ | Service Endpoint ì œê±° | ì• í”Œë¦¬ì¼€ì´ì…˜ ì¤€ë¹„ ìƒíƒœ í™•ì¸ |
| **2. Pod** | Readiness Gate | Pod ìˆ˜ì¤€ ì™¸ë¶€ ì¡°ê±´ | Service Endpoint ì œê±° | ALB/NLB í—¬ìŠ¤ì²´í¬ í†µí•© |
| **3. ë…¸ë“œ** | Node Readiness Controller | ë…¸ë“œ ì¸í”„ë¼ ì¡°ê±´ | Pod ìŠ¤ì¼€ì¤„ë§ ì°¨ë‹¨ (Taint) | CNI, GPU, ìŠ¤í† ë¦¬ì§€ ì¤€ë¹„ í™•ì¸ |

**í†µí•© ì‹œë‚˜ë¦¬ì˜¤ - ì™„ì „í•œ íŠ¸ë˜í”½ ì•ˆì „ì„±:**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: critical-service
spec:
  replicas: 3
  template:
    spec:
      # 3ê³„ì¸µ Readiness ì ìš©
      containers:
      - name: app
        image: myapp:v2
        # 1ê³„ì¸µ: ì»¨í…Œì´ë„ˆ Readiness Probe
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          periodSeconds: 5
          failureThreshold: 2

      # 2ê³„ì¸µ: Pod Readiness Gate
      readinessGates:
      - conditionType: "target-health.alb.ingress.k8s.aws/production-alb"

      # 3ê³„ì¸µ: Node Readiness (NodeReadinessRuleë¡œ ìë™ ì²˜ë¦¬)
      # - ë…¸ë“œì˜ CNI, GPU, ìŠ¤í† ë¦¬ì§€ ì¤€ë¹„ ìƒíƒœ í™•ì¸
      # - Taintê°€ ì—†ëŠ” ë…¸ë“œì—ë§Œ ìŠ¤ì¼€ì¤„ë§ë¨
```

**íŠ¸ë˜í”½ ìˆ˜ì‹  ì²´í¬ë¦¬ìŠ¤íŠ¸:**

```mermaid
flowchart TD
    START[Pod ìƒì„±]

    START --> NODE_CHECK{ë…¸ë“œ ì¤€ë¹„ ì™„ë£Œ?<br/>Node Readiness}
    NODE_CHECK -->|Taint ìˆìŒ| WAIT_NODE[ìŠ¤ì¼€ì¤„ë§ ëŒ€ê¸°]
    WAIT_NODE --> NODE_CHECK
    NODE_CHECK -->|Taint ì—†ìŒ| SCHEDULE[Pod ìŠ¤ì¼€ì¤„ë§]

    SCHEDULE --> POD_START[Pod ì‹œì‘]
    POD_START --> CONTAINER_CHECK{ì»¨í…Œì´ë„ˆ ì¤€ë¹„?<br/>Readiness Probe}
    CONTAINER_CHECK -->|ì‹¤íŒ¨| WAIT_CONTAINER[Endpoint ë¯¸ë“±ë¡]
    WAIT_CONTAINER --> CONTAINER_CHECK
    CONTAINER_CHECK -->|ì„±ê³µ| GATE_CHECK{Pod Gate í†µê³¼?<br/>Readiness Gate}

    GATE_CHECK -->|ì‹¤íŒ¨| WAIT_GATE[Endpoint ë¯¸ë“±ë¡]
    WAIT_GATE --> GATE_CHECK
    GATE_CHECK -->|ì„±ê³µ| READY[Service Endpoint ë“±ë¡]

    READY --> TRAFFIC[íŠ¸ë˜í”½ ìˆ˜ì‹  ì‹œì‘]

    style NODE_CHECK fill:#fbbc04,stroke:#c99603,color:#000
    style CONTAINER_CHECK fill:#fbbc04,stroke:#c99603,color:#000
    style GATE_CHECK fill:#fbbc04,stroke:#c99603,color:#000
    style READY fill:#34a853,stroke:#2a8642,color:#fff
    style TRAFFIC fill:#4286f4,stroke:#2a6acf,color:#fff
```

#### ì„¤ì¹˜ ë° ì„¤ì •

##### 1. Node Readiness Controller ì„¤ì¹˜

```bash
# Helmìœ¼ë¡œ ì„¤ì¹˜
helm repo add node-readiness-controller https://node-readiness-controller.sigs.k8s.io
helm repo update

helm install node-readiness-controller \
  node-readiness-controller/node-readiness-controller \
  --namespace kube-system \
  --create-namespace

# ë˜ëŠ” Kustomizeë¡œ ì„¤ì¹˜
kubectl apply -k https://github.com/kubernetes-sigs/node-readiness-controller/config/default
```

##### 2. ì„¤ì¹˜ í™•ì¸

```bash
# Controller Pod ìƒíƒœ í™•ì¸
kubectl get pods -n kube-system -l app=node-readiness-controller

# CRD í™•ì¸
kubectl get crd nodereadinessrules.readiness.node.x-k8s.io

# ìƒ˜í”Œ ê·œì¹™ ì ìš©
kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/node-readiness-controller/main/examples/basic-rule.yaml

# ê·œì¹™ ëª©ë¡ í™•ì¸
kubectl get nodereadinessrules -A
```

##### 3. ë…¸ë“œ ìƒíƒœ í™•ì¸

```bash
# íŠ¹ì • ë…¸ë“œì˜ Condition í™•ì¸
kubectl get node <node-name> -o jsonpath='{.status.conditions}' | jq

# íŠ¹ì • Conditionë§Œ í•„í„°ë§
kubectl get node <node-name> -o jsonpath='{.status.conditions[?(@.type=="CNIReady")]}' | jq

# ëª¨ë“  ë…¸ë“œì˜ Taint í™•ì¸
kubectl get nodes -o custom-columns=NAME:.metadata.name,TAINTS:.spec.taints
```

#### ë””ë²„ê¹… ë° íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

##### Taintê°€ ì œê±°ë˜ì§€ ì•ŠëŠ” ê²½ìš°

```bash
# 1. NodeReadinessRule ì´ë²¤íŠ¸ í™•ì¸
kubectl describe nodereadinessrule <rule-name> -n kube-system

# 2. ë…¸ë“œ Condition ìƒíƒœ í™•ì¸
kubectl get node <node-name> -o yaml | grep -A 10 conditions

# 3. Controller ë¡œê·¸ í™•ì¸
kubectl logs -n kube-system -l app=node-readiness-controller --tail=100

# 4. ìˆ˜ë™ìœ¼ë¡œ Condition ì„¤ì • (í…ŒìŠ¤íŠ¸ìš©)
kubectl patch node <node-name> --type=json -p='[
  {
    "op": "add",
    "path": "/status/conditions/-",
    "value": {
      "type": "CNIReady",
      "status": "True",
      "lastTransitionTime": "'$(date -u +"%Y-%m-%dT%H:%M:%SZ")'",
      "reason": "ManualSet",
      "message": "Manually set for testing"
    }
  }
]'
```

##### Dry-run ëª¨ë“œë¡œ ê·œì¹™ í…ŒìŠ¤íŠ¸

```bash
# ê¸°ì¡´ ê·œì¹™ì„ dry-runìœ¼ë¡œ ë³€ê²½
kubectl patch nodereadinessrule <rule-name> -n kube-system \
  --type=merge \
  -p '{"spec":{"enforcementMode":"dry-run"}}'

# Controller ë¡œê·¸ì—ì„œ ë™ì‘ í™•ì¸
kubectl logs -n kube-system -l app=node-readiness-controller -f | grep "dry-run"

# í…ŒìŠ¤íŠ¸ ì™„ë£Œ í›„ ì›ë˜ ëª¨ë“œë¡œ ë³µêµ¬
kubectl patch nodereadinessrule <rule-name> -n kube-system \
  --type=merge \
  -p '{"spec":{"enforcementMode":"continuous"}}'
```

:::info ì•ŒíŒŒ ê¸°ëŠ¥ ì£¼ì˜ì‚¬í•­
Node Readiness ControllerëŠ” í˜„ì¬ v0.1.1 ì•ŒíŒŒ ë²„ì „ì…ë‹ˆë‹¤. í”„ë¡œë•ì…˜ í™˜ê²½ì— ì ìš©í•˜ê¸° ì „ì—:
- ìŠ¤í…Œì´ì§• í™˜ê²½ì—ì„œ ì¶©ë¶„í•œ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
- Dry-run ëª¨ë“œë¡œ ê·œì¹™ ë™ì‘ ê²€ì¦
- Controller ë¡œê·¸ ëª¨ë‹ˆí„°ë§ ì„¤ì •
- ë¬¸ì œ ë°œìƒ ì‹œ ìˆ˜ë™ìœ¼ë¡œ Taint ì œê±°í•  ìˆ˜ ìˆëŠ” ì ˆì°¨ ì¤€ë¹„
:::

:::tip ìš´ì˜ Best Practice
1. **Bootstrap-only ìš°ì„  ì‚¬ìš©**: ëŒ€ë¶€ë¶„ì˜ ê²½ìš° ë¶€íŠ¸ìŠ¤íŠ¸ë© ì „ìš© ëª¨ë“œë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤. Continuous ëª¨ë“œëŠ” ëŸ°íƒ€ì„ ì¤‘ ì¥ì• ê°€ ë¹ˆë²ˆí•œ ì»´í¬ë„ŒíŠ¸(GPU ë“œë¼ì´ë²„ ë“±)ì—ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
2. **nodeSelector ì ê·¹ í™œìš©**: ëª¨ë“  ë…¸ë“œì— ë™ì¼í•œ ê·œì¹™ì„ ì ìš©í•˜ì§€ ë§ê³ , ì›Œí¬ë¡œë“œ ìœ í˜•ë³„ë¡œ ì„¸ë¶„í™”í•˜ì„¸ìš”.
3. **Node Problem Detector í†µí•©**: NRCì™€ NPDë¥¼ í•¨ê»˜ ì‚¬ìš©í•˜ë©´ í•˜ë“œì›¨ì–´/OS ìˆ˜ì¤€ ë¬¸ì œê¹Œì§€ ìë™ ëŒ€ì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
4. **ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼**: Taint ì ìš©/ì œê±° ì´ë²¤íŠ¸ë¥¼ CloudWatchë‚˜ Prometheusë¡œ ìˆ˜ì§‘í•˜ê³ , ì¥ì‹œê°„ Taintê°€ ìœ ì§€ë˜ë©´ ì•Œë¦¼ì„ ë°›ë„ë¡ ì„¤ì •í•˜ì„¸ìš”.
:::

:::warning PDBì™€ì˜ ì¶©ëŒ ì£¼ì˜
Node Readiness Controllerê°€ Taintë¥¼ ì ìš©í•˜ë©´ í•´ë‹¹ ë…¸ë“œì˜ Podì´ ìƒˆë¡œ ìƒì„±ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë§Œì•½ ì—¬ëŸ¬ ë…¸ë“œì—ì„œ ë™ì‹œì— Taintê°€ ì ìš©ë˜ê³  PodDisruptionBudgetì´ ì—„ê²©í•˜ê²Œ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´, í´ëŸ¬ìŠ¤í„° ì „ì²´ì˜ ì›Œí¬ë¡œë“œ ë°°ì¹˜ê°€ ë¸”ë¡œí‚¹ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·œì¹™ ì„¤ê³„ ì‹œ PDB ì •ì±…ì„ í•¨ê»˜ ê²€í† í•˜ì„¸ìš”.
:::

#### ì°¸ì¡° ìë£Œ

- **ê³µì‹ ë¬¸ì„œ**: [Node Readiness Controller](https://node-readiness-controller.sigs.k8s.io/)
- **Kubernetes Blog**: [Introducing Node Readiness Controller](https://kubernetes.io/blog/2026/02/03/introducing-node-readiness-controller/)
- **GitHub Repository**: [kubernetes-sigs/node-readiness-controller](https://github.com/kubernetes-sigs/node-readiness-controller)

---

### 3.5 Fargate Pod ë¼ì´í”„ì‚¬ì´í´ íŠ¹ìˆ˜ ê³ ë ¤ì‚¬í•­

AWS FargateëŠ” ì„œë²„ë¦¬ìŠ¤ ì»´í“¨íŒ… ì—”ì§„ìœ¼ë¡œ, ë…¸ë“œ ê´€ë¦¬ ì—†ì´ Podì„ ì‹¤í–‰í•©ë‹ˆë‹¤. Fargate Podì€ EC2 ê¸°ë°˜ Podê³¼ ë‹¤ë¥¸ ë¼ì´í”„ì‚¬ì´í´ íŠ¹ì„±ì„ ê°€ì§‘ë‹ˆë‹¤.

#### Fargate vs EC2 vs Auto Mode ì•„í‚¤í…ì²˜ ë¹„êµ

```mermaid
flowchart TB
    subgraph EC2["EC2 Managed Node Group"]
        EC2Node[EC2 ì¸ìŠ¤í„´ìŠ¤]
        EC2Kubelet[kubelet]
        EC2Pod1[Pod 1]
        EC2Pod2[Pod 2]
        EC2Pod3[Pod 3]

        EC2Node --> EC2Kubelet
        EC2Kubelet --> EC2Pod1
        EC2Kubelet --> EC2Pod2
        EC2Kubelet --> EC2Pod3
    end

    subgraph Fargate["Fargate"]
        FGPod1[Pod 1<br/>ì „ìš© MicroVM]
        FGPod2[Pod 2<br/>ì „ìš© MicroVM]
        FGPod3[Pod 3<br/>ì „ìš© MicroVM]
    end

    subgraph AutoMode["EKS Auto Mode"]
        AutoNode[AWS ê´€ë¦¬í˜• ì¸ìŠ¤í„´ìŠ¤]
        AutoKubelet[kubelet<br/>ìë™ ê´€ë¦¬]
        AutoPod1[Pod 1]
        AutoPod2[Pod 2]
        AutoPod3[Pod 3]

        AutoNode -.->|AWS ì†Œìœ | AutoKubelet
        AutoKubelet --> AutoPod1
        AutoKubelet --> AutoPod2
        AutoKubelet --> AutoPod3
    end

    style EC2 fill:#ff9900,stroke:#cc7a00
    style Fargate fill:#9b59b6,stroke:#7d3c98
    style AutoMode fill:#34a853,stroke:#2a8642
```

#### Fargate Pod OS íŒ¨ì¹˜ ìë™ Eviction

FargateëŠ” ë³´ì•ˆ íŒ¨ì¹˜ë¥¼ ìœ„í•´ ì£¼ê¸°ì ìœ¼ë¡œ Podì„ ìë™ evictí•©ë‹ˆë‹¤.

**ë™ì‘ ë°©ì‹:**

1. **íŒ¨ì¹˜ ê°€ìš©ì„± ê°ì§€**: AWSê°€ ìƒˆë¡œìš´ OS/ëŸ°íƒ€ì„ íŒ¨ì¹˜ ê°ì§€
2. **Graceful Eviction**: Fargateê°€ Podì— SIGTERM ì „ì†¡ â†’ `terminationGracePeriodSeconds` ë‚´ì— ì¢…ë£Œ ëŒ€ê¸°
3. **ê°•ì œ ì¢…ë£Œ**: Timeout ì‹œ SIGKILL ì „ì†¡
4. **ì¬ìŠ¤ì¼€ì¤„ë§**: Kubernetesê°€ ìƒˆë¡œìš´ Fargate Podì— ì¬ìŠ¤ì¼€ì¤„ë§ (ì—…ë°ì´íŠ¸ëœ ëŸ°íƒ€ì„ ì‚¬ìš©)

**ì£¼ìš” íŠ¹ì§•:**

- **ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•œ íƒ€ì´ë°**: ì‚¬ìš©ìê°€ ì œì–´í•  ìˆ˜ ì—†ìŒ (AWS ê´€ë¦¬)
- **ì‚¬ì „ ì•Œë¦¼ ì—†ìŒ**: EC2 Scheduled Eventsì™€ ë‹¬ë¦¬ ì‚¬ì „ ê²½ê³  ì—†ìŒ
- **ìë™ ì¬ì‹œì‘**: PodDisruptionBudget(PDB) ì¡´ì¤‘í•˜ì§€ë§Œ, ë³´ì•ˆ íŒ¨ì¹˜ëŠ” ìš°ì„ ìˆœìœ„ ë†’ìŒ

**ëŒ€ì‘ ì „ëµ:**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: fargate-app
  namespace: fargate-namespace
spec:
  replicas: 3  # ìµœì†Œ 3ê°œ ì´ìƒ ê¶Œì¥ (ìë™ eviction ëŒ€ë¹„)
  selector:
    matchLabels:
      app: fargate-app
  template:
    metadata:
      labels:
        app: fargate-app
    spec:
      containers:
      - name: app
        image: myapp:v1
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
        startupProbe:
          httpGet:
            path: /healthz
            port: 8080
          failureThreshold: 10
          periodSeconds: 5
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8080
          periodSeconds: 10
        lifecycle:
          preStop:
            exec:
              command:
              - /bin/sh
              - -c
              - sleep 10  # Fargate eviction ëŒ€ë¹„ ë” ê¸´ ëŒ€ê¸°
      # FargateëŠ” ì‹œì‘ ì‹œê°„ì´ ê¸¸ ìˆ˜ ìˆìŒ
      terminationGracePeriodSeconds: 60
---
# PDBë¡œ ë™ì‹œ eviction ì œí•œ (ìµœì„  ë…¸ë ¥, ë³´ì•ˆ íŒ¨ì¹˜ ì‹œ ë¬´ì‹œë  ìˆ˜ ìˆìŒ)
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: fargate-app-pdb
  namespace: fargate-namespace
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: fargate-app
```

:::warning Fargate PDB ì œí•œ
FargateëŠ” PDBë¥¼ **ìµœì„  ë…¸ë ¥(best effort)** ìœ¼ë¡œë§Œ ì¡´ì¤‘í•©ë‹ˆë‹¤. ì¤‘ìš”í•œ ë³´ì•ˆ íŒ¨ì¹˜ì˜ ê²½ìš° PDBë¥¼ ë¬´ì‹œí•˜ê³  ê°•ì œ evictioní•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ Fargate í™˜ê²½ì—ì„œëŠ” **ìµœì†Œ 3ê°œ ì´ìƒì˜ replica**ë¡œ ê³ ê°€ìš©ì„±ì„ ë³´ì¥í•´ì•¼ í•©ë‹ˆë‹¤.
:::

#### Fargate Pod ì‹œì‘ ì‹œê°„ íŠ¹ì„±

Fargate Podì€ EC2 ê¸°ë°˜ Podë³´ë‹¤ ì‹œì‘ ì‹œê°„ì´ ê¹ë‹ˆë‹¤.

| ë‹¨ê³„ | EC2 (Managed Node) | Fargate | ì´ìœ  |
|------|-------------------|---------|------|
| **ë…¸ë“œ í”„ë¡œë¹„ì €ë‹** | 0ì´ˆ (ì´ë¯¸ ì‹¤í–‰ ì¤‘) | 20-40ì´ˆ | MicroVM ìƒì„± + ENI ì—°ê²° |
| **ì´ë¯¸ì§€ í’€** | 5-30ì´ˆ | 10-60ì´ˆ | ë ˆì´ì–´ ìºì‹œ ì—†ìŒ (ì²« ì‹¤í–‰ ì‹œ) |
| **ì»¨í…Œì´ë„ˆ ì‹œì‘** | 1-5ì´ˆ | 1-5ì´ˆ | ë™ì¼ |
| **ì´ ì‹œì‘ ì‹œê°„** | 6-35ì´ˆ | 31-105ì´ˆ | Fargate ì˜¤ë²„í—¤ë“œ ì¶”ê°€ |

**Startup Probe ì¡°ì • ì˜ˆì‹œ:**

```yaml
# EC2 Pod
startupProbe:
  httpGet:
    path: /healthz
    port: 8080
  failureThreshold: 6   # 6 Ã— 5ì´ˆ = 30ì´ˆ
  periodSeconds: 5

# Fargate Pod (ë” ê¸´ ì‹œê°„ í—ˆìš©)
startupProbe:
  httpGet:
    path: /healthz
    port: 8080
  failureThreshold: 20  # 20 Ã— 5ì´ˆ = 100ì´ˆ
  periodSeconds: 5
```

**ì´ë¯¸ì§€ í’€ ìµœì í™” (Fargate):**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: fargate-pod
  namespace: fargate-namespace
spec:
  containers:
  - name: app
    image: 123456789012.dkr.ecr.us-east-1.amazonaws.com/myapp:v1
    imagePullPolicy: IfNotPresent  # Always ëŒ€ì‹  IfNotPresent ê¶Œì¥
  imagePullSecrets:
  - name: ecr-secret
```

:::tip Fargate ì´ë¯¸ì§€ ìºì‹±
FargateëŠ” ë™ì¼ ì´ë¯¸ì§€ë¥¼ ë°˜ë³µ ì‚¬ìš© ì‹œ ë ˆì´ì–´ ìºì‹±ì„ ìˆ˜í–‰í•˜ì§€ë§Œ, **Podì´ evictë˜ë©´ ìºì‹œê°€ ì‚¬ë¼ì§‘ë‹ˆë‹¤**. ECR Image Scanningê³¼ Image Replicationì„ í™œìš©í•˜ì—¬ ì´ë¯¸ì§€ í’€ ì‹œê°„ì„ ë‹¨ì¶•í•˜ì„¸ìš”.
:::

#### Fargate DaemonSet ë¯¸ì§€ì›ìœ¼ë¡œ ì¸í•œ ì‚¬ì´ë“œì¹´ íŒ¨í„´

FargateëŠ” DaemonSetì„ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, ë…¸ë“œ ë ˆë²¨ ì—ì´ì „íŠ¸ê°€ í•„ìš”í•œ ê²½ìš° ì‚¬ì´ë“œì¹´ íŒ¨í„´ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.

**EC2 vs Fargate ëª¨ë‹ˆí„°ë§ íŒ¨í„´ ë¹„êµ:**

| ê¸°ëŠ¥ | EC2 (DaemonSet) | Fargate (Sidecar) |
|------|----------------|-------------------|
| **ë¡œê·¸ ìˆ˜ì§‘** | Fluent Bit DaemonSet | Fluent Bit Sidecar + FireLens |
| **ë©”íŠ¸ë¦­ ìˆ˜ì§‘** | CloudWatch Agent DaemonSet | CloudWatch Agent Sidecar |
| **ë³´ì•ˆ ìŠ¤ìº”** | Falco DaemonSet | FargateëŠ” AWS ê´€ë¦¬ (ì‚¬ìš©ì ì œì–´ ë¶ˆê°€) |
| **ë„¤íŠ¸ì›Œí¬ ì •ì±…** | Calico/Cilium DaemonSet | NetworkPolicy ë¯¸ì§€ì› (Security Groups for Pods ì‚¬ìš©) |

**Fargate ë¡œê¹… íŒ¨í„´ (FireLens):**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: fargate-logging-app
  namespace: fargate-namespace
spec:
  replicas: 2
  selector:
    matchLabels:
      app: logging-app
  template:
    metadata:
      labels:
        app: logging-app
    spec:
      containers:
      # ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
      - name: app
        image: myapp:v1
        ports:
        - containerPort: 8080
        resources:
          requests:
            cpu: 500m
            memory: 512Mi
      # FireLens ë¡œê·¸ ë¼ìš°í„° (ì‚¬ì´ë“œì¹´)
      - name: log-router
        image: public.ecr.aws/aws-observability/aws-for-fluent-bit:stable
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 200m
            memory: 256Mi
        env:
        - name: FLB_LOG_LEVEL
          value: "info"
        firelensConfiguration:
          type: fluentbit
          options:
            enable-ecs-log-metadata: "true"
```

:::info CloudWatch Container Insights on Fargate
FargateëŠ” CloudWatch Container Insightsë¥¼ **ë„¤ì´í‹°ë¸Œ ì§€ì›**í•˜ë©°, ë³„ë„ ì‚¬ì´ë“œì¹´ ì—†ì´ ë©”íŠ¸ë¦­ì„ ìë™ ìˆ˜ì§‘í•©ë‹ˆë‹¤. Fargate í”„ë¡œíŒŒì¼ ìƒì„± ì‹œ ìë™ìœ¼ë¡œ í™œì„±í™”ë©ë‹ˆë‹¤.

```bash
aws eks create-fargate-profile \
  --cluster-name my-cluster \
  --fargate-profile-name my-profile \
  --pod-execution-role-arn arn:aws:iam::123456789012:role/FargatePodExecutionRole \
  --selectors namespace=fargate-namespace \
  --tags 'EnableContainerInsights=enabled'
```
:::

#### Fargate Graceful Shutdown íƒ€ì´ë° ê¶Œì¥ì‚¬í•­

FargateëŠ” ìë™ eviction ë° ê¸´ ì‹œì‘ ì‹œê°„ìœ¼ë¡œ ì¸í•´ EC2ì™€ ë‹¤ë¥¸ Graceful Shutdown ì „ëµì´ í•„ìš”í•©ë‹ˆë‹¤.

| ì‹œë‚˜ë¦¬ì˜¤ | terminationGracePeriodSeconds | preStop sleep | ì´ìœ  |
|---------|------------------------------|---------------|------|
| **EC2 Pod** | 30-60ì´ˆ | 5ì´ˆ | Endpoints ì œê±° ëŒ€ê¸° |
| **Fargate Pod (ì¼ë°˜)** | 60-90ì´ˆ | 10-15ì´ˆ | ë” ê¸´ ë„¤íŠ¸ì›Œí¬ ì „íŒŒ ì‹œê°„ |
| **Fargate + ALB** | 90-120ì´ˆ | 15-20ì´ˆ | ALB deregistration delay ê³ ë ¤ |
| **Fargate ì¥ê¸° ì‘ì—…** | 120-300ì´ˆ | 10ì´ˆ | ë°°ì¹˜ ì‘ì—… ì™„ë£Œ ì‹œê°„ í™•ë³´ |

**Fargate ìµœì í™” ì˜ˆì‹œ:**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: fargate-web-app
  namespace: fargate-namespace
spec:
  replicas: 3
  selector:
    matchLabels:
      app: web-app
  template:
    metadata:
      labels:
        app: web-app
    spec:
      containers:
      - name: app
        image: myapp:v1
        ports:
        - containerPort: 8080
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          periodSeconds: 5
          failureThreshold: 3
          successThreshold: 1
        lifecycle:
          preStop:
            exec:
              command:
              - /bin/sh
              - -c
              - |
                # FargateëŠ” ë„¤íŠ¸ì›Œí¬ ì „íŒŒê°€ ëŠë¦´ ìˆ˜ ìˆìŒ
                echo "PreStop: Waiting for network propagation..."
                sleep 15

                # Readiness ì‹¤íŒ¨ ì‹ í˜¸ (ì„ íƒ ì‚¬í•­)
                # curl -X POST http://localhost:8080/shutdown

                echo "PreStop: Graceful shutdown initiated"
      terminationGracePeriodSeconds: 90  # EC2ëŠ” 60ì´ˆ, FargateëŠ” 90ì´ˆ
```

#### Fargate vs EC2 vs Auto Mode ë¹„êµí‘œ: Probe ê´€ì 

| í•­ëª© | EC2 Managed Node Group | Fargate | EKS Auto Mode |
|------|------------------------|---------|---------------|
| **ë…¸ë“œ ê´€ë¦¬** | ì‚¬ìš©ì ê´€ë¦¬ | AWS ê´€ë¦¬ | AWS ê´€ë¦¬ |
| **Pod ë°€ë„** | ë†’ìŒ (ì—¬ëŸ¬ Pod/ë…¸ë“œ) | ë‚®ìŒ (1 Pod = 1 MicroVM) | ì¤‘ê°„ (AWS ìµœì í™”) |
| **ì‹œì‘ ì‹œê°„** | ë¹ ë¦„ (5-35ì´ˆ) | ëŠë¦¼ (30-105ì´ˆ) | ë¹ ë¦„ (10-40ì´ˆ) |
| **Startup Probe failureThreshold** | 6-10 | 15-20 | 8-12 |
| **terminationGracePeriodSeconds** | 30-60ì´ˆ | 60-120ì´ˆ | 30-60ì´ˆ |
| **preStop sleep** | 5ì´ˆ | 10-15ì´ˆ | 5-10ì´ˆ |
| **ìë™ OS íŒ¨ì¹˜** | ìˆ˜ë™ (AMI ì—…ë°ì´íŠ¸) | ìë™ (ì˜ˆì¸¡ ë¶ˆê°€ eviction) | ìë™ (ê³„íšëœ eviction) |
| **PDB ì§€ì›** | ì™„ì „ ì§€ì› | ì œí•œì  (ìµœì„  ë…¸ë ¥) | ì™„ì „ ì§€ì› |
| **DaemonSet ì§€ì›** | ì™„ì „ ì§€ì› | ë¯¸ì§€ì› (ì‚¬ì´ë“œì¹´ í•„ìš”) | ì œí•œì  (AWS ê´€ë¦¬) |
| **ë¹„ìš© ëª¨ë¸** | ì¸ìŠ¤í„´ìŠ¤ë‹¹ (í•­ìƒ ì‹¤í–‰) | Podë‹¹ (ì‹¤í–‰ ì‹œê°„ë§Œ) | Podë‹¹ (ìµœì í™”ë¨) |
| **Spot ì§€ì›** | ì™„ì „ ì§€ì› (Termination Handler) | Fargate Spot ì œí•œì  | ìë™ ìµœì í™” |
| **ë„¤íŠ¸ì›Œí¬ ì •ì±…** | Calico/Cilium ì§€ì› | Security Groups for Podsë§Œ | AWS ê´€ë¦¬ ë„¤íŠ¸ì›Œí¬ ì •ì±… |

**ì„ íƒ ê°€ì´ë“œ:**

```mermaid
flowchart TD
    Start[ì›Œí¬ë¡œë“œ íŠ¹ì„± ë¶„ì„]

    Start --> Q1{ë…¸ë“œ ê´€ë¦¬ë¥¼<br/>ì™„ì „íˆ ìœ„ì„?}
    Q1 -->|ì˜ˆ| Q2{ë°°ì¹˜ ë˜ëŠ”<br/>ë²„ìŠ¤íŠ¸ ì›Œí¬ë¡œë“œ?}
    Q1 -->|ì•„ë‹ˆì˜¤| EC2[EC2 Managed<br/>Node Group]

    Q2 -->|ì˜ˆ| Fargate[Fargate]
    Q2 -->|ì•„ë‹ˆì˜¤| Q3{ìµœì‹  EKS ê¸°ëŠ¥<br/>í•„ìš”?}

    Q3 -->|ì˜ˆ| AutoMode[EKS Auto Mode]
    Q3 -->|ì•„ë‹ˆì˜¤| Fargate

    EC2 --> EC2Details[<b>EC2 íŠ¹ì§•</b><br/>âœ“ ì™„ì „í•œ ì œì–´<br/>âœ“ DaemonSet ì§€ì›<br/>âœ“ ìµœì € ë ˆì´í„´ì‹œ<br/>âœ— ìš´ì˜ ì˜¤ë²„í—¤ë“œ]

    Fargate --> FargateDetails[<b>Fargate íŠ¹ì§•</b><br/>âœ“ ë…¸ë“œ ê´€ë¦¬ ë¶ˆí•„ìš”<br/>âœ“ ê²©ë¦¬ëœ ë³´ì•ˆ<br/>âœ— ê¸´ ì‹œì‘ ì‹œê°„<br/>âœ— DaemonSet ë¯¸ì§€ì›]

    AutoMode --> AutoDetails[<b>Auto Mode íŠ¹ì§•</b><br/>âœ“ ìë™ ìµœì í™”<br/>âœ“ EC2 ìœ ì—°ì„±<br/>âœ“ ì˜ˆì¸¡ ê°€ëŠ¥í•œ íŒ¨ì¹˜<br/>â—‹ ë² íƒ€/GA ì „í™˜ ì¤‘]

    style Start fill:#4286f4,stroke:#2a6acf,color:#fff
    style EC2 fill:#ff9900,stroke:#cc7a00,color:#fff
    style Fargate fill:#9b59b6,stroke:#7d3c98,color:#fff
    style AutoMode fill:#34a853,stroke:#2a8642,color:#fff
```

:::tip Fargate í”„ë¡œë•ì…˜ ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] **Replica ìˆ˜**: ìµœì†Œ 3ê°œ ì´ìƒ (ìë™ eviction ëŒ€ë¹„)
- [ ] **Startup Probe**: failureThreshold 15-20 ì„¤ì • (ê¸´ ì‹œì‘ ì‹œê°„ ê³ ë ¤)
- [ ] **terminationGracePeriodSeconds**: 60-120ì´ˆ ì„¤ì •
- [ ] **preStop sleep**: 10-15ì´ˆ ì„¤ì • (ë„¤íŠ¸ì›Œí¬ ì „íŒŒ ëŒ€ê¸°)
- [ ] **PDB**: minAvailable ì„¤ì • (ìµœì„  ë…¸ë ¥ì´ì§€ë§Œ ê¶Œì¥)
- [ ] **ì´ë¯¸ì§€ ìµœì í™”**: ECR ì‚¬ìš©, ë ˆì´ì–´ ìµœì†Œí™”
- [ ] **ë¡œê¹…**: FireLens ì‚¬ì´ë“œì¹´ ë˜ëŠ” CloudWatch Logs í†µí•©
- [ ] **ëª¨ë‹ˆí„°ë§**: CloudWatch Container Insights í™œì„±í™”
- [ ] **ë¹„ìš© ìµœì í™”**: Fargate Spot ê²€í†  (ì¥ì•  í—ˆìš© ì›Œí¬ë¡œë“œ)
:::

:::info ì°¸ê³  ìë£Œ
- [AWS Fargate on EKS ê³µì‹ ë¬¸ì„œ](https://docs.aws.amazon.com/eks/latest/userguide/fargate.html)
- [Fargate Pod íŒ¨ì¹­ ë° ë³´ì•ˆ ì—…ë°ì´íŠ¸](https://docs.aws.amazon.com/eks/latest/userguide/fargate-pod-patching.html)
- [EKS Auto Mode ê°œìš”](https://aws.amazon.com/blogs/aws/streamline-kubernetes-cluster-management-with-new-amazon-eks-auto-mode/)
- [Fargateì™€ EC2 ë¹„êµ ê°€ì´ë“œ](https://aws.amazon.com/blogs/containers/)
:::

---

## 4. Init Container ëª¨ë²” ì‚¬ë¡€

Init ContainerëŠ” ë©”ì¸ ì»¨í…Œì´ë„ˆê°€ ì‹œì‘ë˜ê¸° ì „ì— ì‹¤í–‰ë˜ì–´ ì´ˆê¸°í™” ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

### 4.1 Init Container ë™ì‘ ì›ë¦¬

- Init ContainerëŠ” **ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰**ë©ë‹ˆë‹¤ (ë™ì‹œ ì‹¤í–‰ ë¶ˆê°€)
- ê° Init ContainerëŠ” ì„±ê³µì ìœ¼ë¡œ ì¢…ë£Œí•´ì•¼ ë‹¤ìŒ Init Containerê°€ ì‹œì‘ë©ë‹ˆë‹¤
- ëª¨ë“  Init Containerê°€ ì™„ë£Œë˜ì–´ì•¼ ë©”ì¸ ì»¨í…Œì´ë„ˆê°€ ì‹œì‘ë©ë‹ˆë‹¤
- Init Container ì‹¤íŒ¨ ì‹œ Podì˜ `restartPolicy`ì— ë”°ë¼ ì¬ì‹œì‘ë©ë‹ˆë‹¤

```mermaid
flowchart LR
    START[Pod ìƒì„±] --> INIT1[Init Container 1]
    INIT1 -->|ì„±ê³µ| INIT2[Init Container 2]
    INIT1 -->|ì‹¤íŒ¨| RESTART1[ì¬ì‹œì‘]
    RESTART1 --> INIT1

    INIT2 -->|ì„±ê³µ| MAIN[ë©”ì¸ ì»¨í…Œì´ë„ˆ ì‹œì‘]
    INIT2 -->|ì‹¤íŒ¨| RESTART2[ì¬ì‹œì‘]
    RESTART2 --> INIT1

    MAIN --> RUNNING[Pod Running]

    style INIT1 fill:#fbbc04,stroke:#c99603,color:#000
    style INIT2 fill:#fbbc04,stroke:#c99603,color:#000
    style MAIN fill:#34a853,stroke:#2a8642,color:#fff
```

### 4.2 Init Container ì‚¬ìš© ì‚¬ë¡€

#### ì‚¬ë¡€ 1: ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-app
spec:
  replicas: 3
  template:
    spec:
      # Init Container: DB ë§ˆì´ê·¸ë ˆì´ì…˜
      initContainers:
      - name: db-migration
        image: myapp/migrator:v1
        command:
        - /bin/sh
        - -c
        - |
          echo "Running database migrations..."
          /app/migrate up
          echo "Migrations completed"
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: url
      # ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
      containers:
      - name: app
        image: myapp/web-app:v1
        ports:
        - containerPort: 8080
```

#### ì‚¬ë¡€ 2: ì„¤ì • íŒŒì¼ ìƒì„± (ConfigMap ë³€í™˜)

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config-template
data:
  config.template: |
    server:
      port: {{ PORT }}
      host: {{ HOST }}
    database:
      url: {{ DB_URL }}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-with-config
spec:
  template:
    spec:
      initContainers:
      - name: config-generator
        image: busybox
        command:
        - /bin/sh
        - -c
        - |
          # í…œí”Œë¦¿ì—ì„œ ì‹¤ì œ ì„¤ì • íŒŒì¼ ìƒì„±
          sed -e "s/{{ PORT }}/$PORT/g" \
              -e "s/{{ HOST }}/$HOST/g" \
              -e "s|{{ DB_URL }}|$DB_URL|g" \
              /config-template/config.template > /config/config.yaml
          echo "Config file generated"
          cat /config/config.yaml
        env:
        - name: PORT
          value: "8080"
        - name: HOST
          value: "0.0.0.0"
        - name: DB_URL
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: url
        volumeMounts:
        - name: config-template
          mountPath: /config-template
        - name: config
          mountPath: /config
      containers:
      - name: app
        image: myapp/app:v1
        volumeMounts:
        - name: config
          mountPath: /app/config
      volumes:
      - name: config-template
        configMap:
          name: app-config-template
      - name: config
        emptyDir: {}
```

#### ì‚¬ë¡€ 3: ì¢…ì† ì„œë¹„ìŠ¤ ëŒ€ê¸°

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend-api
spec:
  template:
    spec:
      initContainers:
      # Init Container 1: DB ì—°ê²° ëŒ€ê¸°
      - name: wait-for-db
        image: busybox
        command:
        - /bin/sh
        - -c
        - |
          echo "Waiting for database..."
          until nc -z postgres-service 5432; do
            echo "Database not ready, sleeping..."
            sleep 2
          done
          echo "Database is ready"
      # Init Container 2: Redis ì—°ê²° ëŒ€ê¸°
      - name: wait-for-redis
        image: busybox
        command:
        - /bin/sh
        - -c
        - |
          echo "Waiting for Redis..."
          until nc -z redis-service 6379; do
            echo "Redis not ready, sleeping..."
            sleep 2
          done
          echo "Redis is ready"
      containers:
      - name: api
        image: myapp/backend-api:v1
        ports:
        - containerPort: 8080
```

:::tip ë” ë‚˜ì€ ëŒ€ì•ˆ: readinessProbe
ì¢…ì† ì„œë¹„ìŠ¤ ëŒ€ê¸°ëŠ” Init Containerë³´ë‹¤ ë©”ì¸ ì»¨í…Œì´ë„ˆì˜ Readiness Probeì—ì„œ ì²˜ë¦¬í•˜ëŠ” ê²ƒì´ ë” ìœ ì—°í•©ë‹ˆë‹¤. Init ContainerëŠ” í•œ ë²ˆë§Œ ì‹¤í–‰ë˜ë¯€ë¡œ, ë©”ì¸ ì»¨í…Œì´ë„ˆ ì‹¤í–‰ ì¤‘ ì¢…ì† ì„œë¹„ìŠ¤ê°€ ë‹¤ìš´ë˜ë©´ ëŒ€ì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
:::

#### ì‚¬ë¡€ 4: ë³¼ë¥¨ ê¶Œí•œ ì„¤ì •

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-with-volume
spec:
  template:
    spec:
      securityContext:
        fsGroup: 1000
      initContainers:
      - name: volume-permissions
        image: busybox
        command:
        - /bin/sh
        - -c
        - |
          echo "Setting up volume permissions..."
          chown -R 1000:1000 /data
          chmod -R 755 /data
          echo "Permissions set"
        volumeMounts:
        - name: data
          mountPath: /data
        securityContext:
          runAsUser: 0  # rootë¡œ ì‹¤í–‰ (ê¶Œí•œ ë³€ê²½ ìœ„í•´)
      containers:
      - name: app
        image: myapp/app:v1
        securityContext:
          runAsUser: 1000
          runAsNonRoot: true
        volumeMounts:
        - name: data
          mountPath: /app/data
      volumes:
      - name: data
        persistentVolumeClaim:
          claimName: app-data-pvc
```

### 4.3 Init Container vs Sidecar Container (Kubernetes 1.29+)

Kubernetes 1.29+ì—ì„œëŠ” Native Sidecar Containerê°€ ë„ì…ë˜ì—ˆìŠµë‹ˆë‹¤.

| íŠ¹ì„± | Init Container | Sidecar Container (1.29+) |
|------|---------------|---------------------------|
| **ì‹¤í–‰ íƒ€ì´ë°** | ë©”ì¸ ì»¨í…Œì´ë„ˆ ì „ ìˆœì°¨ ì‹¤í–‰ | ë©”ì¸ ì»¨í…Œì´ë„ˆì™€ ë™ì‹œ ì‹¤í–‰ |
| **ë¼ì´í”„ì‚¬ì´í´** | ì™„ë£Œ í›„ ì¢…ë£Œ | ë©”ì¸ ì»¨í…Œì´ë„ˆì™€ í•¨ê»˜ ì‹¤í–‰ |
| **ì¬ì‹œì‘** | ì‹¤íŒ¨ ì‹œ Pod ì „ì²´ ì¬ì‹œì‘ | ê°œë³„ ì¬ì‹œì‘ ê°€ëŠ¥ |
| **ì‚¬ìš© ì‚¬ë¡€** | ì¼íšŒì„± ì´ˆê¸°í™” ì‘ì—… | ì§€ì†ì ì¸ ë³´ì¡° ì‘ì—… (ë¡œê·¸ ìˆ˜ì§‘, í”„ë¡ì‹œ) |

**Sidecar Container ì˜ˆì‹œ (K8s 1.29+):**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: app-with-sidecar
spec:
  initContainers:
  # Native sidecar: restartPolicyë¥¼ Alwaysë¡œ ì„¤ì •
  - name: log-collector
    image: fluent/fluent-bit:2.0
    restartPolicy: Always  # Sidecarë¡œ ë™ì‘
    volumeMounts:
    - name: logs
      mountPath: /var/log/app
  containers:
  - name: app
    image: myapp/app:v1
    volumeMounts:
    - name: logs
      mountPath: /app/logs
  volumes:
  - name: logs
    emptyDir: {}
```

---

## 5. Pod Lifecycle Hooks

Lifecycle HooksëŠ” ì»¨í…Œì´ë„ˆì˜ íŠ¹ì • ì‹œì ì— ì»¤ìŠ¤í…€ ë¡œì§ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.

### 5.1 PostStart Hook

PostStart Hookì€ ì»¨í…Œì´ë„ˆê°€ ìƒì„±ëœ ì§í›„ ì‹¤í–‰ë©ë‹ˆë‹¤.

**íŠ¹ì§•:**
- ì»¨í…Œì´ë„ˆì˜ ENTRYPOINTì™€ **ë¹„ë™ê¸°ì ìœ¼ë¡œ** ì‹¤í–‰ë©ë‹ˆë‹¤
- Hookì´ ì‹¤íŒ¨í•˜ë©´ ì»¨í…Œì´ë„ˆê°€ ì¢…ë£Œë©ë‹ˆë‹¤
- Hook ì™„ë£Œë¥¼ ê¸°ë‹¤ë¦¬ì§€ ì•Šê³  ì»¨í…Œì´ë„ˆëŠ” `Running` ìƒíƒœê°€ ë©ë‹ˆë‹¤

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: poststart-example
spec:
  containers:
  - name: app
    image: nginx
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/sh
          - -c
          - |
            echo "Container started at $(date)" >> /var/log/lifecycle.log
            # ì´ˆê¸° ì„¤ì • ì‘ì—…
            mkdir -p /app/cache
            chown -R nginx:nginx /app/cache
```

**ì‚¬ìš© ì‚¬ë¡€:**
- ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì•Œë¦¼ ì „ì†¡
- ì´ˆê¸° ìºì‹œ warming
- ë©”íƒ€ë°ì´í„° ê¸°ë¡

:::warning PostStart Hook ì£¼ì˜ì‚¬í•­
PostStart Hookì€ ì»¨í…Œì´ë„ˆ ì‹œì‘ê³¼ **ë¹„ë™ê¸°**ë¡œ ì‹¤í–‰ë˜ë¯€ë¡œ, Hookì´ ì™„ë£Œë˜ê¸° ì „ì— ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì‹œì‘ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì• í”Œë¦¬ì¼€ì´ì…˜ì´ Hookì˜ ì‘ì—…ì— ì˜ì¡´í•œë‹¤ë©´ Init Containerë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
:::

### 5.2 PreStop Hook

PreStop Hookì€ ì»¨í…Œì´ë„ˆ ì¢…ë£Œ ìš”ì²­ ì‹œ, SIGTERM ì „ì— ì‹¤í–‰ë©ë‹ˆë‹¤.

**íŠ¹ì§•:**
- **ë™ê¸°ì ìœ¼ë¡œ** ì‹¤í–‰ë©ë‹ˆë‹¤ (ì™„ë£Œë  ë•Œê¹Œì§€ SIGTERM ì „ì†¡ ì§€ì—°)
- Hook ì‹¤í–‰ ì‹œê°„ì€ `terminationGracePeriodSeconds`ì— í¬í•¨ë©ë‹ˆë‹¤
- Hook ì‹¤íŒ¨ ì—¬ë¶€ì™€ ë¬´ê´€í•˜ê²Œ SIGTERMì´ ì „ì†¡ë©ë‹ˆë‹¤

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: prestop-example
spec:
  containers:
  - name: app
    image: myapp/app:v1
    lifecycle:
      preStop:
        exec:
          command:
          - /bin/sh
          - -c
          - |
            # 1. Endpoint ì œê±° ëŒ€ê¸°
            sleep 5

            # 2. ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒíƒœ ì €ì¥
            curl -X POST http://localhost:8080/admin/save-state

            # 3. ë¡œê·¸ í”ŒëŸ¬ì‹œ
            kill -USR1 1  # ì• í”Œë¦¬ì¼€ì´ì…˜ì— USR1 ì‹œê·¸ë„ ì „ì†¡

            # 4. SIGTERM ì „ì†¡ (PID 1)
            kill -TERM 1
  terminationGracePeriodSeconds: 60
```

**ì‚¬ìš© ì‚¬ë¡€:**
- Endpoint ì œê±° ëŒ€ê¸° (ë¬´ì¤‘ë‹¨ ë°°í¬)
- ì§„í–‰ ì¤‘ì¸ ì‘ì—… ìƒíƒœ ì €ì¥
- ì™¸ë¶€ ì‹œìŠ¤í…œì— ì¢…ë£Œ ì•Œë¦¼
- ë¡œê·¸ ë²„í¼ í”ŒëŸ¬ì‹œ

### 5.3 Hook ì‹¤í–‰ ë©”ì»¤ë‹ˆì¦˜

KubernetesëŠ” ë‘ ê°€ì§€ ë°©ì‹ìœ¼ë¡œ Hookì„ ì‹¤í–‰í•©ë‹ˆë‹¤.

| ë©”ì»¤ë‹ˆì¦˜ | ì„¤ëª… | ì¥ì  | ë‹¨ì  |
|----------|------|------|------|
| **exec** | ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì—ì„œ ëª…ë ¹ ì‹¤í–‰ | ì»¨í…Œì´ë„ˆ íŒŒì¼ì‹œìŠ¤í…œ ì ‘ê·¼ ê°€ëŠ¥ | ì˜¤ë²„í—¤ë“œ ë†’ìŒ |
| **httpGet** | HTTP GET ìš”ì²­ ì „ì†¡ | ë„¤íŠ¸ì›Œí¬ ê¸°ë°˜, ê°€ë²¼ì›€ | ì• í”Œë¦¬ì¼€ì´ì…˜ì´ HTTP ì§€ì› í•„ìš” |

#### exec Hook ì˜ˆì‹œ

```yaml
lifecycle:
  preStop:
    exec:
      command:
      - /bin/bash
      - -c
      - |
        echo "Shutting down" | tee /var/log/shutdown.log
        /app/cleanup.sh
```

#### httpGet Hook ì˜ˆì‹œ

```yaml
lifecycle:
  preStop:
    httpGet:
      path: /shutdown
      port: 8080
      scheme: HTTP
      httpHeaders:
      - name: X-Shutdown-Token
        value: "secret-token"
```

:::warning Hook ì‹¤í–‰ì€ "At Least Once"
KubernetesëŠ” Hookì´ ìµœì†Œ í•œ ë²ˆ ì‹¤í–‰ë˜ë„ë¡ ë³´ì¥í•˜ì§€ë§Œ, ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Hook ë¡œì§ì€ **ë©±ë“±ì„±(idempotent)**ì„ ë³´ì¥í•´ì•¼ í•©ë‹ˆë‹¤.
:::

---

## 6. ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ìµœì í™”ì™€ ì‹œì‘ ì‹œê°„

ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ í¬ê¸°ì™€ êµ¬ì¡°ëŠ” Pod ì‹œì‘ ì‹œê°„ì— ì§ì ‘ì ì¸ ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤.

### 6.1 ë©€í‹°ìŠ¤í…Œì´ì§€ ë¹Œë“œ

ë©€í‹°ìŠ¤í…Œì´ì§€ ë¹Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì¢… ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ìµœì†Œí™”í•©ë‹ˆë‹¤.

#### Go ì• í”Œë¦¬ì¼€ì´ì…˜

```dockerfile
# ë¹Œë“œ ìŠ¤í…Œì´ì§€
FROM golang:1.22-alpine AS builder

WORKDIR /app
COPY go.mod go.sum ./
RUN go mod download

COPY . .
RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -ldflags="-s -w" -o main .

# ì‹¤í–‰ ìŠ¤í…Œì´ì§€ (scratch: 5MB ì´í•˜)
FROM scratch

COPY --from=builder /app/main /main
COPY --from=builder /etc/ssl/certs/ca-certificates.crt /etc/ssl/certs/

USER 65534:65534
ENTRYPOINT ["/main"]
```

**ê²°ê³¼:**
- ë¹Œë“œ ì´ë¯¸ì§€: 300MB+
- ìµœì¢… ì´ë¯¸ì§€: 5-10MB
- ì‹œì‘ ì‹œê°„: 1ì´ˆ ë¯¸ë§Œ

#### Node.js ì• í”Œë¦¬ì¼€ì´ì…˜

```dockerfile
# ë¹Œë“œ ìŠ¤í…Œì´ì§€
FROM node:20-alpine AS builder

WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production

COPY . .

# ì‹¤í–‰ ìŠ¤í…Œì´ì§€
FROM node:20-alpine

# ë³´ì•ˆ: non-root ì‚¬ìš©ì
RUN addgroup -g 1001 -S nodejs && \
    adduser -S nodejs -u 1001

WORKDIR /app

# í”„ë¡œë•ì…˜ ì˜ì¡´ì„±ë§Œ ë³µì‚¬
COPY --from=builder --chown=nodejs:nodejs /app/node_modules ./node_modules
COPY --chown=nodejs:nodejs . .

USER nodejs

EXPOSE 8080
CMD ["node", "server.js"]
```

**ìµœì í™” íŒ:**
- `npm ci` ì‚¬ìš© (npm installë³´ë‹¤ ë¹ ë¥´ê³  ì•ˆì •ì )
- `--only=production`ìœ¼ë¡œ devDependencies ì œì™¸
- ë ˆì´ì–´ ìºì‹± í™œìš© (COPY package*.json ë¨¼ì €)

#### Java/Spring Boot ì• í”Œë¦¬ì¼€ì´ì…˜

```dockerfile
# ë¹Œë“œ ìŠ¤í…Œì´ì§€
FROM maven:3.9-eclipse-temurin-21 AS builder

WORKDIR /app
COPY pom.xml .
RUN mvn dependency:go-offline

COPY src ./src
RUN mvn clean package -DskipTests

# ì‹¤í–‰ ìŠ¤í…Œì´ì§€
FROM eclipse-temurin:21-jre-alpine

RUN addgroup -S spring && adduser -S spring -G spring
USER spring:spring

WORKDIR /app
COPY --from=builder /app/target/*.jar app.jar

EXPOSE 8080
ENTRYPOINT ["java", "-Xms512m", "-Xmx1g", "-jar", "app.jar"]
```

### 6.2 ì´ë¯¸ì§€ í”„ë¦¬í’€ ì „ëµ

EKSì—ì„œ ì´ë¯¸ì§€ í”„ë¦¬í’€(pre-pull)ì„ í™œìš©í•˜ì—¬ Pod ì‹œì‘ ì‹œê°„ì„ ë‹¨ì¶•í•©ë‹ˆë‹¤.

#### Karpenter ì´ë¯¸ì§€ í”„ë¦¬í’€

```yaml
apiVersion: karpenter.k8s.aws/v1beta1
kind: EC2NodeClass
metadata:
  name: default
spec:
  amiFamily: AL2
  userData: |
    #!/bin/bash
    # ìì£¼ ì‚¬ìš©í•˜ëŠ” ì´ë¯¸ì§€ í”„ë¦¬í’€
    docker pull myapp/backend:v2.1.0
    docker pull myapp/frontend:v1.5.3
    docker pull redis:7-alpine
    docker pull postgres:16-alpine
```

#### DaemonSetìœ¼ë¡œ ì´ë¯¸ì§€ í”„ë¦¬í’€

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: image-prepuller
  namespace: kube-system
spec:
  selector:
    matchLabels:
      app: image-prepuller
  template:
    metadata:
      labels:
        app: image-prepuller
    spec:
      initContainers:
      # í”„ë¦¬í’€í•  ì´ë¯¸ì§€ë§ˆë‹¤ init container ì¶”ê°€
      - name: prepull-backend
        image: myapp/backend:v2.1.0
        command: ["sh", "-c", "echo 'Image pulled'"]
      - name: prepull-frontend
        image: myapp/frontend:v1.5.3
        command: ["sh", "-c", "echo 'Image pulled'"]
      containers:
      - name: pause
        image: registry.k8s.io/pause:3.9
        resources:
          requests:
            cpu: 1m
            memory: 1Mi
```

### 6.3 distrolessì™€ scratch ì´ë¯¸ì§€

Googleì˜ distroless ì´ë¯¸ì§€ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ì— í•„ìš”í•œ ìµœì†Œí•œì˜ íŒŒì¼ë§Œ í¬í•¨í•©ë‹ˆë‹¤.

#### distroless ì˜ˆì‹œ

```dockerfile
FROM golang:1.22-alpine AS builder
WORKDIR /app
COPY . .
RUN CGO_ENABLED=0 go build -o main .

# distroless base
FROM gcr.io/distroless/static-debian12

COPY --from=builder /app/main /main
USER 65534:65534
ENTRYPOINT ["/main"]
```

**distroless ì¥ì :**
- ìµœì†Œ ê³µê²© í‘œë©´ (ì‰˜, íŒ¨í‚¤ì§€ ë§¤ë‹ˆì € ì—†ìŒ)
- ì‘ì€ ì´ë¯¸ì§€ í¬ê¸°
- CVE ì·¨ì•½ì  ê°ì†Œ

**scratch vs distroless:**

| ì´ë¯¸ì§€ | í¬ê¸° | í¬í•¨ ì‚¬í•­ | ì í•©í•œ ê²½ìš° |
|--------|------|-----------|------------|
| **scratch** | 0MB | ë¹ˆ íŒŒì¼ì‹œìŠ¤í…œ | ì™„ì „ ì •ì  ë°”ì´ë„ˆë¦¬ (Go, Rust) |
| **distroless/static** | ~2MB | CA certificates, tzdata | ì •ì  ë°”ì´ë„ˆë¦¬ + TLS/íƒ€ì„ì¡´ í•„ìš” |
| **distroless/base** | ~20MB | glibc, libssl | ë™ì  ë§í¬ ë°”ì´ë„ˆë¦¬ |

### 6.4 ì‹œì‘ ì‹œê°„ ë²¤ì¹˜ë§ˆí¬

ë‹¤ì–‘í•œ ì´ë¯¸ì§€ ì „ëµì˜ ì‹œì‘ ì‹œê°„ ë¹„êµ (EKS 1.30, m6i.xlarge):

| ì• í”Œë¦¬ì¼€ì´ì…˜ | ë² ì´ìŠ¤ ì´ë¯¸ì§€ | ì´ë¯¸ì§€ í¬ê¸° | Pull ì‹œê°„ | ì‹œì‘ ì‹œê°„ | ì´ ì‹œê°„ |
|-------------|--------------|-----------|----------|----------|---------|
| Go API | ubuntu:22.04 | 150MB | 8ì´ˆ | 0.5ì´ˆ | **8.5ì´ˆ** |
| Go API | alpine:3.19 | 15MB | 2ì´ˆ | 0.5ì´ˆ | **2.5ì´ˆ** |
| Go API | distroless/static | 5MB | 1ì´ˆ | 0.5ì´ˆ | **1.5ì´ˆ** |
| Go API | scratch | 3MB | 0.8ì´ˆ | 0.5ì´ˆ | **1.3ì´ˆ** |
| Node.js API | node:20 | 350MB | 15ì´ˆ | 2ì´ˆ | **17ì´ˆ** |
| Node.js API | node:20-alpine | 120MB | 6ì´ˆ | 2ì´ˆ | **8ì´ˆ** |
| Spring Boot | eclipse-temurin:21 | 450MB | 20ì´ˆ | 15ì´ˆ | **35ì´ˆ** |
| Spring Boot | eclipse-temurin:21-jre-alpine | 180MB | 10ì´ˆ | 15ì´ˆ | **25ì´ˆ** |
| Python Flask | python:3.12 | 400MB | 18ì´ˆ | 3ì´ˆ | **21ì´ˆ** |
| Python Flask | python:3.12-slim | 130MB | 7ì´ˆ | 3ì´ˆ | **10ì´ˆ** |
| Python Flask | python:3.12-alpine | 50MB | 3ì´ˆ | 3ì´ˆ | **6ì´ˆ** |

**ìµœì í™” ê¶Œì¥ì‚¬í•­:**
1. **ë©€í‹°ìŠ¤í…Œì´ì§€ ë¹Œë“œ** ì‚¬ìš© â†’ 50-90% í¬ê¸° ê°ì†Œ
2. **alpine ë˜ëŠ” distroless** ì„ íƒ â†’ Pull ì‹œê°„ 50-80% ë‹¨ì¶•
3. **ì´ë¯¸ì§€ ìºì‹±** í™œì„±í™” â†’ ì¬ë°°í¬ ì‹œ Pull ì‹œê°„ ê±°ì˜ 0
4. **Startup Probe** ì„¤ì • â†’ ëŠë¦° ì‹œì‘ ì•± ë³´í˜¸

---

## 7. ì¢…í•© ì²´í¬ë¦¬ìŠ¤íŠ¸ & ì°¸ê³  ìë£Œ

### 7.1 í”„ë¡œë•ì…˜ ë°°í¬ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸

#### Pod í—¬ìŠ¤ì²´í¬

| í•­ëª© | í™•ì¸ ì‚¬í•­ | ìš°ì„ ìˆœìœ„ |
|------|----------|---------|
| **Startup Probe** | ì‹œì‘ì´ ëŠë¦° ì•±(30ì´ˆ+)ì— Startup Probe ì„¤ì • | ë†’ìŒ |
| **Liveness Probe** | ì™¸ë¶€ ì˜ì¡´ì„± ì œì™¸, ë‚´ë¶€ ìƒíƒœë§Œ í™•ì¸ | í•„ìˆ˜ |
| **Readiness Probe** | ì™¸ë¶€ ì˜ì¡´ì„± í¬í•¨, íŠ¸ë˜í”½ ìˆ˜ì‹  ì¤€ë¹„ í™•ì¸ | í•„ìˆ˜ |
| **Probe íƒ€ì´ë°** | failureThreshold Ã— periodSecondsê°€ ì ì ˆí•œì§€ í™•ì¸ | ì¤‘ê°„ |
| **Probe ê²½ë¡œ** | `/healthz` (liveness), `/ready` (readiness) ë¶„ë¦¬ | ë†’ìŒ |
| **ALB í—¬ìŠ¤ì²´í¬** | Readiness Probeì™€ ê²½ë¡œ ì¼ì¹˜ í™•ì¸ | ë†’ìŒ |
| **Pod Readiness Gates** | ALB/NLB ì‚¬ìš© ì‹œ í™œì„±í™” | ì¤‘ê°„ |

#### Graceful Shutdown

| í•­ëª© | í™•ì¸ ì‚¬í•­ | ìš°ì„ ìˆœìœ„ |
|------|----------|---------|
| **preStop Hook** | `sleep 5` ì¶”ê°€ë¡œ Endpoint ì œê±° ëŒ€ê¸° | í•„ìˆ˜ |
| **SIGTERM ì²˜ë¦¬** | ì• í”Œë¦¬ì¼€ì´ì…˜ì— SIGTERM í•¸ë“¤ëŸ¬ êµ¬í˜„ | í•„ìˆ˜ |
| **terminationGracePeriodSeconds** | preStop + Shutdown ì‹œê°„ ê³ ë ¤í•˜ì—¬ ì„¤ì • (30-120ì´ˆ) | í•„ìˆ˜ |
| **Connection Draining** | HTTP Keep-Alive, WebSocket ì—°ê²° ì •ë¦¬ ë¡œì§ | ë†’ìŒ |
| **ë°ì´í„° ì •ë¦¬** | DB ì—°ê²°, ë©”ì‹œì§€ í, íŒŒì¼ í•¸ë“¤ ì •ë¦¬ | ë†’ìŒ |
| **Readiness ì‹¤íŒ¨** | Shutdown ì‹œì‘ ì‹œ Readiness Probe ì‹¤íŒ¨ ì‘ë‹µ | ì¤‘ê°„ |

#### ë¦¬ì†ŒìŠ¤ ë° ì´ë¯¸ì§€

| í•­ëª© | í™•ì¸ ì‚¬í•­ | ìš°ì„ ìˆœìœ„ |
|------|----------|---------|
| **ë¦¬ì†ŒìŠ¤ requests/limits** | CPU/ë©”ëª¨ë¦¬ requests ì„¤ì • (HPA, VPA ê¸°ì¤€) | í•„ìˆ˜ |
| **ì´ë¯¸ì§€ í¬ê¸°** | ë©€í‹°ìŠ¤í…Œì´ì§€ ë¹Œë“œë¡œ ìµœì†Œí™” (100MB ì´í•˜ ëª©í‘œ) | ì¤‘ê°„ |
| **ì´ë¯¸ì§€ íƒœê·¸** | `latest` íƒœê·¸ ì‚¬ìš© ê¸ˆì§€, semantic versioning ì‚¬ìš© | í•„ìˆ˜ |
| **ë³´ì•ˆ ìŠ¤ìº”** | Trivy, Grypeë¡œ CVE ìŠ¤ìº” | ë†’ìŒ |
| **non-root ì‚¬ìš©ì** | ì»¨í…Œì´ë„ˆë¥¼ non-rootë¡œ ì‹¤í–‰ | ë†’ìŒ |

#### ê³ ê°€ìš©ì„±

| í•­ëª© | í™•ì¸ ì‚¬í•­ | ìš°ì„ ìˆœìœ„ |
|------|----------|---------|
| **PodDisruptionBudget** | minAvailable ë˜ëŠ” maxUnavailable ì„¤ì • | í•„ìˆ˜ |
| **Topology Spread** | Multi-AZ ë¶„ì‚° ì„¤ì • | ë†’ìŒ |
| **Replica ìˆ˜** | ìµœì†Œ 2ê°œ ì´ìƒ (í”„ë¡œë•ì…˜ 3ê°œ+) | í•„ìˆ˜ |
| **Affinity/Anti-Affinity** | ë™ì¼ ë…¸ë“œ ë°°ì¹˜ ë°©ì§€ | ì¤‘ê°„ |

### 7.2 ê´€ë ¨ ë¬¸ì„œ

- [EKS ì¥ì•  ì§„ë‹¨ ë° ëŒ€ì‘ ê°€ì´ë“œ](/docs/operations-observability/eks-debugging-guide) â€” Probe ë””ë²„ê¹…, Pod íŠ¸ëŸ¬ë¸”ìŠˆíŒ…
- [EKS ê³ ê°€ìš©ì„± ì•„í‚¤í…ì²˜ ê°€ì´ë“œ](/docs/operations-observability/eks-resiliency-guide) â€” PDB, Graceful Shutdown, Pod Readiness Gates
- [Karpenterë¥¼ í™œìš©í•œ ì´ˆê³ ì† ì˜¤í† ìŠ¤ì¼€ì¼ë§](/docs/infrastructure-optimization/karpenter-autoscaling) â€” Karpenter Disruption, Spot ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬

### 7.3 ì™¸ë¶€ ì°¸ì¡°

#### Kubernetes ê³µì‹ ë¬¸ì„œ

- [Configure Liveness, Readiness and Startup Probes](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/)
- [Pod Lifecycle](https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/)
- [Init Containers](https://kubernetes.io/docs/concepts/workloads/pods/init-containers/)
- [Container Lifecycle Hooks](https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/)
- [Termination of Pods](https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#pod-termination)

#### AWS ê³µì‹ ë¬¸ì„œ

- [EKS Best Practices - Application Health Checks](https://docs.aws.amazon.com/eks/latest/best-practices/reliability.html)
- [AWS Load Balancer Controller - Pod Readiness Gate](https://kubernetes-sigs.github.io/aws-load-balancer-controller/v2.7/deploy/pod_readiness_gate/)
- [EKS Workshop - Health Checks](https://www.eksworkshop.com/docs/fundamentals/managed-node-groups/health-checks/)

#### Red Hat OpenShift ë¬¸ì„œ

- [Monitoring Application Health by Using Health Checks](https://docs.openshift.com/container-platform/4.18/applications/application-health.html) â€” Liveness, Readiness, Startup Probe êµ¬ì„±
- [Using Init Containers](https://docs.openshift.com/container-platform/4.18/nodes/containers/nodes-containers-init.html) â€” Init Container íŒ¨í„´ ë° ìš´ì˜
- [Graceful Cluster Shutdown](https://docs.openshift.com/container-platform/4.18/backup_and_restore/graceful-cluster-shutdown.html) â€” Graceful Shutdown ì ˆì°¨

#### ì¶”ê°€ ì°¸ê³  ìë£Œ

- [gRPC Health Checking Protocol](https://github.com/grpc/grpc/blob/master/doc/health-checking.md)
- [Google Distroless Images](https://github.com/GoogleContainerTools/distroless)
- [AWS Prescriptive Guidance - Container Image Optimization](https://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/optimize-docker-images-for-eks.html)
- [Learnk8s - Graceful Shutdown](https://learnk8s.io/graceful-shutdown)

### 7.4 EKS Auto Mode í™˜ê²½ ì²´í¬ë¦¬ìŠ¤íŠ¸

EKS Auto ModeëŠ” Kubernetes ìš´ì˜ì„ ìë™í™”í•˜ì—¬ ì¸í”„ë¼ ê´€ë¦¬ ë¶€ë‹´ì„ ì¤„ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ Probe ì„¤ì •ê³¼ Pod ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬ì—ì„œëŠ” Auto Mode íŠ¹ìœ ì˜ ê³ ë ¤ì‚¬í•­ì´ ìˆìŠµë‹ˆë‹¤.

#### EKS Auto Modeë€?

EKS Auto Mode(2024ë…„ 12ì›” ë°œí‘œ, ì§€ì† ê°œì„  ì¤‘)ëŠ” ë‹¤ìŒì„ ìë™í™”í•©ë‹ˆë‹¤:
- ì»´í“¨íŒ… ì¸ìŠ¤í„´ìŠ¤ ì„ íƒ ë° í”„ë¡œë¹„ì €ë‹
- ë™ì  ë¦¬ì†ŒìŠ¤ ìŠ¤ì¼€ì¼ë§
- OS íŒ¨ì¹˜ ë° ë³´ì•ˆ ì—…ë°ì´íŠ¸
- ì½”ì–´ ì• ë“œì˜¨ ê´€ë¦¬ (VPC CNI, CoreDNS, kube-proxy ë“±)
- Graviton + Spot ìµœì í™”

#### Auto Mode íŠ¹ì„±ì´ Probeì— ë¯¸ì¹˜ëŠ” ì˜í–¥

| í•­ëª© | Auto Mode | ìˆ˜ë™ ê´€ë¦¬ | Probe ì„¤ì • ê¶Œì¥ ì‚¬í•­ |
|------|----------|----------|---------------------|
| **ë…¸ë“œ êµì²´ ì£¼ê¸°** | ë¹ˆë²ˆí•¨ (OS íŒ¨ì¹˜, ìµœì í™”) | ëª…ì‹œì  ì—…ê·¸ë ˆì´ë“œ ì‹œë§Œ | `terminationGracePeriodSeconds`: 90ì´ˆ ì´ìƒ |
| **ë…¸ë“œ ë‹¤ì–‘ì„±** | ìë™ ì¸ìŠ¤í„´ìŠ¤ ì„ íƒ (ë‹¤ì–‘í•œ íƒ€ì…) | ê³ ì • íƒ€ì… | `startupProbe` failureThreshold ë†’ê²Œ (ì¸ìŠ¤í„´ìŠ¤ë³„ ì‹œì‘ ì‹œê°„ ì°¨ì´) |
| **Spot í†µí•©** | ìë™ Spot/On-Demand í˜¼í•© | ìˆ˜ë™ ì„¤ì • | Spot ì¤‘ë‹¨ ëŒ€ë¹„ `preStop` sleep í•„ìˆ˜ |
| **ë„¤íŠ¸ì›Œí¬ ìµœì í™”** | VPC CNI ìë™ íŠœë‹ | ìˆ˜ë™ ì„¤ì • | Container Network Observability í™œì„±í™” ê¶Œì¥ |

#### Auto Mode í™˜ê²½ Probe ì²´í¬ë¦¬ìŠ¤íŠ¸

| í•­ëª© | í™•ì¸ ì‚¬í•­ | ìš°ì„ ìˆœìœ„ | Auto Mode íŠ¹ì´ì‚¬í•­ |
|------|----------|---------|-------------------|
| **Startup Probe failureThreshold** | 30 ì´ìƒ ì„¤ì • (ì¸ìŠ¤í„´ìŠ¤ ë‹¤ì–‘ì„± ê³ ë ¤) | ë†’ìŒ | Auto ModeëŠ” ì¸ìŠ¤í„´ìŠ¤ íƒ€ì…ì„ ìë™ ì„ íƒí•˜ë¯€ë¡œ ì‹œì‘ ì‹œê°„ í¸ì°¨ í¼ |
| **terminationGracePeriodSeconds** | 90ì´ˆ ì´ìƒ (ë¹ˆë²ˆí•œ ë…¸ë“œ êµì²´ ëŒ€ë¹„) | í•„ìˆ˜ | OS íŒ¨ì¹˜ ì‹œ ìë™ eviction ë°œìƒ ë¹ˆë„ ë†’ìŒ |
| **readinessProbe periodSeconds** | 5ì´ˆ (ë¹ ë¥¸ íŠ¸ë˜í”½ ì „í™˜) | ë†’ìŒ | ë…¸ë“œ êµì²´ ì‹œ ì‹ ì†í•œ Pod Ready ìƒíƒœ ì „í™˜ í•„ìš” |
| **Container Network Observability** | í™œì„±í™” (ë„¤íŠ¸ì›Œí¬ ì´ìƒ ì¡°ê¸° ê°ì§€) | ì¤‘ê°„ | VPC CNI ìë™ íŠœë‹ íš¨ê³¼ ê²€ì¦ |
| **PodDisruptionBudget** | í•„ìˆ˜ ì„¤ì • (ë…¸ë“œ êµì²´ ì¤‘ ê°€ìš©ì„± ë³´ì¥) | í•„ìˆ˜ | Auto Mode ë…¸ë“œ êµì²´ ì¤‘ PDB ì¤€ìˆ˜ |
| **Topology Spread Constraints** | ë…¸ë“œ/AZ ë¶„ì‚° ëª…ì‹œ | ë†’ìŒ | Auto Modeê°€ ì¸ìŠ¤í„´ìŠ¤ ì„ íƒí•˜ì§€ë§Œ ë¶„ì‚°ì€ ì‚¬ìš©ì ì±…ì„ |

#### Auto Mode vs ìˆ˜ë™ ê´€ë¦¬ ì‹œ Probe ì„¤ì • ì°¨ì´

**ìˆ˜ë™ ê´€ë¦¬ í´ëŸ¬ìŠ¤í„°:**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-manual-cluster
spec:
  replicas: 3
  template:
    spec:
      nodeSelector:
        node.kubernetes.io/instance-type: m5.xlarge  # ê³ ì • íƒ€ì…
      containers:
      - name: api
        image: myapp/api:v1
        # ì¸ìŠ¤í„´ìŠ¤ íƒ€ì… ê³ ì •ìœ¼ë¡œ ì˜ˆì¸¡ ê°€ëŠ¥í•œ ì‹œì‘ ì‹œê°„
        startupProbe:
          httpGet:
            path: /healthz
            port: 8080
          failureThreshold: 10  # ë‚®ê²Œ ì„¤ì • ê°€ëŠ¥
          periodSeconds: 5
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          periodSeconds: 5
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh", "-c", "sleep 5"]
      terminationGracePeriodSeconds: 60  # í‘œì¤€ ì„¤ì •
```

**Auto Mode í´ëŸ¬ìŠ¤í„°:**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-auto-mode
  annotations:
    # Auto Mode ìµœì í™” íŒíŠ¸
    eks.amazonaws.com/compute-type: "auto"
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: api
        # Auto ModeëŠ” ìë™ìœ¼ë¡œ ìµœì  ì¸ìŠ¤í„´ìŠ¤ ì„ íƒ
    spec:
      # nodeSelector ì—†ìŒ - Auto Modeê°€ ìë™ ì„ íƒ
      topologySpreadConstraints:
      - maxSkew: 1
        topologyKey: topology.kubernetes.io/zone
        whenUnsatisfiable: DoNotSchedule
        labelSelector:
          matchLabels:
            app: api
      containers:
      - name: api
        image: myapp/api:v1
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          # Auto Modeê°€ ìµœì  ì¸ìŠ¤í„´ìŠ¤ ì„ íƒ
        # ì¸ìŠ¤í„´ìŠ¤ ë‹¤ì–‘ì„± ê³ ë ¤í•œ ê¸´ ì‹œì‘ ì‹œê°„
        startupProbe:
          httpGet:
            path: /healthz
            port: 8080
          failureThreshold: 30  # ë†’ê²Œ ì„¤ì • (ë‹¤ì–‘í•œ ì¸ìŠ¤í„´ìŠ¤ íƒ€ì… ëŒ€ì‘)
          periodSeconds: 5
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          periodSeconds: 5
          failureThreshold: 2
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8080
          periodSeconds: 10
          failureThreshold: 3
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh", "-c", "sleep 10"]  # ì—¬ìœ  ìˆê²Œ
      terminationGracePeriodSeconds: 90  # OS íŒ¨ì¹˜ ìë™ eviction ëŒ€ë¹„
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: api-pdb
spec:
  minAvailable: 2  # Auto Mode ë…¸ë“œ êµì²´ ì¤‘ ê°€ìš©ì„± ë³´ì¥
  selector:
    matchLabels:
      app: api
```

#### Auto Mode í™˜ê²½ì˜ OS íŒ¨ì¹˜ ìë™ eviction ëŒ€ì‘

Auto ModeëŠ” ì£¼ê¸°ì ìœ¼ë¡œ OS íŒ¨ì¹˜ë¥¼ ìœ„í•´ ë…¸ë“œë¥¼ êµì²´í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì—ì„œ Pod Evictionì´ ìë™ìœ¼ë¡œ ë°œìƒí•©ë‹ˆë‹¤.

**OS íŒ¨ì¹˜ eviction ì‹œë‚˜ë¦¬ì˜¤:**

```mermaid
sequenceDiagram
    participant AutoMode as EKS Auto Mode
    participant Node_Old as ê¸°ì¡´ ë…¸ë“œ
    participant Node_New as ìƒˆ ë…¸ë“œ
    participant Pod as Pod

    Note over AutoMode: OS íŒ¨ì¹˜ í•„ìš” ê°ì§€

    AutoMode->>Node_New: ìƒˆ ë…¸ë“œ í”„ë¡œë¹„ì €ë‹
    Node_New->>AutoMode: ë…¸ë“œ Ready

    AutoMode->>Node_Old: Cordon (ìŠ¤ì¼€ì¤„ë§ ì°¨ë‹¨)
    AutoMode->>Pod: Pod Eviction ì‹œì‘

    Pod->>Pod: preStop Hook ì‹¤í–‰
    Note over Pod: sleep 10<br/>(íŠ¸ë˜í”½ ë“œë ˆì¸ ëŒ€ê¸°)

    Pod->>Pod: SIGTERM ìˆ˜ì‹ 
    Pod->>Pod: Graceful Shutdown
    Note over Pod: terminationGracePeriodSeconds<br/>(ìµœëŒ€ 90ì´ˆ)

    Pod->>Node_New: ìƒˆ ë…¸ë“œì— ì¬ìŠ¤ì¼€ì¤„ë§
    Pod->>Pod: startupProbe ì„±ê³µ
    Pod->>Pod: readinessProbe ì„±ê³µ

    AutoMode->>Node_Old: ë…¸ë“œ ì¢…ë£Œ

    Note over AutoMode: OS íŒ¨ì¹˜ ì™„ë£Œ
```

**ëª¨ë‹ˆí„°ë§ ì˜ˆì‹œ:**

```bash
# Auto Mode ë…¸ë“œ êµì²´ ì´ë²¤íŠ¸ ì¶”ì 
kubectl get events --field-selector reason=Evicted --watch

# ë…¸ë“œë³„ OS ë²„ì „ í™•ì¸
kubectl get nodes -o custom-columns=\
NAME:.metadata.name,\
OS_IMAGE:.status.nodeInfo.osImage,\
KERNEL:.status.nodeInfo.kernelVersion

# Auto Mode ê´€ë¦¬ ìƒíƒœ í™•ì¸
kubectl get nodes -L eks.amazonaws.com/compute-type
```

:::tip Auto Mode ë…¸ë“œ êµì²´ ë¹ˆë„
Auto ModeëŠ” ë³´ì•ˆ íŒ¨ì¹˜, ì„±ëŠ¥ ìµœì í™”, ë¹„ìš© ì ˆê°ì„ ìœ„í•´ ìˆ˜ë™ ê´€ë¦¬ë³´ë‹¤ ë…¸ë“œ êµì²´ê°€ ë¹ˆë²ˆí•©ë‹ˆë‹¤(í‰ê·  2ì£¼ 1íšŒ). `terminationGracePeriodSeconds`ë¥¼ 90ì´ˆ ì´ìƒìœ¼ë¡œ ì„¤ì •í•˜ê³ , PDBë¥¼ ë°˜ë“œì‹œ êµ¬ì„±í•˜ì—¬ ì„œë¹„ìŠ¤ ì¤‘ë‹¨ ì—†ì´ ë…¸ë“œ êµì²´ê°€ ê°€ëŠ¥í•˜ë„ë¡ í•˜ì„¸ìš”.
:::

#### Auto Mode í™œì„±í™” í™•ì¸

```bash
# í´ëŸ¬ìŠ¤í„°ê°€ Auto Modeì¸ì§€ í™•ì¸
aws eks describe-cluster --name production-eks \
  --query 'cluster.computeConfig.enabled' \
  --output text

# Auto Mode ë…¸ë“œ í™•ì¸
kubectl get nodes -L eks.amazonaws.com/compute-type
# ì¶œë ¥ ì˜ˆì‹œ:
# NAME                    COMPUTE-TYPE
# ip-10-0-1-100.ec2.internal   auto
# ip-10-0-2-200.ec2.internal   auto
```

**ê´€ë ¨ ë¬¸ì„œ:**
- [AWS Blog: Getting started with EKS Auto Mode](https://aws.amazon.com/blogs/containers/getting-started-with-amazon-eks-auto-mode)
- [AWS Blog: How to build highly available Kubernetes applications with EKS Auto Mode](https://aws.amazon.com/blogs/containers/how-to-build-highly-available-kubernetes-applications-with-amazon-eks-auto-mode/)
- [AWS Blog: Maximize EKS efficiency - Auto Mode, Graviton, and Spot](https://aws.amazon.com/blogs/containers/maximize-amazon-eks-efficiency-how-auto-mode-graviton-and-spot-work-together/)

---

### 7.5 AI/Agentic ê¸°ë°˜ Probe ìµœì í™”

AWS re:Invent 2025 CNS421 ì„¸ì…˜ì—ì„œ ì†Œê°œëœ Agentic AI ê¸°ë°˜ EKS ìš´ì˜ íŒ¨í„´ì„ í™œìš©í•˜ì—¬ Probe ì„¤ì •ì„ ìë™ìœ¼ë¡œ ìµœì í™”í•˜ê³  ì‹¤íŒ¨ë¥¼ ìë™ ì§„ë‹¨í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤.

#### CNS421 ì„¸ì…˜ í•µì‹¬ - Agentic AI for EKS Operations

**ì„¸ì…˜ ê°œìš”:**

"Streamline Amazon EKS Operations with Agentic AI" ì„¸ì…˜ì—ì„œëŠ” Model Context Protocol(MCP)ê³¼ AI ì—ì´ì „íŠ¸ë¥¼ í™œìš©í•˜ì—¬ EKS í´ëŸ¬ìŠ¤í„° ê´€ë¦¬ë¥¼ ìë™í™”í•˜ëŠ” ë°©ë²•ì„ ì½”ë“œ ì‹œì—°ê³¼ í•¨ê»˜ ì†Œê°œí–ˆìŠµë‹ˆë‹¤.

**ì£¼ìš” ê¸°ëŠ¥:**
- ì‹¤ì‹œê°„ ì´ìŠˆ ì§„ë‹¨ (Probe ì‹¤íŒ¨ ì›ì¸ ìë™ ë¶„ì„)
- Guided Remediation (ë‹¨ê³„ë³„ í•´ê²° ê°€ì´ë“œ)
- Tribal Knowledge í™œìš© (ê³¼ê±° ì´ìŠˆ íŒ¨í„´ í•™ìŠµ)
- Auto-Remediation (ë‹¨ìˆœ ì´ìŠˆ ìë™ í•´ê²°)

**ì•„í‚¤í…ì²˜:**

```mermaid
flowchart LR
    PROBE_FAIL[Probe ì‹¤íŒ¨ ê°ì§€]
    PROBE_FAIL --> MCP[EKS MCP Server]

    MCP --> CONTEXT[ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘]
    CONTEXT --> LOGS[Pod Logs]
    CONTEXT --> METRICS[CloudWatch Metrics]
    CONTEXT --> EVENTS[Kubernetes Events]
    CONTEXT --> NETWORK[Network Observability]

    CONTEXT --> AI[Agentic AI<br/>Amazon Bedrock]
    AI --> ANALYZE[ê·¼ë³¸ ì›ì¸ ë¶„ì„]

    ANALYZE --> DECISION{ìë™ í•´ê²°<br/>ê°€ëŠ¥?}

    DECISION -->|Yes| AUTO[ìë™ Remediation]
    AUTO --> FIX_PROBE[Probe ì„¤ì • ì¡°ì •]
    AUTO --> FIX_APP[ì• í”Œë¦¬ì¼€ì´ì…˜ ì¬ì‹œì‘]
    AUTO --> FIX_NETWORK[ë„¤íŠ¸ì›Œí¬ ì •ì±… ìˆ˜ì •]

    DECISION -->|No| GUIDE[í•´ê²° ê°€ì´ë“œ ì œê³µ]
    GUIDE --> HUMAN[ìš´ì˜ì ê°œì…]

    HUMAN --> LEARN[í•´ê²° íŒ¨í„´ í•™ìŠµ]
    LEARN --> TRIBAL[Tribal Knowledge<br/>ì—…ë°ì´íŠ¸]

    style PROBE_FAIL fill:#ff4444,stroke:#cc3636,color:#fff
    style AI fill:#4286f4,stroke:#2a6acf,color:#fff
    style AUTO fill:#34a853,stroke:#2a8642,color:#fff
```

#### Kiro + EKS MCPë¥¼ í™œìš©í•œ Probe ìë™ ìµœì í™”

**Kiroë€:**

KiroëŠ” AWSì˜ AI ê¸°ë°˜ ìš´ì˜ ë„êµ¬ë¡œ, MCP(Model Context Protocol) ì„œë²„ë¥¼ í†µí•´ AWS ë¦¬ì†ŒìŠ¤ì™€ ìƒí˜¸ì‘ìš©í•©ë‹ˆë‹¤.

**ì„¤ì¹˜ ë° ì„¤ì •:**

```bash
# Kiro CLI ì„¤ì¹˜ (macOS)
brew install aws/tap/kiro

# EKS MCP Server ì„¤ì •
kiro mcp add eks \
  --server-type eks \
  --cluster-name production-eks \
  --region ap-northeast-2

# Probe ìµœì í™” ì—ì´ì „íŠ¸ í™œì„±í™”
kiro agent create probe-optimizer \
  --type eks-health-check \
  --auto-remediate true
```

**Probe ì‹¤íŒ¨ ìë™ ì§„ë‹¨ ì›Œí¬í”Œë¡œìš°:**

```yaml
# Kiro Agent ì„¤ì • - Probe ì‹¤íŒ¨ ìë™ ëŒ€ì‘
apiVersion: kiro.aws/v1alpha1
kind: Agent
metadata:
  name: probe-failure-analyzer
spec:
  cluster: production-eks
  triggers:
    - type: ProbeFailure
      conditions:
        - probeType: readiness
          failureThreshold: 3
          duration: 5m
  actions:
    - name: collect-context
      steps:
        - getPodLogs:
            namespace: ${event.namespace}
            podName: ${event.podName}
            tailLines: 500
        - getCloudWatchMetrics:
            namespace: ContainerInsights
            metricName: pod_cpu_utilization
            dimensions:
              - name: PodName
                value: ${event.podName}
            period: 300
        - getNetworkObservability:
            podName: ${event.podName}
            metrics:
              - latency
              - packetLoss
              - connectionErrors
        - getKubernetesEvents:
            namespace: ${event.namespace}
            fieldSelector: involvedObject.name=${event.podName}

    - name: analyze-root-cause
      llm:
        model: anthropic.claude-3-5-sonnet-20241022-v2:0
        prompt: |
          Analyze the following Kubernetes Readiness Probe failure:

          Pod: ${event.podName}
          Namespace: ${event.namespace}
          Probe Config:
          ${context.probeConfig}

          Pod Logs (last 500 lines):
          ${context.podLogs}

          CloudWatch Metrics (last 5 minutes):
          ${context.metrics}

          Network Observability:
          ${context.networkMetrics}

          Kubernetes Events:
          ${context.events}

          Determine the root cause and suggest:
          1. Is this a network issue, application issue, or configuration issue?
          2. Recommended Probe settings (periodSeconds, failureThreshold, timeoutSeconds)
          3. Auto-remediation actions if applicable

    - name: auto-remediate
      conditions:
        - type: RootCauseIdentified
          confidence: ">0.8"
      steps:
        - applyProbeOptimization:
            when: ${analysis.recommendedAction == "adjust_probe_settings"}
            patchDeployment:
              name: ${event.deploymentName}
              namespace: ${event.namespace}
              patch:
                spec:
                  template:
                    spec:
                      containers:
                        - name: ${event.containerName}
                          readinessProbe:
                            periodSeconds: ${analysis.recommendedPeriod}
                            failureThreshold: ${analysis.recommendedThreshold}
                            timeoutSeconds: ${analysis.recommendedTimeout}

        - restartPod:
            when: ${analysis.recommendedAction == "restart_pod"}
            namespace: ${event.namespace}
            podName: ${event.podName}

        - notifySlack:
            channel: "#eks-ops"
            message: |
              ğŸ¤– Probe Failure Auto-Remediated

              Pod: ${event.podName}
              Root Cause: ${analysis.rootCause}
              Action Taken: ${analysis.appliedAction}
              Confidence: ${analysis.confidence}

              Details: ${analysis.explanation}

    - name: manual-guide
      conditions:
        - type: RootCauseIdentified
          confidence: "<0.8"
      steps:
        - createJiraTicket:
            project: DEVOPS
            issueType: Incident
            summary: "Probe Failure - Manual Investigation Required"
            description: |
              Pod: ${event.podName}
              Potential Causes: ${analysis.possibleCauses}
              Investigation Steps: ${analysis.investigationSteps}
              Context: ${context}
```

**ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ - Probe íƒ€ì„ì•„ì›ƒ ìë™ ìµœì í™”:**

```bash
# Kiroë¥¼ í†µí•œ ëŒ€í™”í˜• Probe ìµœì í™”
$ kiro chat --agent probe-optimizer

User: My readiness probe is failing intermittently on pod api-gateway-xyz.
      Can you diagnose and fix it?

Kiro: ğŸ” Analyzing probe failures for pod api-gateway-xyz...

      âœ… Root Cause Identified (Confidence: 92%)
      - Issue: Network latency spikes to external database
      - Current Probe: periodSeconds=5, timeoutSeconds=3, failureThreshold=2
      - Network metrics show p99 latency: 2.8 seconds

      ğŸ“Š Recommendation:
      1. Increase timeoutSeconds from 3 to 5 seconds
      2. Increase failureThreshold from 2 to 3
      3. Enable Container Network Observability for ongoing monitoring

      ğŸ¤– Auto-Remediation Available
      Shall I apply these changes? (yes/no)

User: yes

Kiro: âœ… Applied Probe Optimization
      - Updated Deployment: api-gateway
      - New Probe Config:
        * periodSeconds: 5
        * timeoutSeconds: 5 (increased)
        * failureThreshold: 3 (increased)

      ğŸ“ˆ Monitoring for 5 minutes to verify stability...

      âœ… Verification Complete
      - Probe failures reduced from 12/hour to 0/hour
      - Network latency p99: 2.8s (within new 5s timeout)
      - Recommendation recorded in tribal knowledge

      ğŸ’¡ Suggestion: Consider moving database to same VPC
          to reduce network latency permanently.
```

#### Amazon Q Developerë¥¼ í™œìš©í•œ Probe ì´ìŠˆ ë””ë²„ê¹…

Amazon Q DeveloperëŠ” IDE í†µí•© AI ì–´ì‹œìŠ¤í„´íŠ¸ë¡œ, Probe ì„¤ì • ì½”ë“œ ë¦¬ë·°ì™€ ì‹¤ì‹œê°„ ë””ë²„ê¹…ì„ ì§€ì›í•©ë‹ˆë‹¤.

**VS Code í†µí•© ì˜ˆì‹œ:**

```yaml
# ê°œë°œìê°€ ì‘ì„± ì¤‘ì¸ Deployment YAML
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  template:
    spec:
      containers:
      - name: app
        image: myapp:v1
        readinessProbe:
          httpGet:
            path: /health  # âš ï¸ Q Developer ê²½ê³ 
            port: 8080
          periodSeconds: 10
          timeoutSeconds: 1  # âš ï¸ Q Developer ê²½ê³ 
```

**Q Developer ì œì•ˆ:**

```
ğŸ’¡ Amazon Q Developer Suggestion

Issue 1: Livenessì™€ Readinessê°€ ê°™ì€ ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
Recommendation:
- Liveness Probe: /healthz (ë‚´ë¶€ ìƒíƒœë§Œ)
- Readiness Probe: /ready (ì™¸ë¶€ ì˜ì¡´ì„± í¬í•¨)

Issue 2: timeoutSecondsê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤.
Recommendation:
- timeoutSecondsë¥¼ 3-5ì´ˆë¡œ ì¦ê°€
- EKS í™˜ê²½ì—ì„œ 1ì´ˆëŠ” ë„¤íŠ¸ì›Œí¬ ì§€ì—° ì‹œ íƒ€ì„ì•„ì›ƒ ìœ„í—˜

Issue 3: Startup Probeê°€ ì—†ìŠµë‹ˆë‹¤.
Recommendation:
- ì•± ì‹œì‘ ì‹œê°„ì´ 30ì´ˆ ì´ìƒì´ë©´ Startup Probe ì¶”ê°€
- failureThreshold: 30, periodSeconds: 10

Apply Suggestions? [Yes] [No] [Explain More]
```

**ì‹¤ì‹œê°„ ì½”ë“œ ì‹¤í–‰ ê²€ì¦ (Amazon Q Developer):**

```bash
# Q Developerê°€ ë¡œì»¬ì—ì„œ Probe ì„¤ì • ê²€ì¦
$ q-dev validate deployment.yaml --cluster production-eks

âœ… Syntax Valid
âš ï¸  Best Practices Check:
    - Missing Startup Probe for slow-starting app (15 warnings)
    - Liveness Probe includes external dependency (critical)
    - terminationGracePeriodSeconds should be at least 60s (warning)

ğŸ§ª Simulation Results:
    - Probe success rate: 94% (target: >99%)
    - Estimated pod startup time: 45 seconds
    - Estimated graceful shutdown time: 25 seconds

ğŸ“Š Recommendation:
    Apply Q Developer's suggested configuration? (Y/n)
```

#### Tribal Knowledge ê¸°ë°˜ Probe íŒ¨í„´ í•™ìŠµ

Agentic AIëŠ” ê³¼ê±° Probe ì´ìŠˆ í•´ê²° íŒ¨í„´ì„ í•™ìŠµí•˜ì—¬ ìœ ì‚¬ ìƒí™©ì—ì„œ ì¦‰ì‹œ ëŒ€ì‘í•©ë‹ˆë‹¤.

**Tribal Knowledge ì˜ˆì‹œ:**

```yaml
# ì¡°ì§ì˜ Probe í•´ê²° íŒ¨í„´ ë¼ì´ë¸ŒëŸ¬ë¦¬
apiVersion: kiro.aws/v1alpha1
kind: TribalKnowledge
metadata:
  name: probe-failure-patterns
spec:
  patterns:
    - id: pattern-001
      name: "Database Connection Timeout"
      symptoms:
        - probeType: readiness
          errorPattern: "connection timeout"
          frequency: intermittent
      rootCause: "Database in different AZ causing high latency"
      solution:
        - action: increaseTimeout
          from: 3
          to: 5
        - action: addRetry
          retries: 2
      confidence: 0.95
      resolvedCount: 47
      lastSeen: "2026-02-10"

    - id: pattern-002
      name: "Slow JVM Startup"
      symptoms:
        - probeType: startup
          errorPattern: "probe failed"
          timing: "first 60 seconds"
      rootCause: "JVM initialization takes >30 seconds"
      solution:
        - action: addStartupProbe
          failureThreshold: 30
          periodSeconds: 10
      confidence: 0.98
      resolvedCount: 123
      lastSeen: "2026-02-11"

    - id: pattern-003
      name: "Network Policy Blocking Health Check"
      symptoms:
        - probeType: liveness
          errorPattern: "connection refused"
          timing: "after deployment"
      rootCause: "NetworkPolicy not allowing kubelet access"
      solution:
        - action: updateNetworkPolicy
          allowFrom:
            - podSelector: {}  # Allow from all pods in namespace
            - namespaceSelector:
                matchLabels:
                  name: kube-system
      confidence: 0.92
      resolvedCount: 34
      lastSeen: "2026-02-08"
```

**ìë™ íŒ¨í„´ ë§¤ì¹­:**

```bash
# ìƒˆë¡œìš´ Probe ì‹¤íŒ¨ ë°œìƒ ì‹œ ìë™ ë§¤ì¹­
$ kiro diagnose probe-failure \
  --pod api-backend-abc \
  --namespace production

ğŸ” Analyzing probe failure...

âœ… Pattern Matched: "Database Connection Timeout" (pattern-001)
   Confidence: 89%
   This pattern has been successfully resolved 47 times

ğŸ“‹ Recommended Actions (from tribal knowledge):
   1. Increase readinessProbe.timeoutSeconds from 3 to 5
   2. Add retry logic with 2 retries
   3. Consider co-locating database in same AZ

ğŸ¤– Auto-Apply? (yes/no)
```

#### Probe ìµœì í™” í†µí•© ëŒ€ì‹œë³´ë“œ

```yaml
# Grafana Dashboard - AI ê¸°ë°˜ Probe ìµœì í™” í˜„í™©
apiVersion: v1
kind: ConfigMap
metadata:
  name: ai-probe-optimization-dashboard
  namespace: monitoring
data:
  dashboard.json: |
    {
      "title": "AI-Driven Probe Optimization",
      "panels": [
        {
          "title": "Auto-Remediation ì„±ê³µë¥ ",
          "targets": [{
            "expr": "rate(kiro_auto_remediation_success[1h]) / rate(kiro_auto_remediation_total[1h])"
          }]
        },
        {
          "title": "Tribal Knowledge íŒ¨í„´ ë§¤ì¹­",
          "targets": [{
            "expr": "kiro_pattern_match_count"
          }]
        },
        {
          "title": "Probe ì‹¤íŒ¨ìœ¨ íŠ¸ë Œë“œ (AI ë„ì… ì „í›„)",
          "targets": [
            {"expr": "rate(probe_failures_total[1h])", "legendFormat": "Before AI"},
            {"expr": "rate(probe_failures_ai_optimized_total[1h])", "legendFormat": "After AI"}
          ]
        },
        {
          "title": "í‰ê·  ë¬¸ì œ í•´ê²° ì‹œê°„ (MTTR)",
          "targets": [{
            "expr": "avg(kiro_remediation_duration_seconds)"
          }]
        }
      ]
    }
```

**ROI ì¸¡ì • ì˜ˆì‹œ:**

| ì§€í‘œ | AI ë„ì… ì „ | AI ë„ì… í›„ | ê°œì„ ìœ¨ |
|------|----------|-----------|--------|
| Probe ì‹¤íŒ¨ ê±´ìˆ˜ | 120ê±´/ì£¼ | 12ê±´/ì£¼ | 90% ê°ì†Œ |
| í‰ê·  í•´ê²° ì‹œê°„ (MTTR) | 45ë¶„ | 3ë¶„ | 93% ë‹¨ì¶• |
| ìš´ì˜ì ê°œì… í•„ìš” ê±´ìˆ˜ | 120ê±´/ì£¼ | 12ê±´/ì£¼ | 90% ê°ì†Œ |
| Probe ì„¤ì • ìµœì í™” ì†Œìš” ì‹œê°„ | 2ì‹œê°„/ê±´ | 5ë¶„/ê±´ | 96% ë‹¨ì¶• |

:::tip Agentic AI ë„ì… Best Practice
Agentic AIëŠ” ì¦‰ì‹œ 100% ìë™í™”ë¥¼ ëª©í‘œë¡œ í•˜ì§€ ë§ˆì„¸ìš”. ì²˜ìŒ 3ê°œì›”ì€ "Suggest Mode"ë¡œ ìš´ì˜í•˜ì—¬ AI ì œì•ˆì„ ìš´ì˜ìê°€ ê²€í† í•˜ê³  ìŠ¹ì¸í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì‹œì‘í•˜ì„¸ìš”. Tribal Knowledgeê°€ ì¶©ë¶„íˆ ìŒ“ì´ê³  ì‹ ë¢°ë„ê°€ 90% ì´ìƒì´ ë˜ë©´ "Auto-Remediation Mode"ë¡œ ì „í™˜í•©ë‹ˆë‹¤.
:::

**ê´€ë ¨ ìë£Œ:**
- [YouTube: CNS421 - Streamline Amazon EKS operations with Agentic AI](https://www.youtube.com/watch?v=4s-a0jY4kSE)
- [AWS Blog: Agentic Cloud Modernization with Kiro](https://aws.amazon.com/blogs/migration-and-modernization/agentic-cloud-modernization-accelerating-modernization-with-aws-mcps-and-kiro/)
- [AWS Blog: AWS IaC MCP Server](https://aws.amazon.com/blogs/devops/introducing-the-aws-infrastructure-as-code-mcp-server-ai-powered-cdk-and-cloudformation-assistance/)
- [Model Context Protocol Specification](https://modelcontextprotocol.io/)

---

**ë¬¸ì„œ ê¸°ì—¬**: ì´ ë¬¸ì„œì— ëŒ€í•œ í”¼ë“œë°±, ì˜¤ë¥˜ ì‹ ê³ , ê°œì„  ì œì•ˆì€ GitHub Issuesë¥¼ í†µí•´ ì œì¶œí•´ ì£¼ì„¸ìš”.
