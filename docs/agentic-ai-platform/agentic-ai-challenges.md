---
title: "Agentic AI ì›Œí¬ë¡œë“œì˜ ê¸°ìˆ ì  ë„ì „ê³¼ì œ"
sidebar_label: "ê¸°ìˆ ì  ë„ì „ê³¼ì œ"
description: "Agentic AI ì›Œí¬ë¡œë“œ ìš´ì˜ ì‹œ ì§ë©´í•˜ëŠ” 4ê°€ì§€ í•µì‹¬ ë„ì „ê³¼ì œì™€ Kubernetes ê¸°ë°˜ ì˜¤í”ˆì†ŒìŠ¤ ìƒíƒœê³„"
tags: [kubernetes, genai, agentic-ai, gpu, challenges, open-source]
category: "genai-aiml"
date: "2025-02-05"
authors: [devfloor9]
sidebar_position: 3
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

> ğŸ“… **ì‘ì„±ì¼**: 2025-02-05 | **ìˆ˜ì •ì¼**: 2026-02-04 | â±ï¸ **ì½ëŠ” ì‹œê°„**: ì•½ 25ë¶„

## ì†Œê°œ

Agentic AI í”Œë«í¼ì„ êµ¬ì¶•í•˜ê³  ìš´ì˜í•  ë•Œ, í”Œë«í¼ ì—”ì§€ë‹ˆì–´ì™€ ì•„í‚¤í…íŠ¸ëŠ” ê¸°ì¡´ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ê³¼ëŠ” ê·¼ë³¸ì ìœ¼ë¡œ ë‹¤ë¥¸ ê¸°ìˆ ì  ë„ì „ì— ì§ë©´í•©ë‹ˆë‹¤. ì´ ë¬¸ì„œì—ì„œëŠ” **4ê°€ì§€ í•µì‹¬ ë„ì „ê³¼ì œ**ë¥¼ ë¶„ì„í•˜ê³ , ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ **Kubernetes ê¸°ë°˜ ì˜¤í”ˆì†ŒìŠ¤ ìƒíƒœê³„**ë¥¼ íƒêµ¬í•©ë‹ˆë‹¤.

## Agentic AI í”Œë«í¼ì˜ 4ê°€ì§€ í•µì‹¬ ë„ì „ê³¼ì œ

Frontier Model(ìµœì‹  ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸)ì„ í™œìš©í•œ Agentic AI ì‹œìŠ¤í…œì€ ê¸°ì¡´ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ê³¼ëŠ” **ê·¼ë³¸ì ìœ¼ë¡œ ë‹¤ë¥¸ ì¸í”„ë¼ ìš”êµ¬ì‚¬í•­**ì„ ê°€ì§‘ë‹ˆë‹¤.

```mermaid
graph TB
    subgraph "4ê°€ì§€ í•µì‹¬ ë„ì „ê³¼ì œ"
        C1["ğŸ–¥ï¸ ë„ì „ê³¼ì œ 1<br/>GPU ëª¨ë‹ˆí„°ë§ ë° ë¦¬ì†ŒìŠ¤ ìŠ¤ì¼€ì¤„ë§"]
        C2["ğŸ”€ ë„ì „ê³¼ì œ 2<br/>Agentic AI ìš”ì²­ ë™ì  ë¼ìš°íŒ… ë° ìŠ¤ì¼€ì¼ë§"]
        C3["ğŸ“Š ë„ì „ê³¼ì œ 3<br/>í† í°/ì„¸ì…˜ ìˆ˜ì¤€ ëª¨ë‹ˆí„°ë§ ë° ë¹„ìš© ì»¨íŠ¸ë¡¤"]
        C4["ğŸ”§ ë„ì „ê³¼ì œ 4<br/>FM íŒŒì¸íŠœë‹ê³¼ ìë™í™” íŒŒì´í”„ë¼ì¸"]
    end

    subgraph "ê³µí†µ íŠ¹ì„±"
        COMMON["GPU ë¦¬ì†ŒìŠ¤ ì§‘ì•½ì <br/>ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•œ ì›Œí¬ë¡œë“œ<br/>ë†’ì€ ì¸í”„ë¼ ë¹„ìš©<br/>ë³µì¡í•œ ë¶„ì‚° ì‹œìŠ¤í…œ"]
    end

    C1 --> COMMON
    C2 --> COMMON
    C3 --> COMMON
    C4 --> COMMON

    style C1 fill:#ff6b6b
    style C2 fill:#4ecdc4
    style C3 fill:#45b7d1
    style C4 fill:#96ceb4
    style COMMON fill:#f9f9f9
```

### ë„ì „ê³¼ì œ ìš”ì•½

| ë„ì „ê³¼ì œ | í•µì‹¬ ë¬¸ì œ | ê¸°ì¡´ ì¸í”„ë¼ì˜ í•œê³„ |
| --- | --- | --- |
| **GPU ëª¨ë‹ˆí„°ë§ ë° ìŠ¤ì¼€ì¤„ë§** | ë©€í‹° í´ëŸ¬ìŠ¤í„° GPU ê°€ì‹œì„± ë¶€ì¬, ì„¸ëŒ€ë³„ ì›Œí¬ë¡œë“œ ë§¤ì¹­ | ìˆ˜ë™ ëª¨ë‹ˆí„°ë§, ì •ì  í• ë‹¹ |
| **ë™ì  ë¼ìš°íŒ… ë° ìŠ¤ì¼€ì¼ë§** | ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•œ íŠ¸ë˜í”½, ë©€í‹° ëª¨ë¸ ì„œë¹™ ë³µì¡ì„± | ëŠë¦° í”„ë¡œë¹„ì €ë‹, ê³ ì • ìš©ëŸ‰ |
| **ë¹„ìš© ì»¨íŠ¸ë¡¤** | GPU ìœ íœ´ ë¹„ìš©, í† í° ë ˆë²¨ ì¶”ì  ì–´ë ¤ì›€ | ë¹„ìš© ê°€ì‹œì„± ë¶€ì¬, ìµœì í™” ë¶ˆê°€ |
| **FM íŒŒì¸íŠœë‹** | ë¶„ì‚° í•™ìŠµ ì¸í”„ë¼ ë³µì¡ì„±, ë¦¬ì†ŒìŠ¤ í”„ë¡œë¹„ì €ë‹ ì§€ì—° | ìˆ˜ë™ í´ëŸ¬ìŠ¤í„° ê´€ë¦¬, ë‚®ì€ í™œìš©ë¥  |

:::warning ê¸°ì¡´ ì¸í”„ë¼ ì ‘ê·¼ ë°©ì‹ì˜ í•œê³„
ì „í†µì ì¸ VM ê¸°ë°˜ ì¸í”„ë¼ë‚˜ ìˆ˜ë™ ê´€ë¦¬ ë°©ì‹ìœ¼ë¡œëŠ” Agentic AIì˜ **ë™ì ì´ê³  ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•œ ì›Œí¬ë¡œë“œ íŒ¨í„´**ì— íš¨ê³¼ì ìœ¼ë¡œ ëŒ€ì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. GPU ë¦¬ì†ŒìŠ¤ì˜ ë†’ì€ ë¹„ìš©ê³¼ ë³µì¡í•œ ë¶„ì‚° ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ì€ **ìë™í™”ëœ ì¸í”„ë¼ ê´€ë¦¬**ë¥¼ í•„ìˆ˜ë¡œ ë§Œë“­ë‹ˆë‹¤.
:::

---

## í•´ê²°ì˜ í•µì‹¬: í´ë¼ìš°ë“œ ì¸í”„ë¼ ìë™í™”ì™€ AI í”Œë«í¼ì˜ í†µí•©

Agentic AI í”Œë«í¼ì˜ ë„ì „ê³¼ì œë¥¼ í•´ê²°í•˜ëŠ” í•µì‹¬ì€ **í´ë¼ìš°ë“œ ì¸í”„ë¼ ìë™í™”ì™€ AI ì›Œí¬ë¡œë“œì˜ ìœ ê¸°ì  í†µí•©**ì…ë‹ˆë‹¤. ì´ í†µí•©ì´ ì¤‘ìš”í•œ ì´ìœ ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

```mermaid
graph LR
    subgraph "AI ì›Œí¬ë¡œë“œ íŠ¹ì„±"
        AI1["ë™ì  ë¦¬ì†ŒìŠ¤ ìš”êµ¬"]
        AI2["ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•œ íŠ¸ë˜í”½"]
        AI3["ê³ ë¹„ìš© GPU ë¦¬ì†ŒìŠ¤"]
        AI4["ë³µì¡í•œ ë¶„ì‚° ì²˜ë¦¬"]
    end

    subgraph "ì¸í”„ë¼ ìë™í™” ìš”êµ¬ì‚¬í•­"
        INF1["ì‹¤ì‹œê°„ í”„ë¡œë¹„ì €ë‹"]
        INF2["ìë™ ìŠ¤ì¼€ì¼ë§"]
        INF3["ë¹„ìš© ìµœì í™”"]
        INF4["ì„ ì–¸ì  ê´€ë¦¬"]
    end

    subgraph "í†µí•© í”Œë«í¼"
        PLATFORM["Kubernetes<br/>ì»¨í…Œì´ë„ˆ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜"]
    end

    AI1 --> PLATFORM
    AI2 --> PLATFORM
    AI3 --> PLATFORM
    AI4 --> PLATFORM
    PLATFORM --> INF1
    PLATFORM --> INF2
    PLATFORM --> INF3
    PLATFORM --> INF4

    style PLATFORM fill:#326ce5
```

## ì™œ Kubernetesì¸ê°€?

KubernetesëŠ” Agentic AI í”Œë«í¼ì˜ ëª¨ë“  ë„ì „ê³¼ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆëŠ” **ì´ìƒì ì¸ ê¸°ë°˜ í”Œë«í¼**ì…ë‹ˆë‹¤:

| Kubernetes í•µì‹¬ ê¸°ëŠ¥ | AI í”Œë«í¼ ì ìš© | í•´ê²°ë˜ëŠ” ë„ì „ê³¼ì œ |
| --- | --- | --- |
| **ì„ ì–¸ì  ë¦¬ì†ŒìŠ¤ ê´€ë¦¬** | GPU ë¦¬ì†ŒìŠ¤ë¥¼ ì½”ë“œë¡œ ì •ì˜í•˜ê³  ë²„ì „ ê´€ë¦¬ | ë„ì „ê³¼ì œ 1, 4 |
| **ìë™ ìŠ¤ì¼€ì¼ë§ (HPA/VPA)** | íŠ¸ë˜í”½ íŒ¨í„´ì— ë”°ë¥¸ Pod ìë™ í™•ì¥/ì¶•ì†Œ | ë„ì „ê³¼ì œ 2 |
| **ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ê¸°ë°˜ ê²©ë¦¬** | íŒ€/í”„ë¡œì íŠ¸ë³„ ë¦¬ì†ŒìŠ¤ í• ë‹¹ëŸ‰ ê´€ë¦¬ | ë„ì „ê³¼ì œ 3 |
| **Operator íŒ¨í„´** | ë³µì¡í•œ ë¶„ì‚° í•™ìŠµ ì›Œí¬í”Œë¡œìš° ìë™í™” | ë„ì „ê³¼ì œ 4 |
| **ì„œë¹„ìŠ¤ ë©”ì‹œ í†µí•©** | ë©€í‹° ëª¨ë¸ ë¼ìš°íŒ… ë° íŠ¸ë˜í”½ ê´€ë¦¬ | ë„ì „ê³¼ì œ 2 |
| **ë©”íŠ¸ë¦­ ê¸°ë°˜ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜** | GPU ì‚¬ìš©ë¥  ê¸°ë°˜ ìŠ¤ì¼€ì¤„ë§ ê²°ì • | ë„ì „ê³¼ì œ 1, 3 |

```mermaid
graph TB
    subgraph "Kubernetes í•µì‹¬ ì»´í¬ë„ŒíŠ¸"
        API["API Server<br/>ì„ ì–¸ì  ë¦¬ì†ŒìŠ¤ ê´€ë¦¬"]
        SCHED["Scheduler<br/>GPU ì¸ì‹ ìŠ¤ì¼€ì¤„ë§"]
        CTRL["Controller Manager<br/>ìƒíƒœ ì¡°ì • ë£¨í”„"]
        ETCD["etcd<br/>í´ëŸ¬ìŠ¤í„° ìƒíƒœ ì €ì¥"]
    end

    subgraph "AI ì›Œí¬ë¡œë“œ ì§€ì›"
        GPU["GPU Device Plugin<br/>GPU ë¦¬ì†ŒìŠ¤ ì¶”ìƒí™”"]
        HPA["HPA/KEDA<br/>ë©”íŠ¸ë¦­ ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§"]
        OP["Operators<br/>ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° ìë™í™”"]
    end

    subgraph "ë„ì „ê³¼ì œ í•´ê²°"
        S1["âœ… GPU ë¦¬ì†ŒìŠ¤ í†µí•© ê´€ë¦¬"]
        S2["âœ… ë™ì  ìŠ¤ì¼€ì¼ë§"]
        S3["âœ… ë¦¬ì†ŒìŠ¤ í• ë‹¹ëŸ‰ ê´€ë¦¬"]
        S4["âœ… ë¶„ì‚° í•™ìŠµ ìë™í™”"]
    end

    API --> GPU
    SCHED --> GPU
    CTRL --> HPA
    CTRL --> OP
    GPU --> S1
    HPA --> S2
    API --> S3
    OP --> S4

    style API fill:#326ce5
    style SCHED fill:#326ce5
    style CTRL fill:#326ce5
```

:::info Kubernetesì˜ AI ì›Œí¬ë¡œë“œ ì§€ì›
KubernetesëŠ” NVIDIA GPU Operator, Kubeflow, KEDA ë“± AI/ML ìƒíƒœê³„ì™€ì˜ í’ë¶€í•œ í†µí•©ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ GPU ë¦¬ì†ŒìŠ¤ ê´€ë¦¬, ë¶„ì‚° í•™ìŠµ, ëª¨ë¸ ì„œë¹™ì„ **ë‹¨ì¼ í”Œë«í¼ì—ì„œ í†µí•© ê´€ë¦¬**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
:::

---

ì´ì œ Kubernetesê°€ AI ì›Œí¬ë¡œë“œì— ì í•©í•œ ì´ìœ ë¥¼ ì´í•´í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒìœ¼ë¡œ, **ê° ë„ì „ê³¼ì œë¥¼ í•´ê²°í•˜ëŠ” êµ¬ì²´ì ì¸ ì˜¤í”ˆì†ŒìŠ¤ ì†”ë£¨ì…˜ë“¤**ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.

## Kubernetes ìƒíƒœê³„ì˜ Agentic AI ì†”ë£¨ì…˜ ë²„ë“œë·°

Kubernetes ìƒíƒœê³„ì—ëŠ” Agentic AI í”Œë«í¼ì˜ ê° ë„ì „ê³¼ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ **ì „ë¬¸í™”ëœ ì˜¤í”ˆì†ŒìŠ¤ ì†”ë£¨ì…˜**ë“¤ì´ ì¡´ì¬í•©ë‹ˆë‹¤. ì´ ì†”ë£¨ì…˜ë“¤ì€ Kubernetes ë„¤ì´í‹°ë¸Œë¡œ ì„¤ê³„ë˜ì–´ **ì„ ì–¸ì  ê´€ë¦¬, ìë™ ìŠ¤ì¼€ì¼ë§, ê³ ê°€ìš©ì„±**ì˜ ì´ì ì„ ê·¸ëŒ€ë¡œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ì†”ë£¨ì…˜ ë§¤í•‘ ê°œìš”

```mermaid
graph TB
    subgraph "4ê°€ì§€ í•µì‹¬ ë„ì „ê³¼ì œ"
        C1["ğŸ–¥ï¸ GPU ëª¨ë‹ˆí„°ë§ ë°<br/>ë¦¬ì†ŒìŠ¤ ìŠ¤ì¼€ì¤„ë§"]
        C2["ğŸ”€ ë™ì  ë¼ìš°íŒ… ë°<br/>ìŠ¤ì¼€ì¼ë§"]
        C3["ğŸ“Š í† í°/ì„¸ì…˜ ëª¨ë‹ˆí„°ë§<br/>ë° ë¹„ìš© ì»¨íŠ¸ë¡¤"]
        C4["ğŸ”§ FM íŒŒì¸íŠœë‹ê³¼<br/>ìë™í™” íŒŒì´í”„ë¼ì¸"]
    end

    subgraph "Kubernetes ë„¤ì´í‹°ë¸Œ ì†”ë£¨ì…˜"
        S1["Karpenter<br/>GPU ë…¸ë“œ ìë™ í”„ë¡œë¹„ì €ë‹"]
        S2["Kgateway + LiteLLM<br/>Inference Gateway"]
        S3["LangFuse / LangSmith<br/>LLM Observability"]
        S4["NeMo + Kubeflow<br/>ë¶„ì‚° í•™ìŠµ íŒŒì´í”„ë¼ì¸"]
    end

    subgraph "ëª¨ë¸ ì„œë¹™ ê³„ì¸µ"
        VLLM["vLLM<br/>ê³ ì„±ëŠ¥ ì¶”ë¡  ì—”ì§„"]
        LLMD["llm-d<br/>ë¶„ì‚° ì¶”ë¡  ìŠ¤ì¼€ì¤„ëŸ¬"]
    end

    subgraph "Agent ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜"
        KAGENT["KAgent<br/>Kubernetes Agent í”„ë ˆì„ì›Œí¬"]
    end

    C1 --> S1
    C2 --> S2
    C3 --> S3
    C4 --> S4

    S2 --> VLLM
    S2 --> LLMD
    KAGENT --> S2
    KAGENT --> S3

    style C1 fill:#ff6b6b
    style C2 fill:#4ecdc4
    style C3 fill:#45b7d1
    style C4 fill:#96ceb4
    style S1 fill:#ffd93d
    style S2 fill:#4286f4
    style S3 fill:#9b59b6
    style S4 fill:#76b900
    style VLLM fill:#e74c3c
    style LLMD fill:#e74c3c
    style KAGENT fill:#2ecc71
```

### ë„ì „ê³¼ì œë³„ ì†”ë£¨ì…˜ ìƒì„¸ ë§¤í•‘

| ë„ì „ê³¼ì œ | í•µì‹¬ ì†”ë£¨ì…˜ | ë³´ì¡° ì†”ë£¨ì…˜ | í•´ê²°í•˜ëŠ” ë¬¸ì œ |
| --- | --- | --- | --- |
| **GPU ëª¨ë‹ˆí„°ë§ ë° ìŠ¤ì¼€ì¤„ë§** | Karpenter | DCGM Exporter, NVIDIA GPU Operator | GPU ë…¸ë“œ ìë™ í”„ë¡œë¹„ì €ë‹, ì„¸ëŒ€ë³„ ì›Œí¬ë¡œë“œ ë§¤ì¹­ |
| **ë™ì  ë¼ìš°íŒ… ë° ìŠ¤ì¼€ì¼ë§** | Kgateway, LiteLLM | KEDA, vLLM, llm-d | ë©€í‹° ëª¨ë¸ ë¼ìš°íŒ…, íŠ¸ë˜í”½ ê¸°ë°˜ ìë™ ìŠ¤ì¼€ì¼ë§ |
| **í† í°/ë¹„ìš© ëª¨ë‹ˆí„°ë§** | LangFuse, LangSmith | OpenTelemetry, Prometheus | í† í° ë ˆë²¨ ì¶”ì , ë¹„ìš© ê°€ì‹œì„±, í’ˆì§ˆ í‰ê°€ |
| **FM íŒŒì¸íŠœë‹** | NeMo, Kubeflow | MLflow, Ray | ë¶„ì‚° í•™ìŠµ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜, íŒŒì´í”„ë¼ì¸ ìë™í™” |

---

ì§€ê¸ˆê¹Œì§€ Kubernetes ìƒíƒœê³„ì˜ ë‹¤ì–‘í•œ ì†”ë£¨ì…˜ë“¤ì„ ì‚´í´ë³´ì•˜ìŠµë‹ˆë‹¤. ì´ì œ ì´ ì†”ë£¨ì…˜ë“¤ì´ **ì‹¤ì œë¡œ ì–´ë–»ê²Œ í†µí•©ë˜ì–´ ì‘ë™í•˜ëŠ”ì§€** ì˜¤í”ˆì†ŒìŠ¤ ì•„í‚¤í…ì²˜ ê´€ì ì—ì„œ ìì„¸íˆ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.

## ì˜¤í”ˆì†ŒìŠ¤ ìƒíƒœê³„ì™€ Kubernetes í†µí•© ì•„í‚¤í…ì²˜

Agentic AI í”Œë«í¼ì€ ë‹¤ì–‘í•œ ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ë“¤ì´ Kubernetesë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ìœ ê¸°ì ìœ¼ë¡œ í†µí•©ë˜ì–´ êµ¬ì„±ë©ë‹ˆë‹¤. ì´ ì„¹ì…˜ì—ì„œëŠ” **LLM Observability, ëª¨ë¸ ì„œë¹™, ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤, GPU ì¸í”„ë¼** ì˜ì—­ì˜ í•µì‹¬ ì˜¤í”ˆì†ŒìŠ¤ë“¤ì´ ì–´ë–»ê²Œ í˜‘ë ¥í•˜ì—¬ ì™„ì „í•œ Agentic AI í”Œë«í¼ì„ í˜•ì„±í•˜ëŠ”ì§€ ì„¤ëª…í•©ë‹ˆë‹¤.

### 1. ëª¨ë¸ ì„œë¹™: vLLM + llm-d

**vLLM**ì€ LLM ì¶”ë¡ ì„ ìœ„í•œ ê³ ì„±ëŠ¥ ì„œë¹™ ì—”ì§„ìœ¼ë¡œ, PagedAttentionì„ í†µí•´ **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ê·¹ëŒ€í™”**í•©ë‹ˆë‹¤.

**llm-d**ëŠ” Kubernetes í™˜ê²½ì—ì„œ LLM ì¶”ë¡  ìš”ì²­ì„ **ì§€ëŠ¥ì ìœ¼ë¡œ ë¶„ì‚°**í•˜ëŠ” ìŠ¤ì¼€ì¤„ëŸ¬ì…ë‹ˆë‹¤.

```mermaid
graph LR
    subgraph "ì¶”ë¡  ìš”ì²­ íë¦„"
        REQ["Client Request"]
        LLMD["llm-d<br/>Request Router"]

        subgraph "vLLM Instances"
            V1["vLLM Pod 1<br/>GPU: A100"]
            V2["vLLM Pod 2<br/>GPU: A100"]
            V3["vLLM Pod 3<br/>GPU: H100"]
        end
    end

    REQ --> LLMD
    LLMD --> V1
    LLMD --> V2
    LLMD --> V3

    style LLMD fill:#e74c3c
    style V1 fill:#3498db
    style V2 fill:#3498db
    style V3 fill:#3498db
```

| ì†”ë£¨ì…˜ | ì—­í•  | í•µì‹¬ ê¸°ëŠ¥ |
| --- | --- | --- |
| **vLLM** | ì¶”ë¡  ì—”ì§„ | PagedAttention, Continuous Batching, Speculative Decoding |
| **llm-d** | ë¶„ì‚° ìŠ¤ì¼€ì¤„ëŸ¬ | ë¡œë“œ ë°¸ëŸ°ì‹±, Prefix Caching ì¸ì‹ ë¼ìš°íŒ…, ì¥ì•  ë³µêµ¬ |

**Kubernetes í†µí•©:**
- Kubernetes Deploymentë¡œ ë°°í¬
- Serviceë¥¼ í†µí•´ ë…¸ì¶œ
- í ê¹Šì´ ë©”íŠ¸ë¦­ ê¸°ë°˜ HPAë¡œ ìŠ¤ì¼€ì¼ë§
- resource requests/limitsë¥¼ í†µí•œ GPU í• ë‹¹

### 2. ì¶”ë¡  ê²Œì´íŠ¸ì›¨ì´: Kgateway + LiteLLM

**Kgateway**ëŠ” Kubernetes Gateway API ê¸°ë°˜ì˜ AI ì¶”ë¡  ê²Œì´íŠ¸ì›¨ì´ë¡œ, **ë©€í‹° ëª¨ë¸ ë¼ìš°íŒ…ê³¼ íŠ¸ë˜í”½ ê´€ë¦¬**ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

**LiteLLM**ì€ ë‹¤ì–‘í•œ LLM í”„ë¡œë°”ì´ë”ë¥¼ **í†µí•© APIë¡œ ì¶”ìƒí™”**í•˜ì—¬ ëª¨ë¸ ì „í™˜ì„ ìš©ì´í•˜ê²Œ í•©ë‹ˆë‹¤.

```mermaid
graph TB
    subgraph "Gateway ê³„ì¸µ"
        CLIENT["Client Applications"]
        KGW["Kgateway<br/>Inference Gateway"]
        LITE["LiteLLM<br/>Provider Abstraction"]
    end

    subgraph "ëª¨ë¸ ë°±ì—”ë“œ"
        SELF["Self-hosted<br/>vLLM / TGI"]
        BEDROCK["Amazon Bedrock"]
        OPENAI["OpenAI API"]
    end

    CLIENT --> KGW
    KGW --> LITE
    LITE --> SELF
    LITE --> BEDROCK
    LITE --> OPENAI

    style KGW fill:#4286f4
    style LITE fill:#9b59b6
```

| ì†”ë£¨ì…˜ | ì—­í•  | í•µì‹¬ ê¸°ëŠ¥ |
| --- | --- | --- |
| **Kgateway** | íŠ¸ë˜í”½ ê´€ë¦¬ | í—¤ë” ê¸°ë°˜ ë¼ìš°íŒ…, ê°€ì¤‘ì¹˜ ë¶„ë°°, Rate Limiting, Canary ë°°í¬ |
| **LiteLLM** | API ì¶”ìƒí™” | 100+ LLM í”„ë¡œë°”ì´ë” ì§€ì›, í†µí•© API, í´ë°± ì„¤ì •, ë¹„ìš© ì¶”ì  |

**Kubernetes í†µí•©:**
- Kubernetes Gateway API í‘œì¤€ êµ¬í˜„
- HTTPRoute ë¦¬ì†ŒìŠ¤ë¥¼ í†µí•œ ì„ ì–¸ì  ë¼ìš°íŒ…
- Kubernetes Serviceì™€ ë„¤ì´í‹°ë¸Œ í†µí•©
- í¬ë¡œìŠ¤ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë¼ìš°íŒ… ì§€ì›

### 3. LLM Observability: LangFuse + LangSmith

**LangFuse**ì™€ **LangSmith**ëŠ” LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ **ì „ì²´ ë¼ì´í”„ì‚¬ì´í´ì„ ì¶”ì **í•˜ëŠ” ê´€ì¸¡ì„± í”Œë«í¼ì…ë‹ˆë‹¤.

```mermaid
graph LR
    subgraph "LLM Application"
        APP["Agent Application"]
        CHAIN["LangChain / LlamaIndex"]
    end

    subgraph "Observability Platform"
        LF["LangFuse<br/>(Self-hosted)"]
        LS["LangSmith<br/>(Managed)"]
    end

    subgraph "ë¶„ì„ ê¸°ëŠ¥"
        TRACE["Trace ë¶„ì„"]
        COST["ë¹„ìš© ì¶”ì "]
        EVAL["í’ˆì§ˆ í‰ê°€"]
        DEBUG["ë””ë²„ê¹…"]
    end

    APP --> CHAIN
    CHAIN --> LF
    CHAIN --> LS
    LF --> TRACE & COST & EVAL & DEBUG
    LS --> TRACE & COST & EVAL & DEBUG

    style LF fill:#45b7d1
    style LS fill:#9b59b6
```

| ì†”ë£¨ì…˜ | ë°°í¬ ë°©ì‹ | í•µì‹¬ ê¸°ëŠ¥ |
| --- | --- | --- |
| **LangFuse** | Self-hosted (K8s) | í† í° ì¶”ì , ë¹„ìš© ë¶„ì„, í”„ë¡¬í”„íŠ¸ ê´€ë¦¬, A/B í…ŒìŠ¤íŠ¸ |
| **LangSmith** | Managed SaaS | íŠ¸ë ˆì´ì‹±, í‰ê°€, ë°ì´í„°ì…‹ ê´€ë¦¬, í˜‘ì—… ê¸°ëŠ¥ |

**Kubernetes í†µí•© (LangFuse):**
- StatefulSet ë˜ëŠ” Deploymentë¡œ ë°°í¬
- PostgreSQL ë°±ì—”ë“œ í•„ìš” (ê´€ë¦¬í˜• RDS ë˜ëŠ” í´ëŸ¬ìŠ¤í„° ë‚´ êµ¬ì„± ê°€ëŠ¥)
- Prometheus í˜•ì‹ì˜ ë©”íŠ¸ë¦­ ë…¸ì¶œ
- Pod í™˜ê²½ ë³€ìˆ˜ë¥¼ í†µí•œ SDK ì—°ë™

### 4. Agent ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜: KAgent

**KAgent**ëŠ” Kubernetes ë„¤ì´í‹°ë¸Œ AI Agent í”„ë ˆì„ì›Œí¬ë¡œ, **Agent ì›Œí¬í”Œë¡œìš°ë¥¼ CRDë¡œ ì •ì˜**í•˜ê³  ê´€ë¦¬í•©ë‹ˆë‹¤.

```mermaid
graph TB
    subgraph "KAgent Architecture"
        CRD["Agent CRD<br/>ì„ ì–¸ì  ì •ì˜"]
        CTRL["KAgent Controller<br/>ìƒíƒœ ê´€ë¦¬"]

        subgraph "Agent Components"
            TOOL["Tool Definitions"]
            MEM["Memory Store"]
            LLM["LLM Backend"]
        end
    end

    subgraph "Integration"
        KGW["Kgateway"]
        OBS["LangFuse"]
    end

    CRD --> CTRL
    CTRL --> TOOL & MEM & LLM
    CTRL --> KGW
    CTRL --> OBS

    style CRD fill:#2ecc71
    style CTRL fill:#2ecc71
```

| ê¸°ëŠ¥ | ì„¤ëª… |
| --- | --- |
| **ì„ ì–¸ì  Agent ì •ì˜** | YAMLë¡œ Agent êµ¬ì„±, ë„êµ¬, ë©”ëª¨ë¦¬ ì •ì˜ |
| **ìë™ ìŠ¤ì¼€ì¼ë§** | ìš”ì²­ëŸ‰ì— ë”°ë¥¸ Agent ì¸ìŠ¤í„´ìŠ¤ ìë™ í™•ì¥ |
| **í†µí•© ê´€ì¸¡ì„±** | LangFuse/LangSmithì™€ ìë™ ì—°ë™ |
| **ë„êµ¬ ê´€ë¦¬** | MCP(Model Context Protocol) ê¸°ë°˜ ë„êµ¬ í†µí•© |

**Kubernetes í†µí•©:**
- Custom Resource Definitions (CRD)ë¡œ Kubernetes í™•ì¥
- Controller íŒ¨í„´ì„ í†µí•œ ìƒíƒœ ì¡°ì •
- Kubernetes RBACì™€ ë„¤ì´í‹°ë¸Œ í†µí•©
- Kubernetes Secretsë¥¼ í™œìš©í•œ API í‚¤ ê´€ë¦¬

### ì†”ë£¨ì…˜ ìŠ¤íƒ í†µí•© ì•„í‚¤í…ì²˜

```mermaid
graph TB
    subgraph "Client Layer"
        WEB["Web Application"]
        API["API Clients"]
        AGENT["Agent Applications"]
    end

    subgraph "Gateway Layer"
        KGW["Kgateway<br/>Traffic Management"]
        LITE["LiteLLM<br/>Provider Abstraction"]
    end

    subgraph "Orchestration Layer"
        KAGENT["KAgent<br/>Agent Framework"]
        KEDA["KEDA<br/>Event-driven Scaling"]
    end

    subgraph "Serving Layer"
        LLMD["llm-d<br/>Request Scheduler"]
        VLLM1["vLLM Instance 1"]
        VLLM2["vLLM Instance 2"]
        VLLM3["vLLM Instance 3"]
    end

    subgraph "Infrastructure Layer"
        KARP["Karpenter<br/>Node Provisioning"]
        GPU1["GPU Node 1"]
        GPU2["GPU Node 2"]
        GPU3["GPU Node 3"]
    end

    subgraph "Observability Layer"
        LF["LangFuse<br/>LLM Tracing"]
        PROM["Prometheus<br/>Metrics"]
        GRAF["Grafana<br/>Dashboards"]
    end

    WEB & API & AGENT --> KGW
    KGW --> LITE
    LITE --> KAGENT
    KAGENT --> LLMD
    LLMD --> VLLM1 & VLLM2 & VLLM3
    VLLM1 --> GPU1
    VLLM2 --> GPU2
    VLLM3 --> GPU3
    KARP --> GPU1 & GPU2 & GPU3
    KEDA --> VLLM1 & VLLM2 & VLLM3

    KAGENT -.-> LF
    VLLM1 & VLLM2 & VLLM3 -.-> PROM
    PROM --> GRAF
    LF --> GRAF

    style KGW fill:#4286f4
    style KAGENT fill:#2ecc71
    style KARP fill:#ffd93d
    style LF fill:#45b7d1
    style LLMD fill:#e74c3c
```

---

### ì˜¤í”ˆì†ŒìŠ¤ í†µí•© ì „ì²´ ì•„í‚¤í…ì²˜

```mermaid
graph TB
    subgraph "Application Layer"
        AGENT["Agentic AI Application"]
        RAG["RAG Pipeline"]
    end

    subgraph "LLM Observability Layer"
        LF["LangFuse<br/>(Self-hosted)"]
        LS["LangSmith<br/>(Managed)"]
        RAGAS["RAGAS<br/>(RAG í’ˆì§ˆ í‰ê°€)"]
    end

    subgraph "Inference Gateway Layer"
        LITE["LiteLLM<br/>(Provider Abstraction)"]
        KGW["Kgateway<br/>(Traffic Management)"]
    end

    subgraph "Model Serving Layer"
        LLMD["llm-d<br/>(Distributed Scheduler)"]
        VLLM["vLLM<br/>(Inference Engine)"]
    end

    subgraph "Vector Database Layer"
        MILVUS["Milvus<br/>(Vector Store)"]
    end

    subgraph "GPU Infrastructure Layer"
        DRA["DRA<br/>(Dynamic Resource Allocation)"]
        DCGM["DCGM<br/>(GPU Monitoring)"]
        NCCL["NCCL<br/>(GPU Communication)"]
        KARP["Karpenter<br/>(Node Provisioning)"]
    end

    AGENT --> LF & LS
    AGENT --> LITE
    RAG --> MILVUS
    RAG --> RAGAS
    LITE --> KGW
    KGW --> LLMD
    LLMD --> VLLM
    VLLM --> DRA
    DRA --> DCGM
    VLLM --> NCCL
    KARP --> DRA

    style LF fill:#45b7d1
    style LS fill:#9b59b6
    style RAGAS fill:#e67e22
    style LITE fill:#9b59b6
    style LLMD fill:#e74c3c
    style MILVUS fill:#00d4aa
    style DRA fill:#326ce5
    style DCGM fill:#76b900
    style NCCL fill:#76b900
    style KARP fill:#ffd93d
```

### ê³„ì¸µë³„ ì˜¤í”ˆì†ŒìŠ¤ ì—­í• ê³¼ í†µí•©

#### LLM Observability ê³„ì¸µ: LangFuse, LangSmith, RAGAS

LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ **ì „ì²´ ë¼ì´í”„ì‚¬ì´í´ì„ ì¶”ì í•˜ê³  í’ˆì§ˆì„ í‰ê°€**í•˜ëŠ” í•µì‹¬ ë„êµ¬ë“¤ì…ë‹ˆë‹¤.

| ì†”ë£¨ì…˜ | ì—­í•  | Kubernetes í†µí•© ë°©ì‹ | í•µì‹¬ ê¸°ëŠ¥ |
| --- | --- | --- | --- |
| **LangFuse** | LLM íŠ¸ë ˆì´ì‹± (Self-hosted) | Helm Chart, StatefulSet | í† í° ì¶”ì , ë¹„ìš© ë¶„ì„, í”„ë¡¬í”„íŠ¸ ë²„ì „ ê´€ë¦¬ |
| **LangSmith** | LLM íŠ¸ë ˆì´ì‹± (Managed) | SDK ì—°ë™ | íŠ¸ë ˆì´ì‹±, í‰ê°€, ë°ì´í„°ì…‹ ê´€ë¦¬, í˜‘ì—… |
| **RAGAS** | RAG í’ˆì§ˆ í‰ê°€ | Job/CronJob | Faithfulness, Relevancy, Context Precision í‰ê°€ |

```mermaid
graph LR
    subgraph "LLM Application"
        APP["Agent App"]
        SDK1["LangFuse SDK"]
        SDK2["LangSmith SDK"]
    end

    subgraph "Kubernetes Cluster"
        subgraph "LangFuse Stack"
            LF_WEB["LangFuse Web<br/>(Deployment)"]
            LF_WORKER["LangFuse Worker<br/>(Deployment)"]
            LF_DB["PostgreSQL<br/>(StatefulSet)"]
            LF_REDIS["Redis<br/>(StatefulSet)"]
        end

        subgraph "RAGAS Evaluation"
            RAGAS_JOB["RAGAS Job<br/>(CronJob)"]
        end
    end

    APP --> SDK1 --> LF_WEB
    APP --> SDK2
    LF_WEB --> LF_WORKER --> LF_DB
    LF_WORKER --> LF_REDIS
    RAGAS_JOB --> LF_DB

    style LF_WEB fill:#45b7d1
    style RAGAS_JOB fill:#e67e22
```

**LangFuse Kubernetes ë°°í¬ ì˜ˆì‹œ:**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: langfuse-web
  namespace: observability
spec:
  replicas: 2
  selector:
    matchLabels:
      app: langfuse-web
  template:
    spec:
      containers:
        - name: langfuse
          image: langfuse/langfuse:latest
          env:
            - name: DATABASE_URL
              valueFrom:
                secretKeyRef:
                  name: langfuse-secrets
                  key: database-url
            - name: NEXTAUTH_SECRET
              valueFrom:
                secretKeyRef:
                  name: langfuse-secrets
                  key: nextauth-secret
          resources:
            requests:
              memory: "512Mi"
              cpu: "250m"
---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: ragas-evaluation
  namespace: observability
spec:
  schedule: "0 */6 * * *"  # 6ì‹œê°„ë§ˆë‹¤ ì‹¤í–‰
  jobTemplate:
    spec:
      template:
        spec:
          containers:
            - name: ragas
              image: ragas/ragas:latest
              command: ["python", "-m", "ragas.evaluate"]
              env:
                - name: LANGFUSE_HOST
                  value: "http://langfuse-web:3000"
          restartPolicy: OnFailure
```

#### Inference Gateway ê³„ì¸µ: LiteLLM

**LiteLLM**ì€ 100ê°œ ì´ìƒì˜ LLM í”„ë¡œë°”ì´ë”ë¥¼ **í†µí•© OpenAI í˜¸í™˜ APIë¡œ ì¶”ìƒí™”**í•©ë‹ˆë‹¤.

```mermaid
graph TB
    subgraph "LiteLLM Gateway"
        PROXY["LiteLLM Proxy<br/>(Deployment)"]
        CONFIG["Config<br/>(ConfigMap)"]
        CACHE["Redis Cache<br/>(StatefulSet)"]
    end

    subgraph "LLM Backends"
        SELF["Self-hosted<br/>vLLM / TGI"]
        BEDROCK["Amazon Bedrock"]
        OPENAI["OpenAI API"]
        ANTHROPIC["Anthropic API"]
    end

    subgraph "Features"
        LB["Load Balancing"]
        FALLBACK["Fallback Logic"]
        COST["Cost Tracking"]
        RATE["Rate Limiting"]
    end

    PROXY --> SELF & BEDROCK & OPENAI & ANTHROPIC
    CONFIG --> PROXY
    CACHE --> PROXY
    PROXY --> LB & FALLBACK & COST & RATE

    style PROXY fill:#9b59b6
```

**LiteLLM Kubernetes ë°°í¬ ì˜ˆì‹œ:**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: litellm-proxy
  namespace: ai-gateway
spec:
  replicas: 3
  selector:
    matchLabels:
      app: litellm
  template:
    spec:
      containers:
        - name: litellm
          image: ghcr.io/berriai/litellm:main-latest
          ports:
            - containerPort: 4000
          env:
            - name: LITELLM_MASTER_KEY
              valueFrom:
                secretKeyRef:
                  name: litellm-secrets
                  key: master-key
            - name: REDIS_HOST
              value: "redis-cache"
          volumeMounts:
            - name: config
              mountPath: /app/config.yaml
              subPath: config.yaml
      volumes:
        - name: config
          configMap:
            name: litellm-config
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: litellm-config
  namespace: ai-gateway
data:
  config.yaml: |
    model_list:
      - model_name: gpt-4
        litellm_params:
          model: openai/gpt-4
          api_key: os.environ/OPENAI_API_KEY
      - model_name: claude-3
        litellm_params:
          model: anthropic/claude-3-opus
          api_key: os.environ/ANTHROPIC_API_KEY
      - model_name: llama-70b
        litellm_params:
          model: openai/llama-70b
          api_base: http://vllm-llama:8000/v1

    router_settings:
      routing_strategy: least-busy
      enable_fallbacks: true

    general_settings:
      master_key: os.environ/LITELLM_MASTER_KEY
```

#### ë¶„ì‚° ì¶”ë¡  ê³„ì¸µ: llm-d

**llm-d**ëŠ” Kubernetes í™˜ê²½ì—ì„œ LLM ì¶”ë¡  ìš”ì²­ì„ **ì§€ëŠ¥ì ìœ¼ë¡œ ë¶„ì‚°**í•˜ëŠ” ìŠ¤ì¼€ì¤„ëŸ¬ì…ë‹ˆë‹¤.

| ê¸°ëŠ¥ | ì„¤ëª… | Kubernetes í†µí•© |
| --- | --- | --- |
| **Prefix Caching ì¸ì‹** | ë™ì¼ í”„ë¡¬í”„íŠ¸ í”„ë¦¬í”½ìŠ¤ë¥¼ ê°€ì§„ ìš”ì²­ì„ ê°™ì€ ì¸ìŠ¤í„´ìŠ¤ë¡œ ë¼ìš°íŒ… | Service Discovery í™œìš© |
| **ë¡œë“œ ë°¸ëŸ°ì‹±** | GPU ì‚¬ìš©ë¥  ê¸°ë°˜ ì§€ëŠ¥í˜• ë¶„ë°° | Prometheus ë©”íŠ¸ë¦­ ì—°ë™ |
| **ì¥ì•  ë³µêµ¬** | ì¸ìŠ¤í„´ìŠ¤ ì¥ì•  ì‹œ ìë™ ì¬ë¼ìš°íŒ… | Health Check + Endpoint Slice |
| **ë™ì  ìŠ¤ì¼€ì¼ë§** | ìš”ì²­ëŸ‰ì— ë”°ë¥¸ ë°±ì—”ë“œ í™•ì¥ | KEDA ì—°ë™ |

```mermaid
graph LR
    subgraph "llm-d Architecture"
        ROUTER["llm-d Router<br/>(Deployment)"]
        SCHED["Scheduler Logic"]
        CACHE["Prefix Cache Index"]
    end

    subgraph "vLLM Backends"
        V1["vLLM-1<br/>GPU: A100"]
        V2["vLLM-2<br/>GPU: A100"]
        V3["vLLM-3<br/>GPU: H100"]
    end

    subgraph "Kubernetes Resources"
        SVC["Service"]
        EP["EndpointSlice"]
        HPA["HPA/KEDA"]
    end

    ROUTER --> SCHED --> CACHE
    SCHED --> V1 & V2 & V3
    SVC --> ROUTER
    EP --> V1 & V2 & V3
    HPA --> V1 & V2 & V3

    style ROUTER fill:#e74c3c
    style SCHED fill:#e74c3c
```

**llm-d Kubernetes ë°°í¬ ì˜ˆì‹œ:**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: llm-d-router
  namespace: ai-inference
spec:
  replicas: 2
  selector:
    matchLabels:
      app: llm-d
  template:
    spec:
      containers:
        - name: llm-d
          image: ghcr.io/llm-d/llm-d:latest
          ports:
            - containerPort: 8080
          env:
            - name: BACKENDS
              value: "vllm-0.vllm:8000,vllm-1.vllm:8000,vllm-2.vllm:8000"
            - name: ROUTING_STRATEGY
              value: "prefix-aware"
            - name: PROMETHEUS_ENDPOINT
              value: "http://prometheus:9090"
          resources:
            requests:
              memory: "256Mi"
              cpu: "500m"
---
apiVersion: v1
kind: Service
metadata:
  name: llm-d
  namespace: ai-inference
spec:
  selector:
    app: llm-d
  ports:
    - port: 8080
      targetPort: 8080
```

### 5. ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ê³„ì¸µ: Milvus

RAG íŒŒì´í”„ë¼ì¸ì˜ í•µì‹¬ ì»´í¬ë„ŒíŠ¸ì¸ MilvusëŠ” Kubernetesì—ì„œ ë¶„ì‚° ì•„í‚¤í…ì²˜ë¡œ ìš´ì˜ë©ë‹ˆë‹¤.

ìì„¸í•œ ë‚´ìš©ì€ **[Milvus ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤](./milvus-vector-database.md)** ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

**Milvusì˜ ì£¼ìš” íŠ¹ì§•:**
- **ë¶„ì‚° ì•„í‚¤í…ì²˜**: Query/Data/Index Nodesë¥¼ ë…ë¦½ì ìœ¼ë¡œ ìŠ¤ì¼€ì¼ë§
- **Kubernetes Operator**: CRD ê¸°ë°˜ ì„ ì–¸ì  ê´€ë¦¬
- **GPU ê°€ì†**: Index Nodeì—ì„œ GPUë¥¼ í™œìš©í•œ ë¹ ë¥¸ ì¸ë±ìŠ¤ ë¹Œë“œ
- **S3 í†µí•©**: Amazon S3ë¥¼ ì˜êµ¬ ìŠ¤í† ë¦¬ì§€ë¡œ ì‚¬ìš© ê°€ëŠ¥

### 6. ë¶„ì‚° í•™ìŠµ: NeMo + Kubeflow

**NVIDIA NeMo**ì™€ **Kubeflow**ëŠ” ëŒ€ê·œëª¨ ëª¨ë¸ì˜ **ë¶„ì‚° í•™ìŠµ íŒŒì´í”„ë¼ì¸ ìë™í™”**ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

| ì†”ë£¨ì…˜ | ì—­í•  | í•µì‹¬ ê¸°ëŠ¥ |
| --- | --- | --- |
| **NeMo** | í•™ìŠµ í”„ë ˆì„ì›Œí¬ | LLM/ë©€í‹°ëª¨ë‹¬ í•™ìŠµ, ëª¨ë¸ ë³‘ë ¬í™”, ìµœì í™” ê¸°ë²• |
| **Kubeflow** | ML ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ | íŒŒì´í”„ë¼ì¸ ê´€ë¦¬, ì‹¤í—˜ ì¶”ì , í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ |

```mermaid
graph LR
    subgraph "ë°ì´í„° íŒŒì´í”„ë¼ì¸"
        DATA["í•™ìŠµ ë°ì´í„°"]
        PREP["ë°ì´í„° ì „ì²˜ë¦¬"]
    end

    subgraph "í•™ìŠµ í´ëŸ¬ìŠ¤í„°"
        NEMO["NeMo Framework"]
        DIST["ë¶„ì‚° í•™ìŠµ"]
    end

    subgraph "ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬"
        CKPT["ì²´í¬í¬ì¸íŠ¸ ì €ì¥"]
        MLFLOW["MLflow Registry"]
    end

    subgraph "ë°°í¬"
        SERVE["ëª¨ë¸ ì„œë¹™"]
        CANARY["Canary ë°°í¬"]
    end

    DATA --> PREP
    PREP --> NEMO
    NEMO --> DIST
    DIST --> CKPT
    CKPT --> MLFLOW
    MLFLOW --> SERVE
    SERVE --> CANARY

    style NEMO fill:#76b900
```

**Kubernetes í†µí•©:**
- Kubeflow Training Operators (PyTorchJob, MPIJob ë“±)
- ë¶„ì‚° ì›Œí¬ë¡œë“œë¥¼ ìœ„í•œ Gang ìŠ¤ì¼€ì¤„ë§
- í† í´ë¡œì§€ ì¸ì‹ ìŠ¤ì¼€ì¤„ë§ (ë…¸ë“œ ì–´í”¼ë‹ˆí‹°, ì•ˆí‹° ì–´í”¼ë‹ˆí‹°)
- ê³µìœ  ìŠ¤í† ë¦¬ì§€ë¥¼ ìœ„í•œ CSI ë“œë¼ì´ë²„ ì—°ë™ (FSx for Lustre)

---

## GPU ì¸í”„ë¼ ë° ë¦¬ì†ŒìŠ¤ ê´€ë¦¬

GPU ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ëŠ” Agentic AI í”Œë«í¼ì˜ í•µì‹¬ì…ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì„¸ìš”:

- **[GPU ë¦¬ì†ŒìŠ¤ ê´€ë¦¬](./gpu-resource-management.md)**: Device Plugin, DRA(Dynamic Resource Allocation), GPU í† í´ë¡œì§€ ì¸ì‹ ìŠ¤ì¼€ì¤„ë§
- **[NeMo í”„ë ˆì„ì›Œí¬](./nemo-framework.md)**: ë¶„ì‚° í•™ìŠµê³¼ NCCL ìµœì í™”

:::tip GPU ê´€ë¦¬ì˜ í•µì‹¬ ê°œë…
- **Device Plugin**: Kubernetesì˜ ê¸°ë³¸ GPU í• ë‹¹ ë©”ì»¤ë‹ˆì¦˜
- **DRA (Dynamic Resource Allocation)**: Kubernetes 1.26+ì˜ ìœ ì—°í•œ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬
- **NCCL**: ë¶„ì‚° GPU í•™ìŠµì„ ìœ„í•œ ê³ ì„±ëŠ¥ í†µì‹  ë¼ì´ë¸ŒëŸ¬ë¦¬
:::

### GPU ì¸í”„ë¼ ìŠ¤íƒ ê°œìš”

```mermaid
graph TB
    subgraph "GPU Infrastructure Stack"
        subgraph "Resource Allocation"
            DRA["DRA<br/>(Dynamic Resource Allocation)"]
            DRIVER["NVIDIA Device Plugin"]
        end

        subgraph "Monitoring"
            DCGM["DCGM Exporter"]
            PROM["Prometheus"]
            GRAF["Grafana"]
        end

        subgraph "Communication"
            NCCL["NCCL<br/>(GPU Collective Comm)"]
            EFA["EFA Driver"]
        end

        subgraph "Node Management"
            KARP["Karpenter"]
            GPU_OP["GPU Operator"]
        end
    end

    subgraph "GPU Nodes"
        N1["Node 1<br/>8x A100"]
        N2["Node 2<br/>8x A100"]
        N3["Node 3<br/>8x H100"]
    end

    DRA --> DRIVER --> N1 & N2 & N3
    DCGM --> N1 & N2 & N3
    DCGM --> PROM --> GRAF
    NCCL --> EFA --> N1 & N2 & N3
    KARP --> N1 & N2 & N3
    GPU_OP --> DRIVER & DCGM

    style DRA fill:#326ce5
    style DCGM fill:#76b900
    style NCCL fill:#76b900
    style KARP fill:#ffd93d
```

| ì»´í¬ë„ŒíŠ¸ | ì—­í•  | ìƒì„¸ ë¬¸ì„œ |
| --- | --- | --- |
| **DRA (Dynamic Resource Allocation)** | GPU ë¦¬ì†ŒìŠ¤ ë™ì  í• ë‹¹ | [GPU ë¦¬ì†ŒìŠ¤ ê´€ë¦¬](./gpu-resource-management.md) |
| **DCGM (Data Center GPU Manager)** | GPU ë©”íŠ¸ë¦­ ìˆ˜ì§‘ | [GPU ë¦¬ì†ŒìŠ¤ ê´€ë¦¬](./gpu-resource-management.md) |
| **NCCL (NVIDIA Collective Communication Library)** | ë©€í‹° GPU í†µì‹  ìµœì í™” | [NeMo í”„ë ˆì„ì›Œí¬](./nemo-framework.md) |

---

## ê²°ë¡ : ì™œ Agentic AIì— Kubernetesì¸ê°€?

KubernetesëŠ” í˜„ëŒ€ Agentic AI í”Œë«í¼ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” **ê¸°ë³¸ ì¸í”„ë¼ ê³„ì¸µ**ì„ ì œê³µí•©ë‹ˆë‹¤:

### í•µì‹¬ ì¥ì 

1. **í†µí•© í”Œë«í¼**: ì¶”ë¡ , í•™ìŠµ, ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ì„ ìœ„í•œ ë‹¨ì¼ í”Œë«í¼
2. **ì„ ì–¸ì  ê´€ë¦¬**: ë²„ì „ ê´€ë¦¬ê°€ ê°€ëŠ¥í•œ Infrastructure as Code
3. **í’ë¶€í•œ ìƒíƒœê³„**: AI ì›Œí¬ë¡œë“œë¥¼ ìœ„í•œ ê´‘ë²”ìœ„í•œ ì˜¤í”ˆì†ŒìŠ¤ ì†”ë£¨ì…˜
4. **í´ë¼ìš°ë“œ ì´ì‹ì„±**: ì–´ë””ì„œë‚˜ ì‹¤í–‰ ê°€ëŠ¥ (ì˜¨í”„ë ˆë¯¸ìŠ¤, AWS, GCP, Azure)
5. **ì„±ìˆ™í•œ ë„êµ¬**: kubectl, Helm, operators, ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ
6. **í™œë°œí•œ ì»¤ë®¤ë‹ˆí‹°**: Kubernetes AI/ML SIGê°€ í˜ì‹ ì„ ì£¼ë„

### ì•ìœ¼ë¡œì˜ ë°©í–¥

```mermaid
graph LR
    START["Agentic AI<br/>ìš”êµ¬ì‚¬í•­"] --> K8S["Kubernetes<br/>ê¸°ë°˜ í”Œë«í¼"]
    K8S --> OSS["ì˜¤í”ˆì†ŒìŠ¤<br/>ìƒíƒœê³„"]
    OSS --> CLOUD["í´ë¼ìš°ë“œ í”„ë¡œë°”ì´ë”<br/>í†µí•©"]
    CLOUD --> SOLUTION["ì™„ì „í•œ<br/>AI í”Œë«í¼"]

    style START fill:#ff6b6b
    style K8S fill:#326ce5
    style OSS fill:#2ecc71
    style CLOUD fill:#ff9900
    style SOLUTION fill:#4ecdc4
```

Agentic AI í”Œë«í¼ì„ êµ¬ì¶•í•˜ëŠ” ì¡°ì§ì„ ìœ„í•œ ê¶Œì¥ ì‚¬í•­:

1. **Kubernetesë¡œ ì‹œì‘**: íŒ€ ë‚´ Kubernetes ì „ë¬¸ì„± í™•ë³´
2. **ì˜¤í”ˆì†ŒìŠ¤ í™œìš©**: ê²€ì¦ëœ ì†”ë£¨ì…˜ ë„ì… (vLLM, LangFuse ë“±)
3. **í´ë¼ìš°ë“œ í†µí•©**: ì˜¤í”ˆì†ŒìŠ¤ì™€ ê´€ë¦¬í˜• ì„œë¹„ìŠ¤ ê²°í•©
4. **ì¸í”„ë¼ ìë™í™”**: ìë™ ìŠ¤ì¼€ì¼ë§ ë° í”„ë¡œë¹„ì €ë‹ êµ¬í˜„
5. **ì „ë©´ì  ê´€ì¸¡ì„±**: ì²«ë‚ ë¶€í„° í¬ê´„ì ì¸ ê´€ì¸¡ì„± í™•ë³´

:::info ë‹¤ìŒ ë‹¨ê³„: EKS ê¸°ë°˜ ì†”ë£¨ì…˜
ì´ëŸ¬í•œ ë„ì „ê³¼ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ **Amazon EKSì™€ AWS ì„œë¹„ìŠ¤** í™œìš© ë°©ë²•ì€ [EKS ê¸°ë°˜ Agentic AI ì†”ë£¨ì…˜](./agentic-ai-solutions-eks.md)ì„ ì°¸ì¡°í•˜ì„¸ìš”.
:::

---

## ë‹¤ìŒ ë‹¨ê³„

ì´ ë¬¸ì„œì—ì„œëŠ” Agentic AI ì›Œí¬ë¡œë“œì˜ 4ê°€ì§€ í•µì‹¬ ë„ì „ê³¼ì œì™€ Kubernetes ê¸°ë°˜ ì˜¤í”ˆì†ŒìŠ¤ ìƒíƒœê³„ë¥¼ ì‚´í´ë³´ì•˜ìŠµë‹ˆë‹¤.

:::info ë‹¤ìŒ ë‹¨ê³„: EKS ê¸°ë°˜ í•´ê²°ë°©ì•ˆ
ì´ ë¬¸ì„œì—ì„œ ì†Œê°œí•œ ë„ì „ê³¼ì œë“¤ì„ **Amazon EKSì™€ AWS ì„œë¹„ìŠ¤**ë¥¼ í™œìš©í•˜ì—¬ í•´ê²°í•˜ëŠ” êµ¬ì²´ì ì¸ ë°©ë²•ì€ [EKS ê¸°ë°˜ Agentic AI í•´ê²°ë°©ì•ˆ](./agentic-ai-solutions-eks.md)ì„ ì°¸ì¡°í•˜ì„¸ìš”.

ë‹¤ìŒ ë¬¸ì„œì—ì„œ ë‹¤ë£° ë‚´ìš©:
- EKS Auto Modeë¡œ ì™„ì „ ìë™í™”ëœ í´ëŸ¬ìŠ¤í„° êµ¬ì¶•
- Karpenterë¥¼ í†µí•œ GPU ë…¸ë“œ ìë™ í”„ë¡œë¹„ì €ë‹
- AWS ì„œë¹„ìŠ¤ì™€ì˜ í†µí•© (Bedrock, S3, CloudWatch)
- í”„ë¡œë•ì…˜ í™˜ê²½ì„ ìœ„í•œ ë³´ì•ˆ ë° ìš´ì˜ ì „ëµ
- ì‹¤ì „ ë°°í¬ ê°€ì´ë“œ ë° íŠ¸ëŸ¬ë¸”ìŠˆíŒ…
:::

---

## ì°¸ê³  ìë£Œ

### Kubernetes ë° ì¸í”„ë¼
- [Kubernetes ê³µì‹ ë¬¸ì„œ](https://kubernetes.io/docs/)
- [Karpenter ê³µì‹ ë¬¸ì„œ](https://karpenter.sh/docs/)
- [Amazon EKS Best Practices Guide](https://aws.github.io/aws-eks-best-practices/)
- [NVIDIA GPU Operator Documentation](https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/overview.html)
- [KEDA - Kubernetes Event-driven Autoscaling](https://keda.sh/)

### ëª¨ë¸ ì„œë¹™ ë° ì¶”ë¡ 
- [vLLM Documentation](https://docs.vllm.ai/)
- [llm-d Project](https://github.com/llm-d/llm-d)
- [Kgateway Documentation](https://kgateway.io/docs/)
- [LiteLLM Documentation](https://docs.litellm.ai/)

### LLM Observability
- [LangFuse Documentation](https://langfuse.com/docs)
- [LangSmith Documentation](https://docs.smith.langchain.com/)
- [RAGAS Documentation](https://docs.ragas.io/)

### ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤
- [Milvus Documentation](https://milvus.io/docs)
- [Milvus Operator](https://github.com/milvus-io/milvus-operator)

### GPU ì¸í”„ë¼
- [NVIDIA DRA Documentation](https://docs.nvidia.com/datacenter/cloud-native/kubernetes/latest/dra.html)
- [DCGM Exporter](https://github.com/NVIDIA/dcgm-exporter)
- [NCCL Documentation](https://docs.nvidia.com/deeplearning/nccl/user-guide/docs/index.html)
- [AWS EFA Documentation](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/efa.html)

### Agent í”„ë ˆì„ì›Œí¬ ë° í•™ìŠµ
- [KAgent - Kubernetes Agent Framework](https://github.com/kagent-dev/kagent)
- [NVIDIA NeMo Framework](https://docs.nvidia.com/nemo-framework/user-guide/latest/overview.html)
- [Kubeflow Documentation](https://www.kubeflow.org/docs/)
