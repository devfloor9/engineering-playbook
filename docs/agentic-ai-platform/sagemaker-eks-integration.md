---
title: "SageMaker-EKS í•˜ì´ë¸Œë¦¬ë“œ ML ì•„í‚¤í…ì²˜"
sidebar_label: "16. SageMaker-EKS í†µí•©"
description: "SageMakerì—ì„œ í•™ìŠµí•˜ê³  EKSì—ì„œ ì„œë¹™í•˜ëŠ” í•˜ì´ë¸Œë¦¬ë“œ ML ì•„í‚¤í…ì²˜"
sidebar_position: 16
category: "genai-aiml"
tags: [sagemaker, eks, hybrid, mlops, model-registry, training, inference]
last_update:
  date: 2026-02-13
  author: devfloor9
---

import SpecificationTable from '@site/src/components/tables/SpecificationTable';
import { HybridComparison, CostOptimization } from '@site/src/components/SagemakerTables';

# SageMaker-EKS í•˜ì´ë¸Œë¦¬ë“œ ML ì•„í‚¤í…ì²˜

> ğŸ“… **ì‘ì„±ì¼**: 2026-02-13 | â±ï¸ **ì½ëŠ” ì‹œê°„**: ì•½ 22ë¶„

## ê°œìš”

SageMakerì˜ ê´€ë¦¬í˜• í•™ìŠµ í™˜ê²½ê³¼ EKSì˜ ìœ ì—°í•œ ì„œë¹™ ì¸í”„ë¼ë¥¼ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ML ì•„í‚¤í…ì²˜ë¥¼ ì„¤ê³„í•©ë‹ˆë‹¤. ì´ ì ‘ê·¼ ë°©ì‹ì€ ê° í”Œë«í¼ì˜ ê°•ì ì„ í™œìš©í•˜ì—¬ ë¹„ìš© íš¨ìœ¨ì„±ê³¼ ìš´ì˜ ìœ ì—°ì„±ì„ ë™ì‹œì— ë‹¬ì„±í•©ë‹ˆë‹¤.

### í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜ì˜ ì¥ì 

<HybridComparison />


## í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜ íŒ¨í„´

### ì „ì²´ ì•„í‚¤í…ì²˜ ê°œìš”

```mermaid
flowchart TB
    subgraph "SageMaker Training"
        SM_NB[SageMaker Notebooks<br/>Development]
        SM_TRAIN[SageMaker Training Jobs<br/>Managed Training]
        SM_PIPE[SageMaker Pipelines<br/>Orchestration]
        SM_REG[SageMaker Model Registry<br/>Central Governance]
    end
    
    subgraph "EKS Serving"
        KSERVE[KServe<br/>Model Serving]
        TRITON[Triton Inference Server<br/>GPU Optimization]
        GATEWAY[Inference Gateway<br/>Traffic Management]
        MONITOR[Prometheus + Grafana<br/>Monitoring]
    end
    
    subgraph "Shared Storage"
        S3[S3 Model Artifacts<br/>Versioned Storage]
        ECR[ECR Container Registry<br/>Custom Images]
    end
    
    SM_NB --> SM_TRAIN
    SM_TRAIN --> SM_PIPE
    SM_PIPE --> SM_REG
    SM_REG --> S3
    
    S3 --> KSERVE
    ECR --> KSERVE
    KSERVE --> TRITON
    TRITON --> GATEWAY
    GATEWAY --> MONITOR
    
    SM_PIPE -.->|Trigger Deployment| KSERVE
    
    style SM_TRAIN fill:#ff9900
    style KSERVE fill:#326ce5
    style S3 fill:#569a31
```

### íŒ¨í„´ 1: SageMaker í•™ìŠµ â†’ EKS ì„œë¹™

ê°€ì¥ ì¼ë°˜ì ì¸ í•˜ì´ë¸Œë¦¬ë“œ íŒ¨í„´ìœ¼ë¡œ, SageMakerì—ì„œ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  EKSì—ì„œ ì„œë¹™í•©ë‹ˆë‹¤.

**ì‚¬ìš© ì‚¬ë¡€:**
- ëŒ€ê·œëª¨ ë¶„ì‚° í•™ìŠµì´ í•„ìš”í•œ ê²½ìš°
- í•™ìŠµ ì¸í”„ë¼ ê´€ë¦¬ ë¶€ë‹´ì„ ì¤„ì´ê³  ì‹¶ì€ ê²½ìš°
- ì„œë¹™ í™˜ê²½ì—ì„œ ì„¸ë°€í•œ ì œì–´ê°€ í•„ìš”í•œ ê²½ìš°


### íŒ¨í„´ 2: EKS í•™ìŠµ â†’ SageMaker ì„œë¹™

íŠ¹ìˆ˜í•œ í•™ìŠµ í™˜ê²½ì´ í•„ìš”í•˜ì§€ë§Œ ì„œë¹™ì€ ê´€ë¦¬í˜•ìœ¼ë¡œ ìš´ì˜í•˜ê³  ì‹¶ì€ ê²½ìš°ì…ë‹ˆë‹¤.

**ì‚¬ìš© ì‚¬ë¡€:**
- ì»¤ìŠ¤í…€ í•™ìŠµ í”„ë ˆì„ì›Œí¬ ì‚¬ìš©
- Kubernetes ë„¤ì´í‹°ë¸Œ í•™ìŠµ ë„êµ¬ í™œìš© (Kubeflow, Ray)
- ì„œë¹™ ì¸í”„ë¼ ê´€ë¦¬ ë¶€ë‹´ì„ ì¤„ì´ê³  ì‹¶ì€ ê²½ìš°

### íŒ¨í„´ 3: í•˜ì´ë¸Œë¦¬ë“œ ì„œë¹™

SageMaker Endpointì™€ EKS ì„œë¹™ì„ ë™ì‹œì— ìš´ì˜í•˜ì—¬ ì›Œí¬ë¡œë“œë¥¼ ë¶„ì‚°í•©ë‹ˆë‹¤.

**ì‚¬ìš© ì‚¬ë¡€:**
- ê³ ê°€ìš©ì„±ì´ ì¤‘ìš”í•œ í”„ë¡œë•ì…˜ í™˜ê²½
- ë©€í‹° ë¦¬ì „ ë°°í¬
- A/B í…ŒìŠ¤íŒ… ë° ì¹´ë‚˜ë¦¬ ë°°í¬

---

## SageMaker Pipelines í†µí•©

### SageMaker Components for Kubeflow Pipelines

AWSëŠ” Kubeflow Pipelinesì—ì„œ SageMakerë¥¼ í˜¸ì¶œí•  ìˆ˜ ìˆëŠ” ê³µì‹ ì»´í¬ë„ŒíŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

```python
# sagemaker_kubeflow_pipeline.py
import kfp
from kfp import dsl
from kfp.aws import use_aws_secret
import sagemaker
from sagemaker.workflow.pipeline_context import PipelineSession

@dsl.component(
    base_image="public.ecr.aws/sagemaker/sagemaker-distribution:latest",
    packages_to_install=["sagemaker>=2.200.0"]
)
def sagemaker_training_component(
    training_image: str,
    role_arn: str,
    instance_type: str,
    instance_count: int,
    s3_input_data: str,
    s3_output_path: str,
    hyperparameters: dict
) -> str:
    """SageMaker Training Job ì‹¤í–‰ ì»´í¬ë„ŒíŠ¸"""
    import boto3
    import sagemaker
    from sagemaker.estimator import Estimator
    
    session = sagemaker.Session()
    
    estimator = Estimator(
        image_uri=training_image,
        role=role_arn,
        instance_count=instance_count,
        instance_type=instance_type,
        output_path=s3_output_path,
        sagemaker_session=session,
        hyperparameters=hyperparameters
    )
    
    estimator.fit({"training": s3_input_data}, wait=True)
    
    # ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ê²½ë¡œ ë°˜í™˜
    return estimator.model_data


@dsl.component(
    base_image="public.ecr.aws/sagemaker/sagemaker-distribution:latest",
    packages_to_install=["sagemaker>=2.200.0"]
)
def register_model_to_registry(
    model_data: str,
    model_package_group_name: str,
    inference_image: str,
    role_arn: str
) -> str:
    """SageMaker Model Registryì— ëª¨ë¸ ë“±ë¡"""
    import boto3
    import sagemaker
    from sagemaker.model import Model
    
    session = sagemaker.Session()
    
    model = Model(
        image_uri=inference_image,
        model_data=model_data,
        role=role_arn,
        sagemaker_session=session
    )
    
    # Model Registryì— ë“±ë¡
    model_package = model.register(
        content_types=["application/json"],
        response_types=["application/json"],
        inference_instances=["ml.g5.xlarge"],
        transform_instances=["ml.g5.xlarge"],
        model_package_group_name=model_package_group_name,
        approval_status="PendingManualApproval"
    )
    
    return model_package.model_package_arn


@dsl.component(
    base_image="python:3.10",
    packages_to_install=["kubernetes", "boto3"]
)
def deploy_to_kserve(
    model_package_arn: str,
    model_name: str,
    namespace: str = "kserve-inference"
) -> str:
    """KServe InferenceService ë°°í¬"""
    import boto3
    from kubernetes import client, config
    
    # SageMaker Model Registryì—ì„œ ëª¨ë¸ ì •ë³´ ì¡°íšŒ
    sm_client = boto3.client('sagemaker')
    model_package = sm_client.describe_model_package(
        ModelPackageName=model_package_arn
    )
    
    model_data_url = model_package['InferenceSpecification']['Containers'][0]['ModelDataUrl']
    
    # KServe InferenceService ìƒì„±
    config.load_incluster_config()
    custom_api = client.CustomObjectsApi()
    
    inference_service = {
        "apiVersion": "serving.kserve.io/v1beta1",
        "kind": "InferenceService",
        "metadata": {
            "name": model_name,
            "namespace": namespace
        },
        "spec": {
            "predictor": {
                "pytorch": {
                    "storageUri": model_data_url,
                    "resources": {
                        "requests": {
                            "nvidia.com/gpu": "1",
                            "memory": "8Gi"
                        },
                        "limits": {
                            "nvidia.com/gpu": "1",
                            "memory": "16Gi"
                        }
                    }
                }
            },
            "minReplicas": 2,
            "maxReplicas": 10
        }
    }
    
    custom_api.create_namespaced_custom_object(
        group="serving.kserve.io",
        version="v1beta1",
        namespace=namespace,
        plural="inferenceservices",
        body=inference_service
    )
    
    return f"Deployed {model_name} to KServe"


@dsl.pipeline(
    name="SageMaker to EKS Hybrid Pipeline",
    description="Train on SageMaker, deploy to EKS"
)
def hybrid_ml_pipeline(
    training_image: str = "763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-training:2.1.0-gpu-py310",
    inference_image: str = "763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-inference:2.1.0-gpu-py310",
    role_arn: str = "arn:aws:iam::123456789012:role/SageMakerExecutionRole",
    instance_type: str = "ml.g5.2xlarge",
    s3_input_data: str = "s3://my-bucket/training-data/",
    s3_output_path: str = "s3://my-bucket/models/",
    model_package_group: str = "fraud-detection-models"
):
    # 1. SageMakerì—ì„œ í•™ìŠµ
    training_task = sagemaker_training_component(
        training_image=training_image,
        role_arn=role_arn,
        instance_type=instance_type,
        instance_count=2,
        s3_input_data=s3_input_data,
        s3_output_path=s3_output_path,
        hyperparameters={
            "epochs": "50",
            "batch-size": "64",
            "learning-rate": "0.001"
        }
    )
    training_task.apply(use_aws_secret('aws-secret', 'AWS_ACCESS_KEY_ID', 'AWS_SECRET_ACCESS_KEY'))
    
    # 2. Model Registryì— ë“±ë¡
    registry_task = register_model_to_registry(
        model_data=training_task.output,
        model_package_group_name=model_package_group,
        inference_image=inference_image,
        role_arn=role_arn
    )
    registry_task.apply(use_aws_secret('aws-secret', 'AWS_ACCESS_KEY_ID', 'AWS_SECRET_ACCESS_KEY'))
    
    # 3. EKS KServeì— ë°°í¬
    deploy_task = deploy_to_kserve(
        model_package_arn=registry_task.output,
        model_name="fraud-detection-v1",
        namespace="kserve-inference"
    )
    
    return deploy_task.output
```


---

## SageMaker Model Registry ê±°ë²„ë„ŒìŠ¤

### ì¤‘ì•™ ì§‘ì¤‘ì‹ ëª¨ë¸ ê´€ë¦¬

SageMaker Model RegistryëŠ” ëª¨ë“  ëª¨ë¸ì˜ ì¤‘ì•™ ì €ì¥ì†Œ ì—­í• ì„ í•˜ë©°, EKS ì„œë¹™ í™˜ê²½ì—ì„œë„ ë™ì¼í•œ ê±°ë²„ë„ŒìŠ¤ë¥¼ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```mermaid
flowchart TB
    subgraph "Model Lifecycle"
        DEV[ê°œë°œ í™˜ê²½<br/>ì‹¤í—˜ ëª¨ë¸]
        STAGING[ìŠ¤í…Œì´ì§•<br/>ê²€ì¦ ì¤‘]
        PROD[í”„ë¡œë•ì…˜<br/>ìŠ¹ì¸ëœ ëª¨ë¸]
        ARCHIVED[ì•„ì¹´ì´ë¸Œ<br/>íê¸°ëœ ëª¨ë¸]
    end
    
    subgraph "Approval Process"
        AUTO[ìë™ ìŠ¹ì¸<br/>ë©”íŠ¸ë¦­ ê¸°ë°˜]
        MANUAL[ìˆ˜ë™ ìŠ¹ì¸<br/>ë¦¬ë·° í•„ìš”]
    end
    
    subgraph "Deployment Targets"
        SM_EP[SageMaker Endpoint]
        EKS_KSERVE[EKS KServe]
        BATCH[Batch Transform]
    end
    
    DEV --> STAGING
    STAGING --> AUTO
    STAGING --> MANUAL
    AUTO --> PROD
    MANUAL --> PROD
    PROD --> ARCHIVED
    
    PROD --> SM_EP
    PROD --> EKS_KSERVE
    PROD --> BATCH
    
    style PROD fill:#34a853
    style STAGING fill:#fbbc04
    style ARCHIVED fill:#ea4335
```

### Model Registry ì„¤ì •

```python
# model_registry_setup.py
import boto3
import sagemaker
from sagemaker.model_package import ModelPackageGroup

sm_client = boto3.client('sagemaker')
session = sagemaker.Session()

# Model Package Group ìƒì„±
model_package_group_name = "fraud-detection-models"

try:
    sm_client.create_model_package_group(
        ModelPackageGroupName=model_package_group_name,
        ModelPackageGroupDescription="Fraud detection models for production",
        Tags=[
            {"Key": "Team", "Value": "ml-platform"},
            {"Key": "Environment", "Value": "production"}
        ]
    )
except sm_client.exceptions.ResourceInUse:
    print(f"Model package group {model_package_group_name} already exists")

# ëª¨ë¸ ìŠ¹ì¸ ì •ì±… ì„¤ì •
model_approval_policy = {
    "Rules": [
        {
            "Name": "AutoApproveHighAccuracy",
            "Condition": {
                "MetricName": "accuracy",
                "Operator": "GreaterThanOrEqualTo",
                "Value": 0.95
            },
            "Action": "Approve"
        },
        {
            "Name": "RejectLowAccuracy",
            "Condition": {
                "MetricName": "accuracy",
                "Operator": "LessThan",
                "Value": 0.85
            },
            "Action": "Reject"
        }
    ]
}
```

### EKSì—ì„œ Model Registry ì¡°íšŒ

```python
# eks_model_loader.py
import boto3
from kubernetes import client, config

def get_approved_model_from_registry(model_package_group_name: str) -> str:
    """Model Registryì—ì„œ ìŠ¹ì¸ëœ ìµœì‹  ëª¨ë¸ ì¡°íšŒ"""
    sm_client = boto3.client('sagemaker')
    
    # ìŠ¹ì¸ëœ ëª¨ë¸ íŒ¨í‚¤ì§€ ì¡°íšŒ
    response = sm_client.list_model_packages(
        ModelPackageGroupName=model_package_group_name,
        ModelApprovalStatus='Approved',
        SortBy='CreationTime',
        SortOrder='Descending',
        MaxResults=1
    )
    
    if not response['ModelPackageSummaryList']:
        raise ValueError(f"No approved models found in {model_package_group_name}")
    
    model_package_arn = response['ModelPackageSummaryList'][0]['ModelPackageArn']
    
    # ëª¨ë¸ ìƒì„¸ ì •ë³´ ì¡°íšŒ
    model_package = sm_client.describe_model_package(
        ModelPackageName=model_package_arn
    )
    
    model_data_url = model_package['InferenceSpecification']['Containers'][0]['ModelDataUrl']
    
    return model_data_url


def update_kserve_with_latest_model(model_name: str, namespace: str):
    """KServe InferenceServiceë¥¼ ìµœì‹  ìŠ¹ì¸ ëª¨ë¸ë¡œ ì—…ë°ì´íŠ¸"""
    config.load_incluster_config()
    custom_api = client.CustomObjectsApi()
    
    # Model Registryì—ì„œ ìµœì‹  ëª¨ë¸ ì¡°íšŒ
    model_url = get_approved_model_from_registry("fraud-detection-models")
    
    # InferenceService ì—…ë°ì´íŠ¸
    patch_body = {
        "spec": {
            "predictor": {
                "pytorch": {
                    "storageUri": model_url
                }
            }
        }
    }
    
    custom_api.patch_namespaced_custom_object(
        group="serving.kserve.io",
        version="v1beta1",
        namespace=namespace,
        plural="inferenceservices",
        name=model_name,
        body=patch_body
    )
    
    print(f"Updated {model_name} with model from {model_url}")
```


---

## ë¹„ìš© ìµœì í™” ì „ëµ

### í•™ìŠµ vs ì„œë¹™ ë¹„ìš© ë¶„ì„

<CostOptimization />

### ë¹„ìš© ìµœì í™” ì²´í¬ë¦¬ìŠ¤íŠ¸

```yaml
# cost-optimization-config.yaml
training:
  # SageMaker Managed Spot Training (ìµœëŒ€ 90% ì ˆê°)
  use_spot_instances: true
  max_wait_time_seconds: 86400  # 24ì‹œê°„
  max_run_time_seconds: 43200   # 12ì‹œê°„
  
  # ì²´í¬í¬ì¸íŠ¸ í™œì„±í™” (Spot ì¤‘ë‹¨ ëŒ€ë¹„)
  checkpoint_s3_uri: s3://my-bucket/checkpoints/
  checkpoint_local_path: /opt/ml/checkpoints
  
  # ì¸ìŠ¤í„´ìŠ¤ íƒ€ì… ìµœì í™”
  instance_type: ml.g5.2xlarge  # GPU í•™ìŠµ
  instance_count: 2
  
  # í•™ìŠµ ì™„ë£Œ í›„ ìë™ ì¢…ë£Œ
  auto_terminate: true

serving:
  # Karpenter Spot ì¸ìŠ¤í„´ìŠ¤ (ìµœëŒ€ 70% ì ˆê°)
  capacity_type: spot
  
  # ì˜¤í† ìŠ¤ì¼€ì¼ë§ ì„¤ì •
  min_replicas: 1
  max_replicas: 10
  target_utilization: 70
  
  # ìœ íœ´ ì‹œê°„ ìŠ¤ì¼€ì¼ ë‹¤ìš´
  scale_down_delay: 300  # 5ë¶„
  
  # GPU ê³µìœ  (MIG ë˜ëŠ” MPS)
  enable_gpu_sharing: true
  max_shared_clients: 4

storage:
  # S3 Intelligent-Tiering
  s3_storage_class: INTELLIGENT_TIERING
  
  # ì˜¤ë˜ëœ ëª¨ë¸ ì•„ì¹´ì´ë¸Œ
  lifecycle_policy:
    archive_after_days: 90
    delete_after_days: 365
```

### ë¹„ìš© ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ

```python
# cost_monitoring.py
import boto3
from datetime import datetime, timedelta

def get_sagemaker_training_costs(days=30):
    """SageMaker í•™ìŠµ ë¹„ìš© ì¡°íšŒ"""
    ce_client = boto3.client('ce')
    
    end_date = datetime.now().date()
    start_date = end_date - timedelta(days=days)
    
    response = ce_client.get_cost_and_usage(
        TimePeriod={
            'Start': start_date.strftime('%Y-%m-%d'),
            'End': end_date.strftime('%Y-%m-%d')
        },
        Granularity='DAILY',
        Metrics=['UnblendedCost'],
        Filter={
            'Dimensions': {
                'Key': 'SERVICE',
                'Values': ['Amazon SageMaker']
            }
        },
        GroupBy=[
            {'Type': 'DIMENSION', 'Key': 'USAGE_TYPE'}
        ]
    )
    
    return response


def get_eks_serving_costs(cluster_name: str, days=30):
    """EKS ì„œë¹™ ë¹„ìš© ì¡°íšŒ"""
    ce_client = boto3.client('ce')
    
    end_date = datetime.now().date()
    start_date = end_date - timedelta(days=days)
    
    response = ce_client.get_cost_and_usage(
        TimePeriod={
            'Start': start_date.strftime('%Y-%m-%d'),
            'End': end_date.strftime('%Y-%m-%d')
        },
        Granularity='DAILY',
        Metrics=['UnblendedCost'],
        Filter={
            'And': [
                {
                    'Dimensions': {
                        'Key': 'SERVICE',
                        'Values': ['Amazon Elastic Compute Cloud - Compute']
                    }
                },
                {
                    'Tags': {
                        'Key': 'kubernetes.io/cluster/' + cluster_name,
                        'Values': ['owned']
                    }
                }
            ]
        }
    )
    
    return response
```


---

## ë©€í‹° ë¦¬ì „ ë°°í¬ íŒ¨í„´

### ê¸€ë¡œë²Œ ëª¨ë¸ ë°°í¬ ì•„í‚¤í…ì²˜

```mermaid
flowchart TB
    subgraph "Primary Region (us-west-2)"
        SM_TRAIN[SageMaker Training]
        SM_REG[Model Registry<br/>Primary]
        S3_PRIMARY[S3 Model Artifacts<br/>Primary]
    end
    
    subgraph "Secondary Region (ap-northeast-2)"
        S3_REPLICA[S3 Model Artifacts<br/>Replica]
        EKS_AP[EKS Cluster<br/>Seoul]
        KSERVE_AP[KServe<br/>Asia Pacific]
    end
    
    subgraph "Secondary Region (eu-west-1)"
        S3_EU[S3 Model Artifacts<br/>Replica]
        EKS_EU[EKS Cluster<br/>Ireland]
        KSERVE_EU[KServe<br/>Europe]
    end
    
    subgraph "Global Traffic Management"
        R53[Route 53<br/>Geo Routing]
        CLOUDFRONT[CloudFront<br/>Edge Caching]
    end
    
    SM_TRAIN --> SM_REG
    SM_REG --> S3_PRIMARY
    
    S3_PRIMARY -->|S3 Cross-Region Replication| S3_REPLICA
    S3_PRIMARY -->|S3 Cross-Region Replication| S3_EU
    
    S3_REPLICA --> EKS_AP
    EKS_AP --> KSERVE_AP
    
    S3_EU --> EKS_EU
    EKS_EU --> KSERVE_EU
    
    R53 --> KSERVE_AP
    R53 --> KSERVE_EU
    CLOUDFRONT --> R53
    
    style SM_TRAIN fill:#ff9900
    style KSERVE_AP fill:#326ce5
    style KSERVE_EU fill:#326ce5
```

### S3 Cross-Region Replication ì„¤ì •

```json
{
  "Role": "arn:aws:iam::123456789012:role/S3ReplicationRole",
  "Rules": [
    {
      "ID": "ReplicateModelsToAPNE2",
      "Status": "Enabled",
      "Priority": 1,
      "Filter": {
        "Prefix": "models/"
      },
      "Destination": {
        "Bucket": "arn:aws:s3:::my-models-ap-northeast-2",
        "ReplicationTime": {
          "Status": "Enabled",
          "Time": {
            "Minutes": 15
          }
        },
        "Metrics": {
          "Status": "Enabled",
          "EventThreshold": {
            "Minutes": 15
          }
        }
      }
    },
    {
      "ID": "ReplicateModelsToEUW1",
      "Status": "Enabled",
      "Priority": 2,
      "Filter": {
        "Prefix": "models/"
      },
      "Destination": {
        "Bucket": "arn:aws:s3:::my-models-eu-west-1",
        "ReplicationTime": {
          "Status": "Enabled",
          "Time": {
            "Minutes": 15
          }
        }
      }
    }
  ]
}
```

### ë©€í‹° ë¦¬ì „ ë°°í¬ ìë™í™”

```python
# multi_region_deployment.py
import boto3
from typing import List, Dict

class MultiRegionDeployer:
    def __init__(self, regions: List[str]):
        self.regions = regions
        self.sm_clients = {
            region: boto3.client('sagemaker', region_name=region)
            for region in regions
        }
    
    def deploy_model_to_all_regions(
        self,
        model_package_arn: str,
        model_name: str,
        namespace: str = "kserve-inference"
    ):
        """ëª¨ë“  ë¦¬ì „ì— ëª¨ë¸ ë°°í¬"""
        deployment_results = {}
        
        for region in self.regions:
            try:
                # ë¦¬ì „ë³„ S3 ë²„í‚·ì—ì„œ ëª¨ë¸ ë¡œë“œ
                model_url = self._get_regional_model_url(model_package_arn, region)
                
                # ë¦¬ì „ë³„ EKS í´ëŸ¬ìŠ¤í„°ì— ë°°í¬
                result = self._deploy_to_eks(
                    region=region,
                    model_url=model_url,
                    model_name=model_name,
                    namespace=namespace
                )
                
                deployment_results[region] = {
                    "status": "success",
                    "model_url": model_url,
                    "endpoint": result
                }
                
            except Exception as e:
                deployment_results[region] = {
                    "status": "failed",
                    "error": str(e)
                }
        
        return deployment_results
    
    def _get_regional_model_url(self, model_package_arn: str, region: str) -> str:
        """ë¦¬ì „ë³„ ëª¨ë¸ URL ì¡°íšŒ"""
        sm_client = self.sm_clients[region]
        
        # Model Registryì—ì„œ ëª¨ë¸ ì •ë³´ ì¡°íšŒ
        model_package = sm_client.describe_model_package(
            ModelPackageName=model_package_arn
        )
        
        # ë¦¬ì „ë³„ S3 ë²„í‚·ìœ¼ë¡œ ë³€í™˜
        original_url = model_package['InferenceSpecification']['Containers'][0]['ModelDataUrl']
        regional_url = original_url.replace('us-west-2', region)
        
        return regional_url
    
    def _deploy_to_eks(
        self,
        region: str,
        model_url: str,
        model_name: str,
        namespace: str
    ) -> str:
        """ë¦¬ì „ë³„ EKS í´ëŸ¬ìŠ¤í„°ì— ë°°í¬"""
        from kubernetes import client, config
        
        # ë¦¬ì „ë³„ kubeconfig ë¡œë“œ
        config.load_kube_config(context=f"eks-{region}")
        
        custom_api = client.CustomObjectsApi()
        
        inference_service = {
            "apiVersion": "serving.kserve.io/v1beta1",
            "kind": "InferenceService",
            "metadata": {
                "name": f"{model_name}-{region}",
                "namespace": namespace
            },
            "spec": {
                "predictor": {
                    "pytorch": {
                        "storageUri": model_url,
                        "resources": {
                            "requests": {"nvidia.com/gpu": "1"},
                            "limits": {"nvidia.com/gpu": "1"}
                        }
                    }
                },
                "minReplicas": 2,
                "maxReplicas": 10
            }
        }
        
        custom_api.create_namespaced_custom_object(
            group="serving.kserve.io",
            version="v1beta1",
            namespace=namespace,
            plural="inferenceservices",
            body=inference_service
        )
        
        return f"https://{model_name}-{region}.{namespace}.svc.cluster.local"


# ì‚¬ìš© ì˜ˆì‹œ
deployer = MultiRegionDeployer(
    regions=["us-west-2", "ap-northeast-2", "eu-west-1"]
)

results = deployer.deploy_model_to_all_regions(
    model_package_arn="arn:aws:sagemaker:us-west-2:123456789012:model-package/fraud-detection/1",
    model_name="fraud-detection-v1"
)

print(results)
```


---

## ëª¨ë¸ ëª¨ë‹ˆí„°ë§ ë° ë“œë¦¬í”„íŠ¸ íƒì§€

### í†µí•© ëª¨ë‹ˆí„°ë§ ì•„í‚¤í…ì²˜

```mermaid
flowchart TB
    subgraph "Data Collection"
        KSERVE[KServe Predictor<br/>Inference Requests]
        LOGGER[Request Logger<br/>Sidecar]
    end
    
    subgraph "SageMaker Model Monitor"
        DATA_QUALITY[Data Quality Monitor<br/>Input Drift]
        MODEL_QUALITY[Model Quality Monitor<br/>Prediction Drift]
        BIAS[Bias Monitor<br/>Fairness]
        EXPLAINABILITY[Explainability Monitor<br/>Feature Attribution]
    end
    
    subgraph "Storage & Analysis"
        S3_LOGS[S3 Inference Logs<br/>Structured Data]
        ATHENA[Amazon Athena<br/>SQL Analysis]
    end
    
    subgraph "Alerting"
        CW_ALARMS[CloudWatch Alarms<br/>Threshold Violations]
        SNS[SNS Topics<br/>Notifications]
        LAMBDA[Lambda Functions<br/>Auto-remediation]
    end
    
    KSERVE --> LOGGER
    LOGGER --> S3_LOGS
    
    S3_LOGS --> DATA_QUALITY
    S3_LOGS --> MODEL_QUALITY
    S3_LOGS --> BIAS
    S3_LOGS --> EXPLAINABILITY
    
    S3_LOGS --> ATHENA
    
    DATA_QUALITY --> CW_ALARMS
    MODEL_QUALITY --> CW_ALARMS
    CW_ALARMS --> SNS
    SNS --> LAMBDA
    
    style DATA_QUALITY fill:#ff9900
    style MODEL_QUALITY fill:#ff9900
```

### KServe Logger Sidecar ì„¤ì •

```yaml
apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: fraud-detection-monitored
  namespace: kserve-inference
spec:
  predictor:
    pytorch:
      storageUri: s3://my-models/fraud-detection/model.tar.gz
      resources:
        requests:
          nvidia.com/gpu: 1
        limits:
          nvidia.com/gpu: 1
    
    # Logger Sidecar ì¶”ê°€
    logger:
      mode: all  # request, response, all
      url: http://logger-service.monitoring.svc.cluster.local:8080/log
  
  minReplicas: 2
  maxReplicas: 10
---
apiVersion: v1
kind: Service
metadata:
  name: logger-service
  namespace: monitoring
spec:
  selector:
    app: inference-logger
  ports:
    - port: 8080
      targetPort: 8080
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: inference-logger
  namespace: monitoring
spec:
  replicas: 2
  selector:
    matchLabels:
      app: inference-logger
  template:
    metadata:
      labels:
        app: inference-logger
    spec:
      serviceAccountName: inference-logger-sa
      containers:
        - name: logger
          image: my-registry/inference-logger:latest
          ports:
            - containerPort: 8080
          env:
            - name: S3_BUCKET
              value: "my-inference-logs"
            - name: S3_PREFIX
              value: "fraud-detection/"
            - name: AWS_REGION
              value: "us-west-2"
          resources:
            requests:
              cpu: "500m"
              memory: "1Gi"
            limits:
              cpu: "1"
              memory: "2Gi"
```

### SageMaker Model Monitor í†µí•©

```python
# sagemaker_model_monitor.py
import boto3
from sagemaker.model_monitor import (
    DataCaptureConfig,
    DataQualityMonitor,
    ModelQualityMonitor
)
from sagemaker import Session

session = Session()
sm_client = boto3.client('sagemaker')

# Data Quality Monitor ì„¤ì •
data_quality_monitor = DataQualityMonitor(
    role='arn:aws:iam::123456789012:role/SageMakerModelMonitorRole',
    instance_count=1,
    instance_type='ml.m5.xlarge',
    volume_size_in_gb=20,
    max_runtime_in_seconds=3600,
    sagemaker_session=session
)

# ë² ì´ìŠ¤ë¼ì¸ ìƒì„± (í•™ìŠµ ë°ì´í„° ê¸°ë°˜)
baseline_job = data_quality_monitor.suggest_baseline(
    baseline_dataset='s3://my-bucket/training-data/baseline.csv',
    dataset_format={'csv': {'header': True}},
    output_s3_uri='s3://my-bucket/model-monitor/baseline',
    wait=True
)

# ëª¨ë‹ˆí„°ë§ ìŠ¤ì¼€ì¤„ ìƒì„±
monitoring_schedule = data_quality_monitor.create_monitoring_schedule(
    monitor_schedule_name='fraud-detection-data-quality',
    endpoint_input='s3://my-inference-logs/fraud-detection/',  # EKS ë¡œê·¸
    output_s3_uri='s3://my-bucket/model-monitor/reports',
    statistics=baseline_job.baseline_statistics(),
    constraints=baseline_job.suggested_constraints(),
    schedule_cron_expression='cron(0 * * * ? *)',  # ë§¤ì‹œê°„
    enable_cloudwatch_metrics=True
)

print(f"Monitoring schedule created: {monitoring_schedule.monitoring_schedule_name}")
```

### ë“œë¦¬í”„íŠ¸ íƒì§€ ë° ìë™ ì¬í•™ìŠµ

```python
# drift_detection_handler.py
import boto3
import json
from datetime import datetime

def lambda_handler(event, context):
    """CloudWatch Alarm íŠ¸ë¦¬ê±° ì‹œ ìë™ ì¬í•™ìŠµ"""
    
    # Alarm ì •ë³´ íŒŒì‹±
    message = json.loads(event['Records'][0]['Sns']['Message'])
    alarm_name = message['AlarmName']
    
    if 'DataQualityViolation' in alarm_name:
        print(f"Data quality violation detected: {alarm_name}")
        
        # SageMaker Training Job íŠ¸ë¦¬ê±°
        sm_client = boto3.client('sagemaker')
        
        training_job_name = f"fraud-detection-retrain-{datetime.now().strftime('%Y%m%d%H%M%S')}"
        
        response = sm_client.create_training_job(
            TrainingJobName=training_job_name,
            RoleArn='arn:aws:iam::123456789012:role/SageMakerExecutionRole',
            AlgorithmSpecification={
                'TrainingImage': '763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-training:2.1.0-gpu-py310',
                'TrainingInputMode': 'File'
            },
            InputDataConfig=[
                {
                    'ChannelName': 'training',
                    'DataSource': {
                        'S3DataSource': {
                            'S3DataType': 'S3Prefix',
                            'S3Uri': 's3://my-bucket/training-data/',
                            'S3DataDistributionType': 'FullyReplicated'
                        }
                    }
                }
            ],
            OutputDataConfig={
                'S3OutputPath': 's3://my-bucket/models/'
            },
            ResourceConfig={
                'InstanceType': 'ml.g5.2xlarge',
                'InstanceCount': 2,
                'VolumeSizeInGB': 50
            },
            StoppingCondition={
                'MaxRuntimeInSeconds': 43200  # 12ì‹œê°„
            },
            Tags=[
                {'Key': 'Trigger', 'Value': 'AutoRetraining'},
                {'Key': 'Reason', 'Value': 'DataDrift'}
            ]
        )
        
        print(f"Retraining job started: {training_job_name}")
        
        return {
            'statusCode': 200,
            'body': json.dumps({
                'message': 'Retraining triggered',
                'training_job': training_job_name
            })
        }
    
    return {
        'statusCode': 200,
        'body': json.dumps({'message': 'No action required'})
    }
```


---

## ìš”ì•½

SageMaker-EKS í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜ëŠ” ê´€ë¦¬í˜• í•™ìŠµê³¼ ìœ ì—°í•œ ì„œë¹™ì˜ ì¥ì ì„ ê²°í•©í•©ë‹ˆë‹¤.

### í•µì‹¬ í¬ì¸íŠ¸

1. **í•˜ì´ë¸Œë¦¬ë“œ íŒ¨í„´**: SageMaker í•™ìŠµ + EKS ì„œë¹™ìœ¼ë¡œ ê° í”Œë«í¼ì˜ ê°•ì  í™œìš©
2. **ì¤‘ì•™ ê±°ë²„ë„ŒìŠ¤**: SageMaker Model Registryë¡œ ëª¨ë“  ëª¨ë¸ í†µí•© ê´€ë¦¬
3. **ë¹„ìš© ìµœì í™”**: Spot ì¸ìŠ¤í„´ìŠ¤ì™€ ì˜¤í† ìŠ¤ì¼€ì¼ë§ìœ¼ë¡œ ë¹„ìš© ì ˆê°
4. **ë©€í‹° ë¦¬ì „**: S3 Cross-Region Replicationìœ¼ë¡œ ê¸€ë¡œë²Œ ë°°í¬
5. **ëª¨ë‹ˆí„°ë§**: SageMaker Model Monitorì™€ EKS ë¡œê¹… í†µí•©

### ê¶Œì¥ ì‚¬í•­

- ëŒ€ê·œëª¨ ë¶„ì‚° í•™ìŠµì€ SageMakerì—ì„œ ìˆ˜í–‰í•˜ì—¬ ì¸í”„ë¼ ê´€ë¦¬ ë¶€ë‹´ ê°ì†Œ
- ì„œë¹™ í™˜ê²½ì€ EKSì—ì„œ ìš´ì˜í•˜ì—¬ ì„¸ë°€í•œ ì œì–´ì™€ ë¹„ìš© ìµœì í™”
- Model Registryë¥¼ ì¤‘ì•™ ì €ì¥ì†Œë¡œ í™œìš©í•˜ì—¬ ê±°ë²„ë„ŒìŠ¤ ê°•í™”
- ë“œë¦¬í”„íŠ¸ íƒì§€ ì‹œ ìë™ ì¬í•™ìŠµ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•

### ë‹¤ìŒ ë‹¨ê³„

- [EKS ê¸°ë°˜ MLOps íŒŒì´í”„ë¼ì¸](./mlops-pipeline-eks.md) - Kubeflow + MLflow + KServe
- [GPU ë¦¬ì†ŒìŠ¤ ê´€ë¦¬](./gpu-resource-management.md) - GPU í´ëŸ¬ìŠ¤í„° ìµœì í™”
- [ëª¨ë¸ ëª¨ë‹ˆí„°ë§](./agent-monitoring.md) - í”„ë¡œë•ì…˜ ëª¨ë¸ ê´€ì°°ì„±

---

## ì°¸ê³  ìë£Œ

- [SageMaker Components for Kubeflow Pipelines](https://docs.aws.amazon.com/sagemaker/latest/dg/kubernetes-sagemaker-components-for-kubeflow-pipelines.html)
- [SageMaker Model Registry](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry.html)
- [SageMaker Model Monitor](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html)
- [KServe Documentation](https://kserve.github.io/website/)
- [AWS Multi-Region Architecture](https://aws.amazon.com/solutions/implementations/multi-region-application-architecture/)

