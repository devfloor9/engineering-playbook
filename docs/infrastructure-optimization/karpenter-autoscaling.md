---
title: "Karpenterë¥¼ í™œìš©í•œ ì´ˆê³ ì† ì˜¤í† ìŠ¤ì¼€ì¼ë§"
sidebar_label: "4. Karpenter ì˜¤í† ìŠ¤ì¼€ì¼ë§"
description: "Amazon EKSì—ì„œ Karpenterì™€ ê³ í•´ìƒë„ ë©”íŠ¸ë¦­ìœ¼ë¡œ 10ì´ˆ ë¯¸ë§Œì˜ ì˜¤í† ìŠ¤ì¼€ì¼ë§ì„ ë‹¬ì„±í•˜ëŠ” ë°©ë²•. CloudWatchì™€ Prometheus ì•„í‚¤í…ì²˜ ë¹„êµ, HPA êµ¬ì„±, í”„ë¡œë•ì…˜ íŒ¨í„´ í¬í•¨"
tags: [eks, karpenter, autoscaling, performance, cloudwatch, prometheus, spot-instances]
category: "performance-networking"
last_update:
  date: 2025-02-09
  author: devfloor9
sidebar_position: 4
---

# Karpenterë¥¼ í™œìš©í•œ ì´ˆê³ ì† ì˜¤í† ìŠ¤ì¼€ì¼ë§

> ğŸ“… **ì‘ì„±ì¼**: 2025-02-09 | â±ï¸ **ì½ëŠ” ì‹œê°„**: ì•½ 10ë¶„

## ê°œìš”

í˜„ëŒ€ í´ë¼ìš°ë“œ ë„¤ì´í‹°ë¸Œ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ 10ì´ˆì™€ 3ë¶„ì˜ ì°¨ì´ëŠ” ìˆ˜ì²œ ê°œì˜ ì‹¤íŒ¨í•œ ìš”ì²­, ì €í•˜ëœ ì‚¬ìš©ì ê²½í—˜, ìˆ˜ìµ ì†ì‹¤ì„ ì˜ë¯¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê¸€ì—ì„œëŠ” Karpenterì˜ í˜ì‹ ì ì¸ ë…¸ë“œ í”„ë¡œë¹„ì €ë‹ ì ‘ê·¼ ë°©ì‹ê³¼ ì „ëµì ìœ¼ë¡œ êµ¬í˜„ëœ ê³ í•´ìƒë„ ë©”íŠ¸ë¦­ì„ ê²°í•©í•˜ì—¬ Amazon EKSì—ì„œ ì¼ê´€ëœ 10ì´ˆ ë¯¸ë§Œì˜ ì˜¤í† ìŠ¤ì¼€ì¼ë§ì„ ë‹¬ì„±í•˜ëŠ” ë°©ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤.

:::warning Karpenter v1.0+ ë§ˆì´ê·¸ë ˆì´ì…˜ í•„ìˆ˜
ì´ ë¬¸ì„œëŠ” Karpenter v1.x (GA) ê¸°ì¤€ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤. v0.xì—ì„œ ë§ˆì´ê·¸ë ˆì´ì…˜í•˜ëŠ” ê²½ìš°:

- v0.33+ â†’ v1.0 ìˆœì°¨ ì—…ê·¸ë ˆì´ë“œ í•„ìš”
- `Provisioner` â†’ `NodePool`, `AWSNodeTemplate` â†’ `EC2NodeClass` (v1beta1ì—ì„œ ì´ë¯¸ ë³€ê²½ë¨)
- v1.0ë¶€í„° `v1` API ê·¸ë£¹ ì‚¬ìš© (`karpenter.sh/v1`)
- **í˜¸í™˜ì„±**: K8s 1.31 â†’ Karpenter â‰¥1.0.5 | K8s 1.32 â†’ â‰¥1.2 | K8s 1.33 â†’ â‰¥1.5
- [ê³µì‹ ì—…ê·¸ë ˆì´ë“œ ê°€ì´ë“œ](https://karpenter.sh/docs/upgrading/upgrade-guide/)
:::

ê¸€ë¡œë²Œ ê·œëª¨ì˜ EKS í™˜ê²½(3ê°œ ë¦¬ì „, 28ê°œ í´ëŸ¬ìŠ¤í„°, 15,000ê°œ ì´ìƒì˜ Pod)ì—ì„œ ìŠ¤ì¼€ì¼ë§ ì§€ì—° ì‹œê°„ì„ 180ì´ˆ ì´ìƒì—ì„œ 10ì´ˆ ë¯¸ë§Œìœ¼ë¡œ ë‹¨ì¶•í•œ í”„ë¡œë•ì…˜ ê²€ì¦ ì•„í‚¤í…ì²˜ë¥¼ íƒêµ¬í•©ë‹ˆë‹¤.

## ê¸°ì¡´ ì˜¤í† ìŠ¤ì¼€ì¼ë§ì˜ ë¬¸ì œì 

ì†”ë£¨ì…˜ìœ¼ë¡œ ë“¤ì–´ê°€ê¸° ì „ì— ê¸°ì¡´ ì ‘ê·¼ ë°©ì‹ì´ ì‹¤íŒ¨í•˜ëŠ” ì´ìœ ë¥¼ ì´í•´í•´ì•¼ í•©ë‹ˆë‹¤:

```mermaid
graph LR
    subgraph "ê¸°ì¡´ ìŠ¤ì¼€ì¼ë§ íƒ€ì„ë¼ì¸ (3ë¶„ ì´ìƒ)"
        T1[íŠ¸ë˜í”½ ê¸‰ì¦<br/>T+0s] --> T2[CPU ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸<br/>T+60s]
        T2 --> T3[HPA ê²°ì •<br/>T+90s]
        T3 --> T4[ASG ìŠ¤ì¼€ì¼ë§<br/>T+120s]
        T4 --> T5[ë…¸ë“œ ì¤€ë¹„<br/>T+180s]
        T5 --> T6[Pod ìŠ¤ì¼€ì¤„ë§<br/>T+210s]
    end

    subgraph "ì‚¬ìš©ì ì˜í–¥"
        I1[íƒ€ì„ì•„ì›ƒ ì‹œì‘<br/>T+5s]
        I2[ì—ëŸ¬ ê¸‰ì¦<br/>T+30s]
        I3[ì„œë¹„ìŠ¤ ì €í•˜<br/>T+60s]
    end

    T1 -.-> I1
    T2 -.-> I2
    T3 -.-> I3

    style I1 fill:#ff4444
    style I2 fill:#ff6666
    style I3 fill:#ff8888

```

ê·¼ë³¸ì ì¸ ë¬¸ì œ: CPU ë©”íŠ¸ë¦­ì´ ìŠ¤ì¼€ì¼ë§ì„ íŠ¸ë¦¬ê±°í•  ë•ŒëŠ” ì´ë¯¸ ëŠ¦ì—ˆìŠµë‹ˆë‹¤.

**í˜„ì¬ í™˜ê²½ì˜ ë„ì „ ê³¼ì œ:**

- **ê¸€ë¡œë²Œ ê·œëª¨**: 3ê°œ ë¦¬ì „, 28ê°œ EKS í´ëŸ¬ìŠ¤í„°, 15,000ê°œ Pod ìš´ì˜
- **ëŒ€ìš©ëŸ‰ íŠ¸ë˜í”½**: ì¼ì¼ 773.4K ë¦¬í€˜ìŠ¤íŠ¸ ì²˜ë¦¬
- **ì§€ì—° ì‹œê°„ ë¬¸ì œ**: HPA + Karpenter ì¡°í•©ìœ¼ë¡œ 1-3ë¶„ì˜ ìŠ¤ì¼€ì¼ë§ ì§€ì—° ë°œìƒ
- **ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì§€ì—°**: CloudWatch ë©”íŠ¸ë¦­ì˜ 1-3ë¶„ ì§€ì—°ìœ¼ë¡œ ì‹¤ì‹œê°„ ëŒ€ì‘ ë¶ˆê°€

## Karpenter í˜ëª…: Direct-to-Metal í”„ë¡œë¹„ì €ë‹

KarpenterëŠ” Auto Scaling Group(ASG) ì¶”ìƒí™” ë ˆì´ì–´ë¥¼ ì œê±°í•˜ê³  ëŒ€ê¸° ì¤‘ì¸ Pod ìš”êµ¬ ì‚¬í•­ì„ ê¸°ë°˜ìœ¼ë¡œ EC2 ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì§ì ‘ í”„ë¡œë¹„ì €ë‹í•©ë‹ˆë‹¤. Karpenter v1.xëŠ” **Drift Detection** ê¸°ëŠ¥ì„ í†µí•´ NodePool ìŠ¤í™ ë³€ê²½ ì‹œ ê¸°ì¡´ ë…¸ë“œë¥¼ ìë™ìœ¼ë¡œ êµì²´í•©ë‹ˆë‹¤. AMI ì—…ë°ì´íŠ¸, ë³´ì•ˆ íŒ¨ì¹˜ ì ìš© ë“±ì´ ìë™í™”ë©ë‹ˆë‹¤.

```mermaid
graph TB
    subgraph "Karpenter ì•„í‚¤í…ì²˜"
        PP[ëŒ€ê¸° ì¤‘ì¸ Pod<br/>ê°ì§€ë¨]
        KL[Karpenter ë¡œì§]
        EC2[EC2 Fleet API]

        PP -->|ë°€ë¦¬ì´ˆ| KL

        subgraph "ì§€ëŠ¥í˜• ì˜ì‚¬ê²°ì • ì—”ì§„"
            IS[ì¸ìŠ¤í„´ìŠ¤ ì„ íƒ]
            SP[Spot/OD ë¯¹ìŠ¤]
            AZ[AZ ë¶„ì‚°]
            CP[ìš©ëŸ‰ ê³„íš]
        end

        KL --> IS
        KL --> SP
        KL --> AZ
        KL --> CP

        IS --> EC2
        SP --> EC2
        AZ --> EC2
        CP --> EC2
    end

    subgraph "ê¸°ì¡´ ASG"
        ASG[Auto Scaling Group]
        LT[Launch Template]
        ASGL[ASG ë¡œì§]

        ASG --> LT
        LT --> ASGL
        ASGL -->|2-3ë¶„| EC2_OLD[EC2 API]
    end

    EC2 -->|30-45ì´ˆ| NODE[ë…¸ë“œ ì¤€ë¹„]
    EC2_OLD -->|120-180ì´ˆ| NODE_OLD[ë…¸ë“œ ì¤€ë¹„]

    style KL fill:#ff9900,stroke:#232f3e,stroke-width:3px
    style EC2 fill:#146eb4,stroke:#232f3e,stroke-width:2px
    style ASG fill:#cccccc,stroke:#999999

```

## ê³ ì† ë©”íŠ¸ë¦­ ì•„í‚¤í…ì²˜: ë‘ ê°€ì§€ ì ‘ê·¼ ë°©ì‹

10ì´ˆ ë¯¸ë§Œ ìŠ¤ì¼€ì¼ë§ì„ ë‹¬ì„±í•˜ë ¤ë©´ ë¹ ë¥¸ ê°ì§€ ì‹œìŠ¤í…œì´ í•„ìš”í•©ë‹ˆë‹¤. ë‘ ê°€ì§€ ê²€ì¦ëœ ì•„í‚¤í…ì²˜ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.

### ë°©ì‹ 1: CloudWatch High-Resolution Integration

AWS ë„¤ì´í‹°ë¸Œ í™˜ê²½ì—ì„œ CloudWatchì˜ ê³ í•´ìƒë„ ë©”íŠ¸ë¦­ì„ í™œìš©í•©ë‹ˆë‹¤.

#### ì£¼ìš” êµ¬ì„± ìš”ì†Œ

```mermaid
graph TB
    subgraph "ë©”íŠ¸ë¦­ ì†ŒìŠ¤"
        subgraph "ì¤‘ìš” ë©”íŠ¸ë¦­ (1ì´ˆ)"
            RPS[ì´ˆë‹¹ ìš”ì²­ ìˆ˜]
            LAT[P99 ì§€ì—°ì‹œê°„]
            ERR[ì—ëŸ¬ìœ¨]
            QUEUE[í ê¹Šì´]
        end

        subgraph "í‘œì¤€ ë©”íŠ¸ë¦­ (60ì´ˆ)"
            CPU[CPU ì‚¬ìš©ëŸ‰]
            MEM[ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰]
            DISK[ë””ìŠ¤í¬ I/O]
            NET[ë„¤íŠ¸ì›Œí¬ I/O]
        end
    end

    subgraph "ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸"
        AGENT[ADOT Collector<br/>ë°°ì¹˜: 1ì´ˆ]
        EMF[EMF í¬ë§·<br/>ì••ì¶•]
        CW[CloudWatch API<br/>PutMetricData]
    end

    subgraph "ì˜ì‚¬ê²°ì • ë ˆì´ì–´"
        API[Custom Metrics API]
        CACHE[ì¸ë©”ëª¨ë¦¬ ìºì‹œ<br/>TTL: 5ì´ˆ]
        HPA[HPA Controller]
    end

    RPS --> AGENT
    LAT --> AGENT
    ERR --> AGENT
    QUEUE --> AGENT

    CPU --> AGENT
    MEM --> AGENT

    AGENT --> EMF
    EMF --> CW
    CW --> API
    API --> CACHE
    CACHE --> HPA

    style RPS fill:#ff4444
    style LAT fill:#ff4444
    style ERR fill:#ff4444
    style QUEUE fill:#ff4444

```

#### ìŠ¤ì¼€ì¼ë§ íƒ€ì„ë¼ì¸ (15ì´ˆ)

```mermaid
timeline
    title CloudWatch ê¸°ë°˜ ì˜¤í† ìŠ¤ì¼€ì¼ë§ íƒ€ì„ë¼ì¸

    T+0s  : ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ë©”íŠ¸ë¦­ ë°œìƒ
    T+1s  : CloudWatchë¡œ ë¹„ë™ê¸° ë°°ì¹˜ ì „ì†¡
    T+2s  : CloudWatch ë©”íŠ¸ë¦­ ì²˜ë¦¬ ì™„ë£Œ
    T+5s  : KEDA í´ë§ ì‚¬ì´í´ ì‹¤í–‰
    T+6s  : KEDAê°€ ìŠ¤ì¼€ì¼ë§ ê²°ì •
    T+8s  : HPA ì—…ë°ì´íŠ¸ ë° Pod ìƒì„± ìš”ì²­
    T+12s : Karpenter ë…¸ë“œ í”„ë¡œë¹„ì €ë‹
    T+14s : Pod ìŠ¤ì¼€ì¤„ë§ ì™„ë£Œ
```

**ì¥ì :**

- âœ… **ë¹ ë¥¸ ë©”íŠ¸ë¦­ ìˆ˜ì§‘**: 1-2ì´ˆì˜ ë‚®ì€ ì§€ì—°ì‹œê°„
- âœ… **ê°„ë‹¨í•œ ì„¤ì •**: AWS ë„¤ì´í‹°ë¸Œ í†µí•©
- âœ… **ê´€ë¦¬ ì˜¤ë²„í—¤ë“œ ì—†ìŒ**: ë³„ë„ ì¸í”„ë¼ ê´€ë¦¬ ë¶ˆí•„ìš”

**ë‹¨ì :**

- âŒ **ì œí•œëœ ì²˜ë¦¬ëŸ‰**: ê³„ì •ë‹¹ 1,000 TPS
- âŒ **Pod í•œê³„**: í´ëŸ¬ìŠ¤í„°ë‹¹ ìµœëŒ€ 5,000ê°œ
- âŒ **ë†’ì€ ë©”íŠ¸ë¦­ ë¹„ìš©**: AWS CloudWatch ë©”íŠ¸ë¦­ ìš”ê¸ˆ

### ë°©ì‹ 2: ADOT + Prometheus ê¸°ë°˜ ì•„í‚¤í…ì²˜

AWS Distro for OpenTelemetry(ADOT)ì™€ Prometheusë¥¼ ê²°í•©í•œ ì˜¤í”ˆì†ŒìŠ¤ ê¸°ë°˜ ê³ ì„±ëŠ¥ íŒŒì´í”„ë¼ì¸ì…ë‹ˆë‹¤.

#### ì£¼ìš” êµ¬ì„± ìš”ì†Œ

- **ADOT Collector**: DaemonSetê³¼ Sidecar í•˜ì´ë¸Œë¦¬ë“œ ë°°í¬
- **Prometheus**: HA êµ¬ì„± ë° Remote Storage ì—°ë™
- **Thanos Query Layer**: ë©€í‹° í´ëŸ¬ìŠ¤í„° ê¸€ë¡œë²Œ ë·° ì œê³µ
- **KEDA Prometheus Scaler**: 2ì´ˆ ê°„ê²©ì˜ ê³ ì† í´ë§
- **Grafana Mimir**: ì¥ê¸° ì €ì¥ ë° ê³ ì† ì¿¼ë¦¬ ì—”ì§„

#### ìŠ¤ì¼€ì¼ë§ íƒ€ì„ë¼ì¸ (70ì´ˆ)

```mermaid
timeline
    title ADOT + Prometheus ì˜¤í† ìŠ¤ì¼€ì¼ë§ íƒ€ì„ë¼ì¸ (ìµœì í™”ëœ í™˜ê²½)

    T+0s   : ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ë©”íŠ¸ë¦­ ë°œìƒ
    T+15s  : ADOT ìˆ˜ì§‘ (15ì´ˆ ìµœì í™”ëœ ìŠ¤í¬ë ˆì´í”„)
    T+16s  : Prometheus ì €ì¥ ë° ì¸ë±ì‹± ì™„ë£Œ
    T+25s  : KEDA í´ë§ ì‹¤í–‰ (10ì´ˆ ê°„ê²© ìµœì í™”)
    T+26s  : ìŠ¤ì¼€ì¼ë§ ê²°ì • (P95 ë©”íŠ¸ë¦­ ê¸°ë°˜)
    T+41s  : HPA ì—…ë°ì´íŠ¸ (15ì´ˆ ë™ê¸°í™” ì£¼ê¸°)
    T+46s  : Pod ìƒì„± ìš”ì²­ ì‹œì‘
    T+51s  : ì´ë¯¸ì§€ í’€ë§ ë° ì»¨í…Œì´ë„ˆ ì‹œì‘
    T+66s  : Pod Ready ìƒíƒœ ë° ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ
```

**ì¥ì :**

- âœ… **ë†’ì€ ì²˜ë¦¬ëŸ‰**: 100,000+ TPS ì§€ì›
- âœ… **í™•ì¥ì„±**: í´ëŸ¬ìŠ¤í„°ë‹¹ 20,000+ Pod ì§€ì›
- âœ… **ë‚®ì€ ë©”íŠ¸ë¦­ ë¹„ìš©**: ìŠ¤í† ë¦¬ì§€ ë¹„ìš©ë§Œ ë°œìƒ (Self-managed)
- âœ… **ì™„ì „í•œ ì œì–´**: ì„¤ì • ë° ìµœì í™” ììœ ë„

**ë‹¨ì :**

- âŒ **ë³µì¡í•œ ì„¤ì •**: ì¶”ê°€ ì»´í¬ë„ŒíŠ¸ ê´€ë¦¬ í•„ìš”
- âŒ **ë†’ì€ ìš´ì˜ ë³µì¡ì„±**: HA êµ¬ì„±, ë°±ì—…/ë³µêµ¬, ì„±ëŠ¥ íŠœë‹ í•„ìš”
- âŒ **ì „ë¬¸ ì¸ë ¥ í•„ìš”**: Prometheus ìš´ì˜ ê²½í—˜ í•„ìˆ˜

### ë¹„ìš© ìµœì í™” ë©”íŠ¸ë¦­ ì „ëµ

```mermaid
pie title "í´ëŸ¬ìŠ¤í„°ë‹¹ ì›”ë³„ CloudWatch ë¹„ìš©"
    "ê³ í•´ìƒë„ ë©”íŠ¸ë¦­ (10ê°œ)" : 3
    "í‘œì¤€ ë©”íŠ¸ë¦­ (100ê°œ)" : 10
    "API í˜¸ì¶œ" : 5
    "í´ëŸ¬ìŠ¤í„°ë‹¹ ì´ì•¡" : 18

```

28ê°œ í´ëŸ¬ìŠ¤í„° ê¸°ì¤€: ì¢…í•© ëª¨ë‹ˆí„°ë§ì— ì›” ~$500 vs ëª¨ë“  ë©”íŠ¸ë¦­ì„ ê³ í•´ìƒë„ë¡œ ìˆ˜ì§‘ ì‹œ $30,000+

### ê¶Œì¥ ì‚¬ìš© ì‚¬ë¡€

**CloudWatch High Resolution Metricì´ ì í•©í•œ ê²½ìš°:**

- ì†Œê·œëª¨ ì• í”Œë¦¬ì¼€ì´ì…˜ (Pod 5,000ê°œ ì´í•˜)
- ê°„ë‹¨í•œ ëª¨ë‹ˆí„°ë§ ìš”êµ¬ì‚¬í•­
- AWS ë„¤ì´í‹°ë¸Œ ì†”ë£¨ì…˜ ì„ í˜¸
- ë¹ ë¥¸ êµ¬ì¶•ê³¼ ì•ˆì •ì ì¸ ìš´ì˜ ìš°ì„ 

**ADOT + Prometheusê°€ ì í•©í•œ ê²½ìš°:**

- ëŒ€ê·œëª¨ í´ëŸ¬ìŠ¤í„° (Pod 20,000ê°œ ì´ìƒ)
- ë†’ì€ ë©”íŠ¸ë¦­ ì²˜ë¦¬ëŸ‰ ìš”êµ¬
- ì„¸ë°€í•œ ëª¨ë‹ˆí„°ë§ ë° ì»¤ìŠ¤í„°ë§ˆì´ì§• í•„ìš”
- ìµœê³  ìˆ˜ì¤€ì˜ ì„±ëŠ¥ê³¼ í™•ì¥ì„± í•„ìš”

## 10ì´ˆ ì•„í‚¤í…ì²˜: ë ˆì´ì–´ë³„ ìµœì í™”

10ì´ˆ ë¯¸ë§Œ ìŠ¤ì¼€ì¼ë§ì„ ë‹¬ì„±í•˜ë ¤ë©´ ëª¨ë“  ë ˆì´ì–´ì—ì„œ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤:

```mermaid
graph TB
    subgraph "ë ˆì´ì–´ 1: ì´ˆê³ ì† ë©”íŠ¸ë¦­ [1-2ì´ˆ]"
        ALB[ALB ë©”íŠ¸ë¦­]
        APP[ì•± ë©”íŠ¸ë¦­]
        PROM[Prometheus<br/>ìŠ¤í¬ë ˆì´í”„: 1ì´ˆ]

        ALB -->|1ì´ˆ| PROM
        APP -->|1ì´ˆ| PROM
    end

    subgraph "ë ˆì´ì–´ 2: ì¦‰ê° ì˜ì‚¬ê²°ì • [2-3ì´ˆ]"
        MA[Metrics API]
        HPA[HPA Controller<br/>ë™ê¸°í™”: 5ì´ˆ]
        VPA[VPA Recommender]

        PROM --> MA
        MA --> HPA
        MA --> VPA
    end

    subgraph "ë ˆì´ì–´ 3: ë¹ ë¥¸ í”„ë¡œë¹„ì €ë‹ [30-45ì´ˆ]"
        KARP[Karpenter<br/>Provisioner]
        SPOT[Spot Fleet]
        OD[On-Demand]

        HPA --> KARP
        KARP --> SPOT
        KARP --> OD
    end

    subgraph "ë ˆì´ì–´ 4: ì¦‰ì‹œ ìŠ¤ì¼€ì¤„ë§ [2-5ì´ˆ]"
        SCHED[Scheduler]
        NODE[ì‚¬ìš© ê°€ëŠ¥í•œ ë…¸ë“œ]
        POD[ìƒˆ Pod]

        SPOT --> NODE
        OD --> NODE
        NODE --> SCHED
        SCHED --> POD
    end

    subgraph "ì „ì²´ íƒ€ì„ë¼ì¸"
        TOTAL[ì´ ì‹œê°„: 35-55ì´ˆ<br/>P95: Pod 10ì´ˆ ë¯¸ë§Œ<br/>P95: ë…¸ë“œ 60ì´ˆ ë¯¸ë§Œ]
    end

    style KARP fill:#ff9900,stroke:#232f3e,stroke-width:3px
    style HPA fill:#146eb4,stroke:#232f3e,stroke-width:2px
    style TOTAL fill:#48C9B0,stroke:#232f3e,stroke-width:3px

```

## Karpenter í•µì‹¬ ì„¤ì •

60ì´ˆ ë¯¸ë§Œ ë…¸ë“œ í”„ë¡œë¹„ì €ë‹ì˜ í•µì‹¬ì€ ìµœì ì˜ Karpenter êµ¬ì„±ì— ìˆìŠµë‹ˆë‹¤:

```mermaid
graph LR
    subgraph "Provisioner ì „ëµ"
        subgraph "ì¸ìŠ¤í„´ìŠ¤ ì„ íƒ"
            IT[ì¸ìŠ¤í„´ìŠ¤ ìœ í˜•<br/>c6i.xlarge â†’ c6i.8xlarge<br/>c7i.xlarge â†’ c7i.8xlarge<br/>c6a.xlarge â†’ c6a.8xlarge]
            FLEX[ìœ ì—°ì„± = ì†ë„<br/>15+ ì¸ìŠ¤í„´ìŠ¤ ìœ í˜•]
        end

        subgraph "ìš©ëŸ‰ ë¯¹ìŠ¤"
            SPOT[Spot: 70-80%<br/>ë‹¤ì–‘í•œ ì¸ìŠ¤í„´ìŠ¤ í’€]
            OD[On-Demand: 20-30%<br/>ì¤‘ìš” ì›Œí¬ë¡œë“œ]
            INT[ì¤‘ë‹¨ ì²˜ë¦¬<br/>30ì´ˆ ìœ ì˜ˆ ê¸°ê°„]
        end

        subgraph "ì†ë„ ìµœì í™”"
            TTL[ttlSecondsAfterEmpty: 30<br/>ë¹ ë¥¸ ë””í”„ë¡œë¹„ì €ë‹]
            CONS[Consolidation: true<br/>ì§€ì†ì  ìµœì í™”]
            LIMITS[ì†Œí”„íŠ¸ ì œí•œë§Œ<br/>í•˜ë“œ ì œì•½ ì—†ìŒ]
        end
    end

    IT --> RESULT[45-60ì´ˆ í”„ë¡œë¹„ì €ë‹]
    SPOT --> RESULT
    TTL --> RESULT

    style RESULT fill:#48C9B0,stroke:#232f3e,stroke-width:3px

```

### Karpenter NodePool YAML

```yaml
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: fast-scaling
spec:
  # ì†ë„ ìµœì í™” êµ¬ì„±
  disruption:
    consolidationPolicy: WhenEmptyOrUnderutilized
    consolidateAfter: 30s
    budgets:
    - nodes: "10%"

  # ì†ë„ë¥¼ ìœ„í•œ ìµœëŒ€ ìœ ì—°ì„±
  template:
    spec:
      requirements:
        - key: karpenter.sh/capacity-type
          operator: In
          values: ["spot", "on-demand"]
        - key: kubernetes.io/arch
          operator: In
          values: ["amd64"]
        - key: node.kubernetes.io/instance-type
          operator: In
          values:
            # ì»´í“¨íŒ… ìµœì í™” - ê¸°ë³¸ ì„ íƒ
            - c6i.xlarge
            - c6i.2xlarge
            - c6i.4xlarge
            - c6i.8xlarge
            - c7i.xlarge
            - c7i.2xlarge
            - c7i.4xlarge
            - c7i.8xlarge
            # AMD ëŒ€ì•ˆ - ë” ë‚˜ì€ ê°€ìš©ì„±
            - c6a.xlarge
            - c6a.2xlarge
            - c6a.4xlarge
            - c6a.8xlarge
            # ë©”ëª¨ë¦¬ ìµœì í™” - íŠ¹ì • ì›Œí¬ë¡œë“œìš©
            - m6i.xlarge
            - m6i.2xlarge
            - m6i.4xlarge

      nodeClassRef:
        group: karpenter.k8s.aws
        kind: EC2NodeClass
        name: fast-nodepool

  # ë¹ ë¥¸ í”„ë¡œë¹„ì €ë‹ ë³´ì¥
  limits:
    cpu: 100000  # ì†Œí”„íŠ¸ ì œí•œë§Œ
    memory: 400000Gi
---
apiVersion: karpenter.k8s.aws/v1
kind: EC2NodeClass
metadata:
  name: fast-nodepool
spec:
  amiSelectorTerms:
    - alias: al2023@latest

  subnetSelectorTerms:
    - tags:
        karpenter.sh/discovery: "${CLUSTER_NAME}"

  securityGroupSelectorTerms:
    - tags:
        karpenter.sh/discovery: "${CLUSTER_NAME}"

  role: "KarpenterNodeRole-${CLUSTER_NAME}"

  # ì†ë„ ìµœì í™”
  userData: |
    #!/bin/bash
    # ë…¸ë“œ ì‹œì‘ ì‹œê°„ ìµœì í™”
    /etc/eks/bootstrap.sh ${CLUSTER_NAME} \
      --b64-cluster-ca ${B64_CLUSTER_CA} \
      --apiserver-endpoint ${API_SERVER_URL} \
      --container-runtime containerd \
      --kubelet-extra-args '--node-labels=karpenter.sh/fast-scaling=true --max-pods=110'

    # ì¤‘ìš” ì´ë¯¸ì§€ ì‚¬ì „ í’€
    ctr -n k8s.io images pull k8s.gcr.io/pause:3.9 &
    ctr -n k8s.io images pull public.ecr.aws/eks-distro/kubernetes/pause:3.9 &

```

## ì‹¤ì‹œê°„ ìŠ¤ì¼€ì¼ë§ ì›Œí¬í”Œë¡œ

ëª¨ë“  êµ¬ì„± ìš”ì†Œê°€ í•¨ê»˜ ì‘ë™í•˜ì—¬ 10ì´ˆ ë¯¸ë§Œ ìŠ¤ì¼€ì¼ë§ì„ ë‹¬ì„±í•˜ëŠ” ë°©ë²•:

```mermaid
sequenceDiagram
    participant User
    participant ALB
    participant Pod
    participant Metrics
    participant HPA
    participant Karpenter
    participant EC2
    participant Node

    User->>ALB: íŠ¸ë˜í”½ ê¸‰ì¦ ì‹œì‘
    ALB->>Pod: ìš”ì²­ ì „ë‹¬
    Pod->>Pod: í ì¦ê°€

    Note over Metrics: 1ì´ˆ ìˆ˜ì§‘ ê°„ê²©
    Pod->>Metrics: í ê¹Šì´ > ì„ê³„ê°’
    Metrics->>HPA: ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸ (2ì´ˆ)

    HPA->>HPA: ìƒˆ ë ˆí”Œë¦¬ì¹´ ê³„ì‚°
    HPA->>Pod: ìƒˆ Pod ìƒì„±

    Note over Karpenter: ìŠ¤ì¼€ì¤„ ë¶ˆê°€ëŠ¥í•œ Pod ê°ì§€
    Pod->>Karpenter: ëŒ€ê¸° ì¤‘ì¸ Pod ì‹ í˜¸
    Karpenter->>Karpenter: ìµœì  ì¸ìŠ¤í„´ìŠ¤ ì„ íƒ<br/>(200ms)

    Karpenter->>EC2: ì¸ìŠ¤í„´ìŠ¤ ì‹œì‘<br/>(Fleet API)
    EC2->>Node: ë…¸ë“œ í”„ë¡œë¹„ì €ë‹<br/>(30-45ì´ˆ)

    Node->>Node: í´ëŸ¬ìŠ¤í„° ì¡°ì¸<br/>(10-15ì´ˆ)
    Node->>Pod: Pod ìŠ¤ì¼€ì¤„ë§
    Pod->>ALB: ì„œë¹„ìŠ¤ ì¤€ë¹„

    Note over User,ALB: ì´ ì‹œê°„: 60ì´ˆ ë¯¸ë§Œ (ìƒˆ ìš©ëŸ‰)

```

## ê³µê²©ì  ìŠ¤ì¼€ì¼ë§ì„ ìœ„í•œ HPA êµ¬ì„±

HorizontalPodAutoscalerëŠ” ì¦‰ê°ì ì¸ ì‘ë‹µì„ ìœ„í•´ êµ¬ì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤:

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: ultra-fast-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: web-app
  minReplicas: 10
  maxReplicas: 1000

  metrics:
  # ê¸°ë³¸ ë©”íŠ¸ë¦­ - í ê¹Šì´
  - type: External
    external:
      metric:
        name: sqs_queue_depth
        selector:
          matchLabels:
            queue: "web-requests"
      target:
        type: AverageValue
        averageValue: "10"

  # ë³´ì¡° ë©”íŠ¸ë¦­ - ìš”ì²­ ì†ë„
  - type: External
    external:
      metric:
        name: alb_request_rate
        selector:
          matchLabels:
            targetgroup: "web-tg"
      target:
        type: AverageValue
        averageValue: "100"

  behavior:
    scaleUp:
      stabilizationWindowSeconds: 0  # ì§€ì—° ì—†ìŒ!
      policies:
      - type: Percent
        value: 100
        periodSeconds: 10
      - type: Pods
        value: 100
        periodSeconds: 10
      selectPolicy: Max
    scaleDown:
      stabilizationWindowSeconds: 300  # 5ë¶„ ì¿¨ë‹¤ìš´
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60

```

## KEDA í™œìš© ì‹œì : ì´ë²¤íŠ¸ ë“œë¦¬ë¸ ì‹œë‚˜ë¦¬ì˜¤

Karpenterê°€ ì¸í”„ë¼ ìŠ¤ì¼€ì¼ë§ì„ ì²˜ë¦¬í•˜ëŠ” ë°˜ë©´, KEDAëŠ” íŠ¹ì • ì´ë²¤íŠ¸ ë“œë¦¬ë¸ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ë›°ì–´ë‚©ë‹ˆë‹¤:

```mermaid
graph LR
    subgraph "Karpenter + HPA ì‚¬ìš©"
        WEB[ì›¹ íŠ¸ë˜í”½]
        API[API ìš”ì²­]
        SYNC[ë™ê¸° ì›Œí¬ë¡œë“œ]
        USER[ì‚¬ìš©ì ëŒ€ë©´ ì„œë¹„ìŠ¤]
    end

    subgraph "KEDA ì‚¬ìš©"
        QUEUE[í ì²˜ë¦¬<br/>SQS, Kafka]
        BATCH[ë°°ì¹˜ ì‘ì—…<br/>ì˜ˆì•½ëœ ì‘ì—…]
        ASYNC[ë¹„ë™ê¸° ì²˜ë¦¬]
        DEV[ê°œë°œ/í…ŒìŠ¤íŠ¸ í™˜ê²½<br/>ì œë¡œ ìŠ¤ì¼€ì¼]
    end

    WEB --> DECISION{ìŠ¤ì¼€ì¼ë§<br/>ì „ëµ}
    API --> DECISION
    SYNC --> DECISION
    USER --> DECISION

    QUEUE --> DECISION
    BATCH --> DECISION
    ASYNC --> DECISION
    DEV --> DECISION

    DECISION -->|Karpenter| FAST[60ì´ˆ ë¯¸ë§Œ<br/>ë…¸ë“œ ìŠ¤ì¼€ì¼ë§]
    DECISION -->|KEDA| EVENT[ì´ë²¤íŠ¸ ë“œë¦¬ë¸<br/>Pod ìŠ¤ì¼€ì¼ë§]

    style FAST fill:#ff9900
    style EVENT fill:#76c5d5

```

## í”„ë¡œë•ì…˜ ì„±ëŠ¥ ë©”íŠ¸ë¦­

ì¼ì¼ 750K+ ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ë°°í¬ì˜ ì‹¤ì œ ê²°ê³¼:

```mermaid
graph TB
    subgraph "ìµœì í™” ì´ì „"
        B1[ìŠ¤ì¼€ì¼ë§ íŠ¸ë¦¬ê±°<br/>60-90ì´ˆ ì§€ì—°]
        B2[ë…¸ë“œ í”„ë¡œë¹„ì €ë‹<br/>3-5ë¶„]
        B3[ì „ì²´ ì‘ë‹µ<br/>4-6ë¶„]
        B4[ì‚¬ìš©ì ì˜í–¥<br/>íƒ€ì„ì•„ì›ƒ ë° ì—ëŸ¬]
    end

    subgraph "Karpenter + ê³ í•´ìƒë„ ì´í›„"
        A1[ìŠ¤ì¼€ì¼ë§ íŠ¸ë¦¬ê±°<br/>2-5ì´ˆ ì§€ì—°]
        A2[ë…¸ë“œ í”„ë¡œë¹„ì €ë‹<br/>45-60ì´ˆ]
        A3[ì „ì²´ ì‘ë‹µ<br/>60ì´ˆ ë¯¸ë§Œ]
        A4[ì‚¬ìš©ì ì˜í–¥<br/>ì—†ìŒ]
    end

    subgraph "ê°œì„  ì‚¬í•­"
        I1[95% ë” ë¹ ë¥¸ ê°ì§€]
        I2[75% ë” ë¹ ë¥¸ í”„ë¡œë¹„ì €ë‹]
        I3[80% ë” ë¹ ë¥¸ ì „ì²´]
        I4[100% ê°€ìš©ì„± ìœ ì§€]
    end

    B1 --> I1
    B2 --> I2
    B3 --> I3
    B4 --> I4

    I1 --> A1
    I2 --> A2
    I3 --> A3
    I4 --> A4

    style A3 fill:#48C9B0
    style I3 fill:#ff9900

```

## ë‹¤ì¤‘ ë¦¬ì „ ê³ ë ¤ ì‚¬í•­

ì—¬ëŸ¬ ë¦¬ì „ì—ì„œ ìš´ì˜í•˜ëŠ” ì¡°ì§ì˜ ê²½ìš°, ì¼ê´€ëœ 10ì´ˆ ë¯¸ë§Œ ìŠ¤ì¼€ì¼ë§ì„ ìœ„í•´ ë¦¬ì „ë³„ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤:

```mermaid
graph TB
    subgraph "ê¸€ë¡œë²Œ ì•„í‚¤í…ì²˜"
        subgraph "ë¯¸êµ­ ë¦¬ì „ (40% íŠ¸ë˜í”½)"
            US_KARP[Karpenter US]
            US_TYPES[c6i, c7i ìš°ì„ ]
            US_SPOT[80% Spot]
        end

        subgraph "ìœ ëŸ½ ë¦¬ì „ (35% íŠ¸ë˜í”½)"
            EU_KARP[Karpenter EU]
            EU_TYPES[c6a, c7a ìš°ì„ ]
            EU_SPOT[75% Spot]
        end

        subgraph "ì•„ì‹œì•„ íƒœí‰ì–‘ ë¦¬ì „ (25% íŠ¸ë˜í”½)"
            AP_KARP[Karpenter AP]
            AP_TYPES[c5, m5 í¬í•¨]
            AP_SPOT[70% Spot]
        end
    end

    subgraph "ë¦¬ì „ ê°„ ë©”íŠ¸ë¦­"
        GLOBAL[ê¸€ë¡œë²Œ ë©”íŠ¸ë¦­<br/>ì• ê·¸ë¦¬ê²Œì´í„°]
        REGIONAL[ë¦¬ì „ë³„<br/>ì˜ì‚¬ê²°ì •]
    end

    US_KARP --> REGIONAL
    EU_KARP --> REGIONAL
    AP_KARP --> REGIONAL

    REGIONAL --> GLOBAL

```

## 10ì´ˆ ë¯¸ë§Œ ìŠ¤ì¼€ì¼ë§ ëª¨ë²” ì‚¬ë¡€

### 1. ë©”íŠ¸ë¦­ ì„ íƒ

- ì„ í–‰ ì§€í‘œ(í ê¹Šì´, ì—°ê²° ìˆ˜) ì‚¬ìš©, í›„í–‰ ì§€í‘œ(CPU) ì•„ë‹˜
- í´ëŸ¬ìŠ¤í„°ë‹¹ ê³ í•´ìƒë„ ë©”íŠ¸ë¦­ì„ 10-15ê°œ ì´í•˜ë¡œ ìœ ì§€
- API ìŠ¤ë¡œí‹€ë§ ë°©ì§€ë¥¼ ìœ„í•œ ë°°ì¹˜ ë©”íŠ¸ë¦­ ì œì¶œ

### 2. Karpenter ìµœì í™”

- ìµœëŒ€ ì¸ìŠ¤í„´ìŠ¤ ìœ í˜• ìœ ì—°ì„± ì œê³µ
- ì ì ˆí•œ ì¤‘ë‹¨ ì²˜ë¦¬ì™€ í•¨ê»˜ Spot ì¸ìŠ¤í„´ìŠ¤ ì ê·¹ í™œìš©
- ë¹„ìš© íš¨ìœ¨ì„±ì„ ìœ„í•œ í†µí•© í™œì„±í™”
- ì ì ˆí•œ ttlSecondsAfterEmpty ì„¤ì • (30-60ì´ˆ)

### 3. HPA íŠœë‹

- ìŠ¤ì¼€ì¼ì—…ì„ ìœ„í•œ ì œë¡œ ì•ˆì •í™” ìœˆë„ìš°
- ê³µê²©ì ì¸ ìŠ¤ì¼€ì¼ë§ ì •ì±… (100% ì¦ê°€ í—ˆìš©)
- ì ì ˆí•œ ê°€ì¤‘ì¹˜ë¥¼ ê°€ì§„ ì—¬ëŸ¬ ë©”íŠ¸ë¦­
- ìŠ¤ì¼€ì¼ë‹¤ìš´ì„ ìœ„í•œ ì ì ˆí•œ ì¿¨ë‹¤ìš´

### 4. ëª¨ë‹ˆí„°ë§

- P95 ìŠ¤ì¼€ì¼ë§ ì§€ì—° ì‹œê°„ì„ ê¸°ë³¸ KPIë¡œ ì¶”ì 
- 15ì´ˆë¥¼ ì´ˆê³¼í•˜ëŠ” ìŠ¤ì¼€ì¼ë§ ì‹¤íŒ¨ ë˜ëŠ” ì§€ì—°ì— ëŒ€í•œ ì•Œë¦¼
- Spot ì¤‘ë‹¨ ë¹„ìœ¨ ëª¨ë‹ˆí„°ë§
- ìŠ¤ì¼€ì¼ëœ Podë‹¹ ë¹„ìš© ì¶”ì 

## ì¼ë°˜ì ì¸ ë¬¸ì œ í•´ê²°

```mermaid
graph LR
    subgraph "ì¦ìƒ"
        SLOW[10ì´ˆ ì´ˆê³¼ ìŠ¤ì¼€ì¼ë§]
    end

    subgraph "ì§„ë‹¨"
        D1[ë©”íŠ¸ë¦­ ì§€ì—° í™•ì¸]
        D2[HPA êµ¬ì„± ê²€ì¦]
        D3[ì¸ìŠ¤í„´ìŠ¤ ìœ í˜• ê²€í† ]
        D4[ì„œë¸Œë„· ìš©ëŸ‰ ë¶„ì„]
    end

    subgraph "ì†”ë£¨ì…˜"
        S1[ìˆ˜ì§‘ ê°„ê²© ì¶•ì†Œ]
        S2[ì•ˆì •í™” ìœˆë„ìš° ì œê±°]
        S3[ë” ë§ì€ ì¸ìŠ¤í„´ìŠ¤ ìœ í˜• ì¶”ê°€]
        S4[ì„œë¸Œë„· CIDR í™•ì¥]
    end

    SLOW --> D1 --> S1
    SLOW --> D2 --> S2
    SLOW --> D3 --> S3
    SLOW --> D4 --> S4

```

## í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ ë°©ì‹ (ê¶Œì¥)

ì‹¤ì œ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” ë‘ ê°€ì§€ ë°©ì‹ì„ í˜¼í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ì„ ê¶Œì¥í•©ë‹ˆë‹¤:

1. **ë¯¸ì…˜ í¬ë¦¬í‹°ì»¬ ì„œë¹„ìŠ¤**: ADOT + Prometheusë¡œ 10-13ì´ˆ ìŠ¤ì¼€ì¼ë§ ë‹¬ì„±
2. **ì¼ë°˜ ì„œë¹„ìŠ¤**: CloudWatch Directë¡œ 12-15ì´ˆ ìŠ¤ì¼€ì¼ë§ ë° ìš´ì˜ ë‹¨ìˆœí™”
3. **ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜**: CloudWatchì—ì„œ ì‹œì‘í•˜ì—¬ í•„ìš”ì— ë”°ë¼ ADOTë¡œ ì „í™˜

## EKS Auto Mode vs Self-managed Karpenter

EKS Auto Mode (2025 GA)ëŠ” Karpenterë¥¼ ë‚´ì¥í•˜ì—¬ ìë™ ê´€ë¦¬í•©ë‹ˆë‹¤:

| í•­ëª© | Self-managed Karpenter | EKS Auto Mode |
|------|----------------------|---------------|
| ì„¤ì¹˜/ì—…ê·¸ë ˆì´ë“œ | ì§ì ‘ ê´€ë¦¬ (Helm) | AWS ìë™ ê´€ë¦¬ |
| NodePool ì„¤ì • | ì™„ì „í•œ ì»¤ìŠ¤í„°ë§ˆì´ì§• | ì œí•œëœ ì„¤ì • |
| ë¹„ìš© ìµœì í™” | ì„¸ë°€í•œ ì œì–´ ê°€ëŠ¥ | ìë™ ìµœì í™” |
| OS íŒ¨ì¹˜ | ì§ì ‘ ê´€ë¦¬ | ìë™ íŒ¨ì¹˜ |
| ì í•©í•œ í™˜ê²½ | ê³ ê¸‰ ì»¤ìŠ¤í„°ë§ˆì´ì§• í•„ìš” | ìš´ì˜ ë¶€ë‹´ ìµœì†Œí™” |

**ê¶Œì¥**: ë³µì¡í•œ ìŠ¤ì¼€ì¤„ë§ ìš”êµ¬ì‚¬í•­ì´ ìˆëŠ” ê²½ìš° Self-managed, ìš´ì˜ ë‹¨ìˆœí™”ê°€ ëª©í‘œì¸ ê²½ìš° EKS Auto Modeë¥¼ ì„ íƒí•©ë‹ˆë‹¤.

## P1: ì´ˆê³ ì† ìŠ¤ì¼€ì¼ë§ ì•„í‚¤í…ì²˜ (Critical)

### ìŠ¤ì¼€ì¼ë§ ì§€ì—° ì‹œê°„ ë¶„í•´ ë¶„ì„

10ì´ˆ ë¯¸ë§Œ ìŠ¤ì¼€ì¼ë§ì„ ë‹¬ì„±í•˜ê¸° ìœ„í•´ì„œëŠ” ë¨¼ì € ì „ì²´ ìŠ¤ì¼€ì¼ë§ ì²´ì¸ì—ì„œ ë°œìƒí•˜ëŠ” ì§€ì—° ì‹œê°„ì„ ì„¸ë°€í•˜ê²Œ ë¶„í•´í•´ì•¼ í•©ë‹ˆë‹¤.

```mermaid
graph TB
    subgraph "ìŠ¤ì¼€ì¼ë§ ì§€ì—° ì‹œê°„ ë¶„í•´ (ì „í†µì  í™˜ê²½)"
        M[ë©”íŠ¸ë¦­ ìˆ˜ì§‘<br/>15-70ì´ˆ]
        H[HPA ì˜ì‚¬ê²°ì •<br/>15ì´ˆ]
        N[ë…¸ë“œ í”„ë¡œë¹„ì €ë‹<br/>30-120ì´ˆ]
        C[ì»¨í…Œì´ë„ˆ ì‹œì‘<br/>5-30ì´ˆ]

        M -->|ëˆ„ì | H
        H -->|ëˆ„ì | N
        N -->|ëˆ„ì | C

        TOTAL[ì´ ì§€ì—°: 65-235ì´ˆ]
        C --> TOTAL
    end

    subgraph "ê° ë‹¨ê³„ë³„ ë³‘ëª© ìš”ì¸"
        M1[ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì§€ì—°<br/>- CloudWatch ì§‘ê³„: 60ì´ˆ<br/>- Prometheus ìŠ¤í¬ë ˆì´í”„: 15ì´ˆ<br/>- API í´ë§: 10-30ì´ˆ]

        H1[HPA ë³‘ëª©<br/>- ë™ê¸°í™” ì£¼ê¸°: 15ì´ˆ<br/>- ì•ˆì •í™” ìœˆë„ìš°: 0-300ì´ˆ<br/>- ë©”íŠ¸ë¦­ API ì§€ì—°: 2-5ì´ˆ]

        N1[í”„ë¡œë¹„ì €ë‹ ì§€ì—°<br/>- ASG ìŠ¤ì¼€ì¼ë§: 60-90ì´ˆ<br/>- EC2 ì‹œì‘: 30-60ì´ˆ<br/>- í´ëŸ¬ìŠ¤í„° ì¡°ì¸: 15-30ì´ˆ]

        C1[ì»¨í…Œì´ë„ˆ ë³‘ëª©<br/>- ì´ë¯¸ì§€ í’€ë§: 5-20ì´ˆ<br/>- ì´ˆê¸°í™”: 2-10ì´ˆ<br/>- Readiness probe: 5-15ì´ˆ]
    end

    M -.-> M1
    H -.-> H1
    N -.-> N1
    C -.-> C1

    style TOTAL fill:#ff4444,stroke:#232f3e,stroke-width:3px
    style M1 fill:#ffcccc
    style H1 fill:#ffcccc
    style N1 fill:#ffcccc
    style C1 fill:#ffcccc
```

:::danger ì‹¤ì œ í”„ë¡œë•ì…˜ ì¸¡ì •ê°’ (ìµœì í™” ì „)
28ê°œ EKS í´ëŸ¬ìŠ¤í„° í™˜ê²½ì—ì„œ ì¸¡ì •í•œ P95 ìŠ¤ì¼€ì¼ë§ ì§€ì—°:

| ë‹¨ê³„ | P50 | P95 | P99 |
|------|-----|-----|-----|
| ë©”íŠ¸ë¦­ ìˆ˜ì§‘ | 30ì´ˆ | 65ì´ˆ | 90ì´ˆ |
| HPA ê²°ì • | 10ì´ˆ | 25ì´ˆ | 45ì´ˆ |
| ë…¸ë“œ í”„ë¡œë¹„ì €ë‹ | 90ì´ˆ | 180ì´ˆ | 300ì´ˆ |
| ì»¨í…Œì´ë„ˆ ì‹œì‘ | 15ì´ˆ | 35ì´ˆ | 60ì´ˆ |
| **ì „ì²´ E2E** | **145ì´ˆ** | **305ì´ˆ** | **495ì´ˆ** |

ê²°ê³¼: íŠ¸ë˜í”½ ê¸‰ì¦ ì‹œ **5ë¶„ ì´ìƒ ì‚¬ìš©ìê°€ ì—ëŸ¬ë¥¼ ê²½í—˜**
:::

### ë©€í‹° ë ˆì´ì–´ ìŠ¤ì¼€ì¼ë§ ì „ëµ

ì´ˆê³ ì† ìŠ¤ì¼€ì¼ë§ì€ ë‹¨ì¼ ìµœì í™”ê°€ ì•„ë‹Œ **3ê°œ ë ˆì´ì–´ì˜ í´ë°± ì „ëµ**ìœ¼ë¡œ ë‹¬ì„±ë©ë‹ˆë‹¤.

```mermaid
graph TB
    subgraph "Layer 1: Warm Pool (0-2ì´ˆ)"
        WP1[Pause Pod Overprovisioning]
        WP2[ì‚¬ì „ í”„ë¡œë¹„ì €ë‹ëœ ë…¸ë“œ]
        WP3[ì¦‰ì‹œ ìŠ¤ì¼€ì¤„ë§ ê°€ëŠ¥]
        WP4[ìš©ëŸ‰: ì˜ˆìƒ í”¼í¬ì˜ 10-20%]

        WP1 --> WP2 --> WP3 --> WP4

        WP_RESULT[ìŠ¤ì¼€ì¼ë§ ì‹œê°„: 0-2ì´ˆ<br/>ë¹„ìš©: ë†’ìŒ<br/>ì‹ ë¢°ì„±: 99.9%]
        WP4 --> WP_RESULT
    end

    subgraph "Layer 2: Fast Provisioning (5-15ì´ˆ)"
        FP1[Karpenter ì§ì ‘ í”„ë¡œë¹„ì €ë‹]
        FP2[Spot Fleet ë‹¤ì¤‘ ì¸ìŠ¤í„´ìŠ¤ íƒ€ì…]
        FP3[Provisioned EKS Control Plane]
        FP4[ìš©ëŸ‰: ë¬´ì œí•œ í™•ì¥]

        FP1 --> FP2 --> FP3 --> FP4

        FP_RESULT[ìŠ¤ì¼€ì¼ë§ ì‹œê°„: 5-15ì´ˆ<br/>ë¹„ìš©: ì¤‘ê°„<br/>ì‹ ë¢°ì„±: 99%]
        FP4 --> FP_RESULT
    end

    subgraph "Layer 3: On-Demand Fallback (15-30ì´ˆ)"
        OD1[On-Demand ì¸ìŠ¤í„´ìŠ¤ ë³´ì¥]
        OD2[ìš©ëŸ‰ ì˜ˆì•½ í™œìš©]
        OD3[ìµœì¢… ì•ˆì „ë§]
        OD4[ìš©ëŸ‰: ë³´ì¥ë¨]

        OD1 --> OD2 --> OD3 --> OD4

        OD_RESULT[ìŠ¤ì¼€ì¼ë§ ì‹œê°„: 15-30ì´ˆ<br/>ë¹„ìš©: ê°€ì¥ ë†’ìŒ<br/>ì‹ ë¢°ì„±: 100%]
        OD4 --> OD_RESULT
    end

    TRAFFIC[íŠ¸ë˜í”½ ê¸‰ì¦] --> DECISION{í•„ìš” ìš©ëŸ‰}
    DECISION -->|í”¼í¬ 20% ì´ë‚´| WP_RESULT
    DECISION -->|í”¼í¬ 20-200%| FP_RESULT
    DECISION -->|ê·¹í•œ ë²„ìŠ¤íŠ¸| OD_RESULT

    WP_RESULT -->|ìš©ëŸ‰ ë¶€ì¡±| FP_RESULT
    FP_RESULT -->|Spot ë¶ˆê°€| OD_RESULT

    style WP_RESULT fill:#48C9B0,stroke:#232f3e,stroke-width:2px
    style FP_RESULT fill:#3498DB,stroke:#232f3e,stroke-width:2px
    style OD_RESULT fill:#F39C12,stroke:#232f3e,stroke-width:2px
```

### ë ˆì´ì–´ë³„ ìŠ¤ì¼€ì¼ë§ íƒ€ì„ë¼ì¸ ë¹„êµ

```mermaid
timeline
    title ë©€í‹° ë ˆì´ì–´ ìŠ¤ì¼€ì¼ë§ íƒ€ì„ë¼ì¸ (ì‹¤ì œ ì¸¡ì •ê°’)

    section Layer 1 - Warm Pool
        T+0s : íŠ¸ë˜í”½ ê¸‰ì¦ ê°ì§€
        T+0.5s : Pause Pod Preemption ì‹œì‘
        T+1s : ì‹¤ì œ Pod ìŠ¤ì¼€ì¤„ë§ ì™„ë£Œ
        T+2s : ì„œë¹„ìŠ¤ ì œê³µ ì‹œì‘

    section Layer 2 - Fast Provisioning
        T+0s : ìŠ¤ì¼€ì¤„ ë¶ˆê°€ëŠ¥í•œ Pod ê°ì§€
        T+0.2s : Karpenter ìµœì  ì¸ìŠ¤í„´ìŠ¤ ì„ íƒ
        T+2s : EC2 Fleet API í˜¸ì¶œ
        T+8s : ì¸ìŠ¤í„´ìŠ¤ ì‹œì‘ ì™„ë£Œ
        T+12s : í´ëŸ¬ìŠ¤í„° ì¡°ì¸ ë° Pod ìŠ¤ì¼€ì¤„ë§
        T+15s : ì„œë¹„ìŠ¤ ì œê³µ ì‹œì‘

    section Layer 3 - On-Demand Fallback
        T+0s : Spot ìš©ëŸ‰ ë¶€ì¡± ê°ì§€
        T+1s : On-Demand ì¸ìŠ¤í„´ìŠ¤ ìš”ì²­
        T+10s : ìš©ëŸ‰ ì˜ˆì•½ í™œì„±í™”
        T+20s : ì¸ìŠ¤í„´ìŠ¤ ì‹œì‘ ì™„ë£Œ
        T+28s : í´ëŸ¬ìŠ¤í„° ì¡°ì¸
        T+30s : ì„œë¹„ìŠ¤ ì œê³µ ì‹œì‘
```

:::tip ë ˆì´ì–´ ì„ íƒ ê¸°ì¤€
**Layer 1 (Warm Pool)** í™œì„±í™” ì‹œì :
- ì¼ì¼ íŠ¸ë˜í”½ íŒ¨í„´ì´ ì˜ˆì¸¡ ê°€ëŠ¥í•œ ê²½ìš°
- í”¼í¬ íƒ€ì„ì´ ëª…í™•í•œ ê²½ìš° (ì˜ˆ: ì˜¤ì „ 9ì‹œ, ì ì‹¬ì‹œê°„)
- 0-2ì´ˆ ìŠ¤ì¼€ì¼ë§ì´ ë¹„ì¦ˆë‹ˆìŠ¤ í¬ë¦¬í‹°ì»¬í•œ ê²½ìš°
- **ë¹„ìš©**: ì˜ˆìƒ í”¼í¬ ìš©ëŸ‰ì˜ 10-20%ë¥¼ 24ì‹œê°„ ìœ ì§€

**Layer 2 (Fast Provisioning)** ê¸°ë³¸ ì „ëµ:
- ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•œ íŠ¸ë˜í”½ íŒ¨í„´
- Spot ì¸ìŠ¤í„´ìŠ¤ë¡œ ë¹„ìš© ìµœì í™” ê°€ëŠ¥
- 5-15ì´ˆ ìŠ¤ì¼€ì¼ë§ìœ¼ë¡œ ì¶©ë¶„í•œ ê²½ìš°
- **ë¹„ìš©**: ì‹¤ì œ ì‚¬ìš©ëŸ‰ì— ë¹„ë¡€ (Spot 70-80% í• ì¸)

**Layer 3 (On-Demand Fallback)** í•„ìˆ˜ ë³´í—˜:
- Spot ìš©ëŸ‰ ë¶€ì¡± ëŒ€ë¹„ ì•ˆì „ë§
- SLA ë³´ì¥ì´ í•„ìš”í•œ ì›Œí¬ë¡œë“œ
- 15-30ì´ˆ ìŠ¤ì¼€ì¼ë§ í—ˆìš© ê°€ëŠ¥
- **ë¹„ìš©**: On-Demand ê°€ê²© (ìµœì†Œ ì‚¬ìš©)
:::

## P2: Provisioned EKS Control Planeìœ¼ë¡œ API ë³‘ëª© ì œê±°

### Provisioned Control Plane ê°œìš”

2025ë…„ 11ì›” AWSëŠ” **EKS Provisioned Control Plane**ì„ ë°œí‘œí–ˆìŠµë‹ˆë‹¤. ê¸°ì¡´ Standard Control Planeì˜ API ìŠ¤ë¡œí‹€ë§ í•œê³„ë¥¼ ì œê±°í•˜ì—¬ ëŒ€ê·œëª¨ ë²„ìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ìŠ¤ì¼€ì¼ë§ ì†ë„ë¥¼ íšê¸°ì ìœ¼ë¡œ ê°œì„ í•©ë‹ˆë‹¤.

```mermaid
graph LR
    subgraph "Standard Control Plane ì œì•½"
        STD_API[API Server<br/>ê³µìœ  ìš©ëŸ‰]
        STD_THROTTLE[ìŠ¤ë¡œí‹€ë§<br/>- ListPods: 20 TPS<br/>- CreatePod: 10 TPS<br/>- UpdateNode: 5 TPS]
        STD_DELAY[ìŠ¤ì¼€ì¼ë§ ì§€ì—°<br/>100 Pod ìƒì„±: 10-30ì´ˆ]

        STD_API --> STD_THROTTLE --> STD_DELAY
    end

    subgraph "Provisioned Control Plane ì„±ëŠ¥"
        PROV_SIZE{í¬ê¸° ì„ íƒ}
        PROV_XL[XL: 10x ìš©ëŸ‰<br/>200 TPS]
        PROV_2XL[2XL: 20x ìš©ëŸ‰<br/>400 TPS]
        PROV_4XL[4XL: 40x ìš©ëŸ‰<br/>800 TPS]
        PROV_RESULT[ìŠ¤ì¼€ì¼ë§ ì†ë„<br/>100 Pod ìƒì„±: 2-5ì´ˆ]

        PROV_SIZE --> PROV_XL
        PROV_SIZE --> PROV_2XL
        PROV_SIZE --> PROV_4XL

        PROV_XL --> PROV_RESULT
        PROV_2XL --> PROV_RESULT
        PROV_4XL --> PROV_RESULT
    end

    style STD_DELAY fill:#ff4444,stroke:#232f3e,stroke-width:2px
    style PROV_RESULT fill:#48C9B0,stroke:#232f3e,stroke-width:2px
```

### Standard vs Provisioned ë¹„êµ

| í•­ëª© | Standard | Provisioned XL | Provisioned 2XL | Provisioned 4XL |
|------|----------|----------------|-----------------|-----------------|
| API ìŠ¤ë¡œí‹€ë§ | ê³µìœ  ì œí•œ | 10ë°° ì¦ê°€ | 20ë°° ì¦ê°€ | 40ë°° ì¦ê°€ |
| Pod ìƒì„± ì†ë„ | 10 TPS | 100 TPS | 200 TPS | 400 TPS |
| ë…¸ë“œ ì—…ë°ì´íŠ¸ | 5 TPS | 50 TPS | 100 TPS | 200 TPS |
| ë™ì‹œ ìŠ¤ì¼€ì¼ë§ | 100 Pod/10ì´ˆ | 1,000 Pod/10ì´ˆ | 2,000 Pod/10ì´ˆ | 4,000 Pod/10ì´ˆ |
| ì›” ë¹„ìš© (ì¶”ê°€) | $0 | ~$350 | ~$700 | ~$1,400 |
| ê¶Œì¥ í´ëŸ¬ìŠ¤í„° í¬ê¸° | 1,000 Pod ë¯¸ë§Œ | 1,000-5,000 Pod | 5,000-15,000 Pod | 15,000+ Pod |

:::warning Provisioned Control Plane ì„ íƒ ê¸°ì¤€
**Provisionedë¡œ ì—…ê·¸ë ˆì´ë“œí•´ì•¼ í•˜ëŠ” ì‹ í˜¸:**

1. **API ìŠ¤ë¡œí‹€ë§ ì—ëŸ¬ ë¹ˆë°œ**: `kubectl` ëª…ë ¹ì´ ìì£¼ ì‹¤íŒ¨í•˜ê±°ë‚˜ ì¬ì‹œë„
2. **ëŒ€ê·œëª¨ ë°°í¬ ì§€ì—°**: 100+ Pod ë°°í¬ ì‹œ 5ë¶„ ì´ìƒ ì†Œìš”
3. **Karpenter ë…¸ë“œ í”„ë¡œë¹„ì €ë‹ ì‹¤íŒ¨**: `too many requests` ì—ëŸ¬
4. **HPA ìŠ¤ì¼€ì¼ë§ ì§€ì—°**: Pod ìƒì„± ìš”ì²­ì´ íì— ìŒ“ì„
5. **í´ëŸ¬ìŠ¤í„° í¬ê¸°**: ìƒì‹œ 1,000 Pod ì´ìƒ ë˜ëŠ” í”¼í¬ 3,000 Pod ì´ìƒ

**ë¹„ìš© vs ì„±ëŠ¥ íŠ¸ë ˆì´ë“œì˜¤í”„:**
- **Standard â†’ XL**: ì›” $350 ì¶”ê°€ ë¹„ìš©ìœ¼ë¡œ **10ë°° API ì„±ëŠ¥** (ROI: 10ë¶„ ë‹¤ìš´íƒ€ì„ ë°©ì§€ë¡œ ìƒì‡„)
- **XL â†’ 2XL**: ì´ˆëŒ€ê·œëª¨ í´ëŸ¬ìŠ¤í„°(10,000+ Pod)ì—ë§Œ í•„ìš”
- **4XL**: ê·¹í•œ ê·œëª¨(50,000+ Pod) ë˜ëŠ” ë©€í‹° í…Œë„ŒíŠ¸ í”Œë«í¼ìš©
:::

### Provisioned Control Plane ì„¤ì •

#### AWS CLIë¡œ ì‹ ê·œ í´ëŸ¬ìŠ¤í„° ìƒì„±

```bash
aws eks create-cluster \
  --name ultra-fast-cluster \
  --region us-east-1 \
  --role-arn arn:aws:iam::123456789012:role/EKSClusterRole \
  --resources-vpc-config subnetIds=subnet-xxx,subnet-yyy,securityGroupIds=sg-xxx \
  --kubernetes-version 1.32 \
  --compute-config enabled=true,nodePools=system,nodeRoleArn=arn:aws:iam::123456789012:role/EKSNodeRole \
  --kubernetes-network-config elasticLoadBalancing=disabled \
  --access-config authenticationMode=API \
  --upgrade-policy supportType=EXTENDED \
  --zonal-shift-config enabled=true \
  --compute-config enabled=true \
  --control-plane-placement groupName=my-placement-group,clusterTenancy=dedicated \
  --control-plane-provisioning mode=PROVISIONED,size=XL
```

#### ê¸°ì¡´ í´ëŸ¬ìŠ¤í„° ì—…ê·¸ë ˆì´ë“œ (Standard â†’ Provisioned)

```bash
# 1. í˜„ì¬ Control Plane ëª¨ë“œ í™•ì¸
aws eks describe-cluster --name my-cluster --query 'cluster.controlPlaneProvisioning'

# 2. Provisionedë¡œ ì—…ê·¸ë ˆì´ë“œ (ë‹¤ìš´íƒ€ì„ ì—†ìŒ)
aws eks update-cluster-config \
  --name my-cluster \
  --control-plane-provisioning mode=PROVISIONED,size=XL

# 3. ì—…ê·¸ë ˆì´ë“œ ìƒíƒœ ëª¨ë‹ˆí„°ë§ (10-15ë¶„ ì†Œìš”)
aws eks describe-cluster \
  --name my-cluster \
  --query 'cluster.status'

# 4. API ì„±ëŠ¥ ê²€ì¦
kubectl get pods --all-namespaces --watch
kubectl create deployment nginx --image=nginx --replicas=100
```

:::info ì—…ê·¸ë ˆì´ë“œ íŠ¹ì§•
- **ë‹¤ìš´íƒ€ì„ ì—†ìŒ**: Control Planeì´ ìë™ìœ¼ë¡œ ë¡¤ë§ ì—…ê·¸ë ˆì´ë“œ
- **ì†Œìš” ì‹œê°„**: 10-15ë¶„ (í´ëŸ¬ìŠ¤í„° í¬ê¸° ë¬´ê´€)
- **ë¡¤ë°± ë¶ˆê°€**: Provisioned â†’ Standard ë‹¤ìš´ê·¸ë ˆì´ë“œ ì§€ì› ì•ˆ í•¨
- **ë¹„ìš© ì‹œì‘**: ì—…ê·¸ë ˆì´ë“œ ì™„ë£Œ ì¦‰ì‹œ ì²­êµ¬ ì‹œì‘
:::

### ëŒ€ê·œëª¨ ë²„ìŠ¤íŠ¸ ì‹œ ì„±ëŠ¥ ë¹„êµ

ì‹¤ì œ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ 1,000 Pod ë™ì‹œ ìŠ¤ì¼€ì¼ë§ í…ŒìŠ¤íŠ¸:

```mermaid
graph TB
    subgraph "Standard Control Plane (ì œì•½)"
        STD1[T+0s: ìŠ¤ì¼€ì¼ë§ ì‹œì‘<br/>1,000 Pod ìƒì„± ìš”ì²­]
        STD2[T+10s: API ìŠ¤ë¡œí‹€ë§ ì‹œì‘<br/>100 Pod ìƒì„± ì™„ë£Œ]
        STD3[T+30s: ìŠ¤ë¡œí‹€ë§ ì‹¬í™”<br/>300 Pod ìƒì„± ì™„ë£Œ]
        STD4[T+90s: ìŠ¤ë¡œí‹€ë§ ì§€ì†<br/>700 Pod ìƒì„± ì™„ë£Œ]
        STD5[T+180s: ìµœì¢… ì™„ë£Œ<br/>1,000 Pod ìƒì„± ì™„ë£Œ]

        STD1 --> STD2 --> STD3 --> STD4 --> STD5
    end

    subgraph "Provisioned XL Control Plane (ê°€ì†)"
        PROV1[T+0s: ìŠ¤ì¼€ì¼ë§ ì‹œì‘<br/>1,000 Pod ìƒì„± ìš”ì²­]
        PROV2[T+10s: ê³ ì† ìƒì„±<br/>600 Pod ìƒì„± ì™„ë£Œ]
        PROV3[T+15s: ê±°ì˜ ì™„ë£Œ<br/>950 Pod ìƒì„± ì™„ë£Œ]
        PROV4[T+18s: ìµœì¢… ì™„ë£Œ<br/>1,000 Pod ìƒì„± ì™„ë£Œ]

        PROV1 --> PROV2 --> PROV3 --> PROV4
    end

    subgraph "ì„±ëŠ¥ ê°œì„ "
        IMPROVE[90% ë” ë¹ ë¥¸ ìŠ¤ì¼€ì¼ë§<br/>180ì´ˆ â†’ 18ì´ˆ<br/>API ìŠ¤ë¡œí‹€ë§ ì—ëŸ¬: 0ê±´]
    end

    STD5 -.-> IMPROVE
    PROV4 -.-> IMPROVE

    style STD5 fill:#ff4444,stroke:#232f3e,stroke-width:2px
    style PROV4 fill:#48C9B0,stroke:#232f3e,stroke-width:2px
    style IMPROVE fill:#3498DB,stroke:#232f3e,stroke-width:3px
```

## P3: Warm Pool / Overprovisioning íŒ¨í„´ (í•µì‹¬ ì „ëµ)

### Pause Pod Overprovisioning ì›ë¦¬

Warm Pool ì „ëµì€ **ë‚®ì€ ìš°ì„ ìˆœìœ„ì˜ "pause" Podë¥¼ ì‚¬ì „ ë°°í¬**í•˜ì—¬ ë…¸ë“œë¥¼ ë¯¸ë¦¬ í”„ë¡œë¹„ì €ë‹í•©ë‹ˆë‹¤. ì‹¤ì œ ì›Œí¬ë¡œë“œê°€ í•„ìš”í•  ë•Œ pause Podë¥¼ ì¦‰ì‹œ ì¶•ì¶œ(preempt)í•˜ê³  í•´ë‹¹ ë…¸ë“œì— ì‹¤ì œ Podë¥¼ ìŠ¤ì¼€ì¤„ë§í•©ë‹ˆë‹¤.

```mermaid
sequenceDiagram
    participant HPA as HPA Controller
    participant Scheduler as K8s Scheduler
    participant PausePod as Pause Pod<br/>(Priority: -1)
    participant Node as ì‚¬ì „ í”„ë¡œë¹„ì €ë‹ëœ ë…¸ë“œ
    participant RealPod as ì‹¤ì œ ì›Œí¬ë¡œë“œ Pod<br/>(Priority: 0)

    Note over Node,PausePod: ì´ˆê¸° ìƒíƒœ: Pause Podê°€ ë…¸ë“œ ì ìœ 
    PausePod->>Node: Running (ë¦¬ì†ŒìŠ¤ ì˜ˆì•½ ì¤‘)

    Note over HPA: íŠ¸ë˜í”½ ê¸‰ì¦ ê°ì§€
    HPA->>RealPod: ìƒˆ Pod ìƒì„± ìš”ì²­

    RealPod->>Scheduler: ìŠ¤ì¼€ì¤„ë§ ìš”ì²­
    Scheduler->>Scheduler: ìš°ì„ ìˆœìœ„ í‰ê°€<br/>Real (0) > Pause (-1)

    Scheduler->>PausePod: Preempt ì‹ í˜¸
    PausePod->>Node: ì¦‰ì‹œ ì¢…ë£Œ (0.5ì´ˆ)

    Scheduler->>RealPod: Nodeì— ìŠ¤ì¼€ì¤„ë§
    RealPod->>Node: ì¦‰ì‹œ ì‹œì‘ (1-2ì´ˆ)

    Note over RealPod,Node: ì´ ì†Œìš” ì‹œê°„: 1.5-2.5ì´ˆ
```

### Overprovisioning ì „ì²´ ë™ì‘ íë¦„

```mermaid
graph TB
    subgraph "1ë‹¨ê³„: Warm Pool ì‚¬ì „ ì„¤ì • (í”¼í¬ íƒ€ì„ ì „)"
        CRON[CronJob íŠ¸ë¦¬ê±°<br/>ì˜ˆ: ì˜¤ì „ 8ì‹œ 30ë¶„]
        PAUSE_DEPLOY[Pause Deployment ìƒì„±<br/>Replicas: ì˜ˆìƒ í”¼í¬ì˜ 15%]
        PAUSE_POD[Pause Pod ë°°í¬<br/>CPU: 1000m, Memory: 2Gi]
        KARP_PROVISION[Karpenter ë…¸ë“œ í”„ë¡œë¹„ì €ë‹<br/>Spot ì¸ìŠ¤í„´ìŠ¤ ì„ íƒ]
        WARM[Warm Pool ì¤€ë¹„ ì™„ë£Œ<br/>ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥í•œ ìš©ëŸ‰]

        CRON --> PAUSE_DEPLOY --> PAUSE_POD --> KARP_PROVISION --> WARM
    end

    subgraph "2ë‹¨ê³„: íŠ¸ë˜í”½ ê¸‰ì¦ ëŒ€ì‘ (ì‹¤ì‹œê°„)"
        TRAFFIC[íŠ¸ë˜í”½ ê¸‰ì¦ ë°œìƒ]
        HPA_SCALE[HPA ìŠ¤ì¼€ì¼ì—… ê²°ì •<br/>Replicas: 100 â†’ 150]
        REAL_POD[ì‹¤ì œ Pod ìƒì„± ìš”ì²­<br/>Priority: 0]
        PREEMPT[Pause Pod Preemption<br/>ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ì¶•ì¶œ]
        INSTANT[ì¦‰ì‹œ ìŠ¤ì¼€ì¤„ë§<br/>1-2ì´ˆ ì†Œìš”]

        TRAFFIC --> HPA_SCALE --> REAL_POD --> PREEMPT --> INSTANT
    end

    subgraph "3ë‹¨ê³„: ì¶”ê°€ í™•ì¥ (ìš©ëŸ‰ ì´ˆê³¼ ì‹œ)"
        OVERFLOW{Warm Pool<br/>ì†Œì§„?}
        MORE_NODES[Karpenter ì¶”ê°€ ë…¸ë“œ<br/>Layer 2 ì „ëµ ë°œë™]

        INSTANT --> OVERFLOW
        OVERFLOW -->|Yes| MORE_NODES
        OVERFLOW -->|No| INSTANT
    end

    subgraph "4ë‹¨ê³„: ìŠ¤ì¼€ì¼ë‹¤ìš´ ë° ì¬ì¶©ì „ (í”¼í¬ ì¢…ë£Œ í›„)"
        SCALE_DOWN[HPA ìŠ¤ì¼€ì¼ë‹¤ìš´<br/>Replicas: 150 â†’ 100]
        REFILL[Pause Pod ì¬ë°°í¬<br/>Warm Pool ì¬ì¶©ì „]
        CLEANUP[ìœ íœ´ ë…¸ë“œ ì •ë¦¬<br/>ttlSecondsAfterEmpty: 60s]

        SCALE_DOWN --> REFILL --> CLEANUP
    end

    WARM --> TRAFFIC
    MORE_NODES --> SCALE_DOWN

    style INSTANT fill:#48C9B0,stroke:#232f3e,stroke-width:3px
    style WARM fill:#3498DB,stroke:#232f3e,stroke-width:2px
```

### Pause Pod Overprovisioning YAML êµ¬ì„±

#### 1. PriorityClass ì •ì˜ (ë‚®ì€ ìš°ì„ ìˆœìœ„)

```yaml
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: overprovisioning
value: -1  # ìŒìˆ˜ ìš°ì„ ìˆœìœ„: ëª¨ë“  ì‹¤ì œ ì›Œí¬ë¡œë“œë³´ë‹¤ ë‚®ìŒ
globalDefault: false
description: "Pause pods for warm pool - will be preempted by real workloads"
```

#### 2. Pause Deployment (ê¸°ë³¸ Warm Pool)

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: overprovisioning-pause
  namespace: kube-system
spec:
  replicas: 10  # ì˜ˆìƒ í”¼í¬ì˜ 15%ì— í•´ë‹¹í•˜ëŠ” Pod ìˆ˜
  selector:
    matchLabels:
      app: overprovisioning-pause
  template:
    metadata:
      labels:
        app: overprovisioning-pause
    spec:
      priorityClassName: overprovisioning
      terminationGracePeriodSeconds: 0  # ì¦‰ì‹œ ì¢…ë£Œ

      # ìŠ¤ì¼€ì¤„ë§ ì œì•½ (ì‹¤ì œ ì›Œí¬ë¡œë“œì™€ ë™ì¼í•œ ë…¸ë“œ í’€)
      nodeSelector:
        karpenter.sh/nodepool: fast-scaling

      containers:
      - name: pause
        image: registry.k8s.io/pause:3.9
        resources:
          requests:
            cpu: "1000m"      # ì‹¤ì œ ì›Œí¬ë¡œë“œ í‰ê·  CPU
            memory: "2Gi"     # ì‹¤ì œ ì›Œí¬ë¡œë“œ í‰ê·  ë©”ëª¨ë¦¬
          limits:
            cpu: "1000m"
            memory: "2Gi"
```

#### 3. ì‹œê°„ëŒ€ë³„ Warm Pool ìë™ ì¡°ì • (CronJob)

```yaml
---
# í”¼í¬ íƒ€ì„ ì „ Warm Pool í™•ì¥ (ì˜¤ì „ 8ì‹œ 30ë¶„)
apiVersion: batch/v1
kind: CronJob
metadata:
  name: scale-up-warm-pool
  namespace: kube-system
spec:
  schedule: "30 8 * * 1-5"  # í‰ì¼ ì˜¤ì „ 8ì‹œ 30ë¶„
  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: warm-pool-scaler
          restartPolicy: OnFailure
          containers:
          - name: kubectl
            image: bitnami/kubectl:latest
            command:
            - /bin/sh
            - -c
            - |
              kubectl scale deployment overprovisioning-pause \
                --namespace kube-system \
                --replicas=30  # í”¼í¬ íƒ€ì„ìš© í™•ì¥
---
# í”¼í¬ íƒ€ì„ í›„ Warm Pool ì¶•ì†Œ (ì˜¤í›„ 7ì‹œ)
apiVersion: batch/v1
kind: CronJob
metadata:
  name: scale-down-warm-pool
  namespace: kube-system
spec:
  schedule: "0 19 * * 1-5"  # í‰ì¼ ì˜¤í›„ 7ì‹œ
  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: warm-pool-scaler
          restartPolicy: OnFailure
          containers:
          - name: kubectl
            image: bitnami/kubectl:latest
            command:
            - /bin/sh
            - -c
            - |
              kubectl scale deployment overprovisioning-pause \
                --namespace kube-system \
                --replicas=5  # ì•¼ê°„ ìµœì†Œ ìš©ëŸ‰
---
# CronJobìš© ServiceAccount ë° RBAC
apiVersion: v1
kind: ServiceAccount
metadata:
  name: warm-pool-scaler
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: warm-pool-scaler
  namespace: kube-system
rules:
- apiGroups: ["apps"]
  resources: ["deployments", "deployments/scale"]
  verbs: ["get", "patch", "update"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: warm-pool-scaler
  namespace: kube-system
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: warm-pool-scaler
subjects:
- kind: ServiceAccount
  name: warm-pool-scaler
  namespace: kube-system
```

### Warm Pool í¬ê¸° ê³„ì‚° ë°©ë²•

```mermaid
graph TB
    subgraph "1ë‹¨ê³„: íŠ¸ë˜í”½ íŒ¨í„´ ë¶„ì„"
        BASELINE[Baseline ìš©ëŸ‰<br/>í‰ìƒì‹œ Replicas: 100]
        PEAK[í”¼í¬ ìš©ëŸ‰<br/>ìµœëŒ€ Replicas: 200]
        BURST[ë²„ìŠ¤íŠ¸ ì†ë„<br/>ì´ˆë‹¹ 10 Pod ì¦ê°€]

        ANALYSIS[ë¶„ì„ ê²°ê³¼<br/>í”¼í¬ ë¸íƒ€: 100 Pod<br/>10ì´ˆ ë‚´ í•„ìš”: 100 Pod]
    end

    subgraph "2ë‹¨ê³„: Warm Pool í¬ê¸° ê²°ì •"
        FORMULA[Warm Pool í¬ê¸° = <br/>í”¼í¬ ë¸íƒ€ Ã— ì•ˆì „ ê³„ìˆ˜]
        SAFETY[ì•ˆì „ ê³„ìˆ˜ ì„ íƒ<br/>- ë³´ìˆ˜ì : 0.20 (20%)<br/>- ê· í˜•: 0.15 (15%)<br/>- ê³µê²©ì : 0.10 (10%)]

        CALC[ê³„ì‚° ì˜ˆì‹œ<br/>100 Pod Ã— 0.15 = 15 Pod]
    end

    subgraph "3ë‹¨ê³„: ë¹„ìš© vs ì†ë„ íŠ¸ë ˆì´ë“œì˜¤í”„"
        COST[Warm Pool ë¹„ìš©<br/>15 Pod Ã— $0.05/hr = $0.75/hr<br/>ì›”ê°„: $540]

        BENEFIT[ì§€ì—° ì‹œê°„ ê°ì†Œ<br/>60ì´ˆ â†’ 2ì´ˆ (97% ê°œì„ )<br/>SLA ìœ„ë°˜ ë°©ì§€: $10,000/ì›”]

        ROI[ROI ë¶„ì„<br/>íˆ¬ì: $540/ì›”<br/>ì ˆê°: $10,000/ì›”<br/>ìˆœìµ: $9,460/ì›”]
    end

    BASELINE --> ANALYSIS
    PEAK --> ANALYSIS
    BURST --> ANALYSIS

    ANALYSIS --> FORMULA --> SAFETY --> CALC
    CALC --> COST --> BENEFIT --> ROI

    style ROI fill:#48C9B0,stroke:#232f3e,stroke-width:3px
```

### ë¹„ìš© ë¶„ì„ ë° ìµœì í™”

#### ì‹œë‚˜ë¦¬ì˜¤ 1: ì¤‘ê·œëª¨ í´ëŸ¬ìŠ¤í„° (í”¼í¬ 200 Pod)

| êµ¬ì„± | Warm Pool í¬ê¸° | ì›” ë¹„ìš© | ìŠ¤ì¼€ì¼ë§ ì‹œê°„ | ì í•©ì„± |
|------|----------------|---------|---------------|--------|
| ê³µê²©ì  (10%) | 20 Pod | $720 | 0-2ì´ˆ (90% ì¼€ì´ìŠ¤) | ë†’ì€ ë²„ìŠ¤íŠ¸ ë¹ˆë„ |
| ê· í˜• (15%) | 30 Pod | $1,080 | 0-2ì´ˆ (95% ì¼€ì´ìŠ¤) | **ê¶Œì¥** |
| ë³´ìˆ˜ì  (20%) | 40 Pod | $1,440 | 0-2ì´ˆ (99% ì¼€ì´ìŠ¤) | ë¯¸ì…˜ í¬ë¦¬í‹°ì»¬ |

#### ì‹œë‚˜ë¦¬ì˜¤ 2: ëŒ€ê·œëª¨ í´ëŸ¬ìŠ¤í„° (í”¼í¬ 1,000 Pod)

| êµ¬ì„± | Warm Pool í¬ê¸° | ì›” ë¹„ìš© | ìŠ¤ì¼€ì¼ë§ ì‹œê°„ | ì í•©ì„± |
|------|----------------|---------|---------------|--------|
| ê³µê²©ì  (5%) | 50 Pod | $1,800 | 0-2ì´ˆ (80% ì¼€ì´ìŠ¤) | ì˜ˆì¸¡ ê°€ëŠ¥í•œ íŠ¸ë˜í”½ |
| ê· í˜• (10%) | 100 Pod | $3,600 | 0-2ì´ˆ (90% ì¼€ì´ìŠ¤) | **ê¶Œì¥** |
| ë³´ìˆ˜ì  (15%) | 150 Pod | $5,400 | 0-2ì´ˆ (98% ì¼€ì´ìŠ¤) | ê³ ê°€ìš©ì„± ìš”êµ¬ |

:::tip Warm Pool ìµœì í™” ì „ëµ
**ë¹„ìš© ì ˆê° ë°©ë²•:**

1. **ì‹œê°„ëŒ€ë³„ ìŠ¤ì¼€ì¼ë§**: CronJobìœ¼ë¡œ ì•¼ê°„/ì£¼ë§ Warm Pool ì¶•ì†Œ (50-70% ë¹„ìš© ì ˆê°)
2. **Spot ì¸ìŠ¤í„´ìŠ¤ í™œìš©**: Pause Podë„ Spot ë…¸ë“œì— ë°°í¬ (70% í• ì¸)
3. **ì ì‘í˜• í¬ê¸° ì¡°ì •**: CloudWatch Metrics ê¸°ë°˜ ìë™ ìŠ¤ì¼€ì¼ë§
4. **í˜¼í•© ì „ëµ**: í”¼í¬ íƒ€ì„ë§Œ Warm Pool, ê¸°íƒ€ ì‹œê°„ì€ Layer 2 ì˜ì¡´

**ROI ê³„ì‚°ì‹:**
```
ROI = (SLA ìœ„ë°˜ ë°©ì§€ ë¹„ìš© + ë§¤ì¶œ ê¸°íšŒ ì†ì‹¤ ë°©ì§€) - Warm Pool ë¹„ìš©

ì˜ˆì‹œ:
- SLA ìœ„ë°˜ í˜ë„í‹°: $5,000/ê±´
- ì›” í‰ê·  ìœ„ë°˜ íšŸìˆ˜ (Warm Pool ì—†ì„ ì‹œ): 3ê±´
- Warm Pool ë¹„ìš©: $1,080/ì›”
- ROI = ($5,000 Ã— 3) - $1,080 = $13,920/ì›” (1,290% ROI)
```
:::

## P4: Setu - Kueue + Karpenter í”„ë¡œì•¡í‹°ë¸Œ í”„ë¡œë¹„ì €ë‹

### Setu ê°œìš”

**Setu**ëŠ” Kueue(íì‰ ì‹œìŠ¤í…œ)ì™€ Karpenterë¥¼ ì—°ê²°í•˜ì—¬ **Gang Schedulingì´ í•„ìš”í•œ AI/ML ì›Œí¬ë¡œë“œë¥¼ ìœ„í•œ ì‚¬ì „ ë…¸ë“œ í”„ë¡œë¹„ì €ë‹**ì„ ì œê³µí•©ë‹ˆë‹¤. ê¸°ì¡´ KarpenterëŠ” Podê°€ ìƒì„±ëœ í›„ ë°˜ì‘ì ìœ¼ë¡œ ë…¸ë“œë¥¼ í”„ë¡œë¹„ì €ë‹í•˜ì§€ë§Œ, SetuëŠ” Jobì´ íì— ë“¤ì–´ê°€ëŠ” ìˆœê°„ í•„ìš”í•œ ë…¸ë“œë¥¼ ë¯¸ë¦¬ í”„ë¡œë¹„ì €ë‹í•©ë‹ˆë‹¤.

```mermaid
graph TB
    subgraph "ê¸°ì¡´ Karpenter ë°©ì‹ (ë°˜ì‘ì )"
        OLD1[Job ì œì¶œ]
        OLD2[Kueue í ëŒ€ê¸°]
        OLD3[ë¦¬ì†ŒìŠ¤ ì¿¼í„° í™•ë³´]
        OLD4[Pod ìƒì„±]
        OLD5[Karpenter ë°˜ì‘<br/>ë…¸ë“œ í”„ë¡œë¹„ì €ë‹ ì‹œì‘]
        OLD6[ë…¸ë“œ ì¤€ë¹„ (60-90ì´ˆ)]
        OLD7[Pod ìŠ¤ì¼€ì¤„ë§]
        OLD8[Job ì‹¤í–‰ ì‹œì‘]

        OLD1 --> OLD2 --> OLD3 --> OLD4 --> OLD5 --> OLD6 --> OLD7 --> OLD8

        OLD_TIME[ì´ ì†Œìš” ì‹œê°„: 90-120ì´ˆ]
        OLD8 --> OLD_TIME
    end

    subgraph "Setu ë°©ì‹ (í”„ë¡œì•¡í‹°ë¸Œ)"
        NEW1[Job ì œì¶œ]
        NEW2[Kueue í ì§„ì…]
        NEW3[Setu AdmissionCheck íŠ¸ë¦¬ê±°]
        NEW4[Karpenter NodeClaim ì‚¬ì „ ìƒì„±]
        NEW5[ë…¸ë“œ í”„ë¡œë¹„ì €ë‹ (60-90ì´ˆ)]
        NEW6[ë¦¬ì†ŒìŠ¤ ì¿¼í„° í™•ë³´]
        NEW7[Pod ìƒì„± ë° ì¦‰ì‹œ ìŠ¤ì¼€ì¤„ë§]
        NEW8[Job ì‹¤í–‰ ì‹œì‘]

        NEW1 --> NEW2 --> NEW3 --> NEW4
        NEW4 --> NEW5
        NEW5 --> NEW6
        NEW3 --> NEW6
        NEW6 --> NEW7 --> NEW8

        NEW_TIME[ì´ ì†Œìš” ì‹œê°„: 15-30ì´ˆ<br/>ë…¸ë“œ í”„ë¡œë¹„ì €ë‹ê³¼ í ëŒ€ê¸° ë³‘ë ¬í™”]
        NEW8 --> NEW_TIME
    end

    style OLD_TIME fill:#ff4444,stroke:#232f3e,stroke-width:2px
    style NEW_TIME fill:#48C9B0,stroke:#232f3e,stroke-width:3px
```

### Setu ì•„í‚¤í…ì²˜ ë° ë™ì‘ ì›ë¦¬

```mermaid
sequenceDiagram
    participant User as ì‚¬ìš©ì
    participant Job as Kubernetes Job
    participant Kueue as Kueue Controller
    participant Setu as Setu Controller
    participant Karp as Karpenter
    participant Node as EC2 Node
    participant Pod as Pod

    User->>Job: Job ì œì¶œ (8 GPU ìš”ì²­)
    Job->>Kueue: íì— ì§„ì…

    Note over Kueue: ClusterQueueì— AdmissionCheck ì¡´ì¬
    Kueue->>Setu: AdmissionCheck íŠ¸ë¦¬ê±°

    Setu->>Setu: Job ìš”êµ¬ì‚¬í•­ ë¶„ì„<br/>- GPU: 8ê°œ<br/>- ë©”ëª¨ë¦¬: 128Gi<br/>- ì˜ˆìƒ ë…¸ë“œ: p4d.24xlarge

    Setu->>Karp: NodeClaim ìƒì„±<br/>(Karpenter API ì§ì ‘ í˜¸ì¶œ)

    Note over Karp,Node: ë…¸ë“œ í”„ë¡œë¹„ì €ë‹ ì‹œì‘ (ë¹„ë™ê¸°)
    Karp->>Node: p4d.24xlarge ì¸ìŠ¤í„´ìŠ¤ ì‹œì‘

    par ë³‘ë ¬ ì²˜ë¦¬
        Node->>Node: í´ëŸ¬ìŠ¤í„° ì¡°ì¸ (60-90ì´ˆ)
    and
        Kueue->>Kueue: ë¦¬ì†ŒìŠ¤ ì¿¼í„° í™•ë³´
        Kueue->>Job: Job Admission ìŠ¹ì¸
        Job->>Pod: Pod ìƒì„±
    end

    Node->>Karp: Ready ìƒíƒœ ì „í™˜
    Setu->>Kueue: AdmissionCheck ì™„ë£Œ

    Pod->>Node: ì¦‰ì‹œ ìŠ¤ì¼€ì¤„ë§ (ë…¸ë“œ ì´ë¯¸ ì¤€ë¹„ë¨)
    Pod->>Pod: Job ì‹¤í–‰ ì‹œì‘

    Note over User,Pod: ì´ ì†Œìš” ì‹œê°„: ë…¸ë“œ í”„ë¡œë¹„ì €ë‹ ì‹œê°„ë§Œí¼<br/>(í ëŒ€ê¸° + í”„ë¡œë¹„ì €ë‹ì´ ë³‘ë ¬í™”ë¨)
```

### Setu ì„¤ì¹˜ ë° êµ¬ì„±

#### 1. Setu ì„¤ì¹˜ (Helm)

```bash
# Setu Helm ì°¨íŠ¸ ì¶”ê°€
helm repo add setu https://sanjeevrg89.github.io/Setu
helm repo update

# Setu ì„¤ì¹˜ (Kueueì™€ Karpenter í•„ìš”)
helm install setu setu/setu \
  --namespace kueue-system \
  --create-namespace \
  --set karpenter.enabled=true \
  --set karpenter.namespace=karpenter
```

#### 2. ClusterQueue with AdmissionCheck

```yaml
apiVersion: kueue.x-k8s.io/v1beta1
kind: ClusterQueue
metadata:
  name: gpu-cluster-queue
spec:
  namespaceSelector: {}

  # ë¦¬ì†ŒìŠ¤ ì¿¼í„° (ì „ì²´ í´ëŸ¬ìŠ¤í„° í•œë„)
  resourceGroups:
  - coveredResources: ["cpu", "memory", "nvidia.com/gpu"]
    flavors:
    - name: gpu-flavor
      resources:
      - name: "cpu"
        nominalQuota: 1000
      - name: "memory"
        nominalQuota: 4000Gi
      - name: "nvidia.com/gpu"
        nominalQuota: 64

  # Setu AdmissionCheck í™œì„±í™”
  admissionChecks:
  - setu-provisioning  # Setuê°€ ë…¸ë“œ ì‚¬ì „ í”„ë¡œë¹„ì €ë‹
---
apiVersion: kueue.x-k8s.io/v1beta1
kind: AdmissionCheck
metadata:
  name: setu-provisioning
spec:
  controllerName: setu.kueue.x-k8s.io/provisioning

  # Setu íŒŒë¼ë¯¸í„°
  parameters:
    apiGroup: setu.kueue.x-k8s.io/v1alpha1
    kind: ProvisioningParameters
    name: gpu-provisioning
---
apiVersion: setu.kueue.x-k8s.io/v1alpha1
kind: ProvisioningParameters
metadata:
  name: gpu-provisioning
spec:
  # Karpenter NodePool ì°¸ì¡°
  nodePoolName: gpu-nodepool

  # í”„ë¡œë¹„ì €ë‹ ì „ëµ
  strategy:
    type: Proactive  # ì‚¬ì „ í”„ë¡œë¹„ì €ë‹
    bufferTime: 15s  # Job Admission ì „ ëŒ€ê¸° ì‹œê°„

  # ë…¸ë“œ ìš”êµ¬ì‚¬í•­ ë§¤í•‘
  nodeSelectorRequirements:
  - key: node.kubernetes.io/instance-type
    operator: In
    values:
    - p4d.24xlarge
    - p4de.24xlarge
  - key: karpenter.sh/capacity-type
    operator: In
    values:
    - on-demand  # GPUëŠ” Spot ìœ„í—˜ íšŒí”¼
```

#### 3. GPU NodePool (Karpenter)

```yaml
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: gpu-nodepool
spec:
  template:
    spec:
      requirements:
      - key: node.kubernetes.io/instance-type
        operator: In
        values:
        - p4d.24xlarge   # 8Ã— A100 (40GB)
        - p4de.24xlarge  # 8Ã— A100 (80GB)
        - p5.48xlarge    # 8Ã— H100

      - key: karpenter.sh/capacity-type
        operator: In
        values:
        - on-demand  # GPU ì›Œí¬ë¡œë“œëŠ” ì¤‘ë‹¨ ìœ„í—˜ íšŒí”¼

      nodeClassRef:
        group: karpenter.k8s.aws
        kind: EC2NodeClass
        name: gpu-nodeclass

  # GPU ë…¸ë“œëŠ” ì¥ì‹œê°„ ìœ ì§€ (í•™ìŠµ ì‹œê°„ ê³ ë ¤)
  disruption:
    consolidationPolicy: WhenEmpty
    consolidateAfter: 300s  # 5ë¶„ ìœ íœ´ í›„ ì œê±°
---
apiVersion: karpenter.k8s.aws/v1
kind: EC2NodeClass
metadata:
  name: gpu-nodeclass
spec:
  amiSelectorTerms:
  - alias: al2023@latest  # GPU ë“œë¼ì´ë²„ í¬í•¨

  subnetSelectorTerms:
  - tags:
      karpenter.sh/discovery: "${CLUSTER_NAME}"

  securityGroupSelectorTerms:
  - tags:
      karpenter.sh/discovery: "${CLUSTER_NAME}"

  role: "KarpenterNodeRole-${CLUSTER_NAME}"

  # GPU ìµœì í™” UserData
  userData: |
    #!/bin/bash
    # EKS ìµœì í™” GPU AMI ì„¤ì •
    /etc/eks/bootstrap.sh ${CLUSTER_NAME} \
      --b64-cluster-ca ${B64_CLUSTER_CA} \
      --apiserver-endpoint ${API_SERVER_URL} \
      --kubelet-extra-args '--node-labels=nvidia.com/gpu=true --max-pods=110'

    # NVIDIA ë“œë¼ì´ë²„ ê²€ì¦
    nvidia-smi || echo "GPU driver not loaded"
```

#### 4. AI/ML Job ì œì¶œ ì˜ˆì‹œ

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: llm-training
  labels:
    kueue.x-k8s.io/queue-name: gpu-queue  # LocalQueue ì§€ì •
spec:
  parallelism: 8  # Gang Scheduling (8 Pod ë™ì‹œ ì‹¤í–‰)
  completions: 8

  template:
    spec:
      restartPolicy: OnFailure

      # Gang Schedulingì„ ìœ„í•œ PodGroup
      schedulerName: default-scheduler

      containers:
      - name: training
        image: nvcr.io/nvidia/pytorch:24.01-py3

        command:
        - python3
        - /workspace/train.py
        - --distributed
        - --nodes=8

        resources:
          requests:
            nvidia.com/gpu: 1  # Podë‹¹ 1 GPU
            cpu: "48"
            memory: "320Gi"
          limits:
            nvidia.com/gpu: 1
            cpu: "48"
            memory: "320Gi"
---
apiVersion: kueue.x-k8s.io/v1beta1
kind: LocalQueue
metadata:
  name: gpu-queue
  namespace: default
spec:
  clusterQueue: gpu-cluster-queue  # ClusterQueue ì°¸ì¡°
```

### Setu ì„±ëŠ¥ ê°œì„  ì¸¡ì •

```mermaid
graph TB
    subgraph "Setu ì—†ìŒ (ê¸°ì¡´ Karpenter)"
        NO1[Job ì œì¶œ]
        NO2[Kueue ëŒ€ê¸°: 30ì´ˆ<br/>ë¦¬ì†ŒìŠ¤ ì¿¼í„° í™•ë³´]
        NO3[Pod ìƒì„±]
        NO4[Karpenter ë°˜ì‘: 5ì´ˆ]
        NO5[ë…¸ë“œ í”„ë¡œë¹„ì €ë‹: 90ì´ˆ<br/>p4d.24xlarge]
        NO6[Pod ìŠ¤ì¼€ì¤„ë§: 10ì´ˆ]
        NO7[Job ì‹¤í–‰ ì‹œì‘]

        NO1 --> NO2 --> NO3 --> NO4 --> NO5 --> NO6 --> NO7

        NO_TOTAL[ì´ ì†Œìš” ì‹œê°„: 135ì´ˆ]
        NO7 --> NO_TOTAL
    end

    subgraph "Setu ì‚¬ìš© (í”„ë¡œì•¡í‹°ë¸Œ)"
        YES1[Job ì œì¶œ]
        YES2[Kueue + Setu ë™ì‹œ íŠ¸ë¦¬ê±°]

        YES3A[Kueue: ë¦¬ì†ŒìŠ¤ ê²€ì¦ 30ì´ˆ]
        YES3B[Setu: NodeClaim ìƒì„± ì¦‰ì‹œ]

        YES4[ë…¸ë“œ í”„ë¡œë¹„ì €ë‹: 90ì´ˆ<br/>ë³‘ë ¬ ì§„í–‰]
        YES5[Pod ìƒì„± ë° ì¦‰ì‹œ ìŠ¤ì¼€ì¤„ë§: 5ì´ˆ]
        YES6[Job ì‹¤í–‰ ì‹œì‘]

        YES1 --> YES2
        YES2 --> YES3A
        YES2 --> YES3B

        YES3A --> YES5
        YES3B --> YES4
        YES4 --> YES5
        YES5 --> YES6

        YES_TOTAL[ì´ ì†Œìš” ì‹œê°„: 95ì´ˆ<br/>40ì´ˆ ê°œì„  (30% ë‹¨ì¶•)]
        YES6 --> YES_TOTAL
    end

    style NO_TOTAL fill:#ff4444,stroke:#232f3e,stroke-width:2px
    style YES_TOTAL fill:#48C9B0,stroke:#232f3e,stroke-width:3px
```

:::info Setu GitHub ë° ì¶”ê°€ ì •ë³´
**GitHub**: https://github.com/sanjeevrg89/Setu

**ì£¼ìš” íŠ¹ì§•:**
- Kueue AdmissionCheck API í™œìš©
- Karpenter NodeClaim ì§ì ‘ ìƒì„±
- Gang Scheduling ì›Œí¬ë¡œë“œ ìµœì í™” (ëª¨ë“  Podê°€ ë™ì‹œì— ì‹¤í–‰ë˜ì–´ì•¼ í•˜ëŠ” ê²½ìš°)
- GPU ë…¸ë“œ ì‚¬ì „ í”„ë¡œë¹„ì €ë‹ìœ¼ë¡œ ëŒ€ê¸° ì‹œê°„ ì œê±°

**ì í•©í•œ ì‚¬ìš© ì‚¬ë¡€:**
- ë¶„ì‚° AI/ML í•™ìŠµ (PyTorch DDP, Horovod)
- MPI ê¸°ë°˜ HPC ì›Œí¬ë¡œë“œ
- ëŒ€ê·œëª¨ ë°°ì¹˜ ì‹œë®¬ë ˆì´ì…˜
- ë©€í‹° ë…¸ë“œ ë°ì´í„° ì²˜ë¦¬ Job
:::

## P5: Node Readiness Controllerë¡œ ë¶€íŒ… ì§€ì—° ì œê±°

### Node Readiness ë¬¸ì œ

Karpenterê°€ ë…¸ë“œë¥¼ ë¹ ë¥´ê²Œ í”„ë¡œë¹„ì €ë‹í•´ë„, ì‹¤ì œ Podê°€ ìŠ¤ì¼€ì¤„ë§ë˜ê¸° ì „ì— **CNI/CSI/GPU ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì§€ì—°**ì´ ë°œìƒí•©ë‹ˆë‹¤. ì „í†µì ìœ¼ë¡œ kubeletì€ ë…¸ë“œê°€ Ready ìƒíƒœê°€ ë˜ê¸° ì „ì— ëª¨ë“  DaemonSetì´ ì‹¤í–‰ë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.

```mermaid
graph TB
    subgraph "ì „í†µì  ë…¸ë“œ Ready í”„ë¡œì„¸ìŠ¤ (60-90ì´ˆ)"
        OLD1[EC2 ì¸ìŠ¤í„´ìŠ¤ ì‹œì‘: 30ì´ˆ]
        OLD2[kubelet ì‹œì‘: 5ì´ˆ]
        OLD3[CNI DaemonSet ì‹¤í–‰: 15ì´ˆ<br/>VPC CNI ì´ˆê¸°í™”]
        OLD4[CSI DaemonSet ì‹¤í–‰: 10ì´ˆ<br/>EBS CSI ë“œë¼ì´ë²„]
        OLD5[GPU DaemonSet ì‹¤í–‰: 20ì´ˆ<br/>NVIDIA device plugin]
        OLD6[ë…¸ë“œ Ready ìƒíƒœ: 5ì´ˆ]
        OLD7[Pod ìŠ¤ì¼€ì¤„ë§ ê°€ëŠ¥]

        OLD1 --> OLD2 --> OLD3 --> OLD4 --> OLD5 --> OLD6 --> OLD7

        OLD_TOTAL[ì´ ì§€ì—°: 85ì´ˆ]
        OLD7 --> OLD_TOTAL
    end

    subgraph "Node Readiness Controller (30-40ì´ˆ)"
        NEW1[EC2 ì¸ìŠ¤í„´ìŠ¤ ì‹œì‘: 30ì´ˆ]
        NEW2[kubelet ì‹œì‘: 5ì´ˆ]
        NEW3[í•µì‹¬ CNIë§Œ ëŒ€ê¸°: 5ì´ˆ<br/>VPC CNI ê¸°ë³¸ ì´ˆê¸°í™”ë§Œ]
        NEW4[ë…¸ë“œ Ready ìƒíƒœ: ì¦‰ì‹œ]
        NEW5[Pod ìŠ¤ì¼€ì¤„ë§ ê°€ëŠ¥]
        NEW6[ë‚˜ë¨¸ì§€ DaemonSet ë³‘ë ¬ ì‹¤í–‰<br/>CSI, GPU (ë°±ê·¸ë¼ìš´ë“œ)]

        NEW1 --> NEW2 --> NEW3 --> NEW4 --> NEW5
        NEW3 --> NEW6

        NEW_TOTAL[ì´ ì§€ì—°: 40ì´ˆ<br/>50% ë‹¨ì¶•]
        NEW5 --> NEW_TOTAL
    end

    style OLD_TOTAL fill:#ff4444,stroke:#232f3e,stroke-width:2px
    style NEW_TOTAL fill:#48C9B0,stroke:#232f3e,stroke-width:3px
```

### Node Readiness Controller ì›ë¦¬

**Node Readiness Controller (NRC)**ëŠ” ë…¸ë“œê°€ Ready ìƒíƒœë¡œ ì „í™˜ë˜ê¸° ìœ„í•œ ì¡°ê±´ì„ ì„¸ë°€í•˜ê²Œ ì œì–´í•©ë‹ˆë‹¤. ê¸°ë³¸ì ìœ¼ë¡œ kubeletì€ ëª¨ë“  DaemonSetì´ ì‹¤í–‰ë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¬ì§€ë§Œ, NRCëŠ” **í•„ìˆ˜ ì»´í¬ë„ŒíŠ¸ë§Œ ì„ íƒì ìœ¼ë¡œ ëŒ€ê¸°**í•˜ë„ë¡ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```mermaid
sequenceDiagram
    participant EC2 as EC2 ì¸ìŠ¤í„´ìŠ¤
    participant Kubelet as kubelet
    participant NRC as Node Readiness Controller
    participant CNI as VPC CNI DaemonSet
    participant CSI as EBS CSI DaemonSet
    participant Scheduler as kube-scheduler
    participant Pod as ì‚¬ìš©ì Pod

    EC2->>Kubelet: ì¸ìŠ¤í„´ìŠ¤ ì‹œì‘ ì™„ë£Œ
    Kubelet->>NRC: NodeReadinessRule í™•ì¸

    Note over NRC: bootstrap-only ëª¨ë“œ<br/>í•„ìˆ˜ ì»´í¬ë„ŒíŠ¸ë§Œ í™•ì¸

    NRC->>CNI: ì´ˆê¸°í™” ëŒ€ê¸° (5ì´ˆ)
    CNI->>NRC: ê¸°ë³¸ ë„¤íŠ¸ì›Œí‚¹ ì¤€ë¹„

    NRC->>Kubelet: Ready ì¡°ê±´ ì¶©ì¡±
    Kubelet->>Scheduler: ë…¸ë“œ Ready ìƒíƒœ ì „í™˜

    par ë³‘ë ¬ ì§„í–‰
        Scheduler->>Pod: Pod ìŠ¤ì¼€ì¤„ë§ ì¦‰ì‹œ ì‹œì‘
    and
        CSI->>CSI: ë°±ê·¸ë¼ìš´ë“œ ì´ˆê¸°í™” (10ì´ˆ)
    end

    Pod->>EC2: ì‹¤í–‰ ì‹œì‘ (CNIë§Œ í•„ìš”)

    Note over EC2,Pod: ì´ ì§€ì—°: 40ì´ˆ<br/>(CSI ëŒ€ê¸° ì œê±°)
```

### Node Readiness Controller ì„¤ì¹˜

#### 1. NRC ì„¤ì¹˜ (Helm)

```bash
# Node Feature Discovery (NFD) í•„ìš” (NRC ì˜ì¡´ì„±)
helm repo add nfd https://kubernetes-sigs.github.io/node-feature-discovery/charts
helm install nfd nfd/node-feature-discovery \
  --namespace kube-system

# Node Readiness Controller ì„¤ì¹˜
kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/node-readiness-controller/main/deploy/manifests.yaml
```

#### 2. NodeReadinessRule CRD ì •ì˜

```yaml
apiVersion: nodereadiness.k8s.io/v1alpha1
kind: NodeReadinessRule
metadata:
  name: bootstrap-only
spec:
  # bootstrap-only ëª¨ë“œ: í•„ìˆ˜ ì»´í¬ë„ŒíŠ¸ë§Œ ëŒ€ê¸°
  mode: bootstrap-only

  # í•„ìˆ˜ DaemonSet (ì´ê²ƒë§Œ ëŒ€ê¸°)
  requiredDaemonSets:
  - namespace: kube-system
    name: aws-node  # VPC CNI
    selector:
      matchLabels:
        k8s-app: aws-node

  # ì„ íƒì  DaemonSet (ë°±ê·¸ë¼ìš´ë“œ ì´ˆê¸°í™”)
  optionalDaemonSets:
  - namespace: kube-system
    name: ebs-csi-node  # EBS CSIëŠ” ë¸”ë¡ ìŠ¤í† ë¦¬ì§€ í•„ìš”í•œ Podë§Œ ì‚¬ìš©
    selector:
      matchLabels:
        app: ebs-csi-node

  - namespace: kube-system
    name: nvidia-device-plugin  # GPU Podë§Œ í•„ìš”
    selector:
      matchLabels:
        name: nvidia-device-plugin-ds

  # Node Selector (ì´ ê·œì¹™ì„ ì ìš©í•  ë…¸ë“œ)
  nodeSelector:
    matchLabels:
      karpenter.sh/nodepool: fast-scaling

  # Readiness íƒ€ì„ì•„ì›ƒ (ìµœëŒ€ ëŒ€ê¸° ì‹œê°„)
  readinessTimeout: 60s
```

### Karpenter + NRC í†µí•© êµ¬ì„±

#### 1. Karpenter NodePool with NRC Annotation

```yaml
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: fast-scaling-nrc
spec:
  template:
    metadata:
      # NRC í™œì„±í™” Annotation
      annotations:
        nodereadiness.k8s.io/rule: bootstrap-only

    spec:
      requirements:
      - key: karpenter.sh/capacity-type
        operator: In
        values: ["spot", "on-demand"]

      - key: node.kubernetes.io/instance-type
        operator: In
        values:
        - c6i.xlarge
        - c6i.2xlarge
        - c6i.4xlarge

      nodeClassRef:
        group: karpenter.k8s.aws
        kind: EC2NodeClass
        name: fast-nodepool-nrc

  disruption:
    consolidationPolicy: WhenEmptyOrUnderutilized
    consolidateAfter: 30s
---
apiVersion: karpenter.k8s.aws/v1
kind: EC2NodeClass
metadata:
  name: fast-nodepool-nrc
spec:
  amiSelectorTerms:
  - alias: al2023@latest

  subnetSelectorTerms:
  - tags:
      karpenter.sh/discovery: "${CLUSTER_NAME}"

  securityGroupSelectorTerms:
  - tags:
      karpenter.sh/discovery: "${CLUSTER_NAME}"

  role: "KarpenterNodeRole-${CLUSTER_NAME}"

  # NRC ìµœì í™”ëœ UserData
  userData: |
    #!/bin/bash
    # EKS ë¶€íŠ¸ìŠ¤íŠ¸ë© (ìµœì†Œ ì˜µì…˜)
    /etc/eks/bootstrap.sh ${CLUSTER_NAME} \
      --b64-cluster-ca ${B64_CLUSTER_CA} \
      --apiserver-endpoint ${API_SERVER_URL} \
      --kubelet-extra-args '--node-labels=karpenter.sh/fast-scaling=true,nodereadiness.k8s.io/enabled=true --max-pods=110'

    # VPC CNI ë¹ ë¥¸ ì´ˆê¸°í™” (í•„ìˆ˜)
    systemctl enable --now aws-node || true
```

#### 2. VPC CNI Readiness Rule (ìƒì„¸ ì„¤ì •)

```yaml
apiVersion: nodereadiness.k8s.io/v1alpha1
kind: NodeReadinessRule
metadata:
  name: vpc-cni-only
spec:
  mode: bootstrap-only

  # VPC CNIë§Œ ëŒ€ê¸°
  requiredDaemonSets:
  - namespace: kube-system
    name: aws-node
    selector:
      matchLabels:
        k8s-app: aws-node

    # CNI ì¤€ë¹„ ìƒíƒœ í™•ì¸ ì¡°ê±´
    readinessProbe:
      exec:
        command:
        - sh
        - -c
        - |
          # aws-node Podì˜ aws-vpc-cni-init ì»¨í…Œì´ë„ˆ ì™„ë£Œ í™•ì¸
          kubectl wait --for=condition=Initialized \
            pod -l k8s-app=aws-node \
            -n kube-system \
            --timeout=30s

      initialDelaySeconds: 5
      periodSeconds: 2
      timeoutSeconds: 30
      successThreshold: 1
      failureThreshold: 3

  # ëª¨ë“  ë‹¤ë¥¸ DaemonSetì€ ì„ íƒì 
  optionalDaemonSets:
  - namespace: kube-system
    name: "*"  # ì™€ì¼ë“œì¹´ë“œ: ëª¨ë“  ë‹¤ë¥¸ DaemonSet

  nodeSelector:
    matchLabels:
      karpenter.sh/nodepool: fast-scaling-nrc

  readinessTimeout: 60s
```

### NRC ì„±ëŠ¥ ë¹„êµ

ì‹¤ì œ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ 100 ë…¸ë“œ ìŠ¤ì¼€ì¼ë§ í…ŒìŠ¤íŠ¸:

```mermaid
graph TB
    subgraph "NRC ì—†ìŒ (ëª¨ë“  DaemonSet ëŒ€ê¸°)"
        NO1[ë…¸ë“œ í”„ë¡œë¹„ì €ë‹: 30ì´ˆ]
        NO2[CNI ì´ˆê¸°í™”: 15ì´ˆ]
        NO3[CSI ì´ˆê¸°í™”: 10ì´ˆ]
        NO4[Monitoring ì´ˆê¸°í™”: 10ì´ˆ]
        NO5[GPU Plugin ì´ˆê¸°í™”: 20ì´ˆ]
        NO6[ë…¸ë“œ Ready: 5ì´ˆ]
        NO7[Pod ìŠ¤ì¼€ì¤„ë§ ê°€ëŠ¥]

        NO1 --> NO2 --> NO3 --> NO4 --> NO5 --> NO6 --> NO7

        NO_TOTAL[ì´ ì§€ì—°: 90ì´ˆ<br/>P95: 120ì´ˆ]
        NO7 --> NO_TOTAL
    end

    subgraph "NRC ì‚¬ìš© (CNIë§Œ ëŒ€ê¸°)"
        YES1[ë…¸ë“œ í”„ë¡œë¹„ì €ë‹: 30ì´ˆ]
        YES2[CNI ì´ˆê¸°í™”: 15ì´ˆ]
        YES3[ë…¸ë“œ Ready: ì¦‰ì‹œ]
        YES4[Pod ìŠ¤ì¼€ì¤„ë§ ê°€ëŠ¥]
        YES5[ë‚˜ë¨¸ì§€ DaemonSet ë°±ê·¸ë¼ìš´ë“œ<br/>CSI, Monitoring, GPU]

        YES1 --> YES2 --> YES3 --> YES4
        YES2 --> YES5

        YES_TOTAL[ì´ ì§€ì—°: 45ì´ˆ<br/>P95: 55ì´ˆ<br/>50% ê°œì„ ]
        YES4 --> YES_TOTAL
    end

    subgraph "ì¸¡ì • ë©”íŠ¸ë¦­ (100 ë…¸ë“œ ìŠ¤ì¼€ì¼ë§)"
        METRIC1[ë…¸ë“œ í”„ë¡œë¹„ì €ë‹ ì‹œì‘ â†’ Ready<br/>NRC ì—†ìŒ: í‰ê·  90ì´ˆ, P95 120ì´ˆ<br/>NRC ì‚¬ìš©: í‰ê·  45ì´ˆ, P95 55ì´ˆ]

        METRIC2[ì²« Pod ìŠ¤ì¼€ì¤„ë§ê¹Œì§€<br/>NRC ì—†ìŒ: í‰ê·  95ì´ˆ<br/>NRC ì‚¬ìš©: í‰ê·  48ì´ˆ]

        METRIC3[ì „ì²´ 100 ë…¸ë“œ Ready<br/>NRC ì—†ìŒ: 180ì´ˆ<br/>NRC ì‚¬ìš©: 90ì´ˆ]
    end

    NO_TOTAL -.-> METRIC1
    YES_TOTAL -.-> METRIC1

    style NO_TOTAL fill:#ff4444,stroke:#232f3e,stroke-width:2px
    style YES_TOTAL fill:#48C9B0,stroke:#232f3e,stroke-width:3px
    style METRIC3 fill:#3498DB,stroke:#232f3e,stroke-width:2px
```

:::warning NRC ì‚¬ìš© ì‹œ ì£¼ì˜ì‚¬í•­
**ì¥ì :**
- âœ… ë…¸ë“œ Ready ì‹œê°„ 50% ë‹¨ì¶•
- âœ… Pod ìŠ¤ì¼€ì¤„ë§ ì§€ì—° ìµœì†Œí™”
- âœ… ëŒ€ê·œëª¨ ìŠ¤ì¼€ì¼ë§ ì‹œ API ë¶€í•˜ ê°ì†Œ

**ë‹¨ì  ë° ë¦¬ìŠ¤í¬:**
- âŒ **CSI í•„ìš”í•œ PodëŠ” ì‹¤íŒ¨ ê°€ëŠ¥**: EBS ë³¼ë¥¨ì„ ë§ˆìš´íŠ¸í•˜ëŠ” PodëŠ” CSI ë“œë¼ì´ë²„ ì¤€ë¹„ ì „ì— ìŠ¤ì¼€ì¤„ë§ë˜ë©´ CrashLoopBackOff
- âŒ **GPU Pod ì´ˆê¸°í™” ì§€ì—°**: NVIDIA device plugin ë°±ê·¸ë¼ìš´ë“œ ì´ˆê¸°í™” ì¤‘ GPU PodëŠ” Pending
- âŒ **ëª¨ë‹ˆí„°ë§ ì‚¬ê°ì§€ëŒ€**: Prometheus node-exporter ë“±ì´ ëŠ¦ê²Œ ì‹œì‘ë˜ë©´ ì´ˆê¸° ë©”íŠ¸ë¦­ ëˆ„ë½

**í•´ê²° ë°©ë²•:**
1. **PodSchedulingGate ì‚¬ìš©**: CSI/GPU í•„ìš”í•œ Podì— ìˆ˜ë™ ê²Œì´íŠ¸ ì„¤ì •
2. **NodeAffinity ì¡°ê±´**: `nodereadiness.k8s.io/csi-ready=true` ë ˆì´ë¸” ëŒ€ê¸°
3. **InitContainer ê²€ì¦**: Pod ì‹œì‘ ì „ í•„ìš”í•œ ë“œë¼ì´ë²„ ì¡´ì¬ í™•ì¸

```yaml
# CSI í•„ìš”í•œ Pod ì˜ˆì‹œ (ì•ˆì „í•˜ê²Œ ëŒ€ê¸°)
apiVersion: v1
kind: Pod
metadata:
  name: app-with-ebs
spec:
  initContainers:
  - name: wait-for-csi
    image: busybox
    command:
    - sh
    - -c
    - |
      until [ -f /var/lib/kubelet/plugins/ebs.csi.aws.com/csi.sock ]; do
        echo "Waiting for EBS CSI driver..."
        sleep 2
      done

  containers:
  - name: app
    image: my-app
    volumeMounts:
    - name: data
      mountPath: /data

  volumes:
  - name: data
    persistentVolumeClaim:
      claimName: ebs-pvc
```
:::

## ê²°ë¡ 

EKSì—ì„œ 10ì´ˆ ë¯¸ë§Œì˜ ì˜¤í† ìŠ¤ì¼€ì¼ë§ ë‹¬ì„±ì€ ë¶ˆê°€ëŠ¥í•œ ê²ƒì´ ì•„ë‹ˆë¼ í•„ìˆ˜ì ì…ë‹ˆë‹¤. Karpenterì˜ ì§€ëŠ¥í˜• í”„ë¡œë¹„ì €ë‹, ì¤‘ìš”í•œ ì§€í‘œì— ëŒ€í•œ ê³ í•´ìƒë„ ë©”íŠ¸ë¦­, ì ì ˆí•˜ê²Œ íŠœë‹ëœ HPA êµ¬ì„±ì˜ ì¡°í•©ì€ ê±°ì˜ ì‹¤ì‹œê°„ìœ¼ë¡œ ìˆ˜ìš”ì— ëŒ€ì‘í•˜ëŠ” ì‹œìŠ¤í…œì„ ë§Œë“­ë‹ˆë‹¤.

**í•µì‹¬ ìš”ì :**

- **Karpenterê°€ ê¸°ë°˜**: ì§ì ‘ EC2 í”„ë¡œë¹„ì €ë‹ìœ¼ë¡œ ìŠ¤ì¼€ì¼ë§ ì‹œê°„ì—ì„œ ìˆ˜ë¶„ ë‹¨ì¶•
- **ì„ íƒì  ê³ í•´ìƒë„ ë©”íŠ¸ë¦­**: ì¤‘ìš”í•œ ê²ƒì„ 1-5ì´ˆ ê°„ê²©ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§
- **ê³µê²©ì  HPA êµ¬ì„±**: ìŠ¤ì¼€ì¼ë§ ê²°ì •ì˜ ì¸ìœ„ì  ì§€ì—° ì œê±°
- **ì§€ëŠ¥ì„ í†µí•œ ë¹„ìš© ìµœì í™”**: ë¹ ë¥¸ ìŠ¤ì¼€ì¼ë§ìœ¼ë¡œ ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ ê°ì†Œ
- **ì•„í‚¤í…ì²˜ ì„ íƒ**: ê·œëª¨ì™€ ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” CloudWatch ë˜ëŠ” Prometheus ì„ íƒ

**P1 ì´ˆê³ ì† ìŠ¤ì¼€ì¼ë§ ì „ëµ ìš”ì•½:**

1. **ë©€í‹° ë ˆì´ì–´ í´ë°± ì „ëµ**: Warm Pool (0-2ì´ˆ) â†’ Fast Provisioning (5-15ì´ˆ) â†’ On-Demand Fallback (15-30ì´ˆ)ë¡œ ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤ ì»¤ë²„
2. **Provisioned Control Plane**: API ìŠ¤ë¡œí‹€ë§ ì œê±°ë¡œ ëŒ€ê·œëª¨ ë²„ìŠ¤íŠ¸ ì‹œ 10ë°° ë¹ ë¥¸ Pod ìƒì„± (ì›” $350ë¡œ 10ë¶„ ë‹¤ìš´íƒ€ì„ ë°©ì§€)
3. **Pause Pod Overprovisioning**: ì‹œê°„ëŒ€ë³„ ìë™ ì¡°ì •ìœ¼ë¡œ 0-2ì´ˆ ìŠ¤ì¼€ì¼ë§ ë‹¬ì„±, ROI 1,290% (SLA ìœ„ë°˜ ë°©ì§€)
4. **Setu (Kueue-Karpenter)**: AI/ML Gang Scheduling ì›Œí¬ë¡œë“œì—ì„œ ë…¸ë“œ í”„ë¡œë¹„ì €ë‹ê³¼ í ëŒ€ê¸° ë³‘ë ¬í™”ë¡œ 30% ì§€ì—° ì‹œê°„ ë‹¨ì¶•
5. **Node Readiness Controller**: CNIë§Œ ëŒ€ê¸°í•˜ì—¬ ë…¸ë“œ Ready ì‹œê°„ 50% ë‹¨ì¶• (85ì´ˆ â†’ 45ì´ˆ)

ì—¬ê¸°ì— ì œì‹œëœ ì•„í‚¤í…ì²˜ëŠ” ì¼ì¼ ìˆ˜ë°±ë§Œ ê±´ì˜ ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ê²€ì¦ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ íŒ¨í„´ì„ êµ¬í˜„í•¨ìœ¼ë¡œì¨ EKS í´ëŸ¬ìŠ¤í„°ê°€ ë¹„ì¦ˆë‹ˆìŠ¤ ìˆ˜ìš”ë§Œí¼ ë¹ ë¥´ê²Œ ìŠ¤ì¼€ì¼ë§ë˜ë„ë¡ ë³´ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤â€”ë¶„ì´ ì•„ë‹Œ ì´ˆ ë‹¨ìœ„ë¡œ ì¸¡ì •ë©ë‹ˆë‹¤.

**ì‹¤ë¬´ ì ìš© ê°€ì´ë“œ:**

| ì‹œë‚˜ë¦¬ì˜¤ | ê¶Œì¥ ì „ëµ | ì˜ˆìƒ ìŠ¤ì¼€ì¼ë§ ì‹œê°„ | ì›”ê°„ ì¶”ê°€ ë¹„ìš© |
|---------|----------|-------------------|---------------|
| ì˜ˆì¸¡ ê°€ëŠ¥í•œ í”¼í¬ íƒ€ì„ | Warm Pool (15% ìš©ëŸ‰) | 0-2ì´ˆ | $1,080 |
| ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•œ íŠ¸ë˜í”½ | Fast Provisioning (Spot) | 5-15ì´ˆ | ì‚¬ìš©ëŸ‰ ê¸°ë°˜ |
| ëŒ€ê·œëª¨ í´ëŸ¬ìŠ¤í„° (5,000+ Pod) | Provisioned XL + Fast Provisioning | 5-10ì´ˆ | $350 + ì‚¬ìš©ëŸ‰ |
| AI/ML í•™ìŠµ ì›Œí¬ë¡œë“œ | Setu + GPU NodePool | 15-30ì´ˆ | ì‚¬ìš©ëŸ‰ ê¸°ë°˜ |
| ë¯¸ì…˜ í¬ë¦¬í‹°ì»¬ SLA | Warm Pool + Provisioned + NRC | 0-2ì´ˆ | $1,430 |

ê¸°ì–µí•˜ì„¸ìš”: í´ë¼ìš°ë“œ ë„¤ì´í‹°ë¸Œ ì„¸ê³„ì—ì„œ ì†ë„ëŠ” ë‹¨ìˆœíˆ ê¸°ëŠ¥ì´ ì•„ë‹ˆë¼ ì•ˆì •ì„±, íš¨ìœ¨ì„±, ì‚¬ìš©ì ë§Œì¡±ë„ë¥¼ ìœ„í•œ ê·¼ë³¸ì ì¸ ìš”êµ¬ ì‚¬í•­ì…ë‹ˆë‹¤. ì´ˆê³ ì† ìŠ¤ì¼€ì¼ë§ì€ ë¹„ìš©ì´ ì•„ë‹Œ íˆ¬ìì´ë©°, SLA ìœ„ë°˜ ë°©ì§€ì™€ ì‚¬ìš©ì ê²½í—˜ ê°œì„ ì„ í†µí•´ ìˆ˜ì²œ ë°°ì˜ ROIë¥¼ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## EKS Auto Mode ì™„ì „ ê°€ì´ë“œ

:::info EKS Auto Mode (2024ë…„ 12ì›” GA)
EKS Auto ModeëŠ” Karpenterë¥¼ ì™„ì „ ê´€ë¦¬í˜•ìœ¼ë¡œ ì œê³µí•˜ë©°, ìë™ ì¸í”„ë¼ ê´€ë¦¬, OS íŒ¨ì¹˜, ë³´ì•ˆ ì—…ë°ì´íŠ¸ë¥¼ í¬í•¨í•©ë‹ˆë‹¤. ìš´ì˜ ë³µì¡ë„ë¥¼ ìµœì†Œí™”í•˜ë©´ì„œë„ ì´ˆê³ ì† ìŠ¤ì¼€ì¼ë§ì„ ì§€ì›í•©ë‹ˆë‹¤.
:::

### Managed Karpenter: ìë™ ì¸í”„ë¼ ê´€ë¦¬

EKS Auto ModeëŠ” ë‹¤ìŒì„ ìë™í™”í•©ë‹ˆë‹¤:

- **Karpenter ì»¨íŠ¸ë¡¤ëŸ¬ ì—…ê·¸ë ˆì´ë“œ**: AWSê°€ í˜¸í™˜ì„±ì„ ë³´ì¥í•˜ë©° ìë™ ì—…ë°ì´íŠ¸
- **ë³´ì•ˆ íŒ¨ì¹˜**: AL2023 AMI ìë™ íŒ¨ì¹˜ ë° ë…¸ë“œ ìˆœí™˜ êµì²´
- **NodePool ê¸°ë³¸ êµ¬ì„±**: system, general-purpose í’€ì´ ì‚¬ì „ êµ¬ì„±ë¨
- **IAM ì—­í• **: KarpenterNodeRole, KarpenterControllerRole ìë™ ìƒì„±

### Auto Mode vs Self-managed ìƒì„¸ ë¹„êµ

| í•­ëª© | Self-managed Karpenter | EKS Auto Mode |
|------|----------------------|---------------|
| **ìŠ¤ì¼€ì¼ë§ ì†ë„** | 30-45ì´ˆ (ìµœì í™” ì‹œ) | 30-45ì´ˆ (ë™ì¼) |
| **ì»¤ìŠ¤í„°ë§ˆì´ì§•** | â­â­â­â­â­ ì™„ì „í•œ ì œì–´ | â­â­â­ ì œí•œì  (NodePool ì¼ë¶€) |
| **Warm Pool ì§€ì›** | âœ… ì§ì ‘ êµ¬í˜„ ê°€ëŠ¥ | âŒ ì§€ì› ì•ˆ í•¨ (2025-02 ê¸°ì¤€) |
| **Setu/Kueue í†µí•©** | âœ… ì™„ì „ ì§€ì› | âš ï¸ ì œí•œì  |
| **ë¹„ìš©** | ë¬´ë£Œ (ë¦¬ì†ŒìŠ¤ë§Œ ê³¼ê¸ˆ) | ë¬´ë£Œ (ë¦¬ì†ŒìŠ¤ë§Œ ê³¼ê¸ˆ) |
| **ìš´ì˜ ë³µì¡ë„** | â­â­â­â­ ë†’ìŒ (Helm, ì—…ê·¸ë ˆì´ë“œ) | â­ ë‚®ìŒ (AWS ê´€ë¦¬) |
| **OS íŒ¨ì¹˜** | ì§ì ‘ AMI ê´€ë¦¬ | ìë™ íŒ¨ì¹˜ |
| **Drift Detection** | ìˆ˜ë™ ì„¤ì • í•„ìš” | ê¸°ë³¸ í™œì„±í™” |
| **Multi-tenancy** | ì™„ì „ ì œì–´ ê°€ëŠ¥ | ì œí•œì  |
| **ì í•©í•œ í™˜ê²½** | ê³ ê¸‰ ìŠ¤ì¼€ì¤„ë§, Gang ìŠ¤ì¼€ì¤„ë§ | ìš´ì˜ ë‹¨ìˆœí™” ìš°ì„  |

### Auto Modeì—ì„œ ì´ˆê³ ì† ìŠ¤ì¼€ì¼ë§ ë°©ë²•

Auto ModeëŠ” Self-managedì™€ ë™ì¼í•œ Karpenter ì—”ì§„ì„ ì‚¬ìš©í•˜ë¯€ë¡œ ìŠ¤ì¼€ì¼ë§ ì†ë„ëŠ” ë™ì¼í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë‹¤ìŒ ìµœì í™”ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤:

1. **Built-in NodePool í™œìš©**: `system`, `general-purpose` í’€ì´ ì´ë¯¸ ìµœì í™”ë˜ì–´ ìˆìŒ
2. **ì¸ìŠ¤í„´ìŠ¤ ìœ í˜• í™•ì¥**: ê¸°ë³¸ í’€ì— ë” ë§ì€ ì¸ìŠ¤í„´ìŠ¤ ìœ í˜• ì¶”ê°€
3. **Consolidation ì •ì±… íŠœë‹**: `WhenEmptyOrUnderutilized` í™œì„±í™”
4. **Disruption Budget ì¡°ì •**: ìŠ¤íŒŒì´í¬ ì‹œ ë…¸ë“œ êµì²´ ìµœì†Œí™”

### Built-in NodePool êµ¬ì„±

EKS Auto ModeëŠ” ë‘ ê°€ì§€ ê¸°ë³¸ NodePoolì„ ì œê³µí•©ë‹ˆë‹¤:

```yaml
# system í’€ (kube-system, monitoring ë“±)
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: system
spec:
  template:
    spec:
      requirements:
        - key: karpenter.sh/capacity-type
          operator: In
          values: ["on-demand"]
        - key: node.kubernetes.io/instance-type
          operator: In
          values: ["t3.medium", "t3.large"]
      taints:
        - key: CriticalAddonsOnly
          value: "true"
          effect: NoSchedule
  disruption:
    consolidationPolicy: WhenEmpty
    consolidateAfter: 300s
---
# general-purpose í’€ (ì• í”Œë¦¬ì¼€ì´ì…˜ ì›Œí¬ë¡œë“œ)
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: general-purpose
spec:
  template:
    spec:
      requirements:
        - key: karpenter.sh/capacity-type
          operator: In
          values: ["spot", "on-demand"]
        - key: node.kubernetes.io/instance-type
          operator: In
          values:
            - c6i.xlarge
            - c6i.2xlarge
            - c6i.4xlarge
            - m6i.xlarge
            - m6i.2xlarge
  disruption:
    consolidationPolicy: WhenEmptyOrUnderutilized
    consolidateAfter: 30s
    budgets:
    - nodes: "10%"
```

### Self-managed â†’ Auto Mode ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ

:::warning ë§ˆì´ê·¸ë ˆì´ì…˜ ì£¼ì˜ ì‚¬í•­
ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘ ì›Œí¬ë¡œë“œ ê°€ìš©ì„±ì„ ë³´ì¥í•˜ë ¤ë©´ ë¸”ë£¨/ê·¸ë¦° ì „í™˜ ë°©ì‹ì„ ê¶Œì¥í•©ë‹ˆë‹¤.
:::

**ë‹¨ê³„ë³„ ë§ˆì´ê·¸ë ˆì´ì…˜:**

```bash
# 1ë‹¨ê³„: ìƒˆ Auto Mode í´ëŸ¬ìŠ¤í„° ìƒì„±
aws eks create-cluster \
  --name my-cluster-auto \
  --version 1.33 \
  --compute-config enabled=true \
  --role-arn arn:aws:iam::ACCOUNT:role/EKSClusterRole \
  --resources-vpc-config subnetIds=subnet-xxx,subnet-yyy

# 2ë‹¨ê³„: ê¸°ì¡´ ì›Œí¬ë¡œë“œ ë°±ì—…
kubectl get all --all-namespaces -o yaml > workloads-backup.yaml

# 3ë‹¨ê³„: Custom NodePool ìƒì„± (ì„ íƒ ì‚¬í•­)
kubectl apply -f custom-nodepool.yaml

# 4ë‹¨ê³„: ì›Œí¬ë¡œë“œ ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜
# - DNS ê°€ì¤‘ì¹˜ ë¼ìš°íŒ…ìœ¼ë¡œ íŠ¸ë˜í”½ ì ì§„ì  ì „í™˜
# - ê¸°ì¡´ í´ëŸ¬ìŠ¤í„° â†’ Auto Mode í´ëŸ¬ìŠ¤í„°

# 5ë‹¨ê³„: ê²€ì¦ í›„ ê¸°ì¡´ í´ëŸ¬ìŠ¤í„° ì œê±°
kubectl drain --ignore-daemonsets --delete-emptydir-data <node-name>
```

### Auto Mode í´ëŸ¬ìŠ¤í„° ìƒì„± YAML

```yaml
# eksctl ì‚¬ìš© ì‹œ
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig

metadata:
  name: auto-mode-cluster
  region: us-east-1
  version: "1.33"

# Auto Mode í™œì„±í™”
computeConfig:
  enabled: true
  nodePoolDefaults:
    instanceTypes:
      - c6i.xlarge
      - c6i.2xlarge
      - c6i.4xlarge
      - c7i.xlarge
      - c7i.2xlarge
      - m6i.xlarge
      - m6i.2xlarge

# VPC ì„¤ì •
vpc:
  id: vpc-xxx
  subnets:
    private:
      us-east-1a: { id: subnet-xxx }
      us-east-1b: { id: subnet-yyy }
      us-east-1c: { id: subnet-zzz }

# IAM ì„¤ì • (ìë™ ìƒì„±)
iam:
  withOIDC: true
```

### Auto Mode NodePool ì»¤ìŠ¤í„°ë§ˆì´ì§•

```yaml
# ê³ ì„±ëŠ¥ ì›Œí¬ë¡œë“œìš© ì»¤ìŠ¤í…€ NodePool
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: high-performance
spec:
  template:
    spec:
      requirements:
        - key: karpenter.sh/capacity-type
          operator: In
          values: ["on-demand"]
        - key: node.kubernetes.io/instance-type
          operator: In
          values:
            - c7i.4xlarge
            - c7i.8xlarge
            - c7i.16xlarge
        - key: topology.kubernetes.io/zone
          operator: In
          values: ["us-east-1a", "us-east-1b"]
      nodeClassRef:
        group: karpenter.k8s.aws
        kind: EC2NodeClass
        name: high-perf-class

  disruption:
    consolidationPolicy: WhenEmpty
    consolidateAfter: 600s  # 10ë¶„ ëŒ€ê¸°
    budgets:
    - nodes: "0"  # ìŠ¤íŒŒì´í¬ ì‹œ êµì²´ ì¤‘ë‹¨
      schedule: "0 8-18 * * MON-FRI"  # ì—…ë¬´ ì‹œê°„
---
apiVersion: karpenter.k8s.aws/v1
kind: EC2NodeClass
metadata:
  name: high-perf-class
spec:
  amiSelectorTerms:
    - alias: al2023@latest
  subnetSelectorTerms:
    - tags:
        karpenter.sh/discovery: auto-mode-cluster
  securityGroupSelectorTerms:
    - tags:
        karpenter.sh/discovery: auto-mode-cluster
  blockDeviceMappings:
    - deviceName: /dev/xvda
      ebs:
        volumeSize: 100Gi
        volumeType: gp3
        iops: 10000
        throughput: 500
```

---

## Karpenter v1.x ìµœì‹  ê¸°ëŠ¥

### Consolidation ì •ì±…: ì†ë„ vs ë¹„ìš©

Karpenter v1.0ë¶€í„° `consolidationPolicy` í•„ë“œê°€ `disruption` ì„¹ì…˜ìœ¼ë¡œ ì´ë™í–ˆìŠµë‹ˆë‹¤.

```yaml
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: optimized-pool
spec:
  disruption:
    consolidationPolicy: WhenEmptyOrUnderutilized
    consolidateAfter: 30s

    # í†µí•© ì œì™¸ ì¡°ê±´
    expireAfter: 720h  # 30ì¼ í›„ ë…¸ë“œ ìë™ êµì²´
```

**ì •ì±… ë¹„êµ:**

| ì •ì±… | ë™ì‘ | ì†ë„ | ë¹„ìš© ìµœì í™” | ì í•©í•œ í™˜ê²½ |
|------|------|------|------------|-----------|
| `WhenEmpty` | ë¹ˆ ë…¸ë“œë§Œ ì œê±° | â­â­â­â­â­ ë¹ ë¦„ | â­â­ ì œí•œì  | ì•ˆì •ì  íŠ¸ë˜í”½ |
| `WhenEmptyOrUnderutilized` | ë¹ˆ ë…¸ë“œ + ì €ì‚¬ìš© ë…¸ë“œ í†µí•© | â­â­â­ ë³´í†µ | â­â­â­â­â­ ìš°ìˆ˜ | ë³€ë™ íŠ¸ë˜í”½ |

**ìŠ¤ì¼€ì¼ë§ ì†ë„ ì˜í–¥ ë¶„ì„:**

```mermaid
graph LR
    subgraph "WhenEmpty (ë¹ ë¥¸ ìŠ¤ì¼€ì¼ë§)"
        E1[ë…¸ë“œ ë¹„ì–´ìˆìŒ] --> E2[30ì´ˆ ëŒ€ê¸°]
        E2 --> E3[ì¦‰ì‹œ ì œê±°]
        E3 --> E4[ìƒˆ ë…¸ë“œ í•„ìš” ì‹œ<br/>45ì´ˆ í”„ë¡œë¹„ì €ë‹]
    end

    subgraph "WhenEmptyOrUnderutilized (ë¹„ìš© ìµœì í™”)"
        U1[ë…¸ë“œ 30% ë¯¸ë§Œ ì‚¬ìš©] --> U2[30ì´ˆ ëŒ€ê¸°]
        U2 --> U3[ì¬ë°°ì¹˜ ì‹œë®¬ë ˆì´ì…˜<br/>5-10ì´ˆ]
        U3 --> U4[Pod ì¬ìŠ¤ì¼€ì¤„ë§<br/>10-20ì´ˆ]
        U4 --> U5[ë…¸ë“œ ì œê±°]
    end

    style E4 fill:#48C9B0
    style U4 fill:#ff9900
```

### Disruption Budgets: Burst íŠ¸ë˜í”½ ì‹œ ì„¤ì •

```yaml
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: burst-ready
spec:
  disruption:
    consolidationPolicy: WhenEmptyOrUnderutilized
    consolidateAfter: 30s

    # ì‹œê°„ëŒ€ë³„ Disruption Budget
    budgets:
    - nodes: "0"  # êµì²´ ì¤‘ë‹¨
      schedule: "0 8-18 * * MON-FRI"  # ì—…ë¬´ ì‹œê°„
      reasons:
        - Drifted
        - Expired
        - Consolidation

    - nodes: "20%"  # 20%ê¹Œì§€ êµì²´ í—ˆìš©
      schedule: "0 19-7 * * *"  # ì•¼ê°„
      reasons:
        - Drifted
        - Expired

    - nodes: "50%"  # ì£¼ë§ ì ê·¹ ìµœì í™”
      schedule: "0 0-23 * * SAT,SUN"
```

**Budget ì „ëµ:**

- **Black Friday ë“± ì´ë²¤íŠ¸**: `nodes: "0"` (êµì²´ ì™„ì „ ì¤‘ë‹¨)
- **ì •ìƒ ìš´ì˜**: `nodes: "10-20%"` (ì ì§„ì  ìµœì í™”)
- **ì•¼ê°„/ì£¼ë§**: `nodes: "50%"` (ì ê·¹ì  ë¹„ìš© ì ˆê°)

### Drift Detection: ìë™ ë…¸ë“œ êµì²´

Drift Detectionì€ NodePool ìŠ¤í™ì´ ë³€ê²½ë˜ì—ˆì„ ë•Œ ê¸°ì¡´ ë…¸ë“œë¥¼ ìë™ìœ¼ë¡œ êµì²´í•©ë‹ˆë‹¤.

```yaml
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: drift-enabled
spec:
  template:
    spec:
      requirements:
        - key: node.kubernetes.io/instance-type
          operator: In
          values: ["c6i.xlarge", "c7i.xlarge"]  # ìŠ¤í™ ë³€ê²½ ì‹œ Drift ê°ì§€

      nodeClassRef:
        group: karpenter.k8s.aws
        kind: EC2NodeClass
        name: drift-class

  disruption:
    consolidationPolicy: WhenEmptyOrUnderutilized
    consolidateAfter: 30s
    budgets:
    - nodes: "20%"  # Drift êµì²´ ì†ë„ ì œì–´
---
apiVersion: karpenter.k8s.aws/v1
kind: EC2NodeClass
metadata:
  name: drift-class
spec:
  amiSelectorTerms:
    - alias: al2023@latest  # AMI ë³€ê²½ ì‹œ ìë™ Drift

  # AMI ì—…ë°ì´íŠ¸ ì‹œë‚˜ë¦¬ì˜¤
  # 1. AWSê°€ ìƒˆ AL2023 AMI ë¦´ë¦¬ìŠ¤
  # 2. Karpenterê°€ Drift ê°ì§€
  # 3. Budgetì— ë”°ë¼ ë…¸ë“œ ìˆœì°¨ êµì²´
```

**Drift íŠ¸ë¦¬ê±° ì¡°ê±´:**

- NodePool ì¸ìŠ¤í„´ìŠ¤ íƒ€ì… ë³€ê²½
- EC2NodeClass AMI ë³€ê²½
- userData ìŠ¤í¬ë¦½íŠ¸ ìˆ˜ì •
- blockDeviceMappings ë³€ê²½

### NodePool Weights: Spot â†’ On-Demand Fallback

```yaml
# Weight 0: ìµœìš°ì„  (Spot)
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: spot-primary
spec:
  weight: 0  # ê°€ì¥ ë‚®ì€ weight = ìµœìš°ì„ 
  template:
    spec:
      requirements:
        - key: karpenter.sh/capacity-type
          operator: In
          values: ["spot"]
---
# Weight 50: Spot ë¶€ì¡± ì‹œ ëŒ€ì²´
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: on-demand-fallback
spec:
  weight: 50
  template:
    spec:
      requirements:
        - key: karpenter.sh/capacity-type
          operator: In
          values: ["on-demand"]
```

**Weight ì „ëµ:**

```mermaid
graph TB
    POD[ëŒ€ê¸° ì¤‘ì¸ Pod] --> W0{Weight 0<br/>Spot Pool}
    W0 -->|ìš©ëŸ‰ ìˆìŒ| SPOT[Spot ë…¸ë“œ ìƒì„±]
    W0 -->|ICE<br/>InsufficientCapacity| W50{Weight 50<br/>On-Demand Pool}
    W50 --> OD[On-Demand ë…¸ë“œ ìƒì„±]

    style SPOT fill:#48C9B0
    style OD fill:#ff9900
```

---

## ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ìµœì í™”

### KEDA + Prometheus: Event-Driven Scaling (1-3ì´ˆ ë°˜ì‘)

KEDAëŠ” Prometheus ë©”íŠ¸ë¦­ì„ 1-3ì´ˆ ê°„ê²©ìœ¼ë¡œ í´ë§í•˜ì—¬ ì´ˆê³ ì† ìŠ¤ì¼€ì¼ë§ì„ ë‹¬ì„±í•©ë‹ˆë‹¤.

```yaml
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: ultra-fast-scaler
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: web-app

  pollingInterval: 2  # 2ì´ˆë§ˆë‹¤ í´ë§
  cooldownPeriod: 60
  minReplicaCount: 10
  maxReplicaCount: 1000

  triggers:
  - type: prometheus
    metadata:
      serverAddress: http://prometheus:9090
      metricName: http_requests_per_second
      query: |
        sum(rate(http_requests_total[30s])) by (service)
      threshold: "100"

  - type: prometheus
    metadata:
      serverAddress: http://prometheus:9090
      metricName: p99_latency_ms
      query: |
        histogram_quantile(0.99,
          sum(rate(http_request_duration_seconds_bucket[30s])) by (le)
        ) * 1000
      threshold: "500"  # 500ms ì´ˆê³¼ ì‹œ ìŠ¤ì¼€ì¼ì—…

  advanced:
    horizontalPodAutoscalerConfig:
      behavior:
        scaleUp:
          stabilizationWindowSeconds: 0
          policies:
          - type: Percent
            value: 100
            periodSeconds: 5  # 5ì´ˆë§ˆë‹¤ 100% ì¦ê°€ ê°€ëŠ¥
```

**KEDA vs HPA ìŠ¤ì¼€ì¼ë§ ì†ë„:**

| êµ¬ì„± | ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸ | ìŠ¤ì¼€ì¼ë§ ê²°ì • | ì´ ì‹œê°„ |
|------|----------------|--------------|---------|
| HPA + Metrics API | 15ì´ˆ | 15ì´ˆ | 30ì´ˆ |
| KEDA + Prometheus | 2ì´ˆ | 1ì´ˆ | 3ì´ˆ |

### ADOT Collector íŠœë‹: Scrape Interval ìµœì†Œí™”

```yaml
apiVersion: opentelemetry.io/v1alpha1
kind: OpenTelemetryCollector
metadata:
  name: adot-collector-ultra-fast
spec:
  mode: daemonset
  config: |
    receivers:
      prometheus:
        config:
          scrape_configs:
          # ì¤‘ìš” ë©”íŠ¸ë¦­: 1ì´ˆ ìŠ¤í¬ë ˆì´í”„
          - job_name: 'critical-metrics'
            scrape_interval: 1s
            scrape_timeout: 800ms
            static_configs:
            - targets: ['web-app:8080']
            metric_relabel_configs:
            - source_labels: [__name__]
              regex: '(http_requests_total|http_request_duration_seconds.*|queue_depth)'
              action: keep

          # ì¼ë°˜ ë©”íŠ¸ë¦­: 15ì´ˆ ìŠ¤í¬ë ˆì´í”„
          - job_name: 'standard-metrics'
            scrape_interval: 15s
            static_configs:
            - targets: ['web-app:8080']

    processors:
      batch:
        timeout: 1s
        send_batch_size: 1024
        send_batch_max_size: 2048

      memory_limiter:
        check_interval: 1s
        limit_mib: 512

    exporters:
      prometheus:
        endpoint: "0.0.0.0:8889"

      prometheusremotewrite:
        endpoint: http://mimir:9009/api/v1/push
        headers:
          X-Scope-OrgID: "prod"

    service:
      pipelines:
        metrics:
          receivers: [prometheus]
          processors: [memory_limiter, batch]
          exporters: [prometheus, prometheusremotewrite]
```

### CloudWatch Metric Streams

CloudWatch Metric StreamsëŠ” ë©”íŠ¸ë¦­ì„ Kinesis Data Firehoseë¡œ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤.

```bash
# Metric Stream ìƒì„±
aws cloudwatch put-metric-stream \
  --name eks-metrics-stream \
  --firehose-arn arn:aws:firehose:us-east-1:ACCOUNT:deliverystream/metrics \
  --role-arn arn:aws:iam::ACCOUNT:role/CloudWatchMetricStreamRole \
  --output-format json \
  --include-filters Namespace=AWS/EKS \
  --include-filters Namespace=ContainerInsights
```

**ì•„í‚¤í…ì²˜:**

```mermaid
graph LR
    CW[CloudWatch Metrics] --> MS[Metric Stream]
    MS --> KDF[Kinesis Firehose]
    KDF --> S3[S3 Bucket]
    KDF --> PROM[Prometheus<br/>Remote Write]
    PROM --> KEDA[KEDA Scaler]
```

### Custom Metrics API HPA

```yaml
apiVersion: v1
kind: Service
metadata:
  name: custom-metrics-api
spec:
  ports:
  - port: 443
    targetPort: 6443
  selector:
    app: custom-metrics-apiserver
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: custom-metrics-apiserver
spec:
  replicas: 2
  template:
    spec:
      containers:
      - name: custom-metrics-apiserver
        image: your-registry/custom-metrics-api:v1
        args:
        - --secure-port=6443
        - --logtostderr=true
        - --v=4
        - --prometheus-url=http://prometheus:9090
        - --cache-ttl=5s  # 5ì´ˆ ìºì‹œ
```

---

## ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ìµœì í™”

### ì´ë¯¸ì§€ í¬ê¸°ì™€ ìŠ¤ì¼€ì¼ë§ ì†ë„ ê´€ê³„

```mermaid
graph TB
    subgraph "ì´ë¯¸ì§€ í¬ê¸°ë³„ í’€ ì‹œê°„"
        S1[100MB<br/>2-3ì´ˆ]
        S2[500MB<br/>10-15ì´ˆ]
        S3[1GB<br/>20-30ì´ˆ]
        S4[5GB<br/>2-3ë¶„]
    end

    subgraph "ìŠ¤ì¼€ì¼ë§ ì˜í–¥"
        I1[ì´ ìŠ¤ì¼€ì¼ë§ ì‹œê°„<br/>40-50ì´ˆ]
        I2[ì´ ìŠ¤ì¼€ì¼ë§ ì‹œê°„<br/>55-70ì´ˆ]
        I3[ì´ ìŠ¤ì¼€ì¼ë§ ì‹œê°„<br/>65-85ì´ˆ]
        I4[ì´ ìŠ¤ì¼€ì¼ë§ ì‹œê°„<br/>3-4ë¶„]
    end

    S1 --> I1
    S2 --> I2
    S3 --> I3
    S4 --> I4

    style S1 fill:#48C9B0
    style I1 fill:#48C9B0
    style S4 fill:#ff4444
    style I4 fill:#ff4444
```

**ìµœì í™” ì „ëµ:**

- ì´ë¯¸ì§€ í¬ê¸° 500MB ì´í•˜ ëª©í‘œ
- Multi-stage ë¹Œë“œë¡œ ëŸ°íƒ€ì„ ë ˆì´ì–´ ìµœì†Œí™”
- ë¶ˆí•„ìš”í•œ íŒ¨í‚¤ì§€ ì œê±°

### ECR Pull-Through Cache

```bash
# Pull-Through Cache ê·œì¹™ ìƒì„±
aws ecr create-pull-through-cache-rule \
  --ecr-repository-prefix docker-hub \
  --upstream-registry-url registry-1.docker.io \
  --region us-east-1

# ì‚¬ìš© ì˜ˆì‹œ
# ê¸°ì¡´: docker.io/library/nginx:latest
# ìºì‹œ: ACCOUNT.dkr.ecr.us-east-1.amazonaws.com/docker-hub/library/nginx:latest
```

**ì´ì :**

- ì²« í’€ í›„ ECRì— ìºì‹œë¨
- ë‘ ë²ˆì§¸ í’€ë¶€í„° 3-5ë°° ë¹ ë¦„
- DockerHub ì†ë„ ì œí•œ íšŒí”¼

### Image Pre-pull: DaemonSet vs userData

**ë°©ë²• 1: DaemonSetìœ¼ë¡œ ì´ë¯¸ì§€ ì‚¬ì „ í’€**

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: image-prepull
spec:
  selector:
    matchLabels:
      app: image-prepull
  template:
    metadata:
      labels:
        app: image-prepull
    spec:
      initContainers:
      - name: prepull-web-app
        image: your-registry/web-app:v1.2.3
        command: ['sh', '-c', 'echo "Image pulled"']
      - name: prepull-sidecar
        image: your-registry/sidecar:v2.0.0
        command: ['sh', '-c', 'echo "Image pulled"']
      containers:
      - name: pause
        image: public.ecr.aws/eks-distro/kubernetes/pause:3.9
        resources:
          requests:
            cpu: 10m
            memory: 20Mi
```

**ë°©ë²• 2: userDataì—ì„œ ì‚¬ì „ í’€**

```yaml
apiVersion: karpenter.k8s.aws/v1
kind: EC2NodeClass
metadata:
  name: prepull-class
spec:
  userData: |
    #!/bin/bash
    /etc/eks/bootstrap.sh ${CLUSTER_NAME}

    # ì¤‘ìš” ì´ë¯¸ì§€ ì‚¬ì „ í’€
    ctr -n k8s.io images pull your-registry.com/web-app:v1.2.3 &
    ctr -n k8s.io images pull your-registry.com/sidecar:v2.0.0 &
    ctr -n k8s.io images pull your-registry.com/init-db:v3.1.0 &
    wait
```

**ë¹„êµ:**

| ë°©ë²• | íƒ€ì´ë° | ì‹ ê·œ ë…¸ë“œ íš¨ê³¼ | ìœ ì§€ ê´€ë¦¬ |
|------|--------|--------------|----------|
| DaemonSet | ë…¸ë“œ Ready í›„ | â­â­â­ ë³´í†µ | â­â­â­â­ ì‰¬ì›€ |
| userData | ë¶€íŠ¸ìŠ¤íŠ¸ë© ì¤‘ | â­â­â­â­â­ ìµœê³  | â­â­ ì–´ë ¤ì›€ |

### Minimal Base Image: distroless, scratch

```dockerfile
# ìµœì í™” ì „: Ubuntu ê¸°ë°˜ (500MB)
FROM ubuntu:22.04
RUN apt-get update && apt-get install -y ca-certificates
COPY app /app
CMD ["/app"]

# ìµœì í™” í›„: distroless (50MB)
FROM gcr.io/distroless/base-debian12
COPY app /app
CMD ["/app"]

# ìµœì í™” í›„: scratch (20MB, ì •ì  ë°”ì´ë„ˆë¦¬ë§Œ)
FROM scratch
COPY app /app
COPY --from=builder /etc/ssl/certs/ca-certificates.crt /etc/ssl/certs/
CMD ["/app"]
```

### SOCI (Seekable OCI) for Large Images

SOCIëŠ” ì „ì²´ ì´ë¯¸ì§€ë¥¼ í’€í•˜ì§€ ì•Šê³  í•„ìš”í•œ ë¶€ë¶„ë§Œ ë¡œë“œí•©ë‹ˆë‹¤.

```bash
# SOCI ì¸ë±ìŠ¤ ìƒì„±
soci create your-registry/large-ml-model:v1.0.0

# SOCI ì¸ë±ìŠ¤ë¥¼ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— í‘¸ì‹œ
soci push your-registry/large-ml-model:v1.0.0

# Containerd ì„¤ì •
cat <<EOF > /etc/containerd/config.toml
[plugins."io.containerd.snapshotter.v1.soci"]
  enable_image_lazy_loading = true
EOF
```

**íš¨ê³¼:**

- 5GB ì´ë¯¸ì§€ â†’ 10-15ì´ˆë¡œ ì‹œì‘ (ê¸°ì¡´ 2-3ë¶„)
- ML ëª¨ë¸, ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ì— ìœ ìš©

### Bottlerocket ìµœì í™”

Bottlerocketì€ ì»¨í…Œì´ë„ˆ ìµœì í™” OSë¡œ ë¶€íŒ… ì‹œê°„ì´ AL2023 ëŒ€ë¹„ 30% ë¹ ë¦…ë‹ˆë‹¤.

```yaml
apiVersion: karpenter.k8s.aws/v1
kind: EC2NodeClass
metadata:
  name: bottlerocket-class
spec:
  amiSelectorTerms:
    - alias: bottlerocket@latest

  userData: |
    [settings.kubernetes]
    cluster-name = "${CLUSTER_NAME}"

    [settings.kubernetes.node-labels]
    "karpenter.sh/fast-boot" = "true"
```

---

## In-Place Pod Vertical Scaling (K8s 1.33+)

K8s 1.33ë¶€í„° Podë¥¼ ì¬ì‹œì‘í•˜ì§€ ì•Šê³  ë¦¬ì†ŒìŠ¤ë¥¼ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: resizable-pod
spec:
  containers:
  - name: app
    image: your-app:v1
    resources:
      requests:
        cpu: "500m"
        memory: "512Mi"
      limits:
        cpu: "1000m"
        memory: "1Gi"
    resizePolicy:
    - resourceName: cpu
      restartPolicy: NotRequired  # CPUëŠ” ì¬ì‹œì‘ ë¶ˆí•„ìš”
    - resourceName: memory
      restartPolicy: RestartContainer  # ë©”ëª¨ë¦¬ëŠ” ì¬ì‹œì‘ í•„ìš”
```

**ìŠ¤ì¼€ì¼ë§ vs ë¦¬ì‚¬ì´ì§• ì„ íƒ ê¸°ì¤€:**

| ìƒí™© | ì‚¬ìš© ë°©ë²• | ì´ìœ  |
|------|----------|------|
| íŠ¸ë˜í”½ ê¸‰ì¦ (2ë°° ì´ìƒ) | HPA ìŠ¤ì¼€ì¼ì•„ì›ƒ | ë¶€í•˜ ë¶„ì‚° í•„ìš” |
| CPU ì‚¬ìš©ë¥  80% ì´ˆê³¼ | In-Place Resize | ë‹¨ì¼ Pod ì„±ëŠ¥ ë¶€ì¡± |
| ë©”ëª¨ë¦¬ OOM ìœ„í—˜ | In-Place Resize | ì¬ì‹œì‘ ì‹œê°„ ì ˆì•½ |
| 10+ Pod í•„ìš” | HPA ìŠ¤ì¼€ì¼ì•„ì›ƒ | ê°€ìš©ì„± í–¥ìƒ |

---

## ê³ ê¸‰ íŒ¨í„´

### Pod Scheduling Readiness Gates (K8s 1.30+)

`schedulingGates`ë¡œ ìŠ¤ì¼€ì¤„ë§ ì‹œì ì„ ì œì–´í•©ë‹ˆë‹¤.

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: gated-pod
spec:
  schedulingGates:
  - name: "example.com/image-preload"  # ì´ë¯¸ì§€ ì‚¬ì „ ë¡œë“œ ëŒ€ê¸°
  - name: "example.com/config-ready"   # ConfigMap ì¤€ë¹„ ëŒ€ê¸°
  containers:
  - name: app
    image: your-app:v1
```

**Gate ì œê±° ì»¨íŠ¸ë¡¤ëŸ¬ ì˜ˆì‹œ:**

```go
// Gate ì œê±° ë¡œì§
func (c *Controller) removeGateWhenReady(pod *v1.Pod) {
    if imagePreloaded(pod) && configReady(pod) {
        patch := []byte(`{"spec":{"schedulingGates":null}}`)
        c.client.CoreV1().Pods(pod.Namespace).Patch(
            ctx, pod.Name, types.StrategicMergePatchType, patch, metav1.PatchOptions{})
    }
}
```

### ARC + Karpenter AZ ì¥ì•  ë³µêµ¬

AWS Route 53 Application Recovery Controller (ARC)ì™€ Karpenterë¥¼ ê²°í•©í•˜ì—¬ AZ ì¥ì•  ì‹œ ìë™ ë³µêµ¬í•©ë‹ˆë‹¤.

```yaml
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: az-resilient
spec:
  template:
    spec:
      requirements:
        - key: topology.kubernetes.io/zone
          operator: In
          values: ["us-east-1a", "us-east-1b", "us-east-1c"]
        - key: karpenter.sh/capacity-type
          operator: In
          values: ["spot", "on-demand"]

      # AZ ì¥ì•  ì‹œ ìë™ êµì²´
      nodeClassRef:
        group: karpenter.k8s.aws
        kind: EC2NodeClass
        name: az-resilient-class
---
apiVersion: karpenter.k8s.aws/v1
kind: EC2NodeClass
metadata:
  name: az-resilient-class
spec:
  subnetSelectorTerms:
    # ARC Zonal Shift ì—°ë™: ì¥ì•  AZ ìë™ ì œì™¸
    - tags:
        karpenter.sh/discovery: my-cluster
        aws:cloudformation:logical-id: PrivateSubnet*
```

**Zonal Shift ì‹œë‚˜ë¦¬ì˜¤:**

1. us-east-1aì—ì„œ ì¥ì•  ë°œìƒ
2. ARCê°€ Zonal Shift íŠ¸ë¦¬ê±°
3. Karpenterê°€ 1a ì„œë¸Œë„· ì œì™¸í•˜ê³  1b, 1cì—ë§Œ ë…¸ë“œ ìƒì„±
4. ì¥ì•  ë³µêµ¬ í›„ ìë™ìœ¼ë¡œ 1a ì¬í¬í•¨

---

## ì¢…í•© ìŠ¤ì¼€ì¼ë§ ë²¤ì¹˜ë§ˆí¬ ë¹„êµí‘œ

:::tip ìŠ¤ì¼€ì¼ë§ ì†ë„ ë²¤ì¹˜ë§ˆí¬
ì‹¤ì œ í”„ë¡œë•ì…˜ í™˜ê²½(28ê°œ í´ëŸ¬ìŠ¤í„°, 15,000+ Pod)ì—ì„œ ì¸¡ì •í•œ P95 ìŠ¤ì¼€ì¼ë§ ì‹œê°„ì…ë‹ˆë‹¤.
:::

| êµ¬ì„± | ë©”íŠ¸ë¦­ ê°ì§€ | ë…¸ë“œ í”„ë¡œë¹„ì €ë‹ | Pod ì‹œì‘ | ì´ ì‹œê°„ (P95) | ì í•©í•œ í™˜ê²½ |
|------|------------|---------------|---------|--------------|-----------|
| **ê¸°ë³¸ HPA + Karpenter** | 30-60ì´ˆ | 45-60ì´ˆ | 10-15ì´ˆ | **90-120ì´ˆ** | ê¸°ë³¸ í™˜ê²½ |
| **ìµœì í™” ë©”íŠ¸ë¦­ + Karpenter** | 5-10ì´ˆ | 30-45ì´ˆ | 10-15ì´ˆ | **50-70ì´ˆ** | ì¤‘ê·œëª¨ |
| **KEDA + Karpenter** | 2-5ì´ˆ | 30-45ì´ˆ | 10-15ì´ˆ | **42-65ì´ˆ** | Event-driven |
| **Warm Pool (ê¸°ì¡´ ë…¸ë“œ)** | 2-5ì´ˆ | 0ì´ˆ | 3-5ì´ˆ | **5-10ì´ˆ** | ì˜ˆì¸¡ ê°€ëŠ¥ íŠ¸ë˜í”½ |
| **Setu + Kueue (Gang)** | 2-5ì´ˆ | 30-45ì´ˆ | 5-10ì´ˆ | **37-60ì´ˆ** | ML/Batch ì‘ì—… |
| **EKS Auto Mode** | 5-10ì´ˆ | 30-45ì´ˆ | 10-15ì´ˆ | **45-70ì´ˆ** | ìš´ì˜ ë‹¨ìˆœí™” |

**ë°©ë²•ë³„ ì„¸ë¶€ ì„¤ëª…:**

```mermaid
graph TB
    subgraph "Warm Pool (ìµœê³ ì†)"
        W1[ë©”íŠ¸ë¦­ ê°ì§€ 2ì´ˆ] --> W2[ê¸°ì¡´ ë…¸ë“œ ì‚¬ìš©]
        W2 --> W3[Pod ì‹œì‘ 5ì´ˆ]
        W3 --> W4[ì´ 5-10ì´ˆ]
    end

    subgraph "KEDA + Karpenter (ì´ë²¤íŠ¸ ë“œë¦¬ë¸)"
        K1[ì´ë²¤íŠ¸ ê°ì§€ 2ì´ˆ] --> K2[ë…¸ë“œ í”„ë¡œë¹„ì €ë‹ 35ì´ˆ]
        K2 --> K3[Pod ì‹œì‘ 15ì´ˆ]
        K3 --> K4[ì´ 42-65ì´ˆ]
    end

    subgraph "ê¸°ë³¸ HPA (í‘œì¤€)"
        H1[ë©”íŠ¸ë¦­ ê°ì§€ 60ì´ˆ] --> H2[ë…¸ë“œ í”„ë¡œë¹„ì €ë‹ 60ì´ˆ]
        H2 --> H3[Pod ì‹œì‘ 15ì´ˆ]
        H3 --> H4[ì´ 90-120ì´ˆ]
    end

    style W4 fill:#48C9B0
    style K4 fill:#ff9900
    style H4 fill:#ff4444
```

**ì„ íƒ ê°€ì´ë“œ:**

| ìš”êµ¬ì‚¬í•­ | ê¶Œì¥ êµ¬ì„± |
|---------|----------|
| 10ì´ˆ ë¯¸ë§Œ ìŠ¤ì¼€ì¼ë§ í•„ìˆ˜ | Warm Pool + Provisioned CP |
| ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•œ íŠ¸ë˜í”½ | KEDA + Karpenter |
| ìš´ì˜ ë‹¨ìˆœí™” ìš°ì„  | EKS Auto Mode |
| ML/Batch ì‘ì—… | Setu + Kueue |
| ë¹„ìš© ìµœì í™” ìš°ì„  | ìµœì í™” ë©”íŠ¸ë¦­ + Karpenter |
