---
title: "å¤§è§„æ¨¡ EKS æˆæœ¬ç®¡ç†ï¼š30-90% èŠ‚çœç­–ç•¥"
sidebar_label: "6. EKS æˆæœ¬ç®¡ç†"
description: "åœ¨ Amazon EKS ç¯å¢ƒä¸­å®ç° 30-90% æˆæœ¬èŠ‚çœçš„ FinOps ç­–ç•¥ã€‚åŒ…å«æˆæœ¬ç»“æ„åˆ†æã€Karpenter ä¼˜åŒ–ã€å·¥å…·é€‰æ‹©å’Œå®é™…æˆåŠŸæ¡ˆä¾‹"
tags: [eks, cost-management, finops, karpenter, kubecost, optimization]
category: "performance-networking"
last_update:
  date: 2026-02-14
  author: devfloor9
sidebar_position: 6
---

# å¤§è§„æ¨¡ EKS ç¯å¢ƒæˆæœ¬ç®¡ç†æŒ‡å—

> **ğŸ“Œ æ›´æ–°**ï¼š2025-02-09 - åæ˜  Karpenter v1.6 GA å’Œ EKS Auto Mode æˆæœ¬åˆ†æ

> ğŸ“… **åˆ›å»ºæ—¥æœŸ**ï¼š2025-02-05 | **ä¿®æ”¹æ—¥æœŸ**ï¼š2026-02-14 | â±ï¸ **é˜…è¯»æ—¶é—´**ï¼šçº¦ 11 åˆ†é’Ÿ

## æ¦‚è¿°

Amazon EKS ç¯å¢ƒçš„æˆæœ¬ç®¡ç†æ˜¯äº‘è¿è¥ä¸­æœ€é‡è¦çš„æŒ‘æˆ˜ä¹‹ä¸€ã€‚æˆªè‡³ 2024 å¹´ï¼ŒAWS å®¢æˆ·çš„æ€»æ”¯å‡ºé¢„è®¡å°†è¶…è¿‡ 1000 äº¿ç¾å…ƒï¼Œè€Œå¹³å‡æœ‰ 30-35% çš„äº‘æˆæœ¬è¢«æµªè´¹ã€‚ç‰¹åˆ«æ˜¯åœ¨ Kubernetes ç¯å¢ƒä¸­ï¼Œ68% çš„ç»„ç»‡ç»å†äº†æˆæœ¬è¶…æ”¯ã€‚

æœ¬æŒ‡å—æ¶µç›–äº†åœ¨ EKS ç¯å¢ƒä¸­å®ç° 30-90% æˆæœ¬èŠ‚çœçš„å®æˆ˜ç­–ç•¥ã€‚ä» FinOps åŸåˆ™åˆ°ä½¿ç”¨ Karpenter çš„é«˜çº§ä¼˜åŒ–ï¼Œå†åˆ°å®é™…ä¼ä¸šçš„æˆåŠŸæ¡ˆä¾‹ï¼Œå†…å®¹å…¨é¢è¯¦å°½ã€‚

:::tip EKS Auto Mode æˆæœ¬è€ƒè™‘å› ç´ 
2025 å¹´ GA çš„ EKS Auto Mode å†…ç½® Karpenterï¼Œæä¾›è‡ªåŠ¨æˆæœ¬ä¼˜åŒ–ï¼š

- **é¢å¤–æˆæœ¬**ï¼šEKS Auto Mode èŠ‚ç‚¹éœ€æ”¯ä»˜ EC2 ä»·æ ¼çº¦ 10% çš„æº¢ä»·
- **èŠ‚çœæ•ˆæœ**ï¼šé€šè¿‡è‡ªåŠ¨ Spot ä¼˜åŒ–ã€è£…ç®±å’ŒèŠ‚ç‚¹æ•´åˆé™ä½è¿è¥æˆæœ¬
- **å¯¹æ¯”åˆ†æ**ï¼šéœ€è¦è¯„ä¼°ç›¸å¯¹äºè‡ªç®¡ç†é›†ç¾¤çš„æ€»æ‹¥æœ‰æˆæœ¬ï¼ˆTCOï¼‰
- **é€‚ç”¨åœºæ™¯**ï¼šå¸Œæœ›åœ¨æ²¡æœ‰ä¸“èŒ FinOps å·¥ç¨‹å¸ˆçš„æƒ…å†µä¸‹å®ç°æˆæœ¬ä¼˜åŒ–çš„å›¢é˜Ÿ
:::

### æ ¸å¿ƒå†…å®¹

- **FinOps åŸºç¡€**ï¼šKubernetes ç¯å¢ƒä¸“ç”¨çš„æˆæœ¬ç®¡ç†åŸåˆ™å’Œæˆç†Ÿåº¦æ¨¡å‹
- **æˆæœ¬ç»“æ„åˆ†æ**ï¼šEKS æˆæœ¬çš„ 3 å±‚æ¨¡å‹å’Œæµªè´¹å› ç´ è¯†åˆ«
- **å·¥å…·ä½¿ç”¨**ï¼šSCADã€Kubecostã€OpenCost ç­‰æˆæœ¬ç®¡ç†å·¥å…·å¯¹æ¯”
- **Karpenter ä¼˜åŒ–**ï¼šé€šè¿‡ä¸‹ä¸€ä»£è‡ªåŠ¨æ‰©ç¼©å®¹å®ç° 25-40% æˆæœ¬èŠ‚çœ
- **å®æˆ˜æ¡ˆä¾‹**ï¼šå®ç° 70% ä»¥ä¸Šæˆæœ¬èŠ‚çœçš„ä¼ä¸šç­–ç•¥

### å­¦ä¹ ç›®æ ‡

å®Œæˆæœ¬æŒ‡å—åï¼Œæ‚¨å°†èƒ½å¤Ÿï¼š

- å‡†ç¡®ç†è§£å’Œåˆ†æ EKS ç¯å¢ƒçš„æˆæœ¬ç»“æ„
- è¯„ä¼°ç»„ç»‡çš„ FinOps æˆç†Ÿåº¦å¹¶åˆ¶å®šæ”¹è¿›è·¯çº¿å›¾
- é€‰æ‹©å’Œå®æ–½é€‚å½“çš„æˆæœ¬ç®¡ç†å·¥å…·
- ä½¿ç”¨ Karpenter å’Œ Spot å®ä¾‹è¿›è¡Œæˆæœ¬ä¼˜åŒ–
- åœ¨ 30 å¤©å†…å®ç° 10-20% æˆæœ¬èŠ‚çœ

## å‰ç½®è¦æ±‚

### æ‰€éœ€å·¥å…·

| å·¥å…· | ç‰ˆæœ¬ | ç”¨é€” |
|------|------|------|
| kubectl | 1.28+ | Kubernetes é›†ç¾¤ç®¡ç† |
| helm | 3.12+ | æˆæœ¬ç®¡ç†å·¥å…·å®‰è£… |
| aws-cli | 2.13+ | AWS èµ„æºç®¡ç† |
| eksctl | 0.150+ | EKS é›†ç¾¤é…ç½® |

### æ‰€éœ€æƒé™

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "ce:GetCostAndUsage",
        "ce:GetCostForecast",
        "eks:DescribeCluster",
        "ec2:DescribeInstances",
        "ec2:DescribeSpotPriceHistory",
        "cloudwatch:GetMetricStatistics"
      ],
      "Resource": "*"
    }
  ]
}
```

### å‰ç½®çŸ¥è¯†

- Kubernetes åŸºæœ¬æ¦‚å¿µï¼ˆPodã€Deploymentã€Serviceï¼‰
- AWS EKS æ¶æ„ç†è§£
- å®¹å™¨èµ„æºç®¡ç†ï¼ˆrequestsã€limitsï¼‰
- åŸºæœ¬äº‘æˆæœ¬ç»“æ„

## æ¶æ„

### EKS æˆæœ¬ç›‘æ§ç³»ç»Ÿç»“æ„

```mermaid
graph TB
    subgraph "EKS é›†ç¾¤"
        A[å·¥ä½œè´Ÿè½½ Pod] --> B[Kubecost Agent]
        A --> C[Prometheus]
        B --> C
    end

    subgraph "AWS åŸç”Ÿ"
        D[Cost Explorer]
        E[SCAD - åˆ†æ‘Šæˆæœ¬åˆ†é…]
        F[CUR - æˆæœ¬å’Œä½¿ç”¨æŠ¥å‘Š]
        E --> F
    end

    subgraph "æˆæœ¬åˆ†æå±‚"
        C --> G[Grafana ä»ªè¡¨æ¿]
        F --> H[Athena æŸ¥è¯¢]
        B --> I[Kubecost UI]
    end

    subgraph "ä¼˜åŒ–æ‰§è¡Œ"
        G --> J[Alert Manager]
        I --> J
        J --> K[Karpenter]
        K --> L[EC2 Auto Scaling]
    end

    subgraph "å†³ç­–åˆ¶å®š"
        G --> M[FinOps å›¢é˜Ÿ]
        I --> M
        D --> M
        M --> N[æˆæœ¬ç­–ç•¥]
        N --> K
    end

    style A fill:#e1f5ff
    style K fill:#fff3cd
    style M fill:#d4edda
```

### 3 å±‚æˆæœ¬åˆ†é…æ¨¡å‹

```mermaid
graph LR
    A[AWS è´¦å•] --> B[é›†ç¾¤çº§åˆ«]
    B --> C[å‘½åç©ºé—´çº§åˆ«]
    C --> D[å·¥ä½œè´Ÿè½½çº§åˆ«]

    B --> E[æ§åˆ¶å¹³é¢<br/>$0.10/å°æ—¶]
    B --> F[å·¥ä½œèŠ‚ç‚¹<br/>EC2 æˆæœ¬]
    B --> G[ç½‘ç»œ<br/>NAT/LB]

    C --> H[å›¢é˜Ÿ A å‘½åç©ºé—´]
    C --> I[å›¢é˜Ÿ B å‘½åç©ºé—´]
    C --> J[å…±äº«èµ„æº]

    D --> K[Pod çº§ CPU/å†…å­˜]
    D --> L[å­˜å‚¨å·]
    D --> M[ç½‘ç»œæµé‡]

    style A fill:#ff6b6b
    style B fill:#ffd93d
    style C fill:#6bcf7f
    style D fill:#4d96ff
```

## å®æ–½

### ç¬¬ 1 æ­¥ï¼šFinOps æˆç†Ÿåº¦è¯„ä¼°

ç¬¬ä¸€æ­¥æ˜¯è¯„ä¼°ç»„ç»‡å½“å‰çš„ FinOps æˆç†Ÿåº¦ã€‚

#### æˆç†Ÿåº¦æ¨¡å‹

| é˜¶æ®µ | ç‰¹å¾ | æˆæœ¬åˆ†é…å‡†ç¡®åº¦ | è‡ªåŠ¨åŒ–æ°´å¹³ |
|------|------|----------------|------------|
| **Crawlï¼ˆçˆ¬è¡Œï¼‰** | æ‰‹åŠ¨æµç¨‹ï¼ŒåŸºæœ¬å¯è§æ€§ | ä½äº 50% | å‡ ä¹æ²¡æœ‰ |
| **Walkï¼ˆè¡Œèµ°ï¼‰** | è‡ªåŠ¨è·Ÿè¸ªï¼Œä¸»åŠ¨ä¼˜åŒ– | 70-90% | éƒ¨åˆ†è‡ªåŠ¨åŒ– |
| **Runï¼ˆå¥”è·‘ï¼‰** | å®Œå…¨è‡ªåŠ¨åŒ–ï¼Œä¸šåŠ¡å¯¹é½ | 90% ä»¥ä¸Š | å®Œå…¨è‡ªåŠ¨åŒ– |

#### è‡ªè¯„æ£€æŸ¥æ¸…å•

**Crawl é˜¶æ®µï¼ˆåŸºç¡€ï¼‰**

- [ ] é€šè¿‡ AWS Cost Explorer æ£€æŸ¥æœˆåº¦æˆæœ¬
- [ ] èƒ½å¤ŸæŒ‰ EKS é›†ç¾¤åŒºåˆ†æˆæœ¬
- [ ] èƒ½å¤Ÿè¯†åˆ«ä¸»è¦æˆæœ¬å¢é•¿åŸå› 

**Walk é˜¶æ®µï¼ˆæˆé•¿ï¼‰**

- [ ] æŒ‰å‘½åç©ºé—´/å›¢é˜Ÿåˆ†é…æˆæœ¬
- [ ] è®¾ç½®è‡ªåŠ¨æˆæœ¬å‘Šè­¦
- [ ] è¿›è¡Œå‘¨åº¦æˆæœ¬å®¡æŸ¥ä¼šè®®
- [ ] è¿è¡Œèµ„æºåˆç†é…ç½®ç­–ç•¥

**Run é˜¶æ®µï¼ˆæˆç†Ÿï¼‰**

- [ ] è¿è¥å®æ—¶æˆæœ¬ä»ªè¡¨æ¿
- [ ] Pod çº§åˆ«æˆæœ¬è·Ÿè¸ª
- [ ] è‡ªåŠ¨åŒ–ä¼˜åŒ–å·¥ä½œæµ
- [ ] å°†æˆæœ¬ä¸ä¸šåŠ¡æŒ‡æ ‡å…³è”

### ç¬¬ 2 æ­¥ï¼šç†è§£ EKS æˆæœ¬ç»“æ„

#### æˆæœ¬ç»„æˆéƒ¨åˆ†

**1. æ§åˆ¶å¹³é¢æˆæœ¬**

```
æˆæœ¬ï¼š$0.10/å°æ—¶ = $72/æœˆï¼ˆæ¯ä¸ªé›†ç¾¤ï¼‰
ç‰¹å¾ï¼šå›ºå®šæˆæœ¬ï¼Œæ— æ³•ä¼˜åŒ–
å»ºè®®ï¼šé€šè¿‡é›†ç¾¤æ•´åˆå‡å°‘æ•°é‡
```

**2. å·¥ä½œèŠ‚ç‚¹æˆæœ¬ï¼ˆå æ¯”æœ€å¤§ï¼‰**

| å®šä»·æ¨¡å‹ | æˆæœ¬ | èŠ‚çœç‡ | ä¸­æ–­é£é™© |
|----------|------|--------|----------|
| æŒ‰éœ€ | åŸºå‡†ä»· | 0% | æ—  |
| Savings Plans | -28~-72% | æœ€é«˜ 72% | æ—  |
| é¢„ç•™å®ä¾‹ | -40~-75% | æœ€é«˜ 75% | æ—  |
| Spot å®ä¾‹ | -50~-90% | æœ€é«˜ 90% | æœ‰ï¼ˆ2 åˆ†é’Ÿè­¦å‘Šï¼‰ |

**3. éšè—æˆæœ¬å› ç´ **

```yaml
# å®¹æ˜“å¿½ç•¥çš„æˆæœ¬é¡¹ç›®
hidden_costs:
  load_balancers:
    - classic_lb: "$18/æœˆï¼ˆåŸºç¡€ï¼‰+ æ•°æ®ä¼ è¾“"
    - alb: "$22.50/æœˆï¼ˆåŸºç¡€ï¼‰+ LCU æˆæœ¬"
    - nlb: "$20/æœˆï¼ˆåŸºç¡€ï¼‰+ NLCU æˆæœ¬"

  nat_gateways:
    cost: "$32.40/æœˆ/å¯ç”¨åŒº + $0.045/GB å¤„ç†"
    optimization: "ä½¿ç”¨ NAT å®ä¾‹æˆ– VPC ç«¯ç‚¹"

  data_transfer:
    - inter_az: "$0.01/GBï¼ˆå¯ç”¨åŒºé—´ï¼‰"
    - inter_region: "$0.02/GBï¼ˆåŒºåŸŸé—´ï¼‰"
    - internet_egress: "$0.09/GBï¼ˆå‰ 10TBï¼‰"

  ebs_volumes:
    - gp3: "$0.08/GB/æœˆ"
    - unused_volumes: "å¹³å‡ 20-30% æœªä½¿ç”¨"
```

#### æˆæœ¬æµªè´¹æ¨¡å¼è¯†åˆ«

**è¿‡åº¦é…ç½®ï¼ˆå¹³å‡æµªè´¹ 30%ï¼‰**

```bash
# æ£€æŸ¥å‘½åç©ºé—´èµ„æºæ•ˆç‡
kubectl get pods -A -o json | jq -r '
  .items[] |
  select(.status.phase=="Running") |
  {
    namespace: .metadata.namespace,
    pod: .metadata.name,
    containers: [
      .spec.containers[] | {
        name: .name,
        cpu_request: .resources.requests.cpu,
        mem_request: .resources.requests.memory
      }
    ]
  }
' | jq -s 'group_by(.namespace) |
  map({
    namespace: .[0].namespace,
    total_pods: length
  })'
```

**é—²ç½®èµ„æºï¼ˆå¤œé—´/å‘¨æœ«ï¼‰**

```python
# ä½¿ç”¨ç‡åˆ†æè„šæœ¬ç¤ºä¾‹
import boto3
from datetime import datetime, timedelta

cloudwatch = boto3.client('cloudwatch')

def analyze_idle_resources(cluster_name, hours=168):  # 1 å‘¨
    metrics = cloudwatch.get_metric_statistics(
        Namespace='ContainerInsights',
        MetricName='node_cpu_utilization',
        Dimensions=[{'Name': 'ClusterName', 'Value': cluster_name}],
        StartTime=datetime.now() - timedelta(hours=hours),
        EndTime=datetime.now(),
        Period=3600,
        Statistics=['Average']
    )

    idle_hours = sum(1 for m in metrics['Datapoints'] if m['Average'] < 10)
    idle_percentage = (idle_hours / hours) * 100

    return {
        'idle_hours': idle_hours,
        'idle_percentage': idle_percentage,
        'potential_savings': f"{idle_percentage}% of node costs"
    }
```

**åŒºåŸŸæˆæœ¬å·®å¼‚ï¼ˆæœ€é«˜ 40%ï¼‰**

| åŒºåŸŸ | t3.xlarge æŒ‰éœ€ | èŠ‚çœæœºä¼š |
|------|---------------|----------|
| us-east-1ï¼ˆå¼—å‰å°¼äºšï¼‰ | $0.1664/å°æ—¶ | åŸºå‡† |
| ap-northeast-2ï¼ˆé¦–å°”ï¼‰ | $0.2016/å°æ—¶ | +21% |
| eu-west-1ï¼ˆçˆ±å°”å…°ï¼‰ | $0.1856/å°æ—¶ | +12% |

### ç¬¬ 3 æ­¥ï¼šå®æ–½æˆæœ¬ç®¡ç†å·¥å…·

#### AWS Split Cost Allocation Dataï¼ˆSCADï¼‰

**ä¼˜ç‚¹**ï¼šAWS åŸç”Ÿï¼Œæ— é¢å¤–æˆæœ¬ï¼ŒPod çº§åˆ«å¯è§æ€§

**å¯ç”¨æ–¹æ³•**

```bash
# 1. å¯ç”¨æˆæœ¬å’Œä½¿ç”¨æŠ¥å‘Š
aws cur put-report-definition \
  --report-definition file://cur-definition.json

# cur-definition.json
cat > cur-definition.json << 'EOF'
{
  "ReportName": "eks-cost-report",
  "TimeUnit": "HOURLY",
  "Format": "Parquet",
  "Compression": "Parquet",
  "AdditionalSchemaElements": ["RESOURCES", "SPLIT_COST_ALLOCATION_DATA"],
  "S3Bucket": "your-cur-bucket",
  "S3Prefix": "cur-reports",
  "S3Region": "us-east-1",
  "AdditionalArtifacts": ["ATHENA"],
  "RefreshClosedReports": true,
  "ReportVersioning": "OVERWRITE_REPORT"
}
EOF

# 2. åœ¨ EKS é›†ç¾¤ä¸Šå¯ç”¨ SCAD
aws eks update-cluster-config \
  --name your-cluster \
  --resources-vpc-config splitCostAllocationEnabled=true
```

**Athena æŸ¥è¯¢ç¤ºä¾‹**

```sql
-- æŒ‰å‘½åç©ºé—´çš„æ¯æ—¥æˆæœ¬
SELECT
    line_item_usage_start_date,
    split_line_item_split_cost_kubernetes_namespace as namespace,
    SUM(line_item_unblended_cost) as daily_cost
FROM eks_cost_report
WHERE split_line_item_split_cost_kubernetes_namespace IS NOT NULL
GROUP BY 1, 2
ORDER BY 1 DESC, 3 DESC
LIMIT 100;

-- æŒ‰ Pod çš„æœ€é«˜æˆæœ¬
SELECT
    split_line_item_split_cost_kubernetes_pod as pod_name,
    split_line_item_split_cost_kubernetes_namespace as namespace,
    SUM(line_item_unblended_cost) as total_cost,
    AVG(line_item_unblended_cost) as avg_hourly_cost
FROM eks_cost_report
WHERE line_item_usage_start_date >= DATE_ADD('day', -7, CURRENT_DATE)
GROUP BY 1, 2
ORDER BY 3 DESC
LIMIT 20;
```

**é™åˆ¶**

- 24-48 å°æ—¶æ•°æ®å»¶è¿Ÿ
- ä»…åœ¨ CUR ä¸­å¯è§ï¼ˆCost Explorer ä¸æ”¯æŒï¼‰
- æ— æ³•é‡æ–°å¤„ç†å†å²æ•°æ®

#### Kubecost å®æ–½

**ä¼˜ç‚¹**ï¼šå®æ—¶å¯è§æ€§ï¼Œ15 å¤©å…è´¹ä¿ç•™ï¼Œä¼˜åŒ–å»ºè®®

**å®‰è£…ï¼ˆHelmï¼‰**

```bash
# 1. æ·»åŠ  Helm ä»“åº“
helm repo add kubecost https://kubecost.github.io/cost-analyzer/
helm repo update

# 2. åˆ›å»ºç”Ÿäº§ values.yaml
cat > kubecost-values.yaml << 'EOF'
global:
  prometheus:
    enabled: true
    fqdn: http://prometheus-server.monitoring.svc.cluster.local

kubecostProductConfigs:
  clusterName: "production-eks"
  awsSpotDataRegion: "ap-northeast-2"
  awsSpotDataBucket: "your-spot-data-bucket"

  # AWS é›†æˆ
  athenaProjectID: "your-project-id"
  athenaBucketName: "your-athena-results"
  athenaRegion: "ap-northeast-2"
  athenaDatabase: "athenacurcfn_eks_cost_report"
  athenaTable: "eks_cost_report"

# èµ„æºåˆ†é…
kubecostModel:
  resources:
    requests:
      cpu: "500m"
      memory: "512Mi"
    limits:
      cpu: "1000m"
      memory: "1Gi"

# Ingress è®¾ç½®ï¼ˆå¯é€‰ï¼‰
ingress:
  enabled: true
  annotations:
    kubernetes.io/ingress.class: alb
    alb.ingress.kubernetes.io/scheme: internal
    alb.ingress.kubernetes.io/target-type: ip
  hosts:
    - kubecost.your-domain.com
EOF

# 3. å®‰è£…
helm install kubecost kubecost/cost-analyzer \
  --namespace kubecost \
  --create-namespace \
  -f kubecost-values.yaml

# 4. éªŒè¯å®‰è£…
kubectl get pods -n kubecost
kubectl port-forward -n kubecost svc/kubecost-cost-analyzer 9090:9090
```

**ä¸»è¦åŠŸèƒ½ä½¿ç”¨**

```bash
# æŒ‰å‘½åç©ºé—´çš„æˆæœ¬ API è°ƒç”¨
curl "http://localhost:9090/model/allocation/compute?window=7d&aggregate=namespace"

# æˆæœ¬å‘Šè­¦è®¾ç½®
cat > kubecost-alert.yaml << 'EOF'
apiVersion: v1
kind: ConfigMap
metadata:
  name: alert-configs
  namespace: kubecost
data:
  alerts.json: |
    [
      {
        "type": "budget",
        "threshold": 1000,
        "window": "daily",
        "aggregation": "namespace",
        "filter": "namespace:production",
        "ownerContact": ["team-platform@company.com"]
      },
      {
        "type": "efficiency",
        "threshold": 0.5,
        "window": "7d",
        "aggregation": "deployment",
        "ownerContact": ["team-devops@company.com"]
      }
    ]
EOF

kubectl apply -f kubecost-alert.yaml
```

#### å·¥å…·é€‰æ‹©æŒ‡å—

| å·¥å…· | æœ€ä½³ä½¿ç”¨åœºæ™¯ | æˆæœ¬ | å®æ–½å¤æ‚åº¦ |
|------|-------------|------|-----------|
| **SCAD** | AWS åŸç”Ÿä¼˜é€‰ï¼Œé•¿æœŸåˆ†æ | å…è´¹ | ä½ |
| **Kubecostï¼ˆå…è´¹ï¼‰** | ä¸­å°è§„æ¨¡ï¼Œéœ€è¦å®æ—¶ | å…è´¹ | ä¸­ç­‰ |
| **Kubecostï¼ˆä¼ä¸šç‰ˆï¼‰** | å¤§è§„æ¨¡ï¼Œé«˜çº§åŠŸèƒ½ | $~/æœˆ | ä¸­ç­‰ |
| **OpenCost** | å¼€æºä¼˜é€‰ï¼Œè‡ªå®šä¹‰ | å…è´¹ | é«˜ |
| **CloudHealth** | å¤šäº‘æ²»ç† | $$$$ | é«˜ |
| **CAST AI** | å®Œå…¨è‡ªåŠ¨åŒ–ä¼˜é€‰ | % èŠ‚çœé¢ | ä½ |

**å†³ç­–æ ‘**

```
ç»„ç»‡è§„æ¨¡ï¼Ÿ
â”œâ”€ å°å‹ï¼ˆ< 5 ä¸ªé›†ç¾¤ï¼‰
â”‚  â””â”€ é¢„ç®—ï¼Ÿ
â”‚     â”œâ”€ æœ‰é™ â†’ SCAD + Cost Explorer
â”‚     â””â”€ å……è£• â†’ Kubecost å…è´¹ç‰ˆ
â”‚
â”œâ”€ ä¸­å‹ï¼ˆ5-20 ä¸ªé›†ç¾¤ï¼‰
â”‚  â””â”€ éœ€è¦å®æ—¶ï¼Ÿ
â”‚     â”œâ”€ æ˜¯ â†’ Kubecost ä¼ä¸šç‰ˆ
â”‚     â””â”€ å¦ â†’ SCAD + Athena + Grafana
â”‚
â””â”€ å¤§å‹ï¼ˆ20+ ä¸ªé›†ç¾¤ï¼‰
   â””â”€ å¤šäº‘ï¼Ÿ
      â”œâ”€ æ˜¯ â†’ CloudHealth / CloudCheckr
      â””â”€ å¦ â†’ Kubecost ä¼ä¸šç‰ˆ + SCAD
```

### ç¬¬ 4 æ­¥ï¼šä½¿ç”¨ Karpenter ä¼˜åŒ–æˆæœ¬

Karpenter æ˜¯ä¸‹ä¸€ä»£ Kubernetes è‡ªåŠ¨æ‰©ç¼©å®¹å™¨ï¼Œç›¸æ¯” Cluster Autoscaler å¯å®ç° 25-40% æˆæœ¬èŠ‚çœã€‚

#### Karpenter çš„æˆæœ¬èŠ‚çœæœºåˆ¶

**1. å®æ—¶æœ€ä¼˜å®ä¾‹é€‰æ‹©**

```yaml
# NodePool è®¾ç½®ç¤ºä¾‹
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: default
spec:
  template:
    spec:
      requirements:
        # å…è®¸å¤šç§å®ä¾‹ç±»å‹
        - key: karpenter.sh/capacity-type
          operator: In
          values: ["spot", "on-demand"]
        - key: kubernetes.io/arch
          operator: In
          values: ["amd64"]
        - key: karpenter.k8s.aws/instance-category
          operator: In
          values: ["c", "m", "r"]
        - key: karpenter.k8s.aws/instance-generation
          operator: Gt
          values: ["5"]  # ä»… 5 ä»£ä»¥ä¸Š

      nodeClassRef:
        name: default

  # æˆæœ¬ä¼˜åŒ–è®¾ç½®
  disruption:
    consolidationPolicy: WhenUnderutilized
    consolidateAfter: 30s
    expireAfter: 720h  # 30 å¤©

  limits:
    cpu: "1000"
    memory: "1000Gi"

---
apiVersion: karpenter.k8s.aws/v1
kind: EC2NodeClass
metadata:
  name: default
spec:
  amiFamily: AL2
  role: "KarpenterNodeRole-your-cluster"
  subnetSelectorTerms:
    - tags:
        karpenter.sh/discovery: "your-cluster"
  securityGroupSelectorTerms:
    - tags:
        karpenter.sh/discovery: "your-cluster"

  # Spot å®ä¾‹ä¼˜åŒ–
  instanceStorePolicy: RAID0

  # é€šè¿‡ç”¨æˆ·æ•°æ®æ·»åŠ æˆæœ¬æ ‡ç­¾
  userData: |
    #!/bin/bash
    echo "export CLUSTER_NAME=your-cluster" >> /etc/environment
```

**2. è£…ç®±ï¼ˆBin Packingï¼‰ç®—æ³•**

Karpenter ç”¨æœ€å°‘çš„èŠ‚ç‚¹æ”¾ç½®æœ€å¤šçš„ Podï¼š

```
ä¹‹å‰ï¼ˆCluster Autoscalerï¼‰ï¼š
èŠ‚ç‚¹ 1ï¼š[Pod A(2 CPU)] [Pod B(1 CPU)] - æ€»è®¡ 3/4 CPU ä½¿ç”¨
èŠ‚ç‚¹ 2ï¼š[Pod C(2 CPU)] --------------- - æ€»è®¡ 2/4 CPU ä½¿ç”¨
èŠ‚ç‚¹ 3ï¼š[Pod D(1 CPU)] --------------- - æ€»è®¡ 1/4 CPU ä½¿ç”¨
æ€»æˆæœ¬ï¼š3 ä¸ªèŠ‚ç‚¹

ä¹‹åï¼ˆKarpenterï¼‰ï¼š
èŠ‚ç‚¹ 1ï¼š[Pod A(2 CPU)] [Pod B(1 CPU)] [Pod D(1 CPU)] - æ€»è®¡ 4/4 CPU ä½¿ç”¨
èŠ‚ç‚¹ 2ï¼š[Pod C(2 CPU)] ---------------------------- - æ€»è®¡ 2/4 CPU ä½¿ç”¨
æ€»æˆæœ¬ï¼š2 ä¸ªèŠ‚ç‚¹ï¼ˆèŠ‚çœ 33%ï¼‰
```

**3. Spot å®ä¾‹é›†æˆ**

```yaml
# Spot ä¼˜å…ˆç­–ç•¥
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: spot-optimized
spec:
  template:
    spec:
      requirements:
        - key: karpenter.sh/capacity-type
          operator: In
          values: ["spot"]

        # å¤šç§å®ä¾‹ç±»å‹åˆ†æ•£ä¸­æ–­é£é™©
        - key: node.kubernetes.io/instance-type
          operator: In
          values:
            - "c5.xlarge"
            - "c5a.xlarge"
            - "c5n.xlarge"
            - "c6i.xlarge"
            - "m5.xlarge"
            - "m5a.xlarge"

      # Spot ä¸­æ–­å¤„ç†
      taints:
        - key: spot
          value: "true"
          effect: NoSchedule

  disruption:
    consolidationPolicy: WhenUnderutilized
    # Spot æ•´åˆï¼ˆSpot â†’ Spot ç§»åŠ¨ï¼‰
    budgets:
      - nodes: "10%"
        reason: "Underutilized"
```

**åœ¨å·¥ä½œè´Ÿè½½ä¸Šæ ‡è®°å…è®¸ Spot**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spot-friendly-app
spec:
  replicas: 10
  template:
    spec:
      # å…è®¸ Spot èŠ‚ç‚¹
      tolerations:
        - key: spot
          operator: Equal
          value: "true"
          effect: NoSchedule

      # ä¸ PodDisruptionBudget ä¸€èµ·ä½¿ç”¨
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app: spot-friendly-app
                topologyKey: kubernetes.io/hostname

---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: spot-friendly-app-pdb
spec:
  minAvailable: 7  # ä¿æŒæœ€å°‘ 7 ä¸ª Pod
  selector:
    matchLabels:
      app: spot-friendly-app
```

#### Karpenter å®‰è£…ï¼ˆEKS è‡ªç®¡ç†ï¼‰

```bash
# 1. åˆ›å»º IAM è§’è‰²
export CLUSTER_NAME="your-cluster"
export AWS_ACCOUNT_ID="$(aws sts get-caller-identity --query Account --output text)"
export AWS_REGION="ap-northeast-2"

cat > karpenter-trust-policy.json << EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "Federated": "arn:aws:iam::${AWS_ACCOUNT_ID}:oidc-provider/oidc.eks.${AWS_REGION}.amazonaws.com/id/EXAMPLED539D4633E53DE1B71EXAMPLE"
      },
      "Action": "sts:AssumeRoleWithWebIdentity",
      "Condition": {
        "StringEquals": {
          "oidc.eks.${AWS_REGION}.amazonaws.com/id/EXAMPLED539D4633E53DE1B71EXAMPLE:sub": "system:serviceaccount:karpenter:karpenter",
          "oidc.eks.${AWS_REGION}.amazonaws.com/id/EXAMPLED539D4633E53DE1B71EXAMPLE:aud": "sts.amazonaws.com"
        }
      }
    }
  ]
}
EOF

aws iam create-role \
  --role-name "KarpenterControllerRole-${CLUSTER_NAME}" \
  --assume-role-policy-document file://karpenter-trust-policy.json

# 2. é™„åŠ  Karpenter ç­–ç•¥
aws iam attach-role-policy \
  --role-name "KarpenterControllerRole-${CLUSTER_NAME}" \
  --policy-arn "arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy"

# 3. ä½¿ç”¨ Helm å®‰è£… Karpenter
helm upgrade --install karpenter oci://public.ecr.aws/karpenter/karpenter \
  --version v1.1.1 \
  --namespace karpenter \
  --create-namespace \
  --set settings.clusterName=${CLUSTER_NAME} \
  --set settings.clusterEndpoint=$(aws eks describe-cluster --name ${CLUSTER_NAME} --query "cluster.endpoint" --output text) \
  --set serviceAccount.annotations."eks\.amazonaws\.com/role-arn"="arn:aws:iam::${AWS_ACCOUNT_ID}:role/KarpenterControllerRole-${CLUSTER_NAME}" \
  --set controller.resources.requests.cpu=1 \
  --set controller.resources.requests.memory=1Gi \
  --wait

# 4. éªŒè¯
kubectl get pods -n karpenter
kubectl logs -n karpenter -l app.kubernetes.io/name=karpenter
```

#### ç”Ÿäº§ NodePool ç­–ç•¥

**å¤šç¯å¢ƒç­–ç•¥**

```yaml
# ç”Ÿäº§ï¼šæŒ‰éœ€ä¼˜å…ˆ
---
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: production-on-demand
spec:
  template:
    spec:
      requirements:
        - key: karpenter.sh/capacity-type
          operator: In
          values: ["on-demand"]
        - key: node.kubernetes.io/instance-type
          operator: In
          values: ["m5.2xlarge", "m5.4xlarge"]
      taints:
        - key: workload
          value: production
          effect: NoSchedule
  limits:
    cpu: "500"

---
# å¼€å‘/é¢„å‘å¸ƒï¼šä»… Spot
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: development-spot
spec:
  template:
    spec:
      requirements:
        - key: karpenter.sh/capacity-type
          operator: In
          values: ["spot"]
        - key: karpenter.k8s.aws/instance-category
          operator: In
          values: ["c", "m", "r", "t3"]
      taints:
        - key: workload
          value: development
          effect: NoSchedule
  disruption:
    consolidationPolicy: WhenUnderutilized
    consolidateAfter: 30s

---
# GPU å·¥ä½œè´Ÿè½½
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: gpu-workloads
spec:
  template:
    spec:
      requirements:
        - key: karpenter.k8s.aws/instance-category
          operator: In
          values: ["g4dn", "p3"]
        - key: karpenter.sh/capacity-type
          operator: In
          values: ["spot", "on-demand"]
      taints:
        - key: nvidia.com/gpu
          value: "true"
          effect: NoSchedule
  limits:
    cpu: "200"
```

### ç¬¬ 5 æ­¥ï¼šæˆæœ¬åˆ†é…å’Œæ ‡ç­¾ç­–ç•¥

#### åˆ†å±‚æ ‡ç­¾æ¶æ„

```yaml
# æ ‡ç­¾æ ‡å‡†å®šä¹‰
cost_allocation_tags:
  business:
    - cost_center: "CC-12345"
    - business_unit: "Engineering"
    - product: "Platform"
    - environment: "production"

  technical:
    - cluster: "prod-eks-01"
    - namespace: "backend-services"
    - team: "platform-team"
    - component: "api-gateway"

  governance:
    - owner: "john.doe@company.com"
    - managed_by: "terraform"
    - compliance: "pci-dss"

  financial:
    - billing_code: "PROJ-2024-001"
    - budget_category: "infrastructure"
    - charge_method: "chargeback"
```

**è‡ªåŠ¨æ ‡ç­¾ Lambda å‡½æ•°**

```python
# lambda_tag_enforcer.py
import boto3
import json

ec2 = boto3.client('ec2')
eks = boto3.client('eks')

def lambda_handler(event, context):
    """
    å½“ EKS èŠ‚ç‚¹å¯åŠ¨æ—¶è‡ªåŠ¨æ·»åŠ æˆæœ¬æ ‡ç­¾
    """
    instance_id = event['detail']['instance-id']

    # æŸ¥è¯¢å®ä¾‹ä¿¡æ¯
    instance = ec2.describe_instances(InstanceIds=[instance_id])
    tags = instance['Reservations'][0]['Instances'][0].get('Tags', [])

    # æå–é›†ç¾¤åç§°
    cluster_tag = next((t['Value'] for t in tags
                       if t['Key'].startswith('kubernetes.io/cluster/')), None)

    if not cluster_tag:
        return {'statusCode': 400, 'body': 'Not an EKS node'}

    # æŸ¥è¯¢ EKS é›†ç¾¤å…ƒæ•°æ®
    cluster = eks.describe_cluster(name=cluster_tag)
    cluster_tags = cluster['cluster'].get('tags', {})

    # åˆ›å»ºæˆæœ¬æ ‡ç­¾
    cost_tags = [
        {'Key': 'CostCenter', 'Value': cluster_tags.get('cost_center', 'unallocated')},
        {'Key': 'Environment', 'Value': cluster_tags.get('environment', 'unknown')},
        {'Key': 'Team', 'Value': cluster_tags.get('team', 'unassigned')},
        {'Key': 'ManagedBy', 'Value': 'karpenter'},
        {'Key': 'AutoTagged', 'Value': 'true'}
    ]

    # åº”ç”¨æ ‡ç­¾
    ec2.create_tags(Resources=[instance_id], Tags=cost_tags)

    return {
        'statusCode': 200,
        'body': json.dumps(f'Tagged instance {instance_id}')
    }
```

**EventBridge è§„åˆ™**

```json
{
  "source": ["aws.ec2"],
  "detail-type": ["EC2 Instance State-change Notification"],
  "detail": {
    "state": ["running"]
  }
}
```

#### ä½¿ç”¨ Policy as Code å¼ºåˆ¶æ ‡ç­¾

```yaml
# OPA/Gatekeeper ç­–ç•¥
apiVersion: templates.gatekeeper.sh/v1
kind: ConstraintTemplate
metadata:
  name: k8srequiredtags
spec:
  crd:
    spec:
      names:
        kind: K8sRequiredTags
      validation:
        openAPIV3Schema:
          type: object
          properties:
            tags:
              type: array
              items:
                type: string

  targets:
    - target: admission.k8s.gatekeeper.sh
      rego: |
        package k8srequiredtags

        violation[{"msg": msg}] {
          input.review.kind.kind == "Namespace"
          provided := {tag | input.review.object.metadata.labels[tag]}
          required := {tag | tag := input.parameters.tags[_]}
          missing := required - provided
          count(missing) > 0
          msg := sprintf("Namespace must have required tags: %v", [missing])
        }

---
apiVersion: constraints.gatekeeper.sh/v1beta1
kind: K8sRequiredTags
metadata:
  name: namespace-must-have-cost-tags
spec:
  match:
    kinds:
      - apiGroups: [""]
        kinds: ["Namespace"]
  parameters:
    tags:
      - "cost-center"
      - "team"
      - "environment"
```

### ç¬¬ 6 æ­¥ï¼šç›‘æ§å’Œå‘Šè­¦è®¾ç½®

#### Grafana æˆæœ¬ä»ªè¡¨æ¿

```yaml
# Prometheus è‡ªå®šä¹‰æŒ‡æ ‡
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-cost-rules
  namespace: monitoring
data:
  cost-rules.yml: |
    groups:
      - name: cost_efficiency
        interval: 5m
        rules:
          # æŒ‰å‘½åç©ºé—´çš„æ¯å°æ—¶æˆæœ¬
          - record: namespace:cost_per_hour:sum
            expr: |
              sum by (namespace) (
                label_replace(
                  kube_pod_container_resource_requests{resource="cpu"}
                  * on(node) group_left(label_node_kubernetes_io_instance_type)
                  kube_node_labels{label_node_kubernetes_io_instance_type!=""}
                  * on(label_node_kubernetes_io_instance_type)
                  aws_ec2_instance_type_cost_per_hour,
                  "namespace", "$1", "exported_namespace", "(.*)"
                )
              )

          # èµ„æºæ•ˆç‡
          - record: namespace:resource_efficiency:ratio
            expr: |
              sum by (namespace) (
                rate(container_cpu_usage_seconds_total[5m])
              ) / sum by (namespace) (
                kube_pod_container_resource_requests{resource="cpu"}
              )

          # æµªè´¹æˆæœ¬
          - record: namespace:wasted_cost_per_hour:sum
            expr: |
              namespace:cost_per_hour:sum
              * (1 - namespace:resource_efficiency:ratio)

---
# Grafana ä»ªè¡¨æ¿ JSONï¼ˆéƒ¨åˆ†ï¼‰
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-cost-dashboard
  namespace: monitoring
data:
  eks-cost-dashboard.json: |
    {
      "dashboard": {
        "title": "EKS Cost Analysis",
        "panels": [
          {
            "title": "Total Daily Cost Trend",
            "targets": [
              {
                "expr": "sum(namespace:cost_per_hour:sum) * 24"
              }
            ],
            "type": "graph"
          },
          {
            "title": "Top 10 Expensive Namespaces",
            "targets": [
              {
                "expr": "topk(10, sum by (namespace) (namespace:cost_per_hour:sum))"
              }
            ],
            "type": "table"
          },
          {
            "title": "Resource Efficiency by Namespace",
            "targets": [
              {
                "expr": "namespace:resource_efficiency:ratio"
              }
            ],
            "type": "bargauge"
          }
        ]
      }
    }
```

#### å¤šæ¸ é“å‘Šè­¦è®¾ç½®

```yaml
# AlertManager é…ç½®
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: monitoring
data:
  alertmanager.yml: |
    global:
      slack_api_url: 'https://hooks.slack.com/services/YOUR/WEBHOOK/URL'

    route:
      receiver: 'default'
      group_by: ['alertname', 'namespace']
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 4h

      routes:
        - match:
            severity: critical
          receiver: 'pagerduty-critical'

        - match:
            severity: warning
            alert_type: cost
          receiver: 'slack-cost-alerts'

    receivers:
      - name: 'default'
        slack_configs:
          - channel: '#platform-alerts'
            title: 'EKS Alert'
            text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'

      - name: 'slack-cost-alerts'
        slack_configs:
          - channel: '#finops-alerts'
            title: 'Cost Alert: {{ .GroupLabels.namespace }}'
            text: |
              {{ range .Alerts }}
              *Alert:* {{ .Labels.alertname }}
              *Namespace:* {{ .Labels.namespace }}
              *Current Cost:* ${{ .Annotations.current_cost }}/hour
              *Threshold:* ${{ .Annotations.threshold }}/hour
              *Recommendation:* {{ .Annotations.recommendation }}
              {{ end }}

      - name: 'pagerduty-critical'
        pagerduty_configs:
          - service_key: 'YOUR_PAGERDUTY_KEY'

---
# æˆæœ¬å‘Šè­¦è§„åˆ™
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: cost-alerts
  namespace: monitoring
spec:
  groups:
    - name: cost_thresholds
      interval: 5m
      rules:
        - alert: HighNamespaceCost
          expr: |
            namespace:cost_per_hour:sum > 50
          for: 1h
          labels:
            severity: warning
            alert_type: cost
          annotations:
            description: 'Namespace {{ $labels.namespace }} is costing ${{ $value }}/hour'
            current_cost: '{{ $value }}'
            threshold: '50'
            recommendation: 'Review resource requests and consider rightsizing'

        - alert: UnusualCostSpike
          expr: |
            (
              namespace:cost_per_hour:sum
              / namespace:cost_per_hour:sum offset 24h
            ) > 1.5
          for: 30m
          labels:
            severity: warning
            alert_type: cost
          annotations:
            description: 'Namespace {{ $labels.namespace }} cost increased by {{ $value | humanizePercentage }}'

        - alert: LowResourceEfficiency
          expr: |
            namespace:resource_efficiency:ratio < 0.3
          for: 2h
          labels:
            severity: info
            alert_type: efficiency
          annotations:
            description: 'Namespace {{ $labels.namespace }} has only {{ $value | humanizePercentage }} resource efficiency'
            recommendation: 'Reduce resource requests or increase actual usage'
```

### ç¬¬ 7 æ­¥ï¼šè‡ªåŠ¨åŒ–ä¼˜åŒ–

#### è‡ªåŠ¨åˆç†é…ç½®ç®¡é“

```python
# auto_rightsizing.py
import boto3
import kubernetes
from datetime import datetime, timedelta

def calculate_recommendations(namespace, days=7):
    """
    åˆ†æè¿‡å» 7 å¤©çš„å®é™…ä½¿ç”¨é‡å¹¶è®¡ç®—æ¨èèµ„æº
    """
    prom = PrometheusConnect(url="http://prometheus:9090")

    # å®é™… CPU ä½¿ç”¨é‡ï¼ˆP95ï¼‰
    cpu_query = f'''
        quantile_over_time(0.95,
            sum by (pod) (
                rate(container_cpu_usage_seconds_total{{namespace="{namespace}"}}[5m])
            )[{days}d:5m]
        )
    '''
    cpu_actual = prom.custom_query(query=cpu_query)

    # å®é™…å†…å­˜ä½¿ç”¨é‡ï¼ˆP95ï¼‰
    mem_query = f'''
        quantile_over_time(0.95,
            sum by (pod) (
                container_memory_working_set_bytes{{namespace="{namespace}"}}
            )[{days}d:5m]
        )
    '''
    mem_actual = prom.custom_query(query=mem_query)

    # å½“å‰è¯·æ±‚é‡
    k8s = kubernetes.client.CoreV1Api()
    pods = k8s.list_namespaced_pod(namespace)

    recommendations = []
    for pod in pods.items:
        pod_name = pod.metadata.name

        # å½“å‰ requests
        current_cpu = sum(float(c.resources.requests.get('cpu', '0').rstrip('m'))
                         for c in pod.spec.containers if c.resources.requests)
        current_mem = sum(parse_memory(c.resources.requests.get('memory', '0'))
                         for c in pod.spec.containers if c.resources.requests)

        # å®é™…ä½¿ç”¨é‡ï¼ˆP95 + 20% ç¼“å†²ï¼‰
        actual_cpu = next((float(m['value'][1]) for m in cpu_actual
                          if m['metric']['pod'] == pod_name), 0) * 1.2
        actual_mem = next((float(m['value'][1]) for m in mem_actual
                          if m['metric']['pod'] == pod_name), 0) * 1.2

        # è®¡ç®—æˆæœ¬èŠ‚çœ
        if current_cpu > actual_cpu * 1.5:  # è¿‡åº¦é…ç½® 50% ä»¥ä¸Š
            recommendations.append({
                'pod': pod_name,
                'namespace': namespace,
                'current_cpu': current_cpu,
                'recommended_cpu': int(actual_cpu),
                'current_memory': current_mem,
                'recommended_memory': int(actual_mem),
                'potential_savings_pct': ((current_cpu - actual_cpu) / current_cpu) * 100
            })

    return recommendations

def apply_recommendations(recommendations, dry_run=True):
    """
    å°†å»ºè®®åº”ç”¨åˆ°å®é™…éƒ¨ç½²ï¼ˆæ›´æ–° Deployment/StatefulSetï¼‰
    """
    apps_v1 = kubernetes.client.AppsV1Api()

    for rec in recommendations:
        namespace = rec['namespace']
        pod_name = rec['pod']

        # æŸ¥æ‰¾ Pod çš„æ‰€æœ‰è€…ï¼ˆDeployment/StatefulSetï¼‰
        core_v1 = kubernetes.client.CoreV1Api()
        pod = core_v1.read_namespaced_pod(pod_name, namespace)
        owner = pod.metadata.owner_references[0]

        if owner.kind == 'ReplicaSet':
            # æŸ¥æ‰¾ Deployment
            rs = apps_v1.read_namespaced_replica_set(owner.name, namespace)
            deploy_name = rs.metadata.owner_references[0].name

            # æ›´æ–° Deployment
            deploy = apps_v1.read_namespaced_deployment(deploy_name, namespace)

            for container in deploy.spec.template.spec.containers:
                container.resources.requests['cpu'] = f"{rec['recommended_cpu']}m"
                container.resources.requests['memory'] = f"{rec['recommended_memory']}Mi"

            if not dry_run:
                apps_v1.patch_namespaced_deployment(
                    deploy_name, namespace, deploy
                )
                print(f"âœ… Updated {deploy_name} in {namespace}")
            else:
                print(f"ğŸ” Would update {deploy_name}: CPU {rec['current_cpu']}m â†’ {rec['recommended_cpu']}m")

# æ‰§è¡Œ
if __name__ == '__main__':
    namespaces = ['backend-services', 'frontend', 'data-processing']

    for ns in namespaces:
        print(f"\nğŸ“Š Analyzing namespace: {ns}")
        recs = calculate_recommendations(ns)

        if recs:
            print(f"Found {len(recs)} optimization opportunities:")
            for r in recs:
                print(f"  - {r['pod']}: {r['potential_savings_pct']:.1f}% savings")

            apply_recommendations(recs, dry_run=False)
```

## éªŒè¯

### è¡¡é‡æˆæœ¬èŠ‚çœæ•ˆæœ

#### 1. å»ºç«‹åŸºå‡†

```bash
# è®°å½•ä¼˜åŒ–å‰çš„æœˆåº¦æˆæœ¬
aws ce get-cost-and-usage \
  --time-period Start=2025-01-01,End=2025-01-31 \
  --granularity MONTHLY \
  --metrics UnblendedCost \
  --filter file://eks-filter.json

# eks-filter.json
{
  "Tags": {
    "Key": "kubernetes.io/cluster/your-cluster",
    "Values": ["owned"]
  }
}
```

**åŸºå‡†æŒ‡æ ‡**

| æŒ‡æ ‡ | æµ‹é‡æ–¹æ³• | ç›®æ ‡ |
|------|----------|------|
| æœˆåº¦æ€»æˆæœ¬ | AWS Cost Explorer | -30% |
| CPU æ•ˆç‡ | å®é™…ä½¿ç”¨/è¯·æ±‚æ¯”ç‡ | 60% ä»¥ä¸Š |
| å†…å­˜æ•ˆç‡ | å®é™…ä½¿ç”¨/è¯·æ±‚æ¯”ç‡ | 70% ä»¥ä¸Š |
| Spot ä½¿ç”¨ç‡ | Spot èŠ‚ç‚¹/æ€»èŠ‚ç‚¹ | 50% ä»¥ä¸Š |
| æœªåˆ†é…æˆæœ¬ | æ— æ ‡ç­¾æˆæœ¬ | 5% ä»¥ä¸‹ |

#### 2. å‘¨åº¦è·Ÿè¸ª

```sql
-- Athena æŸ¥è¯¢ï¼šå‘¨åº¦æˆæœ¬è¶‹åŠ¿
SELECT
    DATE_TRUNC('week', line_item_usage_start_date) as week,
    SUM(line_item_unblended_cost) as weekly_cost,
    SUM(CASE WHEN line_item_usage_type LIKE '%SpotUsage%'
        THEN line_item_unblended_cost ELSE 0 END) as spot_cost,
    SUM(CASE WHEN line_item_usage_type LIKE '%SpotUsage%'
        THEN line_item_unblended_cost ELSE 0 END) / SUM(line_item_unblended_cost) * 100 as spot_percentage
FROM eks_cost_report
WHERE line_item_usage_start_date >= DATE_ADD('month', -3, CURRENT_DATE)
GROUP BY 1
ORDER BY 1 DESC;
```

#### 3. ROI è®¡ç®—

```python
# roi_calculator.py
def calculate_finops_roi(
    baseline_monthly_cost,
    current_monthly_cost,
    implementation_hours,
    avg_hourly_rate=100,
    tool_monthly_cost=0
):
    """
    è®¡ç®— FinOps æŠ•èµ„å›æŠ¥ç‡
    """
    # æœˆåº¦èŠ‚çœé¢
    monthly_savings = baseline_monthly_cost - current_monthly_cost

    # å®æ–½æˆæœ¬
    implementation_cost = implementation_hours * avg_hourly_rate

    # å‡€èŠ‚çœï¼ˆé¦–å¹´ï¼‰
    annual_savings = monthly_savings * 12
    annual_tool_cost = tool_monthly_cost * 12
    net_annual_savings = annual_savings - annual_tool_cost - implementation_cost

    # ROI
    roi_percentage = (net_annual_savings / implementation_cost) * 100

    # å›æ”¶æœŸ
    payback_months = implementation_cost / monthly_savings

    return {
        'monthly_savings': monthly_savings,
        'annual_savings': annual_savings,
        'implementation_cost': implementation_cost,
        'net_annual_savings': net_annual_savings,
        'roi_percentage': roi_percentage,
        'payback_months': payback_months
    }

# ç¤ºä¾‹
result = calculate_finops_roi(
    baseline_monthly_cost=50000,   # $50k/æœˆ
    current_monthly_cost=32000,    # $32k/æœˆï¼ˆèŠ‚çœ 36%ï¼‰
    implementation_hours=160,      # 1 ä¸ªæœˆå…¨èŒ
    tool_monthly_cost=500          # Kubecost ä¼ä¸šç‰ˆ
)

print(f"""
FinOps ROI åˆ†æ
--------------
æœˆåº¦èŠ‚çœï¼š${result['monthly_savings']:,.0f}
å¹´åº¦èŠ‚çœï¼š${result['annual_savings']:,.0f}
å®æ–½æˆæœ¬ï¼š${result['implementation_cost']:,.0f}
å‡€å¹´åº¦èŠ‚çœï¼š${result['net_annual_savings']:,.0f}
ROIï¼š{result['roi_percentage']:.0f}%
å›æ”¶æœŸï¼š{result['payback_months']:.1f} ä¸ªæœˆ
""")
```

#### 4. éªŒè¯æ£€æŸ¥æ¸…å•

**30 å¤©åéªŒè¯**

- [ ] æœˆåº¦æ€»æˆæœ¬å‡å°‘ 10-20%
- [ ] é€šè¿‡ Kubecost æˆ– SCAD è·å¾— Pod çº§åˆ«å¯è§æ€§
- [ ] æŒ‰å‘½åç©ºé—´åˆ†é…æˆæœ¬è¾¾åˆ° 70% ä»¥ä¸Š
- [ ] æˆæœ¬å‘Šè­¦æ­£å¸¸è¿ä½œ
- [ ] è¿›è¡Œè‡³å°‘ 1 æ¬¡å›¢é˜Ÿæœˆåº¦æˆæœ¬å®¡æŸ¥

**90 å¤©åéªŒè¯**

- [ ] æœˆåº¦æ€»æˆæœ¬å‡å°‘ 30-40%
- [ ] Karpenter éƒ¨ç½²å®Œæˆä¸”æ­£å¸¸è¿è¡Œ
- [ ] Spot å®ä¾‹æ¯”ç‡è¾¾åˆ° 50% ä»¥ä¸Š
- [ ] CPU æ•ˆç‡è¾¾åˆ° 60% ä»¥ä¸Š
- [ ] å†…å­˜æ•ˆç‡è¾¾åˆ° 70% ä»¥ä¸Š
- [ ] æœªåˆ†é…æˆæœ¬ä½äº 5%
- [ ] è¿è¡Œè‡ªåŠ¨åŒ–åˆç†é…ç½®ç­–ç•¥

**180 å¤©åéªŒè¯**

- [ ] æœˆåº¦æ€»æˆæœ¬å‡å°‘ 40-60%
- [ ] FinOps æˆç†Ÿåº¦è¾¾åˆ°"Walk"ä»¥ä¸Š
- [ ] å»ºç«‹è‡ªåŠ¨åŒ–ä¼˜åŒ–å·¥ä½œæµ
- [ ] å°†æˆæœ¬ä¸ä¸šåŠ¡æŒ‡æ ‡å…³è”
- [ ] è¾¾åˆ° 300% ä»¥ä¸Š ROI

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ³•

#### é—®é¢˜ 1ï¼šSCAD æ•°æ®æœªæ˜¾ç¤ºåœ¨ CUR ä¸­

**ç—‡çŠ¶**

```bash
# Athena æŸ¥è¯¢ç»“æœä¸ºç©º
SELECT * FROM eks_cost_report
WHERE split_line_item_split_cost IS NOT NULL
LIMIT 10;
# 0 rows returned
```

**åŸå› **

- SCAD å¯ç”¨å 24-48 å°æ—¶å»¶è¿Ÿ
- EKS é›†ç¾¤ä¸Šæœªå¯ç”¨ SCAD
- CUR ç¼ºå°‘ SPLIT_COST_ALLOCATION_DATA æ¶æ„å…ƒç´ 

**è§£å†³æ–¹æ³•**

```bash
# 1. ç¡®è®¤é›†ç¾¤ SCAD å¯ç”¨
aws eks describe-cluster --name your-cluster \
  --query 'cluster.resourcesVpcConfig.splitCostAllocationEnabled'

# 2. æ£€æŸ¥ CUR å®šä¹‰
aws cur describe-report-definitions \
  --query 'ReportDefinitions[?ReportName==`eks-cost-report`].AdditionalSchemaElements'

# 3. å¿…è¦æ—¶é‡æ–°å¯ç”¨
aws eks update-cluster-config \
  --name your-cluster \
  --resources-vpc-config splitCostAllocationEnabled=true
```

#### é—®é¢˜ 2ï¼šKarpenter æœªé…ç½®èŠ‚ç‚¹

**ç—‡çŠ¶**

```bash
kubectl get pods
# STATUS: Pendingï¼ˆæœªè°ƒåº¦ï¼‰

kubectl logs -n karpenter -l app.kubernetes.io/name=karpenter
# No suitable node class found
```

**åŸå› **

- NodePool è¦æ±‚ä¸å·¥ä½œè´Ÿè½½ä¸åŒ¹é…
- IAM æƒé™ä¸è¶³
- å­ç½‘/å®‰å…¨ç»„æ ‡ç­¾ç¼ºå¤±
- å®ä¾‹ç±»å‹å®¹é‡ä¸è¶³

**è§£å†³æ–¹æ³•**

```bash
# 1. æ¯”è¾ƒ NodePool å’Œ Pod è¦æ±‚
kubectl get nodepool default -o yaml
kubectl get pod <pending-pod> -o yaml | grep -A 10 "nodeSelector\|affinity\|tolerations"

# 2. æ£€æŸ¥ Karpenter æƒé™
aws iam get-role-policy \
  --role-name KarpenterControllerRole-your-cluster \
  --policy-name KarpenterControllerPolicy

# 3. æ£€æŸ¥å­ç½‘æ ‡ç­¾
aws ec2 describe-subnets \
  --filters "Name=tag:karpenter.sh/discovery,Values=your-cluster"

# 4. æ£€æŸ¥å®‰å…¨ç»„æ ‡ç­¾
aws ec2 describe-security-groups \
  --filters "Name=tag:karpenter.sh/discovery,Values=your-cluster"

# 5. æ£€æŸ¥ EC2 å®¹é‡
aws ec2 describe-instance-type-offerings \
  --location-type availability-zone \
  --filters "Name=instance-type,Values=m5.xlarge" \
  --region ap-northeast-2
```

**NodePool è°ƒè¯•**

```yaml
# ä½¿ç”¨å¹¿æ³›è¦æ±‚è¿›è¡Œæµ‹è¯•
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: debug-nodepool
spec:
  template:
    spec:
      requirements:
        - key: karpenter.sh/capacity-type
          operator: In
          values: ["on-demand"]  # æ’é™¤ Spot
        - key: kubernetes.io/arch
          operator: In
          values: ["amd64"]
        # æ— å®ä¾‹ç±»å‹é™åˆ¶
      nodeClassRef:
        name: default
```

#### é—®é¢˜ 3ï¼šKubecost æˆæœ¬å·®å¼‚å¤§

**ç—‡çŠ¶**

- Kubecost UI æˆæœ¬ä¸ AWS è´¦å•å·®å¼‚è¶…è¿‡ 20%
- ç‰¹å®šå‘½åç©ºé—´æˆæœ¬å¼‚å¸¸é«˜

**åŸå› **

- Prometheus æŒ‡æ ‡ç¼ºå¤±
- AWS Spot ä»·æ ¼æ•°æ®é”™è¯¯
- å…±äº«èµ„æºåˆ†é…æ–¹æ³•é”™è¯¯

**è§£å†³æ–¹æ³•**

```bash
# 1. æ£€æŸ¥ Prometheus æŒ‡æ ‡
kubectl port-forward -n kubecost svc/kubecost-prometheus-server 9090:80
# åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ http://localhost:9090
# æŸ¥è¯¢ï¼šup{job="kubecost-cost-model"}

# 2. éªŒè¯ Kubecost é…ç½®
kubectl get configmap -n kubecost kubecost-cost-analyzer -o yaml | grep -A 20 "kubecostProductConfigs"

# 3. é‡æ–°é…ç½® AWS é›†æˆ
cat > kubecost-aws-fix.yaml << 'EOF'
kubecostProductConfigs:
  awsSpotDataRegion: "ap-northeast-2"
  awsSpotDataBucket: "your-bucket"
  spotLabel: "karpenter.sh/capacity-type"
  spotLabelValue: "spot"

  # CUR é›†æˆ
  athenaProjectID: "your-project"
  athenaBucketName: "s3://your-athena-results"
  athenaRegion: "ap-northeast-2"
  athenaDatabase: "athenacurcfn_eks_cost_report"
  athenaTable: "eks_cost_report"
  athenaWorkgroup: "primary"
EOF

helm upgrade kubecost kubecost/cost-analyzer \
  -n kubecost \
  -f kubecost-aws-fix.yaml

# 4. å¼ºåˆ¶é‡æ–°è®¡ç®—æˆæœ¬
kubectl delete pod -n kubecost -l app=cost-model
```

#### é—®é¢˜ 4ï¼šSpot å®ä¾‹ä¸­æ–­å½±å“æœåŠ¡

**ç—‡çŠ¶**

- 2 åˆ†é’Ÿè­¦å‘Šå Pod çªç„¶ç»ˆæ­¢
- å¯ç”¨æ€§ä¸‹é™

**è§£å†³ç­–ç•¥**

```yaml
# 1. åŠ å¼º PodDisruptionBudget
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: critical-app-pdb
spec:
  minAvailable: 80%  # å§‹ç»ˆä¿æŒ 80% Pod
  selector:
    matchLabels:
      app: critical-app

---
# 2. ä½¿ç”¨å¤šæ ·åŒ– Spot æ± 
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: diversified-spot
spec:
  template:
    spec:
      requirements:
        - key: karpenter.sh/capacity-type
          operator: In
          values: ["spot"]
        - key: node.kubernetes.io/instance-type
          operator: In
          values:
            # 15+ å¤šæ ·åŒ–å®ä¾‹ç±»å‹
            - "c5.xlarge"
            - "c5.2xlarge"
            - "c5a.xlarge"
            - "c5a.2xlarge"
            - "c6i.xlarge"
            - "c6i.2xlarge"
            - "m5.xlarge"
            - "m5.2xlarge"
            - "m5a.xlarge"
            - "m5a.2xlarge"
            - "m6i.xlarge"
            - "m6i.2xlarge"
            - "r5.xlarge"
            - "r5a.xlarge"
            - "r6i.xlarge"

---
# 3. å®æ–½ä¼˜é›…å…³é—­
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spot-aware-app
spec:
  template:
    spec:
      containers:
        - name: app
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh", "-c", "sleep 120"]  # ç­‰å¾… 2 åˆ†é’Ÿ
          terminationGracePeriodSeconds: 130
```

**Spot ä¸­æ–­ç›‘æ§**

```bash
# å®‰è£… AWS Node Termination Handler
helm repo add eks https://aws.github.io/eks-charts
helm install aws-node-termination-handler \
  --namespace kube-system \
  eks/aws-node-termination-handler \
  --set enableSpotInterruptionDraining=true \
  --set enableScheduledEventDraining=true
```

#### é—®é¢˜ 5ï¼šæ•°æ®ä¼ è¾“æˆæœ¬é«˜

**ç—‡çŠ¶**

- AWS è´¦å•ä¸­æ•°æ®ä¼ è¾“æˆæœ¬é«˜äºé¢„æœŸ
- "DataTransfer-Regional-Bytes"é¡¹ç›®æ¿€å¢

**åŸå› **

- å¯ç”¨åŒºé—´ä¸å¿…è¦çš„æµé‡
- å‡ºç«™äº’è”ç½‘æµé‡æœªä¼˜åŒ–
- NAT ç½‘å…³è¿‡åº¦ä½¿ç”¨

**è§£å†³æ–¹æ³•**

```yaml
# 1. å¯ç”¨æ‹“æ‰‘æ„ŸçŸ¥è·¯ç”±
apiVersion: v1
kind: Service
metadata:
  name: backend-service
  annotations:
    service.kubernetes.io/topology-mode: Auto
spec:
  selector:
    app: backend
  ports:
    - port: 80
  # ä¼˜å…ˆåŒå¯ç”¨åŒºå†…æµé‡
  topologyKeys:
    - "topology.kubernetes.io/zone"
    - "kubernetes.io/hostname"
    - "*"

---
# 2. Karpenter å•å¯ç”¨åŒºæ•´åˆè®¾ç½®
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: single-az-consolidation
spec:
  disruption:
    consolidationPolicy: WhenUnderutilized
    consolidateAfter: 30s
  template:
    spec:
      requirements:
        # å°†å·¥ä½œè´Ÿè½½å›ºå®šåˆ°ç‰¹å®šå¯ç”¨åŒº
        - key: topology.kubernetes.io/zone
          operator: In
          values: ["ap-northeast-2a"]
```

**ä½¿ç”¨ VPC ç«¯ç‚¹**

```bash
# ä¸º S3ã€ECR ç­‰ AWS æœåŠ¡åˆ›å»º VPC ç«¯ç‚¹
aws ec2 create-vpc-endpoint \
  --vpc-id vpc-xxxxx \
  --service-name com.amazonaws.ap-northeast-2.s3 \
  --route-table-ids rtb-xxxxx

aws ec2 create-vpc-endpoint \
  --vpc-id vpc-xxxxx \
  --vpc-endpoint-type Interface \
  --service-name com.amazonaws.ap-northeast-2.ecr.dkr \
  --subnet-ids subnet-xxxxx subnet-yyyyy \
  --security-group-ids sg-xxxxx
```

## ç»“è®º

### æ ¸å¿ƒæ€»ç»“

æœ¬æŒ‡å—æ¶µç›–äº†åœ¨ EKS ç¯å¢ƒä¸­å®ç° 30-90% æˆæœ¬èŠ‚çœçš„å…¨é¢ç­–ç•¥ã€‚

**ç«‹å³å¯æ‰§è¡Œçš„ 10 é¡¹è¡ŒåŠ¨**

1. **åœ¨ AWS Cost Explorer ä¸­äº†è§£ EKS æˆæœ¬ç°çŠ¶**ï¼ˆ30 åˆ†é’Ÿï¼‰
2. **å¯ç”¨ SCAD è·å¾— Pod çº§åˆ«å¯è§æ€§**ï¼ˆ1 å°æ—¶ï¼‰
3. **å®‰è£… Kubecost å…è´¹ç‰ˆå¹¶æ£€æŸ¥ä»ªè¡¨æ¿**ï¼ˆ2 å°æ—¶ï¼‰
4. **å‘å‘½åç©ºé—´æ·»åŠ æˆæœ¬åˆ†é…æ ‡ç­¾**ï¼ˆ1 å°æ—¶ï¼‰
5. **è¯†åˆ«è¿‡åº¦é…ç½®çš„å·¥ä½œè´Ÿè½½å¹¶è°ƒæ•´å¤§å°**ï¼ˆ4 å°æ—¶ï¼‰
6. **é€‰æ‹©å¯ä½¿ç”¨ Spot å®ä¾‹çš„å·¥ä½œè´Ÿè½½**ï¼ˆ2 å°æ—¶ï¼‰
7. **éƒ¨ç½² 1 ä¸ª Karpenter NodePoolï¼ˆå¼€å‘ç¯å¢ƒï¼‰**ï¼ˆ4 å°æ—¶ï¼‰
8. **è®¾ç½®æˆæœ¬å‘Šè­¦ï¼ˆè¶…è¿‡é˜ˆå€¼æ—¶ï¼‰**ï¼ˆ1 å°æ—¶ï¼‰
9. **å»ºç«‹å‘¨åº¦æˆæœ¬å®¡æŸ¥ä¼šè®®**ï¼ˆ30 åˆ†é’Ÿï¼‰
10. **ç¼–å†™ 90 å¤©ä¼˜åŒ–è·¯çº¿å›¾**ï¼ˆ2 å°æ—¶ï¼‰

**é¢„æœŸèŠ‚çœæ—¶é—´è¡¨**

| æœŸé—´ | èŠ‚çœç‡ | ä¸»è¦æ´»åŠ¨ |
|------|--------|----------|
| **0-30 å¤©** | 10-20% | å»ºç«‹å¯è§æ€§å·¥å…·ï¼Œå¿«é€Ÿèƒœåˆ©ï¼ˆè°ƒæ•´å¤§å°ï¼‰ |
| **31-90 å¤©** | 30-40% | éƒ¨ç½² Karpenterï¼ŒSpot é›†æˆï¼Œè‡ªåŠ¨åŒ– |
| **91-180 å¤©** | 40-60% | é«˜çº§ä¼˜åŒ–ï¼Œæ–‡åŒ–å»ºç«‹ï¼ŒæŒç»­æ”¹è¿› |
| **180 å¤©+** | 60-90% | å®Œå…¨è‡ªåŠ¨åŒ–ï¼Œé¢„æµ‹åˆ†æï¼Œä¸šåŠ¡å¯¹é½ |

**æˆåŠŸå› ç´ **

- **é«˜ç®¡æ”¯æŒ**ï¼šå°† FinOps è§†ä¸ºæˆ˜ç•¥ä¸¾æª
- **ä¸“èŒå›¢é˜Ÿ**ï¼šè‡³å°‘ 1 åå…¨èŒ FinOps å·¥ç¨‹å¸ˆ
- **æ˜ç¡® KPI**ï¼šå¯è¡¡é‡çš„æˆæœ¬æ•ˆç‡ç›®æ ‡
- **æ–‡åŒ–å˜é©**ï¼šå°†æˆæœ¬æ„è¯†ä½œä¸ºå·¥ç¨‹å“è¶Šçš„ä¸€éƒ¨åˆ†
- **æŒç»­æ”¹è¿›**ï¼šå‘¨åº¦å®¡æŸ¥å’Œå­£åº¦æˆ˜ç•¥è°ƒæ•´

**è¦é¿å…çš„é™·é˜±**

- **æ— å¯è§æ€§å°±ä¼˜åŒ–**ï¼šä»æ•°æ®æ”¶é›†å¼€å§‹
- **è¿‡åº¦ä¼˜åŒ–**ï¼šä¸è¦ç‰ºç‰²ç¨³å®šæ€§
- **å·¥å…·è¿‡åº¦æŠ•èµ„**ï¼šé€‰æ‹©ä¸æˆç†Ÿåº¦åŒ¹é…çš„å·¥å…·
- **ä¸€æ¬¡æ€§é¡¹ç›®**ï¼šä½œä¸ºæŒç»­æµç¨‹è¿è¥
- **å›¢é˜Ÿå­¤ç«‹**ï¼šæ‰€æœ‰åˆ©ç›Šç›¸å…³è€…å‚ä¸

### å…¶ä»–å­¦ä¹ èµ„æº

**å®˜æ–¹æ–‡æ¡£**

- [AWS EKS æœ€ä½³å®è·µ - æˆæœ¬ä¼˜åŒ–](https://docs.aws.amazon.com/eks/latest/best-practices/cost-opt.html)
- [Karpenter æ–‡æ¡£](https://karpenter.sh/)
- [Kubecost æ¶æ„](https://docs.kubecost.com/)
- [FinOps åŸºé‡‘ä¼š](https://www.finops.org/framework/)

**å®æˆ˜æ¡ˆä¾‹**

- [AWS å®¹å™¨åšå®¢ - æˆæœ¬ä¼˜åŒ–](https://aws.amazon.com/blogs/containers/)
- [FinOps åŸºé‡‘ä¼š - è´¹ç‡ä¼˜åŒ–](https://www.finops.org/framework/capabilities/rate-optimization/)

**ç›¸å…³æ–‡æ¡£**

- [4. Karpenter è‡ªåŠ¨æ‰©ç¼©å®¹](./karpenter-autoscaling.md)
- [1. Gateway API é‡‡ç”¨æŒ‡å—](./gateway-api-adoption-guide/)
- [GitOps é›†ç¾¤è¿è¥](../operations-observability/gitops-cluster-operation.md)
- [æ··åˆèŠ‚ç‚¹æŒ‡å—](../hybrid-infrastructure/hybrid-nodes-adoption-guide.md)

**ç¤¾åŒº**

- [FinOps åŸºé‡‘ä¼š](https://www.finops.org/)
- [Karpenter Slack](https://kubernetes.slack.com/archives/C02SFFZSA2K)
- [AWS å®¹å™¨è·¯çº¿å›¾](https://github.com/aws/containers-roadmap)

---

**åé¦ˆå’Œè´¡çŒ®**

æœ‰å…³æœ¬æ–‡æ¡£çš„åé¦ˆæˆ–æ”¹è¿›å»ºè®®ï¼Œè¯·åœ¨ [GitHub Issues](https://github.com/devfloor9/engineering-playbook/issues) ä¸­æäº¤ã€‚

**æ–‡æ¡£ç‰ˆæœ¬**ï¼šv2.0ï¼ˆ2025-02-05ï¼‰
**ä¸‹æ¬¡å®¡æŸ¥**ï¼š2025-05-05
