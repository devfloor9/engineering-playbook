---
title: "é¢„æµ‹æ€§æ‰©å±•å’Œè‡ªåŠ¨ä¿®å¤æ¨¡å¼"
sidebar_label: "é¢„æµ‹æ€§æ‰©å±•ä¸è‡ªåŠ¨ä¿®å¤"
description: "åŸºäº ML çš„é¢„æµ‹æ€§è‡ªåŠ¨æ‰©å±•ã€Karpenter+AI ä¸»åŠ¨é…ç½®ã€AI Agent è‡ªä¸»äº‹ä»¶å“åº”ã€Kiro ç¨‹åºåŒ–è°ƒè¯•æ¨¡å¼"
sidebar_position: 7
category: "aiops-aidlc"
tags: [aiops, predictive-scaling, auto-remediation, karpenter, self-healing, eks, kiro, mcp, ai-agent, chaos-engineering]
last_update:
  date: 2026-02-12
  author: devfloor9
---

import { ScalingComparison, ResponsePatterns, MaturityTable, EvolutionStages, MLModelComparison, AnomalyMetrics, RightSizingResults, ChaosExperiments, DashboardPanels } from '@site/src/components/PredictiveOpsTables';

# é¢„æµ‹æ€§æ‰©å±•å’Œè‡ªåŠ¨ä¿®å¤æ¨¡å¼

> ğŸ“… **æ’°å†™æ—¥æœŸ**: 2026-02-12 | â±ï¸ **é˜…è¯»æ—¶é—´**: çº¦ 30 åˆ†é’Ÿ | ğŸ“Œ **å‚è€ƒç¯å¢ƒ**: EKS 1.35+, Karpenter v1.1+, CloudWatch, Kiro

---

## 1. æ¦‚è¿°

### 1.1 ä»å“åº”å¼åˆ°è‡ªä¸»å¼

EKS è¿ç»´çš„æ¼”è¿›éµå¾ªä¸‰ä¸ªé˜¶æ®µ:**å“åº”å¼ â†’ é¢„æµ‹å¼ â†’ è‡ªä¸»å¼**ã€‚

<EvolutionStages />

:::info æœ¬æ–‡æ¡£èŒƒå›´
è¶…è¶Šå“åº”å¼æ‰©å±•çš„å±€é™æ€§,æœ¬æ–‡æ¡£æ¶µç›–åŸºäº ML çš„é¢„æµ‹æ€§æ‰©å±•å’Œé€šè¿‡ AI Agents çš„è‡ªä¸»æ¢å¤æ¨¡å¼ã€‚å®ƒç‰¹åˆ«å…³æ³¨ä½¿ç”¨ Kiro+MCP çš„**ç¨‹åºåŒ–è°ƒè¯•**å’Œä½¿ç”¨ Kagent/Strands çš„**è‡ªåŠ¨äº‹ä»¶å“åº”**ã€‚
:::

### 1.2 ä¸ºä»€ä¹ˆéœ€è¦é¢„æµ‹æ€§è¿ç»´

- **HPA å±€é™æ€§**: åœ¨æŒ‡æ ‡è¶…è¿‡é˜ˆå€¼åæ‰å“åº” â†’ ç”¨æˆ·å½±å“å·²ç»å‘ç”Ÿ
- **å†·å¯åŠ¨é—®é¢˜**: æ–° Pod å¯åŠ¨éœ€è¦ 30 ç§’-2 åˆ†é’Ÿ â†’ æ— æ³•å¤„ç†æµé‡å³°å€¼
- **èŠ‚ç‚¹é…ç½®å»¶è¿Ÿ**: å³ä½¿æ˜¯ Karpenter ä¹Ÿéœ€è¦ 1-3 åˆ†é’Ÿå¯åŠ¨èŠ‚ç‚¹
- **å¤æ‚æ•…éšœ**: å•ä¸€æŒ‡æ ‡æ— æ³•æ£€æµ‹åˆ°çš„å¤åˆåŸå› æ•…éšœè¶Šæ¥è¶Šå¤š
- **æˆæœ¬æ•ˆç‡ä½ä¸‹**: è¿‡åº¦çš„èµ„æºç¼“å†² â†’ æµªè´¹æˆæœ¬

---

## 2. åŸºäº ML çš„é¢„æµ‹æ€§æ‰©å±•

### 2.1 HPA å±€é™æ€§

HPA (Horizontal Pod Autoscaler) å› ä¸ºå“åº”**å½“å‰æŒ‡æ ‡**è€Œå­˜åœ¨ç»“æ„æ€§å±€é™ã€‚

<ScalingComparison />

```
[HPA å“åº”å¼æ‰©å±•]

æµé‡ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘
                      â†‘ è¶…è¿‡é˜ˆå€¼
                      |
Pod æ•°é‡ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
                  â†‘ å¼€å§‹æ‰©å®¹
                  |  (å‘ç”Ÿå»¶è¿Ÿ)
ç”¨æˆ·ä½“éªŒ âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ—âœ—âœ—âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“
               â†‘ æ€§èƒ½ä¸‹é™æœŸ

[ML é¢„æµ‹æ€§æ‰©å±•]

æµé‡ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘
             â†‘ é¢„æµ‹ç‚¹ (æå‰ 30 åˆ†é’Ÿ)
             |
Pod æ•°é‡ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
             â†‘ é¢„å…ˆæ‰©å®¹
             |
ç”¨æˆ·ä½“éªŒ âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“âœ“
         (æ— æ€§èƒ½ä¸‹é™)
```

### 2.2 æ—¶é—´åºåˆ—é¢„æµ‹æ¨¡å‹

ç”¨äºé¢„æµ‹ EKS å·¥ä½œè´Ÿè½½æµé‡æ¨¡å¼çš„ä»£è¡¨æ€§ ML æ¨¡å‹:

<MLModelComparison />

### 2.3 åŸºäº Prophet çš„é¢„æµ‹æ€§æ‰©å±•å®ç°

```python
# åŸºäº Prophet çš„ EKS æµé‡é¢„æµ‹
import boto3
from prophet import Prophet
import pandas as pd
from datetime import datetime, timedelta

def fetch_metrics_from_amp(workspace_id, query, hours=168):
    """ä» AMP æŸ¥è¯¢æœ€è¿‘ 7 å¤©çš„æŒ‡æ ‡"""
    client = boto3.client('amp', region_name='ap-northeast-2')
    end_time = datetime.utcnow()
    start_time = end_time - timedelta(hours=hours)

    response = client.query_range(
        workspaceId=workspace_id,
        query=query,
        startTime=start_time,
        endTime=end_time,
        step='5m'
    )
    return response

def predict_scaling(metrics_df, forecast_hours=2):
    """ä½¿ç”¨ Prophet é¢„æµ‹æœªæ¥æµé‡"""
    # è½¬æ¢ä¸º Prophet æ ¼å¼
    df = metrics_df.rename(columns={
        'timestamp': 'ds',
        'value': 'y'
    })

    model = Prophet(
        changepoint_prior_scale=0.05,
        seasonality_mode='multiplicative',
        daily_seasonality=True,
        weekly_seasonality=True,
    )
    model.fit(df)

    # é¢„æµ‹æ¥ä¸‹æ¥çš„ forecast_hours
    future = model.make_future_dataframe(
        periods=forecast_hours * 12,  # 5 åˆ†é’Ÿé—´éš”
        freq='5min'
    )
    forecast = model.predict(future)

    return forecast[['ds', 'yhat', 'yhat_upper', 'yhat_lower']]

def calculate_required_pods(predicted_rps, pod_capacity_rps=100):
    """æ ¹æ®é¢„æµ‹çš„ RPS è®¡ç®—æ‰€éœ€çš„ Pod æ•°é‡"""
    # ä½¿ç”¨ä¸Šç•Œ (yhat_upper) ä½œä¸ºå®‰å…¨è¾¹é™…
    required = int(predicted_rps / pod_capacity_rps) + 1
    return max(required, 2)  # ä¿æŒæœ€å°å€¼ä¸º 2

def apply_scaling(namespace, deployment, target_replicas):
    """é€šè¿‡ kubectl åº”ç”¨æ‰©å±•"""
    import subprocess
    cmd = f"kubectl scale deployment/{deployment} -n {namespace} --replicas={target_replicas}"
    subprocess.run(cmd.split(), check=True)
    print(f"Scaled {deployment} to {target_replicas} replicas")
```

### 2.4 åŸºäº CronJob çš„é¢„æµ‹æ€§æ‰©å±•è‡ªåŠ¨åŒ–

```yaml
# å®šæœŸæ‰§è¡Œé¢„æµ‹æ€§æ‰©å±•çš„ CronJob
apiVersion: batch/v1
kind: CronJob
metadata:
  name: predictive-scaler
  namespace: scaling
spec:
  schedule: "*/15 * * * *"  # æ¯ 15 åˆ†é’Ÿè¿è¡Œä¸€æ¬¡
  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: predictive-scaler
          containers:
            - name: scaler
              image: my-registry/predictive-scaler:latest
              env:
                - name: AMP_WORKSPACE_ID
                  value: "ws-xxxxx"
                - name: TARGET_NAMESPACE
                  value: "payment"
                - name: TARGET_DEPLOYMENT
                  value: "payment-service"
                - name: FORECAST_HOURS
                  value: "2"
              resources:
                requests:
                  cpu: 500m
                  memory: 1Gi
                limits:
                  cpu: "1"
                  memory: 2Gi
          restartPolicy: OnFailure
```

---

## 3. Karpenter + AI é¢„æµ‹

### 3.1 Karpenter åŸºæœ¬æ“ä½œ

Karpenter æ£€æµ‹ Pending Pods å¹¶**è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„å®ä¾‹ç±»å‹**è¿›è¡Œé…ç½®ã€‚

```yaml
# Karpenter NodePool é…ç½®
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: default
spec:
  template:
    spec:
      requirements:
        - key: kubernetes.io/arch
          operator: In
          values: ["amd64", "arm64"]
        - key: karpenter.sh/capacity-type
          operator: In
          values: ["on-demand", "spot"]
        - key: karpenter.k8s.aws/instance-family
          operator: In
          values: ["m7g", "m7i", "c7g", "c7i", "r7g"]
        - key: karpenter.k8s.aws/instance-size
          operator: In
          values: ["medium", "large", "xlarge", "2xlarge"]
      nodeClassRef:
        group: karpenter.k8s.aws
        kind: EC2NodeClass
        name: default
  limits:
    cpu: "100"
    memory: 400Gi
  disruption:
    consolidationPolicy: WhenEmptyOrUnderutilized
    consolidateAfter: 30s
---
apiVersion: karpenter.k8s.aws/v1
kind: EC2NodeClass
metadata:
  name: default
spec:
  role: KarpenterNodeRole
  amiSelectorTerms:
    - alias: al2023@latest
  subnetSelectorTerms:
    - tags:
        karpenter.sh/discovery: my-cluster
  securityGroupSelectorTerms:
    - tags:
        karpenter.sh/discovery: my-cluster
  blockDeviceMappings:
    - deviceName: /dev/xvda
      ebs:
        volumeSize: 100Gi
        volumeType: gp3
        iops: 3000
        throughput: 125
```

### 3.2 åŸºäº AI é¢„æµ‹çš„ä¸»åŠ¨é…ç½®

è™½ç„¶ Karpenter æœ¬èº«å“åº” Pending Pods,ä½†**å°†å…¶ä¸ AI é¢„æµ‹ç»“åˆ**å¯ä»¥å®ç°ä¸»åŠ¨èŠ‚ç‚¹é…ç½®ã€‚

```mermaid
graph TD
    subgraph Prediction["ğŸ§  é¢„æµ‹å±‚"]
        CW_M["CloudWatch<br/>æŒ‡æ ‡"]
        ML["ML æ¨¡å‹<br/>(Prophet/ARIMA)"]
        PRED["æµé‡<br/>é¢„æµ‹ç»“æœ"]
    end

    subgraph Preemptive["âš¡ ä¸»åŠ¨è¡ŒåŠ¨"]
        WARM["Warm Pool<br/>Pod åˆ›å»º"]
        PAUSE["Pause<br/>å®¹å™¨"]
        KARP["Karpenter<br/>èŠ‚ç‚¹é…ç½®"]
    end

    subgraph Runtime["ğŸš€ å®é™…æµé‡"]
        TRAFFIC["æµé‡<br/>æ¶Œå…¥"]
        HPA2["HPA<br/>ç«‹å³æ‰©å±•"]
        READY["Pod<br/>ç«‹å³æœåŠ¡"]
    end

    CW_M --> ML --> PRED
    PRED --> WARM --> KARP
    PRED --> PAUSE --> KARP
    TRAFFIC --> HPA2 --> READY
    KARP -.->|èŠ‚ç‚¹å°±ç»ª| READY
```

**ä¸»åŠ¨é…ç½®ç­–ç•¥**:

```yaml
# å ä½ Pod ä¸»åŠ¨ç¡®ä¿èŠ‚ç‚¹
apiVersion: apps/v1
kind: Deployment
metadata:
  name: capacity-reservation
  namespace: scaling
spec:
  replicas: 0  # ç”±é¢„æµ‹æ€§æ‰©å±•å™¨åŠ¨æ€è°ƒæ•´
  selector:
    matchLabels:
      app: capacity-reservation
  template:
    metadata:
      labels:
        app: capacity-reservation
    spec:
      priorityClassName: capacity-reservation  # ä½ä¼˜å…ˆçº§
      terminationGracePeriodSeconds: 0
      containers:
        - name: pause
          image: registry.k8s.io/pause:3.9
          resources:
            requests:
              cpu: "1"
              memory: 2Gi
---
# ä½ä¼˜å…ˆçº§ç±» (è¢«å®é™…å·¥ä½œè´Ÿè½½é©±é€)
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: capacity-reservation
value: -10
globalDefault: false
description: "ç”¨äº Karpenter ä¸»åŠ¨èŠ‚ç‚¹é…ç½®"
```

:::tip ä¸»åŠ¨é…ç½®åŸç†

1. ML æ¨¡å‹é¢„æµ‹ 30 åˆ†é’Ÿåæµé‡å¢åŠ 
2. å¢åŠ å ä½ Pod çš„å‰¯æœ¬(pause å®¹å™¨)
3. Karpenter æ£€æµ‹ Pending Pods å¹¶é…ç½®èŠ‚ç‚¹
4. å½“å®é™…æµé‡åˆ°è¾¾æ—¶,HPA åˆ›å»ºçœŸå® Pods
5. å ä½ Pods ç”±äºä½ä¼˜å…ˆçº§ç«‹å³è¢«é©±é€
6. ç”±äºèŠ‚ç‚¹å·²å°±ç»ª,Pods ç«‹å³è°ƒåº¦
:::

---

## 4. CloudWatch å¼‚å¸¸æ£€æµ‹

### 4.1 å¼‚å¸¸æ£€æµ‹å¸¦

CloudWatch å¼‚å¸¸æ£€æµ‹ä½¿ç”¨ ML è‡ªåŠ¨å­¦ä¹ æŒ‡æ ‡çš„**æ­£å¸¸èŒƒå›´å¸¦**å¹¶æ£€æµ‹è¿™äº›å¸¦ä¹‹å¤–çš„å¼‚å¸¸ã€‚

```bash
# åˆ›å»ºå¼‚å¸¸æ£€æµ‹æ¨¡å‹
aws cloudwatch put-anomaly-detector \
  --namespace "ContainerInsights" \
  --metric-name "pod_cpu_utilization" \
  --dimensions Name=ClusterName,Value=my-cluster \
  --stat "Average" \
  --configuration '{
    "ExcludedTimeRanges": [
      {
        "StartTime": "2026-01-01T00:00:00Z",
        "EndTime": "2026-01-02T00:00:00Z"
      }
    ],
    "MetricTimezone": "Asia/Seoul"
  }'
```

### 4.2 EKS æŒ‡æ ‡åº”ç”¨

åº”ç”¨å¼‚å¸¸æ£€æµ‹çš„æ ¸å¿ƒ EKS æŒ‡æ ‡:

<AnomalyMetrics />

### 4.3 åŸºäºå¼‚å¸¸æ£€æµ‹çš„å‘Šè­¦

```bash
# åŸºäºå¼‚å¸¸æ£€æµ‹çš„ CloudWatch å‘Šè­¦
aws cloudwatch put-metric-alarm \
  --alarm-name "EKS-CPU-Anomaly" \
  --comparison-operator GreaterThanUpperThreshold \
  --threshold-metric-id ad1 \
  --evaluation-periods 3 \
  --datapoints-to-alarm 2 \
  --metrics '[
    {
      "Id": "m1",
      "MetricStat": {
        "Metric": {
          "Namespace": "ContainerInsights",
          "MetricName": "pod_cpu_utilization",
          "Dimensions": [
            {"Name": "ClusterName", "Value": "my-cluster"}
          ]
        },
        "Period": 300,
        "Stat": "Average"
      }
    },
    {
      "Id": "ad1",
      "Expression": "ANOMALY_DETECTION_BAND(m1, 2)"
    }
  ]' \
  --alarm-actions "arn:aws:sns:ap-northeast-2:ACCOUNT_ID:ops-alerts"
```

---

## 5. AI Agent è‡ªåŠ¨äº‹ä»¶å“åº”

### 5.1 ä¼ ç»Ÿè‡ªåŠ¨åŒ–çš„å±€é™æ€§

åŸºäº EventBridge + Lambda çš„è‡ªåŠ¨åŒ–æ˜¯**åŸºäºè§„åˆ™çš„**å¹¶ä¸”æœ‰å±€é™æ€§:

```
[ä¼ ç»Ÿæ–¹æ³•: åŸºäºè§„åˆ™çš„è‡ªåŠ¨åŒ–]
CloudWatch å‘Šè­¦ â†’ EventBridge è§„åˆ™ â†’ Lambda â†’ å›ºå®šæ“ä½œ

é—®é¢˜:
  âœ— "CPU > 80% æ—¶æ‰©å±•" â€” æ ¹æœ¬åŸå› å¯èƒ½æ˜¯å†…å­˜æ³„æ¼
  âœ— "Pod é‡å¯ > 5 æ¬¡æ—¶å‘Šè­¦" â€” ä¸åŒåŸå› éœ€è¦ä¸åŒå“åº”
  âœ— æ— æ³•å¤„ç†å¤æ‚æ•…éšœ
  âœ— æ— æ³•é€‚åº”æ–°æ¨¡å¼
```

### 5.2 åŸºäº AI Agent çš„è‡ªä¸»å“åº”

<ResponsePatterns />

AI Agents é€šè¿‡**åŸºäºä¸Šä¸‹æ–‡çš„åˆ¤æ–­**è‡ªä¸»å“åº”ã€‚

```mermaid
graph TD
    subgraph Trigger["ğŸ”” è§¦å‘å™¨"]
        CWA["CloudWatch<br/>å‘Šè­¦"]
        DGA["DevOps Guru<br/>æ´å¯Ÿ"]
        K8SE["K8s<br/>äº‹ä»¶"]
    end

    subgraph Agent["ğŸ¤– AI Agent"]
        COLLECT["æ•°æ®æ”¶é›†<br/>(MCP é›†æˆ)"]
        ANALYZE["AI åˆ†æ<br/>(æ ¹æœ¬åŸå› )"]
        DECIDE["å†³ç­–<br/>(è‡ªåŠ¨/æ‰‹åŠ¨)"]
        ACT["æ‰§è¡Œ<br/>(å®‰å…¨æ“ä½œ)"]
        REPORT["æŠ¥å‘Š<br/>(Slack/Jira)"]
    end

    subgraph Actions["âš¡ å“åº”æ“ä½œ"]
        SCALE["æ‰©å±•<br/>è°ƒæ•´"]
        RESTART["Pod<br/>é‡å¯"]
        ROLLBACK["éƒ¨ç½²<br/>å›æ»š"]
        ESCALATE["å‡çº§åˆ°<br/>äººå·¥"]
    end

    CWA --> COLLECT
    DGA --> COLLECT
    K8SE --> COLLECT
    COLLECT --> ANALYZE --> DECIDE
    DECIDE --> ACT --> REPORT
    ACT --> SCALE
    ACT --> RESTART
    ACT --> ROLLBACK
    ACT --> ESCALATE
```

### 5.3 Kagent è‡ªåŠ¨äº‹ä»¶å“åº”

```yaml
# Kagent: è‡ªåŠ¨äº‹ä»¶å“åº”ä»£ç†
apiVersion: kagent.dev/v1alpha1
kind: Agent
metadata:
  name: incident-responder
  namespace: kagent-system
spec:
  description: "EKS äº‹ä»¶è‡ªåŠ¨å“åº”ä»£ç†"
  modelConfig:
    provider: bedrock
    model: anthropic.claude-sonnet
    region: ap-northeast-2
  systemPrompt: |
    æ‚¨æ˜¯ä¸€ä¸ª EKS äº‹ä»¶å“åº”ä»£ç†ã€‚

    ## å“åº”åŸåˆ™
    1. å®‰å…¨ç¬¬ä¸€: å°†é£é™©å˜æ›´å‡çº§ç»™äººå·¥
    2. æ ¹æœ¬åŸå› ä¼˜å…ˆ: å¤„ç†åŸå› ,è€Œéç—‡çŠ¶
    3. æœ€å°å¹²é¢„: ä»…æ‰§è¡Œå¿…è¦çš„æ“ä½œ
    4. è®°å½•æ‰€æœ‰æ“ä½œ: è‡ªåŠ¨å‘ Slack å’Œ JIRA æŠ¥å‘Š

    ## å…è®¸çš„è‡ªåŠ¨æ“ä½œ
    - Pod é‡å¯ (CrashLoopBackOff, 5+ æ¬¡)
    - HPA min/max è°ƒæ•´ (å½“å‰å€¼çš„ Â±50%)
    - éƒ¨ç½²å›æ»š (åˆ°å…ˆå‰ç‰ˆæœ¬)
    - èŠ‚ç‚¹æ’ç©º (MemoryPressure/DiskPressure)

    ## å‡çº§ç›®æ ‡
    - å¯èƒ½å¯¼è‡´æ•°æ®ä¸¢å¤±çš„æ“ä½œ
    - å½±å“ 50%+ å‰¯æœ¬çš„æ›´æ”¹
    - StatefulSet ç›¸å…³æ›´æ”¹
    - ç½‘ç»œç­–ç•¥æ›´æ”¹

  tools:
    - name: kubectl
      type: kmcp
      config:
        allowedVerbs: ["get", "describe", "logs", "top", "rollout", "scale", "delete"]
        deniedResources: ["secrets", "configmaps"]
    - name: cloudwatch
      type: kmcp
      config:
        actions: ["GetMetricData", "DescribeAlarms", "GetInsight"]
    - name: slack
      type: mcp
      config:
        webhook_url: "${SLACK_WEBHOOK}"
        channel: "#incidents"

  triggers:
    - type: cloudwatch-alarm
      filter:
        severity: ["CRITICAL", "HIGH"]
    - type: kubernetes-event
      filter:
        reason: ["CrashLoopBackOff", "OOMKilled", "FailedScheduling"]
```

### 5.4 Strands Agent SOP: å¤æ‚æ•…éšœå“åº”

```python
# Strands Agent: å¤æ‚æ•…éšœè‡ªåŠ¨å“åº”
from strands import Agent
from strands.tools import eks_tool, cloudwatch_tool, slack_tool, jira_tool

incident_agent = Agent(
    name="complex-incident-handler",
    model="bedrock/anthropic.claude-sonnet",
    tools=[eks_tool, cloudwatch_tool, slack_tool, jira_tool],
    sop="""
    ## å¤æ‚æ•…éšœå“åº” SOP

    ### é˜¶æ®µ 1: æƒ…å†µè¯„ä¼° (30 ç§’å†…)
    1. æŸ¥è¯¢ CloudWatch å‘Šè­¦å’Œ DevOps Guru æ´å¯Ÿ
    2. æ£€æŸ¥ç›¸å…³æœåŠ¡çš„ Pod çŠ¶æ€
    3. æ£€æŸ¥èŠ‚ç‚¹çŠ¶æ€å’Œèµ„æºåˆ©ç”¨ç‡
    4. å®¡æŸ¥æœ€è¿‘çš„éƒ¨ç½²å†å² (10 åˆ†é’Ÿå†…çš„æ›´æ”¹)

    ### é˜¶æ®µ 2: æ ¹æœ¬åŸå› åˆ†æ (2 åˆ†é’Ÿå†…)
    1. ä»æ—¥å¿—ä¸­æå–é”™è¯¯æ¨¡å¼
    2. æŒ‡æ ‡ç›¸å…³æ€§åˆ†æ (CPU, Memory, Network, Disk)
    3. åˆ†æä¸éƒ¨ç½²æ›´æ”¹çš„æ—¶é—´ç›¸å…³æ€§
    4. æ£€æŸ¥ä¾èµ–æœåŠ¡çŠ¶æ€

    ### é˜¶æ®µ 3: è‡ªåŠ¨å“åº”
    æŒ‰æ ¹æœ¬åŸå› åˆ†ç±»çš„æ“ä½œ:

    **éƒ¨ç½²ç›¸å…³æ•…éšœ:**
    - å¦‚æœ 10 åˆ†é’Ÿå†…æœ‰éƒ¨ç½² â†’ è‡ªåŠ¨å›æ»š
    - å›æ»šåæ£€æŸ¥çŠ¶æ€ â†’ å¦‚æœæ¢å¤æ­£å¸¸åˆ™å®Œæˆ

    **èµ„æºçŸ­ç¼º:**
    - CPU/Memory > 90% â†’ è°ƒæ•´ HPA æˆ–æ·»åŠ  Karpenter èŠ‚ç‚¹
    - Disk > 85% â†’ æ¸…ç†ä¸å¿…è¦çš„æ—¥å¿—/é•œåƒ

    **ä¾èµ–æœåŠ¡æ•…éšœ:**
    - RDS è¿æ¥å¤±è´¥ â†’ æ£€æŸ¥è¿æ¥æ± è®¾ç½®,å¿…è¦æ—¶é‡å¯
    - SQS å»¶è¿Ÿ â†’ æ£€æŸ¥ DLQ,æ‰©å±•æ¶ˆè´¹è€…

    **æœªçŸ¥åŸå› :**
    - å‡çº§ç»™äººå·¥
    - åœ¨ Slack ä¸Šåˆ†äº«æ‰€æœ‰æ”¶é›†çš„æ•°æ®

    ### é˜¶æ®µ 4: åå¤„ç†
    1. ç”Ÿæˆäº‹ä»¶æ—¶é—´çº¿
    2. åˆ›å»º JIRA äº‹ä»¶å·¥å•
    3. å‘ Slack #incidents é¢‘é“å‘å¸ƒæŠ¥å‘Š
    4. ä¿å­˜ä¸ºå­¦ä¹ æ•°æ® (åé¦ˆå¾ªç¯)
    """
)
```

:::info AI Agents çš„æ ¸å¿ƒä»·å€¼
è¶…è¶Š EventBridge+Lambda,åŸºäº AI ä¸Šä¸‹æ–‡çš„è‡ªä¸»å“åº”æˆä¸ºå¯èƒ½ã€‚é€šè¿‡**é€šè¿‡ MCP é›†æˆæŸ¥è¯¢å„ç§æ•°æ®æº**(CloudWatchã€EKS APIã€X-Rayã€éƒ¨ç½²å†å²),AI å¯ä»¥åˆ†æè§„åˆ™æ— æ³•å¤„ç†çš„å¤æ‚æ•…éšœçš„æ ¹æœ¬åŸå› å¹¶è‡ªåŠ¨æ‰§è¡Œé€‚å½“çš„æ“ä½œã€‚
:::

---

## 6. Kiro ç¨‹åºåŒ–è°ƒè¯•

### 6.1 æŒ‡ä»¤å¼ vs ç¨‹åºåŒ–å“åº”æ¯”è¾ƒ

```
[æŒ‡ä»¤å¼å“åº”] â€” æ‰‹åŠ¨ã€é‡å¤ã€é«˜æˆæœ¬
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  æ“ä½œå‘˜: "payment-service 500 é”™è¯¯å‘ç”Ÿ"
  AI:       "å‘ç”Ÿåœ¨å“ªä¸ª Pod?"
  æ“ä½œå‘˜: "payment-xxx Pod"
  AI:       "è¯·æ˜¾ç¤ºæ—¥å¿—"
  æ“ä½œå‘˜: (æ‰§è¡Œ kubectl logs å¹¶å¤åˆ¶ç²˜è´´)
  AI:       "çœ‹èµ·æ¥åƒ DB è¿æ¥é”™è¯¯ã€‚è¯·æ£€æŸ¥ RDS çŠ¶æ€"
  æ“ä½œå‘˜: (åœ¨ AWS æ§åˆ¶å°æ£€æŸ¥ RDS)
  ...é‡å¤...

  æ€»æ—¶é—´: 15-30 åˆ†é’Ÿ,å¤šä¸ªæ‰‹åŠ¨ä»»åŠ¡

[ç¨‹åºåŒ–å“åº”] â€” è‡ªåŠ¨åŒ–ã€ç³»ç»ŸåŒ–ã€æˆæœ¬é«˜æ•ˆ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  å‘Šè­¦: "payment-service 500 é”™è¯¯å‘ç”Ÿ"

  Kiro è§„æ ¼:
    1. é€šè¿‡ EKS MCP æŸ¥è¯¢ Pod çŠ¶æ€
    2. æ”¶é›†å¹¶åˆ†æé”™è¯¯æ—¥å¿—
    3. æ£€æŸ¥ç›¸å…³ AWS æœåŠ¡ (RDS, SQS) çŠ¶æ€
    4. è¯Šæ–­æ ¹æœ¬åŸå› 
    5. ç”Ÿæˆè‡ªåŠ¨ä¿®å¤ä»£ç 
    6. åˆ›å»º PR å¹¶éªŒè¯

  æ€»æ—¶é—´: 2-5 åˆ†é’Ÿ,è‡ªåŠ¨åŒ–
```

### 6.2 Kiro + MCP è°ƒè¯•å·¥ä½œæµ

```mermaid
graph TD
    subgraph Trigger2["ğŸ”” é—®é¢˜æ£€æµ‹"]
        ALERT["CloudWatch<br/>å‘Šè­¦"]
        GURU["DevOps Guru<br/>æ´å¯Ÿ"]
    end

    subgraph Kiro2["ğŸ¤– Kiro (ç¨‹åºåŒ–)"]
        SPEC["åŸºäºè§„æ ¼<br/>è¯Šæ–­è®¡åˆ’"]
        MCP_Q["MCP é›†æˆ<br/>æ•°æ®æ”¶é›†"]
        ANALYZE2["AI åˆ†æ<br/>æ ¹æœ¬åŸå› "]
        FIX["ä¿®å¤ä»£ç <br/>è‡ªåŠ¨ç”Ÿæˆ"]
        PR["PR åˆ›å»º<br/>+ éªŒè¯"]
    end

    subgraph Deploy2["ğŸš€ éƒ¨ç½²"]
        REVIEW["AI å®¡æŸ¥<br/>+ æ‰¹å‡†"]
        ARGO2["Argo CD<br/>è‡ªåŠ¨éƒ¨ç½²"]
        VERIFY["éƒ¨ç½²å<br/>éªŒè¯"]
    end

    ALERT --> SPEC
    GURU --> SPEC
    SPEC --> MCP_Q --> ANALYZE2 --> FIX --> PR
    PR --> REVIEW --> ARGO2 --> VERIFY
    VERIFY -.->|é—®é¢˜æŒç»­| SPEC

    style Kiro2 fill:#e3f2fd,stroke:#2196f3
```

### 6.3 å…·ä½“åœºæ™¯: OOMKilled è‡ªåŠ¨å“åº”

```
[Kiro ç¨‹åºåŒ–è°ƒè¯•: OOMKilled]

1. æ£€æµ‹: payment-service Pod OOMKilled äº‹ä»¶

2. Kiro è§„æ ¼æ‰§è¡Œ:
   â†’ EKS MCP: get_events(namespace="payment", reason="OOMKilled")
   â†’ EKS MCP: get_pod_logs(pod="payment-xxx", previous=true)
   â†’ CloudWatch MCP: query_metrics("pod_memory_utilization", last="1h")

3. AI åˆ†æ:
   "åœ¨ payment-service ä¸­æ£€æµ‹åˆ°å†…å­˜æ³„æ¼æ¨¡å¼,å¯åŠ¨åæ¯ 2 å°æ—¶
    å¢åŠ  256Miã€‚
    æ—¥å¿—ç¡®è®¤ Redis è¿æ¥æœªæ­£ç¡®å…³é—­ã€‚"

4. è‡ªåŠ¨ä¿®å¤:
   - memory limits 256Mi â†’ 512Mi (ä¸´æ—¶æªæ–½)
   - ç”Ÿæˆ Redis è¿æ¥æ± æ¸…ç†ä»£ç è¡¥ä¸
   - æ·»åŠ å†…å­˜åˆ†æé…ç½®

5. PR åˆ›å»º:
   æ ‡é¢˜: "fix: payment-service Redis è¿æ¥æ³„æ¼"
   - deployment.yaml: è°ƒæ•´å†…å­˜é™åˆ¶
   - redis_client.go: æ·»åŠ  defer conn.Close()
   - monitoring: æ·»åŠ å†…å­˜ä½¿ç”¨ä»ªè¡¨æ¿
```

:::tip ç¨‹åºåŒ–è°ƒè¯•çš„æ ¸å¿ƒ
é€šè¿‡ Kiro + EKS MCP,é—®é¢˜è¢«**ç¨‹åºåŒ–åœ°åˆ†æå’Œè§£å†³**ã€‚ä¸æ‰‹åŠ¨æŒ‡ä»¤å¼å“åº”ç›¸æ¯”,è¿™å®ç°äº†**æˆæœ¬é«˜æ•ˆå’Œå¿«é€Ÿçš„è‡ªåŠ¨åŒ–**,å­¦ä¹ çš„è§„æ ¼å¯ä»¥åœ¨ç›¸åŒé—®é¢˜é‡å¤æ—¶é‡ç”¨ã€‚
:::

---

## 7. AI èµ„æºè°ƒä¼˜

### 7.1 åŸºäº Container Insights çš„å»ºè®®

CloudWatch Container Insights åˆ†æå®é™… Pod èµ„æºä½¿ç”¨æ¨¡å¼ä»¥æ¨èé€‚å½“çš„å¤§å°ã€‚

```promql
# æ¯”è¾ƒå®é™… CPU ä½¿ç”¨ vs è¯·æ±‚
avg(rate(container_cpu_usage_seconds_total{namespace="payment"}[1h]))
  by (pod)
/ avg(kube_pod_container_resource_requests{resource="cpu", namespace="payment"})
  by (pod)
* 100

# æ¯”è¾ƒå®é™…å†…å­˜ä½¿ç”¨ vs è¯·æ±‚
avg(container_memory_working_set_bytes{namespace="payment"})
  by (pod)
/ avg(kube_pod_container_resource_requests{resource="memory", namespace="payment"})
  by (pod)
* 100
```

### 7.2 åŸºäº VPA + ML çš„è‡ªåŠ¨èµ„æºè°ƒä¼˜

```yaml
# VPA (Vertical Pod Autoscaler) é…ç½®
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: payment-service-vpa
  namespace: payment
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: payment-service
  updatePolicy:
    updateMode: "Auto"  # Off, Initial, Auto
  resourcePolicy:
    containerPolicies:
      - containerName: app
        minAllowed:
          cpu: 100m
          memory: 128Mi
        maxAllowed:
          cpu: "2"
          memory: 4Gi
        controlledResources: ["cpu", "memory"]
```

### 7.3 èµ„æºè°ƒä¼˜ç»“æœ

<RightSizingResults />

:::tip K8s 1.35: åŸåœ° Pod èµ„æºæ›´æ–°
ä» K8s 1.35 å¼€å§‹(2026å¹´1æœˆ,EKS æ”¯æŒ),**åŸåœ° Pod èµ„æºæ›´æ–°**åŠŸèƒ½å…è®¸åœ¨ä¸é‡å¯ Pod çš„æƒ…å†µä¸‹åŠ¨æ€è°ƒæ•´ CPU å’Œå†…å­˜ã€‚è¿™è§£å†³äº† VPA æœ€å¤§çš„å±€é™æ€§"èµ„æºæ›´æ”¹æ—¶ Pod é‡å¯"ã€‚å‚ç›´æ‰©å±•ç°åœ¨å¯¹ StatefulSets å’Œé‡å¯æ•æ„Ÿçš„å·¥ä½œè´Ÿè½½ä¹Ÿæ˜¯å®‰å…¨çš„ã€‚
:::

:::warning VPA æ³¨æ„äº‹é¡¹ (K8s 1.34 åŠä»¥ä¸‹)
åœ¨ K8s 1.34 åŠä»¥ä¸‹ç‰ˆæœ¬ä¸­,VPA `Auto` æ¨¡å¼ä¼šé‡å¯ Pods ä»¥è°ƒæ•´èµ„æºã€‚å¯¹äº StatefulSets æˆ–é‡å¯æ•æ„Ÿçš„å·¥ä½œè´Ÿè½½,ä½¿ç”¨ `Off` æ¨¡å¼ä»…æ£€æŸ¥å»ºè®®å¹¶æ‰‹åŠ¨åº”ç”¨æ›´å®‰å…¨ã€‚åŒæ—¶ä½¿ç”¨ VPA å’Œ HPA ä¸ç›¸åŒæŒ‡æ ‡(CPU/Memory)å¯èƒ½ä¼šå¯¼è‡´å†²çªã€‚
:::

---

## 8. åé¦ˆå¾ªç¯

### 8.1 æµ‹é‡é¢„æµ‹å‡†ç¡®æ€§

```python
# æµ‹é‡é¢„æµ‹å‡†ç¡®æ€§å¹¶é‡æ–°è®­ç»ƒæ¨¡å‹
import numpy as np

def calculate_accuracy(predicted, actual):
    """è®¡ç®— MAPE (å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®)"""
    mape = np.mean(np.abs((actual - predicted) / actual)) * 100
    return {
        'mape': mape,
        'accuracy': 100 - mape,
        'over_prediction_rate': np.mean(predicted > actual) * 100,
        'under_prediction_rate': np.mean(predicted < actual) * 100
    }

def should_retrain(accuracy_history, threshold=85):
    """ç¡®å®šæ˜¯å¦éœ€è¦é‡æ–°è®­ç»ƒ"""
    recent_accuracy = np.mean(accuracy_history[-10:])
    if recent_accuracy < threshold:
        return True, f"æœ€è¿‘å‡†ç¡®ç‡ {recent_accuracy:.1f}% < é˜ˆå€¼ {threshold}%"
    return False, f"å‡†ç¡®ç‡è‰¯å¥½: {recent_accuracy:.1f}%"
```

### 8.2 è‡ªåŠ¨é‡æ–°è®­ç»ƒæµæ°´çº¿

```yaml
# é¢„æµ‹æ¨¡å‹è‡ªåŠ¨é‡æ–°è®­ç»ƒ CronJob
apiVersion: batch/v1
kind: CronJob
metadata:
  name: model-retrainer
  namespace: scaling
spec:
  schedule: "0 2 * * 0"  # æ¯å‘¨æ—¥ 02:00
  jobTemplate:
    spec:
      template:
        spec:
          containers:
            - name: retrainer
              image: my-registry/model-retrainer:latest
              env:
                - name: AMP_WORKSPACE_ID
                  value: "ws-xxxxx"
                - name: TRAINING_WEEKS
                  value: "4"
                - name: ACCURACY_THRESHOLD
                  value: "85"
              resources:
                requests:
                  cpu: "2"
                  memory: 4Gi
          restartPolicy: OnFailure
```

### 8.3 A/B æ‰©å±•æµ‹è¯•

```
[A/B æ‰©å±•]

ç»„ A (50% æµé‡): åŸºäº HPA çš„å“åº”å¼æ‰©å±•
ç»„ B (50% æµé‡): åŸºäº ML é¢„æµ‹çš„ä¸»åŠ¨æ‰©å±•

æ¯”è¾ƒæŒ‡æ ‡:
  - P99 å»¶è¿Ÿå·®å¼‚
  - æ‰©å±•äº‹ä»¶æ•°é‡
  - èµ„æºä½¿ç”¨æ•ˆç‡
  - æˆæœ¬-æ€§èƒ½æ¯”
```

---

## 9. æ··æ²Œå·¥ç¨‹ + AI

### 9.1 AWS Fault Injection Service (FIS)

```json
{
  "description": "EKS Pod æ•…éšœæ³¨å…¥æµ‹è¯•",
  "targets": {
    "eks-pods": {
      "resourceType": "aws:eks:pod",
      "selectionMode": "COUNT(2)",
      "resourceTags": {
        "app": "payment-service"
      },
      "parameters": {
        "clusterIdentifier": "my-cluster",
        "namespace": "payment"
      }
    }
  },
  "actions": {
    "terminate-pods": {
      "actionId": "aws:eks:terminate-pod",
      "parameters": {},
      "targets": {
        "Pods": "eks-pods"
      }
    }
  },
  "stopConditions": [
    {
      "source": "aws:cloudwatch:alarm",
      "value": "arn:aws:cloudwatch:ap-northeast-2:ACCOUNT_ID:alarm:PaymentServiceSLO"
    }
  ],
  "roleArn": "arn:aws:iam::ACCOUNT_ID:role/FISRole",
  "tags": {
    "Environment": "staging",
    "Team": "platform"
  }
}
```

### 9.2 åŸºäº AI çš„æ•…éšœæ¨¡å¼å­¦ä¹ 

AI ä»æ··æ²Œå·¥ç¨‹å®éªŒç»“æœä¸­å­¦ä¹ ä»¥æé«˜å“åº”èƒ½åŠ›ã€‚

<ChaosExperiments />

```python
# FIS å®éªŒåæ”¶é›† AI å­¦ä¹ æ•°æ®
from strands import Agent

chaos_analyzer = Agent(
    name="chaos-pattern-analyzer",
    model="bedrock/anthropic.claude-sonnet",
    sop="""
    ## æ··æ²Œå·¥ç¨‹ç»“æœåˆ†æ

    1. æ”¶é›† FIS å®éªŒç»“æœ
       - æ³¨å…¥çš„æ•…éšœç±»å‹
       - ç³»ç»Ÿååº”æ—¶é—´
       - æ¢å¤æ—¶é—´
       - å½±å“èŒƒå›´

    2. æ¨¡å¼åˆ†æ
       - æ˜ å°„æ•…éšœä¼ æ’­è·¯å¾„
       - è¯†åˆ«è„†å¼±ç‚¹
       - è¯†åˆ«æ¢å¤ç“¶é¢ˆ

    3. æ›´æ–°å“åº”è§„åˆ™
       - å°†å­¦ä¹ æ·»åŠ åˆ°ç°æœ‰ SOP
       - ä¸ºæ–°æ¨¡å¼åˆ›å»ºå“åº”è§„åˆ™
       - è°ƒæ•´å‡çº§é˜ˆå€¼

    4. ç”ŸæˆæŠ¥å‘Š
       - å®éªŒæ‘˜è¦
       - å‘ç°çš„è„†å¼±æ€§
       - æ¨èçš„æ”¹è¿›
    """
)
```

:::tip æ··æ²Œå·¥ç¨‹ + AI åé¦ˆå¾ªç¯
é€šè¿‡ä½¿ç”¨ FIS æ³¨å…¥æ•…éšœå¹¶è®© AI å­¦ä¹ ç³»ç»Ÿååº”æ¨¡å¼,AI Agent çš„è‡ªåŠ¨å“åº”èƒ½åŠ›æŒç»­æ”¹è¿›ã€‚"æ•…éšœæ³¨å…¥ â†’ è§‚å¯Ÿ â†’ å­¦ä¹  â†’ å“åº”æ”¹è¿›"çš„åé¦ˆå¾ªç¯æ˜¯è‡ªä¸»è¿ç»´çš„æ ¸å¿ƒã€‚
:::

---

## 10. é›†æˆè¿ç»´ä»ªè¡¨æ¿

### 10.1 AMG ä»ªè¡¨æ¿é…ç½®

<MaturityTable />

é›†æˆè¿ç»´ä»ªè¡¨æ¿å°†é¢„æµ‹å’Œå®é™…æ•°æ®ä¸€èµ·æ˜¾ç¤ºã€‚

```json
{
  "dashboard": {
    "title": "EKS é¢„æµ‹æ€§è¿ç»´ä»ªè¡¨æ¿",
    "panels": [
      {
        "title": "æµé‡é¢„æµ‹ vs å®é™…",
        "type": "timeseries",
        "targets": [
          {
            "expr": "sum(rate(http_requests_total{namespace='payment'}[5m]))",
            "legendFormat": "å®é™… RPS"
          },
          {
            "expr": "predicted_rps{service='payment'}",
            "legendFormat": "é¢„æµ‹ RPS"
          }
        ]
      },
      {
        "title": "æ‰©å±•äº‹ä»¶",
        "type": "timeseries",
        "targets": [
          {
            "expr": "kube_deployment_spec_replicas{deployment='payment-service'}",
            "legendFormat": "å½“å‰å‰¯æœ¬"
          },
          {
            "expr": "predicted_replicas{deployment='payment-service'}",
            "legendFormat": "é¢„æµ‹æ‰€éœ€å‰¯æœ¬"
          }
        ]
      },
      {
        "title": "SLO çŠ¶æ€",
        "type": "gauge",
        "targets": [
          {
            "expr": "1 - (sum(rate(http_requests_total{status=~'5..'}[30d])) / sum(rate(http_requests_total[30d])))",
            "legendFormat": "å¯ç”¨æ€§ SLO"
          }
        ],
        "thresholds": {
          "steps": [
            {"value": 0.999, "color": "green"},
            {"value": 0.995, "color": "yellow"},
            {"value": 0, "color": "red"}
          ]
        }
      },
      {
        "title": "å‰©ä½™é”™è¯¯é¢„ç®—",
        "type": "stat",
        "targets": [
          {
            "expr": "error_budget_remaining_percent{service='payment'}",
            "legendFormat": "å‰©ä½™é”™è¯¯é¢„ç®—"
          }
        ]
      },
      {
        "title": "é¢„æµ‹å‡†ç¡®ç‡",
        "type": "stat",
        "targets": [
          {
            "expr": "prediction_accuracy_percent",
            "legendFormat": "å‡†ç¡®ç‡"
          }
        ]
      },
      {
        "title": "äº‹ä»¶è‡ªåŠ¨å“åº”ç‡",
        "type": "stat",
        "targets": [
          {
            "expr": "auto_remediation_success_rate",
            "legendFormat": "è‡ªåŠ¨å“åº”æˆåŠŸç‡"
          }
        ]
      }
    ]
  }
}
```

### 10.2 æ ¸å¿ƒä»ªè¡¨æ¿é¢æ¿

<DashboardPanels />

---

## 11. ç»“è®º

### 11.1 é‡‡ç”¨è·¯çº¿å›¾

```
é˜¶æ®µ 1: æ„å»ºå¯è§‚æµ‹æ€§åŸºç¡€
  â””â”€â”€ AMP/AMG + CloudWatch + å¼‚å¸¸æ£€æµ‹

é˜¶æ®µ 2: é¢„æµ‹æ€§æ‰©å±•
  â””â”€â”€ Prophet/ARIMA + Karpenter ä¸»åŠ¨é…ç½®

é˜¶æ®µ 3: AI Agent æ‰©å±•
  â””â”€â”€ Q Developer + Strands + Kagent + MCP é›†æˆ

é˜¶æ®µ 4: Kiro ç¨‹åºåŒ–è°ƒè¯•
  â””â”€â”€ Kiro è§„æ ¼ â†’ è‡ªåŠ¨è¯Šæ–­ â†’ è‡ªåŠ¨ä¿®å¤

é˜¶æ®µ 5: æ··æ²Œå·¥ç¨‹ + åé¦ˆå¾ªç¯
  â””â”€â”€ FIS å®éªŒ â†’ AI å­¦ä¹  â†’ è‡ªä¸»è¿ç»´æ¼”è¿›
```

### 11.2 åç»­æ­¥éª¤

- **[AIOps ä»‹ç»](./aiops-introduction.md)**: é¢„æµ‹æ€§è¿ç»´çš„æ›´é«˜å±‚ç­–ç•¥ â€” æ•´ä½“ AIOps ä¸Šä¸‹æ–‡
- **[æ™ºèƒ½å¯è§‚æµ‹æ€§å †æ ˆ](./aiops-observability-stack.md)**: é¢„æµ‹æ€§è¿ç»´çš„æ•°æ®åŸºç¡€ â€” æ„å»ºå¯è§‚æµ‹æ€§
- **[AIDLC æ¡†æ¶](./aidlc-framework.md)**: åŒ…æ‹¬é¢„æµ‹æ€§è¿ç»´çš„ AI å¼€å‘ç”Ÿå‘½å‘¨æœŸ

### 11.3 å­¦ä¹ è·¯å¾„

```
[å‰ç½®] AIOps ä»‹ç» â€” ç†è§£ç­–ç•¥å’Œæ–¹å‘
     â†“
[å‰ç½®] æ™ºèƒ½å¯è§‚æµ‹æ€§å †æ ˆ â€” æ„å»ºæ•°æ®æ”¶é›†/åˆ†æåŸºç¡€
     â†“
[å‰ç½®] AIDLC æ¡†æ¶ â€” AI é©±åŠ¨çš„å¼€å‘æ–¹æ³•è®º
     â†“
[å½“å‰æ–‡æ¡£] é¢„æµ‹æ€§æ‰©å±•å’Œè‡ªåŠ¨ä¿®å¤ â€” å®ç°è‡ªä¸»è¿ç»´
```

:::info ç›¸å…³æ–‡æ¡£

- [AIOps ç­–ç•¥æŒ‡å—](./aiops-introduction.md) â€” æ•´ä½“ AIOps ç­–ç•¥
- [æ„å»ºæ™ºèƒ½å¯è§‚æµ‹æ€§å †æ ˆ](./aiops-observability-stack.md) â€” åŸºäºå¯è§‚æµ‹æ€§çš„åŸºç¡€è®¾æ–½
- [AIDLC æ¡†æ¶](./aidlc-framework.md) â€” AI é©±åŠ¨çš„å¼€å‘æ–¹æ³•è®º
:::
