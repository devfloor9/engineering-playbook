---
title: "æ¨ç†ç½‘å…³ä¸åŠ¨æ€è·¯ç”±"
sidebar_label: "9. Inference Gateway"
description: "ä½¿ç”¨ Kgateway ä¸º AI æ¨¡å‹æ¨ç†è¯·æ±‚é…ç½®åŠ¨æ€è·¯ç”±å’Œè´Ÿè½½å‡è¡¡"
tags: [eks, gateway-api, kgateway, routing, load-balancing, inference]
category: "genai-aiml"
sidebar_position: 9
last_update:
  date: 2026-02-14
  author: devfloor9
---

# æ¨ç†ç½‘å…³ä¸åŠ¨æ€è·¯ç”±

> ğŸ“… **æ’°å†™æ—¥æœŸ**: 2025-02-05 | **ä¿®æ”¹æ—¥æœŸ**: 2026-02-14 | â±ï¸ **é˜…è¯»æ—¶é—´**: çº¦ 4 åˆ†é’Ÿ

åœ¨å¤§è§„æ¨¡ AI æ¨¡å‹æœåŠ¡ç¯å¢ƒä¸­ï¼Œé«˜æ•ˆåœ°è·¯ç”±å’Œç®¡ç†å„ç§æ¨¡å‹çš„æ¨ç†è¯·æ±‚è‡³å…³é‡è¦ã€‚æœ¬æ–‡æ¶µç›–å¦‚ä½•ä½¿ç”¨ Kubernetes Gateway API å’Œ Kgateway ä¸º AI æ¨¡å‹æ¨ç†è¯·æ±‚é…ç½®åŠ¨æ€è·¯ç”±ã€è´Ÿè½½å‡è¡¡å’Œæ•…éšœå“åº”ç­–ç•¥ã€‚

## æ¦‚è¿°

### æ ¸å¿ƒç›®æ ‡

- **æ™ºèƒ½è·¯ç”±**ï¼šæ ¹æ®è¯·æ±‚ç‰¹å¾é€‰æ‹©æœ€ä¼˜æ¨¡å‹åç«¯
- **æµé‡åˆ†é…**ï¼šé€šè¿‡åŸºäºæƒé‡çš„è´Ÿè½½å‡è¡¡æä¾›ç¨³å®šæœåŠ¡
- **æ¸è¿›å¼éƒ¨ç½²**ï¼šé€šè¿‡é‡‘ä¸é›€å‘å¸ƒå’Œ A/B æµ‹è¯•å®ç°å®‰å…¨çš„æ¨¡å‹æ›´æ–°
- **é«˜å¯ç”¨æ€§**ï¼šé€šè¿‡é™çº§å’Œé‡è¯•ç­–ç•¥ç¡®ä¿æœåŠ¡è¿ç»­æ€§

---

## æ¨ç†ç½‘å…³æ¶æ„

### å®Œæ•´æ¶æ„å›¾

```mermaid
flowchart TB
    subgraph "Client Layer"
        CLIENT[API Clients]
        SDK[Agent SDK]
        UI[Web Dashboard]
    end

    subgraph "Gateway Layer"
        direction TB
        GC[GatewayClass<br/>kgateway]
        GW[Gateway<br/>ai-inference-gateway]

        subgraph "Routing Rules"
            HR1[HTTPRoute<br/>model-routing]
            HR2[HTTPRoute<br/>canary-routing]
            HR3[HTTPRoute<br/>fallback-routing]
        end
    end

    subgraph "Backend Services"
        subgraph "Model Pool A"
            VLLM1[vLLM<br/>GPT-4 Primary]
            VLLM2[vLLM<br/>GPT-4 Canary]
        end

        subgraph "Model Pool B"
            VLLM3[vLLM<br/>Claude-3]
        end

        subgraph "Model Pool C"
            TGI1[TGI<br/>Mixtral-8x7B]
        end
    end

    subgraph "Observability"
        METRICS[Prometheus<br/>Metrics]
        TRACES[OpenTelemetry<br/>Traces]
    end

    CLIENT --> GW
    SDK --> GW
    UI --> GW

    GC --> GW
    GW --> HR1 & HR2 & HR3

    HR1 --> VLLM1 & VLLM3 & TGI1
    HR2 --> VLLM1 & VLLM2
    HR3 --> VLLM1 & VLLM3

    GW --> METRICS
    GW --> TRACES
```

### ç»„ä»¶ç»“æ„

import { ComponentStructureTable } from '@site/src/components/InferenceGatewayTables';

<ComponentStructureTable />

{/* Original table preserved for reference
| Component | Role | Description |
|---------|------|------|
| **GatewayClass** | Gateway implementation definition | Designate Kgateway controller |
| **Gateway** | Entry point definition | Configure listeners, TLS, addresses |
| **HTTPRoute** | Routing rules | Path, header-based routing |
| **Backend** | Model service | vLLM, TGI and other inference servers |
*/}

### æµé‡æµç¨‹

```mermaid
sequenceDiagram
    participant Client as Client
    participant GW as Kgateway
    participant Route as HTTPRoute
    participant LB as Load Balancer
    participant Model as Model Backend

    Client->>GW: 1. POST /v1/chat/completions<br/>Header: x-model-id: gpt-4
    GW->>Route: 2. Match routing rules
    Route->>LB: 3. Select backend (weight-based)
    LB->>Model: 4. Forward request
    Model-->>LB: 5. Inference result
    LB-->>GW: 6. Return response
    GW-->>Client: 7. Final response
```

:::info Gateway API æ ‡å‡†
Kgateway å®ç°äº† Kubernetes Gateway API æ ‡å‡†ï¼Œæ”¯æŒå‚å•†æ— å…³çš„é…ç½®ã€‚è¿™æœ‰åŠ©äºè¿ç§»åˆ°å…¶ä»–ç½‘å…³å®ç°ã€‚
:::

---

## Kgateway å®‰è£…ä¸é…ç½®

### å‰ç½®æ¡ä»¶

- Kubernetes 1.28 æˆ–æ›´é«˜ç‰ˆæœ¬
- Helm 3.x
- å·²å®‰è£… Gateway API CRD

### å®‰è£… Gateway API CRD

```bash
# å®‰è£…æ ‡å‡† Gateway API CRD
kubectl apply -f https://github.com/kubernetes-sigs/gateway-api/releases/download/v1.2.0/standard-install.yaml

# å®‰è£…å®éªŒæ€§åŠŸèƒ½ï¼ˆHTTPRoute filters ç­‰ï¼‰
kubectl apply -f https://github.com/kubernetes-sigs/gateway-api/releases/download/v1.2.0/experimental-install.yaml
```

### å®‰è£… Kgateway Helm Chart

```bash
# æ·»åŠ  Helm ä»“åº“
helm repo add kgateway https://kgateway-dev.github.io/kgateway/
helm repo update

# åˆ›å»ºå‘½åç©ºé—´
kubectl create namespace kgateway-system

# å®‰è£… Kgateway
helm install kgateway kgateway/kgateway \
  --namespace kgateway-system \
  --set controller.replicaCount=2 \
  --set controller.resources.requests.cpu=500m \
  --set controller.resources.requests.memory=512Mi \
  --set controller.resources.limits.cpu=1000m \
  --set controller.resources.limits.memory=1Gi \
  --set metrics.enabled=true \
  --set metrics.serviceMonitor.enabled=true
```

### Helm Values è¯¦ç»†é…ç½®

```yaml
# values.yaml
controller:
  replicaCount: 2

  resources:
    requests:
      cpu: 500m
      memory: 512Mi
    limits:
      cpu: 1000m
      memory: 1Gi

  # é«˜å¯ç”¨é…ç½®
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchLabels:
                app: kgateway
            topologyKey: kubernetes.io/hostname

# æŒ‡æ ‡é…ç½®
metrics:
  enabled: true
  port: 9090
  serviceMonitor:
    enabled: true
    interval: 15s
    labels:
      release: prometheus

# æ—¥å¿—é…ç½®
logging:
  level: info
  format: json

# TLS é…ç½®
tls:
  enabled: true
  certManager:
    enabled: true
    issuerRef:
      name: letsencrypt-prod
      kind: ClusterIssuer
```

---

## GatewayClass ä¸ Gateway é…ç½®

### GatewayClass å®šä¹‰

å®šä¹‰ç½‘å…³å®ç°ã€‚

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: GatewayClass
metadata:
  name: kgateway
spec:
  controllerName: kgateway.dev/kgateway-controller
  description: "Kgateway for AI inference routing"
  parametersRef:
    group: kgateway.dev
    kind: GatewayClassConfig
    name: kgateway-config
---
apiVersion: kgateway.dev/v1alpha1
kind: GatewayClassConfig
metadata:
  name: kgateway-config
spec:
  # ä»£ç†é…ç½®
  proxy:
    replicas: 3
    resources:
      requests:
        cpu: "1"
        memory: "2Gi"
      limits:
        cpu: "2"
        memory: "4Gi"

  # è¿æ¥è®¾ç½®
  connectionSettings:
    maxConnections: 10000
    connectTimeout: 10s
    idleTimeout: 60s
```

### Gateway èµ„æºå®šä¹‰

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: ai-inference-gateway
  namespace: ai-gateway
  annotations:
    # AWS ALB é›†æˆ
    service.beta.kubernetes.io/aws-load-balancer-type: "external"
    service.beta.kubernetes.io/aws-load-balancer-nlb-target-type: "ip"
    service.beta.kubernetes.io/aws-load-balancer-scheme: "internet-facing"
spec:
  gatewayClassName: kgateway

  listeners:
    # HTTPS ç›‘å¬å™¨
    - name: https
      protocol: HTTPS
      port: 443
      hostname: "inference.example.com"
      tls:
        mode: Terminate
        certificateRefs:
          - name: inference-tls-cert
            kind: Secret
      allowedRoutes:
        namespaces:
          from: Selector
          selector:
            matchLabels:
              gateway-access: "true"

    # HTTP ç›‘å¬å™¨ï¼ˆç”¨äº HTTPS é‡å®šå‘ï¼‰
    - name: http
      protocol: HTTP
      port: 80
      hostname: "inference.example.com"
      allowedRoutes:
        namespaces:
          from: Same

    # å†…éƒ¨ gRPC ç›‘å¬å™¨
    - name: grpc
      protocol: HTTPS
      port: 8443
      hostname: "inference-grpc.example.com"
      tls:
        mode: Terminate
        certificateRefs:
          - name: inference-grpc-tls-cert
      allowedRoutes:
        kinds:
          - kind: GRPCRoute
```

:::warning TLS è¯ä¹¦ç®¡ç†
åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œä½¿ç”¨ cert-manager è‡ªåŠ¨ç®¡ç† TLS è¯ä¹¦ã€‚æ‰‹åŠ¨è¯ä¹¦ç®¡ç†å­˜åœ¨å› è¯ä¹¦è¿‡æœŸå¯¼è‡´æœåŠ¡ä¸­æ–­çš„é£é™©ã€‚
:::

---

## åŠ¨æ€è·¯ç”±é…ç½®

### åŸºäº Header çš„è·¯ç”±

æ ¹æ® `x-model-id` Header å€¼è·¯ç”±åˆ°ç›¸åº”çš„æ¨¡å‹åç«¯ã€‚

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: model-header-routing
  namespace: ai-gateway
spec:
  parentRefs:
    - name: ai-inference-gateway
      namespace: ai-gateway
      sectionName: https

  hostnames:
    - "inference.example.com"

  rules:
    # GPT-4 æ¨¡å‹è·¯ç”±
    - matches:
        - path:
            type: PathPrefix
            value: /v1/chat/completions
          headers:
            - name: x-model-id
              value: "gpt-4"
      backendRefs:
        - name: vllm-gpt4-service
          namespace: ai-inference
          port: 8000
          weight: 100

    # Claude-3 æ¨¡å‹è·¯ç”±
    - matches:
        - path:
            type: PathPrefix
            value: /v1/chat/completions
          headers:
            - name: x-model-id
              value: "claude-3"
      backendRefs:
        - name: vllm-claude3-service
          namespace: ai-inference
          port: 8000
          weight: 100

    # Mixtral MoE æ¨¡å‹è·¯ç”±
    - matches:
        - path:
            type: PathPrefix
            value: /v1/chat/completions
          headers:
            - name: x-model-id
              value: "mixtral-8x7b"
      backendRefs:
        - name: tgi-mixtral-service
          namespace: ai-inference
          port: 8080
          weight: 100
```

### åŸºäºè·¯å¾„çš„è·¯ç”±

æ ¹æ® API è·¯å¾„è·¯ç”±åˆ°ä¸åŒçš„æœåŠ¡ã€‚

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: path-based-routing
  namespace: ai-gateway
spec:
  parentRefs:
    - name: ai-inference-gateway
      namespace: ai-gateway

  hostnames:
    - "inference.example.com"

  rules:
    # Chat Completions API
    - matches:
        - path:
            type: PathPrefix
            value: /v1/chat/completions
      backendRefs:
        - name: chat-completion-service
          port: 8000

    # Embeddings API
    - matches:
        - path:
            type: PathPrefix
            value: /v1/embeddings
      backendRefs:
        - name: embedding-service
          port: 8000

    # Completions APIï¼ˆæ—§ç‰ˆï¼‰
    - matches:
        - path:
            type: PathPrefix
            value: /v1/completions
      backendRefs:
        - name: completion-service
          port: 8000

    # å¥åº·æ£€æŸ¥
    - matches:
        - path:
            type: Exact
            value: /health
      backendRefs:
        - name: health-check-service
          port: 8080
```

### é«˜çº§ç»„åˆè·¯ç”±

ç»„åˆå¤šä¸ªæ¡ä»¶çš„é«˜çº§è·¯ç”±è§„åˆ™ã€‚

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: advanced-routing
  namespace: ai-gateway
spec:
  parentRefs:
    - name: ai-inference-gateway

  rules:
    # é«˜çº§å®¢æˆ· + GPT-4 è¯·æ±‚ â†’ ä¸“ç”¨åç«¯
    - matches:
        - path:
            type: PathPrefix
            value: /v1/chat/completions
          headers:
            - name: x-model-id
              value: "gpt-4"
            - name: x-customer-tier
              value: "premium"
      backendRefs:
        - name: vllm-gpt4-premium
          port: 8000

    # æ ‡å‡†å®¢æˆ· + GPT-4 è¯·æ±‚ â†’ å…±äº«åç«¯
    - matches:
        - path:
            type: PathPrefix
            value: /v1/chat/completions
          headers:
            - name: x-model-id
              value: "gpt-4"
            - name: x-customer-tier
              value: "standard"
      backendRefs:
        - name: vllm-gpt4-shared
          port: 8000
```

---

## è´Ÿè½½å‡è¡¡ç­–ç•¥

### åŸºäºæƒé‡çš„æµé‡åˆ†é…

æŒ‰æƒé‡åœ¨æ¨¡å‹ç‰ˆæœ¬é—´åˆ†é…æµé‡ã€‚

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: weighted-routing
  namespace: ai-gateway
spec:
  parentRefs:
    - name: ai-inference-gateway

  rules:
    - matches:
        - path:
            type: PathPrefix
            value: /v1/chat/completions
          headers:
            - name: x-model-id
              value: "gpt-4"
      backendRefs:
        # ä¸»åç«¯ï¼š80% æµé‡
        - name: vllm-gpt4-v1
          port: 8000
          weight: 80
        # å‰¯åç«¯ï¼š20% æµé‡
        - name: vllm-gpt4-v2
          port: 8000
          weight: 20
```

### A/B æµ‹è¯•è·¯ç”±

ä»…å‘ç‰¹å®šç”¨æˆ·ç»„æš´éœ²æ–°æ¨¡å‹ç‰ˆæœ¬ã€‚

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: ab-test-routing
  namespace: ai-gateway
spec:
  parentRefs:
    - name: ai-inference-gateway

  rules:
    # A/B æµ‹è¯•ç»„ Aï¼ˆåŸºçº¿æ¨¡å‹ï¼‰
    - matches:
        - path:
            type: PathPrefix
            value: /v1/chat/completions
          headers:
            - name: x-ab-test-group
              value: "control"
      backendRefs:
        - name: vllm-model-baseline
          port: 8000

    # A/B æµ‹è¯•ç»„ Bï¼ˆæ–°æ¨¡å‹ï¼‰
    - matches:
        - path:
            type: PathPrefix
            value: /v1/chat/completions
          headers:
            - name: x-ab-test-group
              value: "experiment"
      backendRefs:
        - name: vllm-model-new
          port: 8000
```

### é‡‘ä¸é›€éƒ¨ç½²

é€æ­¥å‘å¸ƒæ–°æ¨¡å‹ç‰ˆæœ¬ã€‚

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: canary-deployment
  namespace: ai-gateway
  annotations:
    # è¿½è¸ªé‡‘ä¸é›€éƒ¨ç½²é˜¶æ®µ
    deployment.kubernetes.io/canary-weight: "10"
spec:
  parentRefs:
    - name: ai-inference-gateway

  rules:
    - matches:
        - path:
            type: PathPrefix
            value: /v1/chat/completions
          headers:
            - name: x-model-id
              value: "gpt-4"
      backendRefs:
        # ç¨³å®šç‰ˆæœ¬ï¼š90%
        - name: vllm-gpt4-stable
          port: 8000
          weight: 90
        # é‡‘ä¸é›€ç‰ˆæœ¬ï¼š10%
        - name: vllm-gpt4-canary
          port: 8000
          weight: 10
```

:::tip é‡‘ä¸é›€éƒ¨ç½²ç­–ç•¥

1. **åˆå§‹é˜¶æ®µ**ï¼šä» 5-10% æµé‡å¼€å§‹
2. **ç›‘æ§**ï¼šæ£€æŸ¥é”™è¯¯ç‡ã€å»¶è¿Ÿã€è´¨é‡æŒ‡æ ‡
3. **é€æ­¥å¢åŠ **ï¼šæ— é—®é¢˜åˆ™å¢åŠ åˆ° 25% â†’ 50% â†’ 75% â†’ 100%
4. **éšæ—¶å›æ»š**ï¼šå‡ºç°é—®é¢˜æ—¶ç«‹å³å›æ»šåˆ° 0%

:::

### é‡‘ä¸é›€éƒ¨ç½²æ—¶é—´çº¿ç¤ºä¾‹

```mermaid
gantt
    title Canary Deployment Timeline
    dateFormat  HH:mm
    axisFormat %H:%M

    section Traffic Ratio
    Canary 10%     :a1, 00:00, 30m
    Canary 25%     :a2, after a1, 30m
    Canary 50%     :a3, after a2, 60m
    Canary 75%     :a4, after a3, 60m
    Canary 100%    :a5, after a4, 60m

    section Monitoring
    Check Metrics  :b1, 00:00, 300m
```

---

## æ•…éšœå“åº”é…ç½®

### é™çº§é…ç½®

å½“ä¸»åç«¯æ•…éšœæ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°å¤‡ç”¨åç«¯ã€‚

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: fallback-routing
  namespace: ai-gateway
spec:
  parentRefs:
    - name: ai-inference-gateway

  rules:
    - matches:
        - path:
            type: PathPrefix
            value: /v1/chat/completions
          headers:
            - name: x-model-id
              value: "gpt-4"
      backendRefs:
        # ä¸»åç«¯
        - name: vllm-gpt4-primary
          port: 8000
          weight: 100
      # é€šè¿‡ BackendLBPolicy é…ç½®é™çº§
---
apiVersion: gateway.networking.k8s.io/v1alpha2
kind: BackendLBPolicy
metadata:
  name: gpt4-fallback-policy
  namespace: ai-gateway
spec:
  targetRefs:
    - group: ""
      kind: Service
      name: vllm-gpt4-primary
  sessionPersistence:
    sessionName: "model-session"
    type: Cookie
  # æŒ‡å®šé™çº§åç«¯
  default:
    backendRef:
      name: vllm-gpt4-fallback
      port: 8000
```

### è¶…æ—¶é…ç½®

ä¸ºæ¨ç†è¯·æ±‚è®¾ç½®è¶…æ—¶ã€‚

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: timeout-config
  namespace: ai-gateway
spec:
  parentRefs:
    - name: ai-inference-gateway

  rules:
    - matches:
        - path:
            type: PathPrefix
            value: /v1/chat/completions
      backendRefs:
        - name: vllm-service
          port: 8000
      timeouts:
        # è¯·æ±‚è¶…æ—¶ï¼ˆæ€»è¯·æ±‚å¤„ç†æ—¶é—´ï¼‰
        request: 120s
        # åç«¯è¿æ¥è¶…æ—¶
        backendRequest: 60s
```

### é‡è¯•ç­–ç•¥

ä¸ºç¬æ—¶æ•…éšœé…ç½®è‡ªåŠ¨é‡è¯•ã€‚

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: retry-policy
  namespace: ai-gateway
spec:
  parentRefs:
    - name: ai-inference-gateway

  rules:
    - matches:
        - path:
            type: PathPrefix
            value: /v1/chat/completions
      backendRefs:
        - name: vllm-service
          port: 8000
      # é‡è¯•é…ç½®ï¼ˆKgateway æ‰©å±•ï¼‰
      filters:
        - type: ExtensionRef
          extensionRef:
            group: kgateway.dev
            kind: RetryPolicy
            name: inference-retry-policy
---
apiVersion: kgateway.dev/v1alpha1
kind: RetryPolicy
metadata:
  name: inference-retry-policy
  namespace: ai-gateway
spec:
  # æœ€å¤§é‡è¯•æ¬¡æ•°
  numRetries: 3

  # é‡è¯•æ¡ä»¶
  retryOn:
    - "5xx"
    - "reset"
    - "connect-failure"
    - "retriable-4xx"

  # æ¯æ¬¡å°è¯•è¶…æ—¶
  perTryTimeout: 30s

  # é€€é¿é…ç½®
  retryBackOff:
    baseInterval: 100ms
    maxInterval: 1s
```

### ç†”æ–­å™¨é…ç½®

è¿ç»­æ•…éšœæ—¶ä¸´æ—¶é˜»æ–­åç«¯ã€‚

```yaml
apiVersion: kgateway.dev/v1alpha1
kind: CircuitBreakerPolicy
metadata:
  name: inference-circuit-breaker
  namespace: ai-gateway
spec:
  targetRefs:
    - group: ""
      kind: Service
      name: vllm-gpt4-service

  # æœ€å¤§å¹¶å‘è¿æ¥æ•°
  maxConnections: 1000

  # æœ€å¤§æŒ‚èµ·è¯·æ±‚æ•°
  maxPendingRequests: 100

  # æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
  maxRequests: 1000

  # è¿ç»­å¤±è´¥é˜ˆå€¼
  consecutiveErrors: 5

  # é˜»æ–­æŒç»­æ—¶é—´
  interval: 10s

  # è§£é™¤é˜»æ–­åçš„æµ‹è¯•è¯·æ±‚
  maxEjectionPercent: 50
```

:::danger æ•…éšœå“åº”é…ç½®æ³¨æ„äº‹é¡¹

- **è¶…æ—¶è®¾ç½®**ï¼šLLM æ¨ç†å¯èƒ½è€—æ—¶è¾ƒé•¿ï¼Œéœ€è®¾ç½®å……è¶³çš„è¶…æ—¶æ—¶é—´
- **é‡è¯•é™åˆ¶**ï¼šæ— é™é‡è¯•å¯èƒ½å¯¼è‡´ç³»ç»Ÿè¿‡è½½
- **ç†”æ–­å™¨**ï¼šè®¾ç½®è¿‡äºæ•æ„Ÿå¯èƒ½é˜»æ–­æ­£å¸¸æµé‡

:::

---

## ç›‘æ§ä¸å¯è§‚æµ‹æ€§

### Prometheus æŒ‡æ ‡

Kgateway æš´éœ²çš„å…³é”®æŒ‡æ ‡ã€‚

import { MonitoringMetricsTable } from '@site/src/components/InferenceGatewayTables';

<MonitoringMetricsTable />

{/* Original table preserved for reference
| Metric | Description | Usage |
|--------|------|------|
| `kgateway_requests_total` | Total request count | Traffic monitoring |
| `kgateway_request_duration_seconds` | Request processing time | Latency analysis |
| `kgateway_upstream_rq_xx` | Backend response codes | Error tracking |
| `kgateway_upstream_cx_active` | Active connections | Capacity planning |
| `kgateway_retry_count` | Retry count | Stability analysis |
*/}

### ServiceMonitor é…ç½®

```yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: kgateway-metrics
  namespace: monitoring
spec:
  selector:
    matchLabels:
      app: kgateway
  namespaceSelector:
    matchNames:
      - kgateway-system
  endpoints:
    - port: metrics
      interval: 15s
      path: /metrics
```

### Grafana ä»ªè¡¨æ¿æŸ¥è¯¢ç¤ºä¾‹

```promql
# æ¯ç§’è¯·æ±‚æ•°ï¼ˆRPSï¼‰
sum(rate(kgateway_requests_total[5m])) by (route)

# P99 å»¶è¿Ÿ
histogram_quantile(0.99,
  sum(rate(kgateway_request_duration_seconds_bucket[5m])) by (le, route)
)

# é”™è¯¯ç‡
sum(rate(kgateway_upstream_rq_5xx[5m])) /
sum(rate(kgateway_requests_total[5m])) * 100

# æŒ‰åç«¯çš„æ´»è·ƒè¿æ¥æ•°
sum(kgateway_upstream_cx_active) by (upstream_cluster)
```

### å‘Šè­¦è§„åˆ™

```yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kgateway-alerts
  namespace: monitoring
spec:
  groups:
    - name: kgateway-alerts
      rules:
        - alert: HighErrorRate
          expr: |
            sum(rate(kgateway_upstream_rq_5xx[5m])) /
            sum(rate(kgateway_requests_total[5m])) > 0.05
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "æ¨ç†ç½‘å…³é”™è¯¯ç‡è¶…è¿‡ 5%"
            description: "è¿‡å» 5 åˆ†é’Ÿçš„é”™è¯¯ç‡ä¸º {{ $value | humanizePercentage }}"

        - alert: HighLatency
          expr: |
            histogram_quantile(0.99,
              sum(rate(kgateway_request_duration_seconds_bucket[5m])) by (le)
            ) > 30
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "æ¨ç†ç½‘å…³ P99 å»¶è¿Ÿè¶…è¿‡ 30 ç§’"

        - alert: CircuitBreakerOpen
          expr: kgateway_circuit_breaker_open == 1
          for: 1m
          labels:
            severity: critical
          annotations:
            summary: "ç†”æ–­å™¨å·²æ¿€æ´»"
            description: "{{ $labels.upstream_cluster }} çš„ç†”æ–­å™¨å·²æ‰“å¼€"
```

---

## è¿ç»´æœ€ä½³å®è·µ

### è·¯ç”±è§„åˆ™ç®¡ç†

1. **ç‰ˆæœ¬æ§åˆ¶**ï¼šä½¿ç”¨ Git ç®¡ç† HTTPRoute ä»¥è¿½è¸ªå˜æ›´
2. **å‘½åç©ºé—´åˆ†ç¦»**ï¼šæŒ‰ç¯å¢ƒï¼ˆdev/staging/prodï¼‰åˆ†ç¦»å‘½åç©ºé—´
3. **æ ‡ç­¾åŒ–**ï¼šä½¿ç”¨ä¸€è‡´çš„æ ‡ç­¾ä¾¿äºèµ„æºç®¡ç†

### æ€§èƒ½ä¼˜åŒ–

```yaml
# è¿æ¥æ± ä¼˜åŒ–
apiVersion: kgateway.dev/v1alpha1
kind: ConnectionPoolSettings
metadata:
  name: inference-connection-pool
spec:
  targetRefs:
    - kind: Service
      name: vllm-service
  tcp:
    maxConnections: 1000
    connectTimeout: 10s
  http:
    h2UpgradePolicy: UPGRADE
    maxRequestsPerConnection: 100
    maxRetries: 3
```

### å®‰å…¨é…ç½®

```yaml
# é€Ÿç‡é™åˆ¶
apiVersion: kgateway.dev/v1alpha1
kind: RateLimitPolicy
metadata:
  name: inference-rate-limit
spec:
  targetRefs:
    - kind: HTTPRoute
      name: model-routing
  local:
    tokenBucket:
      maxTokens: 1000
      tokensPerFill: 100
      fillInterval: 1s
  # æ¯ç§Ÿæˆ·é€Ÿç‡é™åˆ¶
  descriptors:
    - entries:
        - key: x-tenant-id
      limit:
        requestsPerUnit: 100
        unit: MINUTE
```

---

## æ€»ç»“

æ¨ç†ç½‘å…³æ˜¯ AI æ¨¡å‹æœåŠ¡ç¯å¢ƒä¸­æµé‡ç®¡ç†çš„æ ¸å¿ƒç»„ä»¶ã€‚

### æ ¸å¿ƒè¦ç‚¹

1. **Kubernetes Gateway API**ï¼šåŸºäºæ ‡å‡†çš„é…ç½®ç¡®ä¿å¯ç§»æ¤æ€§
2. **åŠ¨æ€è·¯ç”±**ï¼šçµæ´»çš„åŸºäº Header å’Œè·¯å¾„çš„è·¯ç”±è§„åˆ™
3. **è´Ÿè½½å‡è¡¡**ï¼šåŸºäºæƒé‡çš„æµé‡åˆ†é…æ”¯æŒæ¸è¿›å¼éƒ¨ç½²
4. **æ•…éšœå“åº”**ï¼šè¶…æ—¶ã€é‡è¯•å’Œç†”æ–­å™¨ç¡®ä¿å¯é æ€§
5. **å¯è§‚æµ‹æ€§**ï¼šé€šè¿‡ Prometheus æŒ‡æ ‡è¿›è¡Œå®æ—¶ç›‘æ§

### åç»­æ­¥éª¤

- [GPU èµ„æºç®¡ç†](./gpu-resource-management.md) - åŠ¨æ€èµ„æºåˆ†é…ç­–ç•¥
- [MoE æ¨¡å‹æœåŠ¡](./moe-model-serving.md) - Mixture of Experts æ¨¡å‹éƒ¨ç½²
- [Agent ç›‘æ§](./agent-monitoring.md) - LangFuse é›†æˆæŒ‡å—

---

## å‚è€ƒèµ„æ–™

- [Kubernetes Gateway API å®˜æ–¹æ–‡æ¡£](https://gateway-api.sigs.k8s.io/)
- [Kgateway å®˜æ–¹æ–‡æ¡£](https://kgateway.dev/docs/)
- [vLLM å®˜æ–¹æ–‡æ¡£](https://docs.vllm.ai/)
- [Envoy Proxy æ–‡æ¡£](https://www.envoyproxy.io/docs/)
