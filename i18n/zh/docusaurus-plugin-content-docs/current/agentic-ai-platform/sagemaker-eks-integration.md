---
title: "SageMaker-EKS æ··åˆ ML æ¶æ„"
sidebar_label: "16. SageMaker-EKS Integration"
description: "æ··åˆ ML æ¶æ„ï¼šåœ¨ SageMaker ä¸Šè®­ç»ƒï¼Œåœ¨ EKS ä¸ŠæœåŠ¡"
sidebar_position: 16
category: "aiops-aidlc"
tags: [sagemaker, eks, hybrid, mlops, model-registry, training, inference]
last_update:
  date: 2026-02-14
  author: devfloor9
---

import SpecificationTable from '@site/src/components/tables/SpecificationTable';
import { HybridComparison, CostOptimization } from '@site/src/components/SagemakerTables';

# SageMaker-EKS æ··åˆ ML æ¶æ„

> ğŸ“… **æ’°å†™æ—¥æœŸ**: 2025-02-05 | **ä¿®æ”¹æ—¥æœŸ**: 2026-02-14 | â±ï¸ **é˜…è¯»æ—¶é—´**: çº¦ 18 åˆ†é’Ÿ

## æ¦‚è¿°

è®¾è®¡ä¸€ç§æ··åˆ ML æ¶æ„ï¼Œå°† SageMaker çš„æ‰˜ç®¡è®­ç»ƒç¯å¢ƒä¸ EKS çµæ´»çš„æœåŠ¡åŸºç¡€è®¾æ–½ç›¸ç»“åˆã€‚è¿™ç§æ–¹æ³•åˆ©ç”¨å„å¹³å°çš„ä¼˜åŠ¿ï¼ŒåŒæ—¶å®ç°æˆæœ¬æ•ˆç‡å’Œè¿è¥çµæ´»æ€§ã€‚

### æ··åˆæ¶æ„çš„ä¼˜åŠ¿

<HybridComparison />


## æ··åˆæ¶æ„æ¨¡å¼

### æ•´ä½“æ¶æ„æ¦‚è§ˆ

```mermaid
flowchart TB
    subgraph "SageMaker Training"
        SM_NB[SageMaker Notebooks<br/>Development]
        SM_TRAIN[SageMaker Training Jobs<br/>Managed Training]
        SM_PIPE[SageMaker Pipelines<br/>Orchestration]
        SM_REG[SageMaker Model Registry<br/>Central Governance]
    end

    subgraph "EKS Serving"
        KSERVE[KServe<br/>Model Serving]
        TRITON[Triton Inference Server<br/>GPU Optimization]
        GATEWAY[Inference Gateway<br/>Traffic Management]
        MONITOR[Prometheus + Grafana<br/>Monitoring]
    end

    subgraph "Shared Storage"
        S3[S3 Model Artifacts<br/>Versioned Storage]
        ECR[ECR Container Registry<br/>Custom Images]
    end

    SM_NB --> SM_TRAIN
    SM_TRAIN --> SM_PIPE
    SM_PIPE --> SM_REG
    SM_REG --> S3

    S3 --> KSERVE
    ECR --> KSERVE
    KSERVE --> TRITON
    TRITON --> GATEWAY
    GATEWAY --> MONITOR

    SM_PIPE -.->|Trigger Deployment| KSERVE

    style SM_TRAIN fill:#ff9900
    style KSERVE fill:#326ce5
    style S3 fill:#569a31
```

### æ¨¡å¼ 1ï¼šSageMaker è®­ç»ƒ â†’ EKS æœåŠ¡

æœ€å¸¸è§çš„æ··åˆæ¨¡å¼ï¼Œåœ¨ SageMaker ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œåœ¨ EKS ä¸Šæä¾›æœåŠ¡ã€‚

**ä½¿ç”¨åœºæ™¯ï¼š**
- éœ€è¦å¤§è§„æ¨¡åˆ†å¸ƒå¼è®­ç»ƒçš„æƒ…å†µ
- å¸Œæœ›å‡å°‘è®­ç»ƒåŸºç¡€è®¾æ–½ç®¡ç†è´Ÿæ‹…çš„æƒ…å†µ
- æœåŠ¡ç¯å¢ƒä¸­éœ€è¦ç²¾ç»†æ§åˆ¶çš„æƒ…å†µ


### æ¨¡å¼ 2ï¼šEKS è®­ç»ƒ â†’ SageMaker æœåŠ¡

éœ€è¦ç‰¹æ®Šè®­ç»ƒç¯å¢ƒï¼Œä½†å¸Œæœ›ä»¥æ‰˜ç®¡æ–¹å¼è¿è¥æœåŠ¡çš„æƒ…å†µã€‚

**ä½¿ç”¨åœºæ™¯ï¼š**
- ä½¿ç”¨è‡ªå®šä¹‰è®­ç»ƒæ¡†æ¶
- åˆ©ç”¨ Kubernetes åŸç”Ÿè®­ç»ƒå·¥å…·ï¼ˆKubeflowã€Rayï¼‰
- å¸Œæœ›å‡å°‘æœåŠ¡åŸºç¡€è®¾æ–½ç®¡ç†è´Ÿæ‹…çš„æƒ…å†µ

### æ¨¡å¼ 3ï¼šæ··åˆæœåŠ¡

åŒæ—¶è¿è¥ SageMaker Endpoint å’Œ EKS æœåŠ¡ä»¥åˆ†æ•£å·¥ä½œè´Ÿè½½ã€‚

**ä½¿ç”¨åœºæ™¯ï¼š**
- é«˜å¯ç”¨æ€§è‡³å…³é‡è¦çš„ç”Ÿäº§ç¯å¢ƒ
- å¤šåŒºåŸŸéƒ¨ç½²
- A/B æµ‹è¯•å’Œé‡‘ä¸é›€éƒ¨ç½²

---

## SageMaker Pipelines é›†æˆ

### SageMaker Components for Kubeflow Pipelines

AWS æä¾›äº†å®˜æ–¹ç»„ä»¶ï¼Œå¯ä»¥åœ¨ Kubeflow Pipelines ä¸­è°ƒç”¨ SageMakerã€‚

```python
# sagemaker_kubeflow_pipeline.py
import kfp
from kfp import dsl
from kfp.aws import use_aws_secret
import sagemaker
from sagemaker.workflow.pipeline_context import PipelineSession

@dsl.component(
    base_image="public.ecr.aws/sagemaker/sagemaker-distribution:latest",
    packages_to_install=["sagemaker>=2.200.0"]
)
def sagemaker_training_component(
    training_image: str,
    role_arn: str,
    instance_type: str,
    instance_count: int,
    s3_input_data: str,
    s3_output_path: str,
    hyperparameters: dict
) -> str:
    """æ‰§è¡Œ SageMaker Training Job çš„ç»„ä»¶"""
    import boto3
    import sagemaker
    from sagemaker.estimator import Estimator

    session = sagemaker.Session()

    estimator = Estimator(
        image_uri=training_image,
        role=role_arn,
        instance_count=instance_count,
        instance_type=instance_type,
        output_path=s3_output_path,
        sagemaker_session=session,
        hyperparameters=hyperparameters
    )

    estimator.fit({"training": s3_input_data}, wait=True)

    # è¿”å›æ¨¡å‹å·¥ä»¶è·¯å¾„
    return estimator.model_data


@dsl.component(
    base_image="public.ecr.aws/sagemaker/sagemaker-distribution:latest",
    packages_to_install=["sagemaker>=2.200.0"]
)
def register_model_to_registry(
    model_data: str,
    model_package_group_name: str,
    inference_image: str,
    role_arn: str
) -> str:
    """å°†æ¨¡å‹æ³¨å†Œåˆ° SageMaker Model Registry"""
    import boto3
    import sagemaker
    from sagemaker.model import Model

    session = sagemaker.Session()

    model = Model(
        image_uri=inference_image,
        model_data=model_data,
        role=role_arn,
        sagemaker_session=session
    )

    # æ³¨å†Œåˆ° Model Registry
    model_package = model.register(
        content_types=["application/json"],
        response_types=["application/json"],
        inference_instances=["ml.g5.xlarge"],
        transform_instances=["ml.g5.xlarge"],
        model_package_group_name=model_package_group_name,
        approval_status="PendingManualApproval"
    )

    return model_package.model_package_arn


@dsl.component(
    base_image="python:3.10",
    packages_to_install=["kubernetes", "boto3"]
)
def deploy_to_kserve(
    model_package_arn: str,
    model_name: str,
    namespace: str = "kserve-inference"
) -> str:
    """éƒ¨ç½² KServe InferenceService"""
    import boto3
    from kubernetes import client, config

    # ä» SageMaker Model Registry æŸ¥è¯¢æ¨¡å‹ä¿¡æ¯
    sm_client = boto3.client('sagemaker')
    model_package = sm_client.describe_model_package(
        ModelPackageName=model_package_arn
    )

    model_data_url = model_package['InferenceSpecification']['Containers'][0]['ModelDataUrl']

    # åˆ›å»º KServe InferenceService
    config.load_incluster_config()
    custom_api = client.CustomObjectsApi()

    inference_service = {
        "apiVersion": "serving.kserve.io/v1beta1",
        "kind": "InferenceService",
        "metadata": {
            "name": model_name,
            "namespace": namespace
        },
        "spec": {
            "predictor": {
                "pytorch": {
                    "storageUri": model_data_url,
                    "resources": {
                        "requests": {
                            "nvidia.com/gpu": "1",
                            "memory": "8Gi"
                        },
                        "limits": {
                            "nvidia.com/gpu": "1",
                            "memory": "16Gi"
                        }
                    }
                }
            },
            "minReplicas": 2,
            "maxReplicas": 10
        }
    }

    custom_api.create_namespaced_custom_object(
        group="serving.kserve.io",
        version="v1beta1",
        namespace=namespace,
        plural="inferenceservices",
        body=inference_service
    )

    return f"Deployed {model_name} to KServe"


@dsl.pipeline(
    name="SageMaker to EKS Hybrid Pipeline",
    description="Train on SageMaker, deploy to EKS"
)
def hybrid_ml_pipeline(
    training_image: str = "763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-training:2.1.0-gpu-py310",
    inference_image: str = "763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-inference:2.1.0-gpu-py310",
    role_arn: str = "arn:aws:iam::123456789012:role/SageMakerExecutionRole",
    instance_type: str = "ml.g5.2xlarge",
    s3_input_data: str = "s3://my-bucket/training-data/",
    s3_output_path: str = "s3://my-bucket/models/",
    model_package_group: str = "fraud-detection-models"
):
    # 1. åœ¨ SageMaker ä¸Šè®­ç»ƒ
    training_task = sagemaker_training_component(
        training_image=training_image,
        role_arn=role_arn,
        instance_type=instance_type,
        instance_count=2,
        s3_input_data=s3_input_data,
        s3_output_path=s3_output_path,
        hyperparameters={
            "epochs": "50",
            "batch-size": "64",
            "learning-rate": "0.001"
        }
    )
    training_task.apply(use_aws_secret('aws-secret', 'AWS_ACCESS_KEY_ID', 'AWS_SECRET_ACCESS_KEY'))

    # 2. æ³¨å†Œåˆ° Model Registry
    registry_task = register_model_to_registry(
        model_data=training_task.output,
        model_package_group_name=model_package_group,
        inference_image=inference_image,
        role_arn=role_arn
    )
    registry_task.apply(use_aws_secret('aws-secret', 'AWS_ACCESS_KEY_ID', 'AWS_SECRET_ACCESS_KEY'))

    # 3. éƒ¨ç½²åˆ° EKS KServe
    deploy_task = deploy_to_kserve(
        model_package_arn=registry_task.output,
        model_name="fraud-detection-v1",
        namespace="kserve-inference"
    )

    return deploy_task.output
```


---

## SageMaker Model Registry æ²»ç†

### é›†ä¸­å¼æ¨¡å‹ç®¡ç†

SageMaker Model Registry ä½œä¸ºæ‰€æœ‰æ¨¡å‹çš„ä¸­å¤®å­˜å‚¨åº“ï¼Œåœ¨ EKS æœåŠ¡ç¯å¢ƒä¸­ä¹Ÿå¯ä»¥åº”ç”¨ç›¸åŒçš„æ²»ç†ç­–ç•¥ã€‚

```mermaid
flowchart TB
    subgraph "Model Lifecycle"
        DEV[å¼€å‘ç¯å¢ƒ<br/>å®éªŒæ¨¡å‹]
        STAGING[é¢„å‘å¸ƒ<br/>éªŒè¯ä¸­]
        PROD[ç”Ÿäº§<br/>å·²æ‰¹å‡†æ¨¡å‹]
        ARCHIVED[å½’æ¡£<br/>å·²åºŸå¼ƒæ¨¡å‹]
    end

    subgraph "Approval Process"
        AUTO[è‡ªåŠ¨æ‰¹å‡†<br/>åŸºäºæŒ‡æ ‡]
        MANUAL[æ‰‹åŠ¨æ‰¹å‡†<br/>éœ€è¦å®¡æ ¸]
    end

    subgraph "Deployment Targets"
        SM_EP[SageMaker Endpoint]
        EKS_KSERVE[EKS KServe]
        BATCH[Batch Transform]
    end

    DEV --> STAGING
    STAGING --> AUTO
    STAGING --> MANUAL
    AUTO --> PROD
    MANUAL --> PROD
    PROD --> ARCHIVED

    PROD --> SM_EP
    PROD --> EKS_KSERVE
    PROD --> BATCH

    style PROD fill:#34a853
    style STAGING fill:#fbbc04
    style ARCHIVED fill:#ea4335
```

### Model Registry è®¾ç½®

```python
# model_registry_setup.py
import boto3
import sagemaker
from sagemaker.model_package import ModelPackageGroup

sm_client = boto3.client('sagemaker')
session = sagemaker.Session()

# åˆ›å»º Model Package Group
model_package_group_name = "fraud-detection-models"

try:
    sm_client.create_model_package_group(
        ModelPackageGroupName=model_package_group_name,
        ModelPackageGroupDescription="Fraud detection models for production",
        Tags=[
            {"Key": "Team", "Value": "ml-platform"},
            {"Key": "Environment", "Value": "production"}
        ]
    )
except sm_client.exceptions.ResourceInUse:
    print(f"Model package group {model_package_group_name} already exists")

# è®¾ç½®æ¨¡å‹æ‰¹å‡†ç­–ç•¥
model_approval_policy = {
    "Rules": [
        {
            "Name": "AutoApproveHighAccuracy",
            "Condition": {
                "MetricName": "accuracy",
                "Operator": "GreaterThanOrEqualTo",
                "Value": 0.95
            },
            "Action": "Approve"
        },
        {
            "Name": "RejectLowAccuracy",
            "Condition": {
                "MetricName": "accuracy",
                "Operator": "LessThan",
                "Value": 0.85
            },
            "Action": "Reject"
        }
    ]
}
```

### ä» EKS æŸ¥è¯¢ Model Registry

```python
# eks_model_loader.py
import boto3
from kubernetes import client, config

def get_approved_model_from_registry(model_package_group_name: str) -> str:
    """ä» Model Registry æŸ¥è¯¢å·²æ‰¹å‡†çš„æœ€æ–°æ¨¡å‹"""
    sm_client = boto3.client('sagemaker')

    # æŸ¥è¯¢å·²æ‰¹å‡†çš„æ¨¡å‹åŒ…
    response = sm_client.list_model_packages(
        ModelPackageGroupName=model_package_group_name,
        ModelApprovalStatus='Approved',
        SortBy='CreationTime',
        SortOrder='Descending',
        MaxResults=1
    )

    if not response['ModelPackageSummaryList']:
        raise ValueError(f"No approved models found in {model_package_group_name}")

    model_package_arn = response['ModelPackageSummaryList'][0]['ModelPackageArn']

    # æŸ¥è¯¢æ¨¡å‹è¯¦ç»†ä¿¡æ¯
    model_package = sm_client.describe_model_package(
        ModelPackageName=model_package_arn
    )

    model_data_url = model_package['InferenceSpecification']['Containers'][0]['ModelDataUrl']

    return model_data_url


def update_kserve_with_latest_model(model_name: str, namespace: str):
    """ä½¿ç”¨æœ€æ–°å·²æ‰¹å‡†æ¨¡å‹æ›´æ–° KServe InferenceService"""
    config.load_incluster_config()
    custom_api = client.CustomObjectsApi()

    # ä» Model Registry æŸ¥è¯¢æœ€æ–°æ¨¡å‹
    model_url = get_approved_model_from_registry("fraud-detection-models")

    # æ›´æ–° InferenceService
    patch_body = {
        "spec": {
            "predictor": {
                "pytorch": {
                    "storageUri": model_url
                }
            }
        }
    }

    custom_api.patch_namespaced_custom_object(
        group="serving.kserve.io",
        version="v1beta1",
        namespace=namespace,
        plural="inferenceservices",
        name=model_name,
        body=patch_body
    )

    print(f"Updated {model_name} with model from {model_url}")
```


---

## æˆæœ¬ä¼˜åŒ–ç­–ç•¥

### è®­ç»ƒ vs æœåŠ¡æˆæœ¬åˆ†æ

<CostOptimization />

### æˆæœ¬ä¼˜åŒ–æ£€æŸ¥æ¸…å•

```yaml
# cost-optimization-config.yaml
training:
  # SageMaker Managed Spot Trainingï¼ˆæœ€é«˜èŠ‚çœ 90%ï¼‰
  use_spot_instances: true
  max_wait_time_seconds: 86400  # 24å°æ—¶
  max_run_time_seconds: 43200   # 12å°æ—¶

  # å¯ç”¨æ£€æŸ¥ç‚¹ï¼ˆåº”å¯¹ Spot ä¸­æ–­ï¼‰
  checkpoint_s3_uri: s3://my-bucket/checkpoints/
  checkpoint_local_path: /opt/ml/checkpoints

  # å®ä¾‹ç±»å‹ä¼˜åŒ–
  instance_type: ml.g5.2xlarge  # GPU è®­ç»ƒ
  instance_count: 2

  # è®­ç»ƒå®Œæˆåè‡ªåŠ¨ç»ˆæ­¢
  auto_terminate: true

serving:
  # Karpenter Spot å®ä¾‹ï¼ˆæœ€é«˜èŠ‚çœ 70%ï¼‰
  capacity_type: spot

  # è‡ªåŠ¨æ‰©ç¼©è®¾ç½®
  min_replicas: 1
  max_replicas: 10
  target_utilization: 70

  # ç©ºé—²æ—¶é—´ç¼©å®¹
  scale_down_delay: 300  # 5åˆ†é’Ÿ

  # GPU å…±äº«ï¼ˆMIG æˆ– MPSï¼‰
  enable_gpu_sharing: true
  max_shared_clients: 4

storage:
  # S3 Intelligent-Tiering
  s3_storage_class: INTELLIGENT_TIERING

  # æ—§æ¨¡å‹å½’æ¡£
  lifecycle_policy:
    archive_after_days: 90
    delete_after_days: 365
```

### æˆæœ¬ç›‘æ§ä»ªè¡¨æ¿

```python
# cost_monitoring.py
import boto3
from datetime import datetime, timedelta

def get_sagemaker_training_costs(days=30):
    """æŸ¥è¯¢ SageMaker è®­ç»ƒæˆæœ¬"""
    ce_client = boto3.client('ce')

    end_date = datetime.now().date()
    start_date = end_date - timedelta(days=days)

    response = ce_client.get_cost_and_usage(
        TimePeriod={
            'Start': start_date.strftime('%Y-%m-%d'),
            'End': end_date.strftime('%Y-%m-%d')
        },
        Granularity='DAILY',
        Metrics=['UnblendedCost'],
        Filter={
            'Dimensions': {
                'Key': 'SERVICE',
                'Values': ['Amazon SageMaker']
            }
        },
        GroupBy=[
            {'Type': 'DIMENSION', 'Key': 'USAGE_TYPE'}
        ]
    )

    return response


def get_eks_serving_costs(cluster_name: str, days=30):
    """æŸ¥è¯¢ EKS æœåŠ¡æˆæœ¬"""
    ce_client = boto3.client('ce')

    end_date = datetime.now().date()
    start_date = end_date - timedelta(days=days)

    response = ce_client.get_cost_and_usage(
        TimePeriod={
            'Start': start_date.strftime('%Y-%m-%d'),
            'End': end_date.strftime('%Y-%m-%d')
        },
        Granularity='DAILY',
        Metrics=['UnblendedCost'],
        Filter={
            'And': [
                {
                    'Dimensions': {
                        'Key': 'SERVICE',
                        'Values': ['Amazon Elastic Compute Cloud - Compute']
                    }
                },
                {
                    'Tags': {
                        'Key': 'kubernetes.io/cluster/' + cluster_name,
                        'Values': ['owned']
                    }
                }
            ]
        }
    )

    return response
```


---

## å¤šåŒºåŸŸéƒ¨ç½²æ¨¡å¼

### å…¨çƒæ¨¡å‹éƒ¨ç½²æ¶æ„

```mermaid
flowchart TB
    subgraph "Primary Region (us-west-2)"
        SM_TRAIN[SageMaker Training]
        SM_REG[Model Registry<br/>Primary]
        S3_PRIMARY[S3 Model Artifacts<br/>Primary]
    end

    subgraph "Secondary Region (ap-northeast-2)"
        S3_REPLICA[S3 Model Artifacts<br/>Replica]
        EKS_AP[EKS Cluster<br/>Seoul]
        KSERVE_AP[KServe<br/>Asia Pacific]
    end

    subgraph "Secondary Region (eu-west-1)"
        S3_EU[S3 Model Artifacts<br/>Replica]
        EKS_EU[EKS Cluster<br/>Ireland]
        KSERVE_EU[KServe<br/>Europe]
    end

    subgraph "Global Traffic Management"
        R53[Route 53<br/>Geo Routing]
        CLOUDFRONT[CloudFront<br/>Edge Caching]
    end

    SM_TRAIN --> SM_REG
    SM_REG --> S3_PRIMARY

    S3_PRIMARY -->|S3 Cross-Region Replication| S3_REPLICA
    S3_PRIMARY -->|S3 Cross-Region Replication| S3_EU

    S3_REPLICA --> EKS_AP
    EKS_AP --> KSERVE_AP

    S3_EU --> EKS_EU
    EKS_EU --> KSERVE_EU

    R53 --> KSERVE_AP
    R53 --> KSERVE_EU
    CLOUDFRONT --> R53

    style SM_TRAIN fill:#ff9900
    style KSERVE_AP fill:#326ce5
    style KSERVE_EU fill:#326ce5
```

### S3 Cross-Region Replication è®¾ç½®

```json
{
  "Role": "arn:aws:iam::123456789012:role/S3ReplicationRole",
  "Rules": [
    {
      "ID": "ReplicateModelsToAPNE2",
      "Status": "Enabled",
      "Priority": 1,
      "Filter": {
        "Prefix": "models/"
      },
      "Destination": {
        "Bucket": "arn:aws:s3:::my-models-ap-northeast-2",
        "ReplicationTime": {
          "Status": "Enabled",
          "Time": {
            "Minutes": 15
          }
        },
        "Metrics": {
          "Status": "Enabled",
          "EventThreshold": {
            "Minutes": 15
          }
        }
      }
    },
    {
      "ID": "ReplicateModelsToEUW1",
      "Status": "Enabled",
      "Priority": 2,
      "Filter": {
        "Prefix": "models/"
      },
      "Destination": {
        "Bucket": "arn:aws:s3:::my-models-eu-west-1",
        "ReplicationTime": {
          "Status": "Enabled",
          "Time": {
            "Minutes": 15
          }
        }
      }
    }
  ]
}
```

### å¤šåŒºåŸŸéƒ¨ç½²è‡ªåŠ¨åŒ–

```python
# multi_region_deployment.py
import boto3
from typing import List, Dict

class MultiRegionDeployer:
    def __init__(self, regions: List[str]):
        self.regions = regions
        self.sm_clients = {
            region: boto3.client('sagemaker', region_name=region)
            for region in regions
        }

    def deploy_model_to_all_regions(
        self,
        model_package_arn: str,
        model_name: str,
        namespace: str = "kserve-inference"
    ):
        """å°†æ¨¡å‹éƒ¨ç½²åˆ°æ‰€æœ‰åŒºåŸŸ"""
        deployment_results = {}

        for region in self.regions:
            try:
                # ä»åŒºåŸŸçº§ S3 å­˜å‚¨æ¡¶åŠ è½½æ¨¡å‹
                model_url = self._get_regional_model_url(model_package_arn, region)

                # éƒ¨ç½²åˆ°åŒºåŸŸçº§ EKS é›†ç¾¤
                result = self._deploy_to_eks(
                    region=region,
                    model_url=model_url,
                    model_name=model_name,
                    namespace=namespace
                )

                deployment_results[region] = {
                    "status": "success",
                    "model_url": model_url,
                    "endpoint": result
                }

            except Exception as e:
                deployment_results[region] = {
                    "status": "failed",
                    "error": str(e)
                }

        return deployment_results

    def _get_regional_model_url(self, model_package_arn: str, region: str) -> str:
        """æŸ¥è¯¢åŒºåŸŸçº§æ¨¡å‹ URL"""
        sm_client = self.sm_clients[region]

        # ä» Model Registry æŸ¥è¯¢æ¨¡å‹ä¿¡æ¯
        model_package = sm_client.describe_model_package(
            ModelPackageName=model_package_arn
        )

        # è½¬æ¢ä¸ºåŒºåŸŸçº§ S3 å­˜å‚¨æ¡¶
        original_url = model_package['InferenceSpecification']['Containers'][0]['ModelDataUrl']
        regional_url = original_url.replace('us-west-2', region)

        return regional_url

    def _deploy_to_eks(
        self,
        region: str,
        model_url: str,
        model_name: str,
        namespace: str
    ) -> str:
        """éƒ¨ç½²åˆ°åŒºåŸŸçº§ EKS é›†ç¾¤"""
        from kubernetes import client, config

        # åŠ è½½åŒºåŸŸçº§ kubeconfig
        config.load_kube_config(context=f"eks-{region}")

        custom_api = client.CustomObjectsApi()

        inference_service = {
            "apiVersion": "serving.kserve.io/v1beta1",
            "kind": "InferenceService",
            "metadata": {
                "name": f"{model_name}-{region}",
                "namespace": namespace
            },
            "spec": {
                "predictor": {
                    "pytorch": {
                        "storageUri": model_url,
                        "resources": {
                            "requests": {"nvidia.com/gpu": "1"},
                            "limits": {"nvidia.com/gpu": "1"}
                        }
                    }
                },
                "minReplicas": 2,
                "maxReplicas": 10
            }
        }

        custom_api.create_namespaced_custom_object(
            group="serving.kserve.io",
            version="v1beta1",
            namespace=namespace,
            plural="inferenceservices",
            body=inference_service
        )

        return f"https://{model_name}-{region}.{namespace}.svc.cluster.local"


# ä½¿ç”¨ç¤ºä¾‹
deployer = MultiRegionDeployer(
    regions=["us-west-2", "ap-northeast-2", "eu-west-1"]
)

results = deployer.deploy_model_to_all_regions(
    model_package_arn="arn:aws:sagemaker:us-west-2:123456789012:model-package/fraud-detection/1",
    model_name="fraud-detection-v1"
)

print(results)
```


---

## æ¨¡å‹ç›‘æ§ä¸æ¼‚ç§»æ£€æµ‹

### ç»Ÿä¸€ç›‘æ§æ¶æ„

```mermaid
flowchart TB
    subgraph "Data Collection"
        KSERVE[KServe Predictor<br/>Inference Requests]
        LOGGER[Request Logger<br/>Sidecar]
    end

    subgraph "SageMaker Model Monitor"
        DATA_QUALITY[Data Quality Monitor<br/>Input Drift]
        MODEL_QUALITY[Model Quality Monitor<br/>Prediction Drift]
        BIAS[Bias Monitor<br/>Fairness]
        EXPLAINABILITY[Explainability Monitor<br/>Feature Attribution]
    end

    subgraph "Storage & Analysis"
        S3_LOGS[S3 Inference Logs<br/>Structured Data]
        ATHENA[Amazon Athena<br/>SQL Analysis]
    end

    subgraph "Alerting"
        CW_ALARMS[CloudWatch Alarms<br/>Threshold Violations]
        SNS[SNS Topics<br/>Notifications]
        LAMBDA[Lambda Functions<br/>Auto-remediation]
    end

    KSERVE --> LOGGER
    LOGGER --> S3_LOGS

    S3_LOGS --> DATA_QUALITY
    S3_LOGS --> MODEL_QUALITY
    S3_LOGS --> BIAS
    S3_LOGS --> EXPLAINABILITY

    S3_LOGS --> ATHENA

    DATA_QUALITY --> CW_ALARMS
    MODEL_QUALITY --> CW_ALARMS
    CW_ALARMS --> SNS
    SNS --> LAMBDA

    style DATA_QUALITY fill:#ff9900
    style MODEL_QUALITY fill:#ff9900
```

### KServe Logger Sidecar è®¾ç½®

```yaml
apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: fraud-detection-monitored
  namespace: kserve-inference
spec:
  predictor:
    pytorch:
      storageUri: s3://my-models/fraud-detection/model.tar.gz
      resources:
        requests:
          nvidia.com/gpu: 1
        limits:
          nvidia.com/gpu: 1

    # æ·»åŠ  Logger Sidecar
    logger:
      mode: all  # request, response, all
      url: http://logger-service.monitoring.svc.cluster.local:8080/log

  minReplicas: 2
  maxReplicas: 10
---
apiVersion: v1
kind: Service
metadata:
  name: logger-service
  namespace: monitoring
spec:
  selector:
    app: inference-logger
  ports:
    - port: 8080
      targetPort: 8080
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: inference-logger
  namespace: monitoring
spec:
  replicas: 2
  selector:
    matchLabels:
      app: inference-logger
  template:
    metadata:
      labels:
        app: inference-logger
    spec:
      serviceAccountName: inference-logger-sa
      containers:
        - name: logger
          image: my-registry/inference-logger:latest
          ports:
            - containerPort: 8080
          env:
            - name: S3_BUCKET
              value: "my-inference-logs"
            - name: S3_PREFIX
              value: "fraud-detection/"
            - name: AWS_REGION
              value: "us-west-2"
          resources:
            requests:
              cpu: "500m"
              memory: "1Gi"
            limits:
              cpu: "1"
              memory: "2Gi"
```

### SageMaker Model Monitor é›†æˆ

```python
# sagemaker_model_monitor.py
import boto3
from sagemaker.model_monitor import (
    DataCaptureConfig,
    DataQualityMonitor,
    ModelQualityMonitor
)
from sagemaker import Session

session = Session()
sm_client = boto3.client('sagemaker')

# è®¾ç½® Data Quality Monitor
data_quality_monitor = DataQualityMonitor(
    role='arn:aws:iam::123456789012:role/SageMakerModelMonitorRole',
    instance_count=1,
    instance_type='ml.m5.xlarge',
    volume_size_in_gb=20,
    max_runtime_in_seconds=3600,
    sagemaker_session=session
)

# åˆ›å»ºåŸºçº¿ï¼ˆåŸºäºè®­ç»ƒæ•°æ®ï¼‰
baseline_job = data_quality_monitor.suggest_baseline(
    baseline_dataset='s3://my-bucket/training-data/baseline.csv',
    dataset_format={'csv': {'header': True}},
    output_s3_uri='s3://my-bucket/model-monitor/baseline',
    wait=True
)

# åˆ›å»ºç›‘æ§è°ƒåº¦
monitoring_schedule = data_quality_monitor.create_monitoring_schedule(
    monitor_schedule_name='fraud-detection-data-quality',
    endpoint_input='s3://my-inference-logs/fraud-detection/',  # EKS æ—¥å¿—
    output_s3_uri='s3://my-bucket/model-monitor/reports',
    statistics=baseline_job.baseline_statistics(),
    constraints=baseline_job.suggested_constraints(),
    schedule_cron_expression='cron(0 * * * ? *)',  # æ¯å°æ—¶
    enable_cloudwatch_metrics=True
)

print(f"Monitoring schedule created: {monitoring_schedule.monitoring_schedule_name}")
```

### æ¼‚ç§»æ£€æµ‹ä¸è‡ªåŠ¨é‡è®­ç»ƒ

```python
# drift_detection_handler.py
import boto3
import json
from datetime import datetime

def lambda_handler(event, context):
    """CloudWatch Alarm è§¦å‘æ—¶è‡ªåŠ¨é‡è®­ç»ƒ"""

    # è§£æ Alarm ä¿¡æ¯
    message = json.loads(event['Records'][0]['Sns']['Message'])
    alarm_name = message['AlarmName']

    if 'DataQualityViolation' in alarm_name:
        print(f"Data quality violation detected: {alarm_name}")

        # è§¦å‘ SageMaker Training Job
        sm_client = boto3.client('sagemaker')

        training_job_name = f"fraud-detection-retrain-{datetime.now().strftime('%Y%m%d%H%M%S')}"

        response = sm_client.create_training_job(
            TrainingJobName=training_job_name,
            RoleArn='arn:aws:iam::123456789012:role/SageMakerExecutionRole',
            AlgorithmSpecification={
                'TrainingImage': '763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-training:2.1.0-gpu-py310',
                'TrainingInputMode': 'File'
            },
            InputDataConfig=[
                {
                    'ChannelName': 'training',
                    'DataSource': {
                        'S3DataSource': {
                            'S3DataType': 'S3Prefix',
                            'S3Uri': 's3://my-bucket/training-data/',
                            'S3DataDistributionType': 'FullyReplicated'
                        }
                    }
                }
            ],
            OutputDataConfig={
                'S3OutputPath': 's3://my-bucket/models/'
            },
            ResourceConfig={
                'InstanceType': 'ml.g5.2xlarge',
                'InstanceCount': 2,
                'VolumeSizeInGB': 50
            },
            StoppingCondition={
                'MaxRuntimeInSeconds': 43200  # 12å°æ—¶
            },
            Tags=[
                {'Key': 'Trigger', 'Value': 'AutoRetraining'},
                {'Key': 'Reason', 'Value': 'DataDrift'}
            ]
        )

        print(f"Retraining job started: {training_job_name}")

        return {
            'statusCode': 200,
            'body': json.dumps({
                'message': 'Retraining triggered',
                'training_job': training_job_name
            })
        }

    return {
        'statusCode': 200,
        'body': json.dumps({'message': 'No action required'})
    }
```


---

## æ€»ç»“

SageMaker-EKS æ··åˆæ¶æ„ç»“åˆäº†æ‰˜ç®¡è®­ç»ƒå’Œçµæ´»æœåŠ¡çš„ä¼˜åŠ¿ã€‚

### æ ¸å¿ƒè¦ç‚¹

1. **æ··åˆæ¨¡å¼**ï¼šSageMaker è®­ç»ƒ + EKS æœåŠ¡ï¼Œå‘æŒ¥å„å¹³å°ä¼˜åŠ¿
2. **é›†ä¸­æ²»ç†**ï¼šé€šè¿‡ SageMaker Model Registry ç»Ÿä¸€ç®¡ç†æ‰€æœ‰æ¨¡å‹
3. **æˆæœ¬ä¼˜åŒ–**ï¼šä½¿ç”¨ Spot å®ä¾‹å’Œè‡ªåŠ¨æ‰©ç¼©é™ä½æˆæœ¬
4. **å¤šåŒºåŸŸ**ï¼šé€šè¿‡ S3 Cross-Region Replication å®ç°å…¨çƒéƒ¨ç½²
5. **ç›‘æ§**ï¼šSageMaker Model Monitor ä¸ EKS æ—¥å¿—é›†æˆ

### å»ºè®®

- å¤§è§„æ¨¡åˆ†å¸ƒå¼è®­ç»ƒåœ¨ SageMaker ä¸Šè¿›è¡Œï¼Œå‡å°‘åŸºç¡€è®¾æ–½ç®¡ç†è´Ÿæ‹…
- æœåŠ¡ç¯å¢ƒåœ¨ EKS ä¸Šè¿è¥ï¼Œå®ç°ç²¾ç»†æ§åˆ¶å’Œæˆæœ¬ä¼˜åŒ–
- å°† Model Registry ä½œä¸ºä¸­å¤®å­˜å‚¨åº“ï¼Œå¼ºåŒ–æ²»ç†
- æ£€æµ‹åˆ°æ¼‚ç§»æ—¶æ„å»ºè‡ªåŠ¨é‡è®­ç»ƒæµæ°´çº¿

### åç»­æ­¥éª¤

- [åŸºäº EKS çš„ MLOps æµæ°´çº¿](./mlops-pipeline-eks.md) - Kubeflow + MLflow + KServe
- [GPU èµ„æºç®¡ç†](./gpu-resource-management.md) - GPU é›†ç¾¤ä¼˜åŒ–
- [æ¨¡å‹ç›‘æ§](./agent-monitoring.md) - ç”Ÿäº§æ¨¡å‹å¯è§‚æµ‹æ€§

---

## å‚è€ƒèµ„æ–™

- [SageMaker Components for Kubeflow Pipelines](https://docs.aws.amazon.com/sagemaker/latest/dg/kubernetes-sagemaker-components-for-kubeflow-pipelines.html)
- [SageMaker Model Registry](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry.html)
- [SageMaker Model Monitor](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html)
- [KServe Documentation](https://kserve.github.io/website/)
- [AWS Multi-Region Architecture](https://aws.amazon.com/solutions/implementations/multi-region-application-architecture/)
