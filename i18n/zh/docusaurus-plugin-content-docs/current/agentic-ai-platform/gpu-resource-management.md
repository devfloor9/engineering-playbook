---
title: "åŠ¨æ€ GPU é›†ç¾¤èµ„æºç®¡ç†"
sidebar_label: "4. GPU Resource Management"
description: "å¤š GPU é›†ç¾¤ç¯å¢ƒä¸­çš„åŠ¨æ€èµ„æºåˆ†é…ä¸åŸºäº Karpenter çš„è‡ªåŠ¨æ‰©ç¼©å®¹"
tags: [eks, gpu, karpenter, autoscaling, resource-management, dcgm]
category: "genai-aiml"
sidebar_position: 4
last_update:
  date: 2026-02-14
  author: devfloor9
---

import { DraLimitationsTable, ScalingDecisionTable } from '@site/src/components/GpuResourceTables';

# åŠ¨æ€ GPU é›†ç¾¤èµ„æºç®¡ç†

> ğŸ“… **æ’°å†™æ—¥æœŸ**: 2025-02-05 | **ä¿®æ”¹æ—¥æœŸ**: 2026-02-14 | â±ï¸ **é˜…è¯»æ—¶é—´**: çº¦ 8 åˆ†é’Ÿ

## æ¦‚è¿°

åœ¨å¤§è§„æ¨¡ GenAI æœåŠ¡ç¯å¢ƒä¸­ï¼Œå…³é”®åœ¨äºé«˜æ•ˆç®¡ç†å¤šä¸ª GPU é›†ç¾¤ï¼Œå¹¶æ ¹æ®æµé‡å˜åŒ–åŠ¨æ€é‡æ–°åˆ†é…èµ„æºã€‚æœ¬æ–‡æ¡£æ¶µç›–åœ¨ Amazon EKS ç¯å¢ƒä¸­ä½¿ç”¨ Karpenter è¿›è¡Œ GPU èŠ‚ç‚¹è‡ªåŠ¨æ‰©ç¼©å®¹ã€ä½¿ç”¨ DCGMï¼ˆData Center GPU Managerï¼‰è¿›è¡ŒæŒ‡æ ‡é‡‡é›†ï¼Œä»¥åŠé€šè¿‡ KEDA å®ç°å·¥ä½œè´Ÿè½½è‡ªåŠ¨æ‰©ç¼©å®¹ç­–ç•¥ã€‚

### æ ¸å¿ƒç›®æ ‡

- **èµ„æºæ•ˆç‡**ï¼šæœ€å¤§é™åº¦å‡å°‘ GPU èµ„æºçš„ç©ºé—²æ—¶é—´
- **æˆæœ¬ä¼˜åŒ–**ï¼šé€šè¿‡ä½¿ç”¨ Spot å®ä¾‹å’Œæ•´åˆç­–ç•¥é™ä½æˆæœ¬
- **è‡ªåŠ¨åŒ–æ‰©ç¼©å®¹**ï¼šæ ¹æ®æµé‡æ¨¡å¼è‡ªåŠ¨è°ƒæ•´èµ„æº
- **æœåŠ¡ç¨³å®šæ€§**ï¼šç¡®ä¿è·å–é€‚å½“èµ„æºä»¥æ»¡è¶³ SLA

---

## å¤š GPU é›†ç¾¤æ¶æ„

### å®Œæ•´æ¶æ„å›¾

```mermaid
flowchart TB
    subgraph "Traffic Layer"
        ALB[Application Load Balancer]
        IGW[Ingress Gateway]
    end

    subgraph "EKS Control Plane"
        API[Kubernetes API Server]
        KARP[Karpenter Controller]
        KEDA_OP[KEDA Operator]
    end

    subgraph "GPU Node Pool A - Model Serving"
        NPA1[p4d.24xlarge Node 1]
        NPA2[p4d.24xlarge Node 2]
        NPA3[p5.48xlarge Node 3]

        subgraph "Model A Pods"
            MA1[vLLM Pod A-1]
            MA2[vLLM Pod A-2]
            MA3[vLLM Pod A-3]
        end
    end

    subgraph "GPU Node Pool B - Model Serving"
        NPB1[g5.48xlarge Node 1]
        NPB2[g5.48xlarge Node 2]

        subgraph "Model B Pods"
            MB1[vLLM Pod B-1]
            MB2[vLLM Pod B-2]
        end
    end

    subgraph "Monitoring Stack"
        DCGM[DCGM Exporter]
        PROM[Prometheus]
        GRAF[Grafana]
    end

    ALB --> IGW
    IGW --> MA1 & MA2 & MA3
    IGW --> MB1 & MB2

    API --> KARP
    API --> KEDA_OP

    KARP --> NPA1 & NPA2 & NPA3
    KARP --> NPB1 & NPB2

    DCGM --> PROM
    PROM --> KEDA_OP
    PROM --> GRAF
```

### èµ„æºå…±äº«æ¶æ„

ç”¨äºåœ¨å¤šä¸ªæ¨¡å‹ä¹‹é—´é«˜æ•ˆå…±äº« GPU èµ„æºçš„æ¶æ„ã€‚

```mermaid
flowchart LR
    subgraph "Shared GPU Pool"
        direction TB
        GPU1[GPU 1-4<br/>Model A Primary]
        GPU2[GPU 5-8<br/>Model B Primary]
        GPU3[GPU 9-12<br/>Elastic Pool]
    end

    subgraph "Resource Allocator"
        RA[Dynamic Resource<br/>Allocator]
        METRICS[GPU Metrics<br/>Collector]
    end

    subgraph "Workloads"
        WA[Model A<br/>Workload]
        WB[Model B<br/>Workload]
    end

    METRICS --> RA
    RA --> GPU1 & GPU2 & GPU3
    WA --> GPU1
    WB --> GPU2
    WA -.->|Traffic Surge| GPU3
    WB -.->|Traffic Surge| GPU3
```

:::info èµ„æºå…±äº«åŸåˆ™

- **ä¸»è¦èµ„æºæ± **ï¼šä¸ºæ¯ä¸ªæ¨¡å‹åˆ†é…çš„åŸºç¡€ GPU èµ„æº
- **å¼¹æ€§èµ„æºæ± **ï¼šåœ¨æµé‡æ¿€å¢æ—¶åŠ¨æ€åˆ†é…çš„å…±äº«èµ„æº
- **åŸºäºä¼˜å…ˆçº§çš„åˆ†é…**ï¼šé€šè¿‡åŸºäºä¼˜å…ˆçº§çš„èµ„æºåˆ†é…ä¿æŠ¤å…³é”®å·¥ä½œè´Ÿè½½

:::

---

## åŠ¨æ€èµ„æºåˆ†é…ç­–ç•¥

### æµé‡æ¿€å¢åœºæ™¯

ç”Ÿäº§ç¯å¢ƒä¸­å¯èƒ½å‡ºç°çš„æµé‡æ¿€å¢åœºæ™¯åŠç›¸åº”çš„åº”å¯¹ç­–ç•¥ã€‚

```mermaid
sequenceDiagram
    participant User as User Traffic
    participant LB as Load Balancer
    participant ModelA as Model A Service
    participant ModelB as Model B Service
    participant KEDA as KEDA Controller
    participant Karpenter as Karpenter
    participant AWS as AWS EC2

    Note over User,AWS: æ­£å¸¸çŠ¶æ€ï¼šModel A 40%ã€Model B 30% GPU åˆ©ç”¨ç‡

    User->>LB: æµé‡æ¿€å¢ (Model A)
    LB->>ModelA: ä¼ é€’è¯·æ±‚
    ModelA->>KEDA: æ£€æµ‹åˆ° GPU åˆ©ç”¨ç‡ 85%

    KEDA->>ModelA: è§¦å‘ HPA - Pod æ‰©å®¹
    KEDA->>Karpenter: è¯·æ±‚é¢å¤–èŠ‚ç‚¹

    Karpenter->>AWS: é…ç½® p4d.24xlarge
    AWS-->>Karpenter: èŠ‚ç‚¹å°±ç»ª

    Note over ModelA,ModelB: å°†éƒ¨åˆ† Model B èµ„æºé‡æ–°åˆ†é…ç»™ Model A

    Karpenter->>ModelA: åœ¨æ–°èŠ‚ç‚¹ä¸Šè°ƒåº¦ Pod
    ModelA-->>User: å“åº”å»¶è¿Ÿæ¢å¤æ­£å¸¸
```

### æ¨¡å‹é—´èµ„æºé‡æ–°åˆ†é…æµç¨‹

å½“ Model A ç»å†æµé‡æ¿€å¢æ—¶ï¼Œå°† Model B çš„ç©ºé—²èµ„æºé‡æ–°åˆ†é…ç»™ Model A çš„å…·ä½“æµç¨‹ã€‚

#### æ­¥éª¤ 1ï¼šæŒ‡æ ‡é‡‡é›†ä¸åˆ†æ

```yaml
# DCGM Exporter é‡‡é›†çš„æ ¸å¿ƒæŒ‡æ ‡
# - DCGM_FI_DEV_GPU_UTIL: GPU åˆ©ç”¨ç‡
# - DCGM_FI_DEV_MEM_COPY_UTIL: å†…å­˜æ‹·è´åˆ©ç”¨ç‡
# - DCGM_FI_DEV_FB_USED: å¸§ç¼“å†²åŒºå·²ç”¨å†…å­˜
```

#### æ­¥éª¤ 2ï¼šæ‰©ç¼©å®¹å†³ç­–

<ScalingDecisionTable />

#### æ­¥éª¤ 3ï¼šæ‰§è¡Œèµ„æºé‡æ–°åˆ†é…

```bash
# å‡å°‘ Model B å‰¯æœ¬æ•°ï¼ˆé‡Šæ”¾ç©ºé—²èµ„æºï¼‰
kubectl scale deployment model-b-serving --replicas=1 -n inference

# å¢åŠ  Model A å‰¯æœ¬æ•°
kubectl scale deployment model-a-serving --replicas=5 -n inference

# æˆ–ç”± KEDA è‡ªåŠ¨å¤„ç†
```

#### æ­¥éª¤ 4ï¼šèŠ‚ç‚¹çº§æ‰©ç¼©å®¹

Karpenter è‡ªåŠ¨é…ç½®é¢å¤–èŠ‚ç‚¹æˆ–æ¸…ç†ç©ºé—²èŠ‚ç‚¹ã€‚

:::warning æ³¨æ„äº‹é¡¹

é‡æ–°åˆ†é…èµ„æºæ—¶ï¼Œè¯·é€šè¿‡è®¾ç½® `minReplicas` ç¡®ä¿ Model B çš„æœ€ä½ SLAã€‚å®Œå…¨å›æ”¶èµ„æºå¯èƒ½å¯¼è‡´æœåŠ¡ä¸­æ–­ã€‚

:::

---

## åŸºäº Karpenter çš„èŠ‚ç‚¹æ‰©ç¼©å®¹

### NodePool é…ç½®

ç”¨äº GPU å·¥ä½œè´Ÿè½½çš„ Karpenter NodePool é…ç½®ç¤ºä¾‹ã€‚

```yaml
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: gpu-inference-pool
spec:
  template:
    metadata:
      labels:
        node-type: gpu-inference
        workload: genai
    spec:
      requirements:
        - key: kubernetes.io/arch
          operator: In
          values: ["amd64"]
        - key: karpenter.sh/capacity-type
          operator: In
          values: ["on-demand", "spot"]
        - key: node.kubernetes.io/instance-type
          operator: In
          values:
            - p4d.24xlarge    # 8x A100 40GB
            - p5.48xlarge     # 8x H100 80GB
            - g5.48xlarge     # 8x A10G 24GB
        - key: karpenter.k8s.aws/instance-gpu-count
          operator: Gt
          values: ["0"]
      nodeClassRef:
        group: karpenter.k8s.aws
        kind: EC2NodeClass
        name: gpu-nodeclass
      taints:
        - key: nvidia.com/gpu
          value: "true"
          effect: NoSchedule
  limits:
    cpu: 1000
    memory: 4000Gi
    nvidia.com/gpu: 64
  disruption:
    consolidationPolicy: WhenEmptyOrUnderutilized
    consolidateAfter: 30s
  weight: 100
```

### EC2NodeClass é…ç½®

ç”¨äº GPU å®ä¾‹çš„ EC2NodeClass é…ç½®ã€‚

```yaml
apiVersion: karpenter.k8s.aws/v1
kind: EC2NodeClass
metadata:
  name: gpu-nodeclass
spec:
  role: KarpenterNodeRole-${CLUSTER_NAME}
  amiSelectorTerms:
    - alias: al2023@latest
  subnetSelectorTerms:
    - tags:
        karpenter.sh/discovery: ${CLUSTER_NAME}
  securityGroupSelectorTerms:
    - tags:
        karpenter.sh/discovery: ${CLUSTER_NAME}
  blockDeviceMappings:
    - deviceName: /dev/xvda
      ebs:
        volumeSize: 500Gi
        volumeType: gp3
        iops: 10000
        throughput: 500
        encrypted: true
        deleteOnTermination: true
  instanceStorePolicy: RAID0
  userData: |
    #!/bin/bash
    # NVIDIA é©±åŠ¨å’Œ Container Toolkit è®¾ç½®
    nvidia-smi

    # è®¾ç½® GPU å†…å­˜æ¨¡å¼ï¼ˆPersistence Modeï¼‰
    nvidia-smi -pm 1

    # åŠ è½½ EFA é©±åŠ¨ï¼ˆç”¨äº p4dã€p5 å®ä¾‹ï¼‰
    modprobe efa
  tags:
    Environment: production
    Workload: genai-inference
```

### GPU å®ä¾‹ç±»å‹å¯¹æ¯”

| å®ä¾‹ç±»å‹ | GPU | GPU å†…å­˜ | vCPU | å†…å­˜ | ç½‘ç»œ | ä½¿ç”¨åœºæ™¯ |
|--------------|-----|-----------|------|--------|---------|------|
| p4d.24xlarge | 8x A100 | 40GB x 8 | 96 | 1152 GiB | 400 Gbps EFA | å¤§å‹ LLM æ¨ç† |
| p5.48xlarge | 8x H100 | 80GB x 8 | 192 | 2048 GiB | 3200 Gbps EFA | è¶…å¤§æ¨¡å‹ã€è®­ç»ƒ |
| g5.48xlarge | 8x A10G | 24GB x 8 | 192 | 768 GiB | 100 Gbps | ä¸­å°å‹æ¨¡å‹æ¨ç† |

:::tip å®ä¾‹é€‰æ‹©æŒ‡å—

- **p5.48xlarge**ï¼š70B+ å‚æ•°æ¨¡å‹ï¼Œéœ€è¦æœ€é«˜æ€§èƒ½
- **p4d.24xlarge**ï¼š13B-70B å‚æ•°æ¨¡å‹ï¼Œæˆæœ¬ä¸æ€§èƒ½çš„å¹³è¡¡
- **g5.48xlarge**ï¼š7B åŠä»¥ä¸‹æ¨¡å‹ï¼Œé«˜æ€§ä»·æ¯”æ¨ç†

:::

---

## åŸºäº GPU æŒ‡æ ‡çš„è‡ªåŠ¨æ‰©ç¼©å®¹

### DCGM Exporter è®¾ç½®

é€šè¿‡ NVIDIA DCGM Exporter å°† GPU æŒ‡æ ‡é‡‡é›†åˆ° Prometheusã€‚

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: dcgm-exporter
  namespace: gpu-monitoring
  labels:
    app: dcgm-exporter
spec:
  selector:
    matchLabels:
      app: dcgm-exporter
  template:
    metadata:
      labels:
        app: dcgm-exporter
    spec:
      nodeSelector:
        nvidia.com/gpu.present: "true"
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
      containers:
        - name: dcgm-exporter
          image: nvcr.io/nvidia/k8s/dcgm-exporter:3.3.5-3.4.0-ubuntu22.04
          ports:
            - name: metrics
              containerPort: 9400
          env:
            - name: DCGM_EXPORTER_LISTEN
              value: ":9400"
            - name: DCGM_EXPORTER_KUBERNETES
              value: "true"
            - name: DCGM_EXPORTER_COLLECTORS
              value: "/etc/dcgm-exporter/dcp-metrics-included.csv"
          volumeMounts:
            - name: pod-resources
              mountPath: /var/lib/kubelet/pod-resources
              readOnly: true
          securityContext:
            runAsNonRoot: false
            runAsUser: 0
            capabilities:
              add: ["SYS_ADMIN"]
      volumes:
        - name: pod-resources
          hostPath:
            path: /var/lib/kubelet/pod-resources
```

### æ ¸å¿ƒ GPU æŒ‡æ ‡

DCGM Exporter é‡‡é›†çš„æ ¸å¿ƒæŒ‡æ ‡ã€‚

| æŒ‡æ ‡åç§° | æè¿° | æ‰©ç¼©å®¹ç”¨é€” |
|------------|------|--------------|
| `DCGM_FI_DEV_GPU_UTIL` | GPU æ ¸å¿ƒåˆ©ç”¨ç‡ (%) | HPA è§¦å‘é˜ˆå€¼ |
| `DCGM_FI_DEV_MEM_COPY_UTIL` | å†…å­˜å¸¦å®½åˆ©ç”¨ç‡ (%) | å†…å­˜ç“¶é¢ˆæ£€æµ‹ |
| `DCGM_FI_DEV_FB_USED` | å¸§ç¼“å†²åŒºå·²ç”¨å†…å­˜ (MB) | é˜²æ­¢ OOM |
| `DCGM_FI_DEV_FB_FREE` | å¸§ç¼“å†²åŒºå¯ç”¨å†…å­˜ (MB) | å®¹é‡è§„åˆ’ |
| `DCGM_FI_DEV_POWER_USAGE` | åŠŸè€— (W) | æˆæœ¬ç›‘æ§ |
| `DCGM_FI_DEV_SM_CLOCK` | SM æ—¶é’Ÿé¢‘ç‡ (MHz) | æ€§èƒ½ç›‘æ§ |
| `DCGM_FI_DEV_GPU_TEMP` | GPU æ¸©åº¦ (Â°C) | æ•£çƒ­ç®¡ç† |

### Prometheus ServiceMonitor è®¾ç½®

```yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: dcgm-exporter
  namespace: gpu-monitoring
spec:
  selector:
    matchLabels:
      app: dcgm-exporter
  endpoints:
    - port: metrics
      interval: 15s
      path: /metrics
  namespaceSelector:
    matchNames:
      - gpu-monitoring
```

### KEDA ScaledObject è®¾ç½®

ä½¿ç”¨ KEDA é…ç½®åŸºäº GPU æŒ‡æ ‡çš„è‡ªåŠ¨æ‰©ç¼©å®¹ã€‚

```yaml
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: model-a-gpu-scaler
  namespace: inference
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: model-a-serving
  pollingInterval: 15
  cooldownPeriod: 60
  minReplicaCount: 2
  maxReplicaCount: 10
  fallback:
    failureThreshold: 3
    replicas: 3
  advanced:
    horizontalPodAutoscalerConfig:
      behavior:
        scaleDown:
          stabilizationWindowSeconds: 300
          policies:
            - type: Percent
              value: 25
              periodSeconds: 60
        scaleUp:
          stabilizationWindowSeconds: 0
          policies:
            - type: Percent
              value: 100
              periodSeconds: 15
            - type: Pods
              value: 4
              periodSeconds: 15
          selectPolicy: Max
  triggers:
    - type: prometheus
      metadata:
        serverAddress: http://prometheus-server.monitoring:9090
        metricName: gpu_utilization
        query: |
          avg(DCGM_FI_DEV_GPU_UTIL{pod=~"model-a-.*"})
        threshold: "70"
        activationThreshold: "50"
```

### è‡ªåŠ¨æ‰©ç¼©å®¹é˜ˆå€¼é…ç½®

åŸºäºå·¥ä½œè´Ÿè½½ç‰¹å¾çš„æ¨èé˜ˆå€¼ã€‚

| å·¥ä½œè´Ÿè½½ç±»å‹ | æ‰©å®¹é˜ˆå€¼ | ç¼©å®¹é˜ˆå€¼ | å†·å´æ—¶é—´ |
|--------------|----------------|------------------|----------|
| å®æ—¶æ¨ç† | GPU 70% | GPU 30% | 60 ç§’ |
| æ‰¹å¤„ç† | GPU 85% | GPU 40% | 300 ç§’ |
| äº¤äº’å¼æœåŠ¡ | GPU 60% | GPU 25% | 30 ç§’ |

:::tip é˜ˆå€¼è°ƒä¼˜æŒ‡å—

1. **åˆå§‹è®¾ç½®**ï¼šä»ä¿å®ˆå€¼å¼€å§‹ï¼ˆæ‰©å®¹ 80%ï¼Œç¼©å®¹ 20%ï¼‰
2. **ç›‘æ§**ï¼šè§‚å¯Ÿ 2-3 å¤©çš„å®é™…æµé‡æ¨¡å¼
3. **è°ƒæ•´**ï¼šç»¼åˆè€ƒè™‘å“åº”æ—¶é—´ SLA å’Œæˆæœ¬é€æ­¥è°ƒæ•´
4. **éªŒè¯**ï¼šé€šè¿‡å‹åŠ›æµ‹è¯•éªŒè¯è®¾ç½®

:::

### HPA ä¸ KEDA é›†æˆ

åŒæ—¶ä½¿ç”¨åŸºç¡€ HPA å’Œ KEDA çš„é…ç½®ã€‚

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: model-a-hpa
  namespace: inference
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: model-a-serving
  minReplicas: 2
  maxReplicas: 10
  metrics:
    - type: External
      external:
        metric:
          name: gpu_utilization
          selector:
            matchLabels:
              scaledobject.keda.sh/name: model-a-gpu-scaler
        target:
          type: AverageValue
          averageValue: "70"
```

---

## æˆæœ¬ä¼˜åŒ–ç­–ç•¥

### Spot å®ä¾‹ä½¿ç”¨

ä½¿ç”¨ GPU Spot å®ä¾‹å¯ä»¥é™ä½é«˜è¾¾ 90% çš„æˆæœ¬ã€‚

```yaml
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: gpu-spot-pool
spec:
  template:
    spec:
      requirements:
        - key: karpenter.sh/capacity-type
          operator: In
          values: ["spot"]
        - key: node.kubernetes.io/instance-type
          operator: In
          values:
            - g5.12xlarge
            - g5.24xlarge
            - g5.48xlarge
      nodeClassRef:
        group: karpenter.k8s.aws
        kind: EC2NodeClass
        name: gpu-spot-nodeclass
      taints:
        - key: nvidia.com/gpu
          value: "true"
          effect: NoSchedule
        - key: karpenter.sh/capacity-type
          value: "spot"
          effect: NoSchedule
  limits:
    nvidia.com/gpu: 32
  disruption:
    consolidationPolicy: WhenEmpty
    consolidateAfter: 30s
  weight: 50
```

:::warning Spot å®ä¾‹æ³¨æ„äº‹é¡¹

- **ä¸­æ–­å¤„ç†**ï¼šSpot å®ä¾‹åœ¨ä¸­æ–­å‰ä¼šæ”¶åˆ° 2 åˆ†é’Ÿçš„é€šçŸ¥ã€‚è¯·å®ç°é€‚å½“çš„ä¼˜é›…å…³é—­æœºåˆ¶
- **å·¥ä½œè´Ÿè½½é€‚ç”¨æ€§**ï¼šæœ€é€‚åˆæ— çŠ¶æ€æ¨ç†å·¥ä½œè´Ÿè½½
- **å¯ç”¨æ€§**ï¼šç‰¹å®šå®ä¾‹ç±»å‹çš„ Spot å¯ç”¨æ€§å¯èƒ½æœ‰é™ï¼›å»ºè®®æŒ‡å®šå¤šç§ç±»å‹

:::

### Spot å®ä¾‹ä¸­æ–­å¤„ç†

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: model-serving-spot
  namespace: inference
spec:
  template:
    spec:
      terminationGracePeriodSeconds: 120
      containers:
        - name: vllm
          lifecycle:
            preStop:
              exec:
                command:
                  - /bin/sh
                  - -c
                  - |
                    # åœæ­¢æ¥å—æ–°è¯·æ±‚
                    curl -X POST localhost:8000/drain
                    # ç­‰å¾…è¿›è¡Œä¸­çš„è¯·æ±‚å®Œæˆ
                    sleep 90
      tolerations:
        - key: karpenter.sh/capacity-type
          operator: Equal
          value: "spot"
          effect: NoSchedule
```

### æ•´åˆç­–ç•¥

è‡ªåŠ¨æ¸…ç†ç©ºé—²èŠ‚ç‚¹ä»¥ä¼˜åŒ–æˆæœ¬ã€‚

```yaml
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: gpu-inference-pool
spec:
  disruption:
    # å½“èŠ‚ç‚¹ä¸ºç©ºæˆ–åˆ©ç”¨ç‡ä¸è¶³æ—¶è¿›è¡Œæ•´åˆ
    consolidationPolicy: WhenEmptyOrUnderutilized
    # æ•´åˆç­‰å¾…æ—¶é—´
    consolidateAfter: 30s
    # é¢„ç®—è®¾ç½® - é™åˆ¶åŒæ—¶å¯è¢«ä¸­æ–­çš„èŠ‚ç‚¹æ•°é‡
    budgets:
      - nodes: "20%"
      - nodes: "0"
        schedule: "0 9 * * 1-5"  # å·¥ä½œæ—¶é—´å†…é˜²æ­¢ä¸­æ–­
        duration: 8h
```

### æˆæœ¬ä¼˜åŒ–æ¸…å•

| é¡¹ç›® | æè¿° | é¢„æœŸèŠ‚çœ |
|------|------|----------|
| Spot å®ä¾‹ä½¿ç”¨ | ç”¨äºéç”Ÿäº§ç¯å¢ƒå’Œå®¹é”™å·¥ä½œè´Ÿè½½ | 60-90% |
| å¯ç”¨æ•´åˆ | è‡ªåŠ¨æ¸…ç†ç©ºé—²èŠ‚ç‚¹ | 20-30% |
| åˆç†é€‰å‹ | é€‰æ‹©åŒ¹é…å·¥ä½œè´Ÿè½½çš„å®ä¾‹ | 15-25% |
| åŸºäºè°ƒåº¦çš„æ‰©ç¼©å®¹ | éå·¥ä½œæ—¶é—´å‡å°‘èµ„æº | 30-40% |

:::tip æˆæœ¬ç›‘æ§

ä½¿ç”¨ Kubecost æˆ– AWS Cost Explorer è·Ÿè¸ª GPU å·¥ä½œè´Ÿè½½æˆæœ¬ï¼Œå¹¶å®šæœŸå®¡æŸ¥ä¼˜åŒ–æœºä¼šã€‚

:::

---

## è¿ç»´æœ€ä½³å®è·µ

### GPU èµ„æºè¯·æ±‚é…ç½®

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: model-a-serving
  namespace: inference
spec:
  template:
    spec:
      containers:
        - name: vllm
          resources:
            requests:
              nvidia.com/gpu: 1
              memory: "32Gi"
              cpu: "8"
            limits:
              nvidia.com/gpu: 1
              memory: "64Gi"
              cpu: "16"
```

### ç›‘æ§ä»ªè¡¨æ¿é…ç½®

Grafana ä»ªè¡¨æ¿ä¸­éœ€è¦ç›‘æ§çš„å…³é”®é¢æ¿ï¼š

1. **GPU åˆ©ç”¨ç‡è¶‹åŠ¿**ï¼šGPU åˆ©ç”¨ç‡éšæ—¶é—´çš„å˜åŒ–
2. **å†…å­˜ä½¿ç”¨æƒ…å†µ**ï¼šGPU å†…å­˜ä½¿ç”¨é‡å’Œå¯ç”¨ç©ºé—´
3. **Pod æ‰©ç¼©å®¹äº‹ä»¶**ï¼šHPA/KEDA æ‰©ç¼©å®¹å†å²
4. **èŠ‚ç‚¹é…ç½®**ï¼šKarpenter èŠ‚ç‚¹åˆ›å»º/åˆ é™¤äº‹ä»¶
5. **æˆæœ¬è·Ÿè¸ª**ï¼šæ¯å°æ—¶/æ¯å¤©çš„ GPU æˆæœ¬

### å‘Šè­¦é…ç½®

```yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: gpu-alerts
  namespace: monitoring
spec:
  groups:
    - name: gpu-alerts
      rules:
        - alert: HighGPUUtilization
          expr: avg(DCGM_FI_DEV_GPU_UTIL) > 90
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "GPU åˆ©ç”¨ç‡è¶…è¿‡ 90%"

        - alert: GPUMemoryPressure
          expr: (DCGM_FI_DEV_FB_USED / DCGM_FI_DEV_FB_FREE) > 0.9
          for: 2m
          labels:
            severity: critical
          annotations:
            summary: "GPU å†…å­˜ä¸è¶³é£é™©"
```

---

## æ€»ç»“

GPU é›†ç¾¤çš„åŠ¨æ€èµ„æºç®¡ç†æ˜¯å†³å®š GenAI æœåŠ¡æ€§èƒ½å’Œæˆæœ¬æ•ˆç‡çš„å…³é”®å› ç´ ã€‚

### æ ¸å¿ƒè¦ç‚¹

1. **åˆ©ç”¨ Karpenter**ï¼šé€šè¿‡è‡ªåŠ¨é…ç½®å’Œæ¸…ç† GPU èŠ‚ç‚¹æœ€å¤§åŒ–èµ„æºæ•ˆç‡
2. **DCGM æŒ‡æ ‡**ï¼šé€šè¿‡ç²¾ç¡®çš„ GPU åˆ©ç”¨ç‡ç›‘æ§åšå‡ºæ•°æ®é©±åŠ¨çš„æ‰©ç¼©å®¹å†³ç­–
3. **KEDA é›†æˆ**ï¼šåŸºäº GPU æŒ‡æ ‡å®ç°å·¥ä½œè´Ÿè½½è‡ªåŠ¨æ‰©ç¼©å®¹
4. **Spot å®ä¾‹**ï¼šé€šè¿‡å¯¹åˆé€‚çš„å·¥ä½œè´Ÿè½½ä½¿ç”¨ Spot é™ä½æˆæœ¬
5. **æ•´åˆ**ï¼šé€šè¿‡è‡ªåŠ¨æ¸…ç†ç©ºé—²èµ„æºä¼˜åŒ–æˆæœ¬

### åç»­æ­¥éª¤

- [Agentic AI å¹³å°æ¶æ„](./agentic-platform-architecture.md) - å®Œæ•´å¹³å°é…ç½®
- [Agentic AI åŸºç¡€è®¾æ–½](./agentic-ai-challenges.md) - AI Agent è¿ç»´ç­–ç•¥

---

---

## æ·±å…¥æ¢è®¨ï¼šåŠ¨æ€èµ„æºåˆ†é…ï¼ˆDRAï¼‰

### DRA çš„èƒŒæ™¯ä¸å¿…è¦æ€§

åœ¨ Kubernetes æ—©æœŸé˜¶æ®µï¼ŒGPU èµ„æºåˆ†é…ä½¿ç”¨çš„æ˜¯ **Device Plugin** æ¨¡å‹ã€‚è¯¥æ¨¡å‹å­˜åœ¨æ ¹æœ¬æ€§çš„å±€é™ï¼š

<DraLimitationsTable />

**DRAï¼ˆDynamic Resource Allocationï¼‰** åœ¨ Kubernetes 1.26+ ä¸­å¼•å…¥ï¼Œä»¥å…‹æœè¿™äº›å±€é™ã€‚

### DRA çš„æ ¸å¿ƒæ¦‚å¿µ

DRA æ˜¯ä¸€ç§æ–°èŒƒå¼ï¼Œå°†**å£°æ˜å¼èµ„æºè¯·æ±‚ä¸å³æ—¶åˆ†é…**åˆ†ç¦»ï¼š

```mermaid
graph LR
    A["Pod åˆ›å»º<br/>(ResourceClaim è¯·æ±‚)"] -->|Pending| B["Karpenter<br/>(èŠ‚ç‚¹åˆ†æ)"]
    B -->|èµ„æºä¸è¶³| C["é…ç½®æ–°èŠ‚ç‚¹"]
    C -->|å‡†å¤‡åˆ†é…| D["DRA Controller<br/>(èµ„æºé¢„ç•™)"]
    D -->|Allocated| E["Pod ç»‘å®š"]
    E -->|Reserved| F["Pod è°ƒåº¦"]
    F -->|InUse| G["Pod è¿è¡Œ"]

    H["Resource Quota<br/>æ£€æŸ¥"] -->|Applied| D
    I["GPU Partitioning<br/>ç­–ç•¥"] -->|Applied| D

    style A fill:#e8f4f8
    style D fill:#326ce5
    style E fill:#76b900
    style G fill:#ffd93d
```

### ResourceClaim ç”Ÿå‘½å‘¨æœŸ

DRA çš„æ ¸å¿ƒæ˜¯ **ResourceClaim**ï¼Œä¸€ç§æ–°çš„ Kubernetes èµ„æºï¼š

```yaml
# 1. ç”Ÿå‘½å‘¨æœŸçŠ¶æ€æè¿°

# PENDING çŠ¶æ€ï¼šç­‰å¾…èµ„æºåˆ†é…
apiVersion: resource.k8s.io/v1alpha2
kind: ResourceClaim
metadata:
  name: gpu-claim-vllm
  namespace: ai-inference
spec:
  resourceClassName: gpu.nvidia.com
  parametersRef:
    apiGroup: gpu.nvidia.com
    kind: GpuClaimParameters
    name: h100-params
status:
  phase: Pending  # å°šæœªåˆ†é…

---

# ALLOCATED çŠ¶æ€ï¼šDRA æ§åˆ¶å™¨å®Œæˆèµ„æºé¢„ç•™
status:
  phase: Allocated
  allocation:
    resourceHandle: "gpu-handle-12345"
    shareable: false

---

# RESERVED çŠ¶æ€ï¼šå‡†å¤‡å¥½è¿›è¡Œ Pod ç»‘å®š
status:
  phase: Reserved
  allocation:
    resourceHandle: "gpu-handle-12345"
    nodeName: "gpu-node-01"

---

# INUSE çŠ¶æ€ï¼šPod æ­£åœ¨è¿è¡Œ
status:
  phase: InUse
  allocation:
    resourceHandle: "gpu-handle-12345"
    nodeName: "gpu-node-01"
  reservedFor:
    - kind: Pod
      name: vllm-inference
      namespace: ai-inference
      uid: "abc123"
```

ä»ä¸€ä¸ªçŠ¶æ€è½¬æ¢åˆ°ä¸‹ä¸€ä¸ªçŠ¶æ€éœ€è¦æ»¡è¶³ç‰¹å®šæ¡ä»¶ï¼š

- **Pending â†’ Allocated**ï¼šDRA é©±åŠ¨ç¡®è®¤å¹¶é¢„ç•™å¯ç”¨èµ„æº
- **Allocated â†’ Reserved**ï¼šPod æŒ‡å®š ResourceClaimï¼Œè°ƒåº¦å™¨ç¡®å®šèŠ‚ç‚¹
- **Reserved â†’ InUse**ï¼šPod å®é™…åœ¨èŠ‚ç‚¹ä¸Šå¼€å§‹è¿è¡Œ

### è¯¦ç»†å¯¹æ¯”ï¼šDRA vs Device Plugin

| æ–¹é¢ | Device Plugin | DRA |
| --- | --- | --- |
| **èµ„æºåˆ†é…æ—¶æœº** | èŠ‚ç‚¹å¯åŠ¨æ—¶ï¼ˆé™æ€ï¼‰ | Pod è°ƒåº¦æ—¶ï¼ˆåŠ¨æ€ï¼‰ |
| **åˆ†é…å•ä½** | ä»…æ•´ä¸ª GPU | GPU å¯åˆ†å‰²ï¼ˆMIGã€time-slicingï¼‰ |
| **ä¼˜å…ˆçº§æ”¯æŒ** | æ— ï¼ˆå…ˆåˆ°å…ˆå¾—ï¼‰ | æ”¯æŒ ResourceClaim ä¼˜å…ˆçº§ |
| **å¤šèµ„æºåè°ƒ** | ä¸å¯èƒ½ | åœ¨ Pod çº§åˆ«åè°ƒå¤šä¸ªèµ„æº |
| **æ€§èƒ½çº¦æŸç­–ç•¥** | æ—  | å¯é€šè¿‡ ResourceClass å®šä¹‰æ€§èƒ½ç­–ç•¥ |
| **åˆ†é…å¼¹æ€§** | èŠ‚ç‚¹æ•…éšœæ—¶éœ€æ‰‹åŠ¨æ¸…ç† | è‡ªåŠ¨æ¢å¤æœºåˆ¶ |
| **Kubernetes ç‰ˆæœ¬** | 1.8+ | 1.26+ï¼ˆAlphaï¼‰ã€1.29+ï¼ˆBetaï¼‰ |
| **æˆç†Ÿåº¦** | ç”Ÿäº§å°±ç»ª | å»ºè®®é€æ­¥é‡‡ç”¨ |

:::tip DRA é€‰æ‹©æŒ‡å—
**ä½•æ—¶ä½¿ç”¨ DRAï¼š**

- éœ€è¦ GPU åˆ†åŒºï¼ˆMIGã€time-slicingï¼‰
- å¤šç§Ÿæˆ·ç¯å¢ƒä¸­éœ€è¦å…¬å¹³çš„èµ„æºåˆ†é…
- éœ€è¦åº”ç”¨èµ„æºä¼˜å…ˆçº§
- åŠ¨æ€æ‰©ç¼©å®¹è‡³å…³é‡è¦

**Device Plugin è¶³å¤Ÿçš„åœºæ™¯ï¼š**

- ç®€å•åœ°ä»¥æ•´ä¸ª GPU ä¸ºå•ä½åˆ†é…
- ä¸é—ç•™ç³»ç»Ÿçš„å…¼å®¹æ€§å¾ˆé‡è¦
- Kubernetes ç‰ˆæœ¬ä¸º 1.25 æˆ–ä»¥ä¸‹
:::

### é«˜çº§ GPU åˆ†åŒºç­–ç•¥

#### 1. åŸºäº MIGï¼ˆMulti-Instance GPUï¼‰çš„åˆ†åŒº

MIG å¯ä»¥å°† H100 å’Œ A100 ç­‰ç°ä»£ GPU æœ€å¤šåˆ†å‰²ä¸º 7 ä¸ªç‹¬ç«‹ GPUï¼š

```yaml
# MIG Profile å®šä¹‰
apiVersion: gpu.nvidia.com/v1alpha1
kind: GpuClaimParameters
metadata:
  name: a100-mig-1g.5gb
  namespace: ai-inference
spec:
  # MIG Profile é€‰æ‹©ï¼š1g.5gbã€2g.10gbã€3g.20gbã€7g.40gb
  mig:
    profile: "1g.5gb"  # 5GB å†…å­˜çš„ MIG å®ä¾‹
    count: 1

---

# åŸºäº MIG çš„ ResourceClass
apiVersion: resource.k8s.io/v1alpha2
kind: ResourceClass
metadata:
  name: gpu.nvidia.com/mig
driverName: nvidia.com/gpu
structuredParameters: true
parametersSchema:
  openAPIV3Schema:
    type: object
    properties:
      gpuProfile:
        type: string
        enum: ["1g.5gb", "2g.10gb", "3g.20gb", "7g.40gb"]
        default: "1g.5gb"

---

# MIG ResourceClaim ä½¿ç”¨ç¤ºä¾‹
apiVersion: resource.k8s.io/v1alpha2
kind: ResourceClaim
metadata:
  name: inference-gpu-mig
  namespace: ai-inference
spec:
  resourceClassName: gpu.nvidia.com/mig
  parametersRef:
    apiGroup: gpu.nvidia.com
    kind: GpuClaimParameters
    name: a100-mig-1g.5gb

---

# åœ¨ Pod ä¸­ä½¿ç”¨ MIG ResourceClaim
apiVersion: v1
kind: Pod
metadata:
  name: vllm-mig-inference
  namespace: ai-inference
spec:
  containers:
    - name: vllm
      image: vllm/vllm-openai:latest
      command: ["python", "-m", "vllm.entrypoints.openai.api_server"]
      args:
        - "--model"
        - "meta-llama/Llama-2-7b-hf"
        - "--gpu-memory-utilization"
        - "0.9"
      resources:
        requests:
          memory: "4Gi"
          cpu: "4"
        claims:
          - name: mig-gpu
  resourceClaims:
    - name: mig-gpu
      source:
        resourceClaimTemplateName: mig-template
```

**MIG Profile æ€§èƒ½æŒ‡æ ‡ï¼š**

| Profile | å†…å­˜ | SM æ•°é‡ | ä½¿ç”¨åœºæ™¯ | é¢„æœŸååé‡ |
| --- | --- | --- | --- | --- |
| 1g.5gb | 5GB | 14 | å°å‹æ¨¡å‹ï¼ˆ3B-7Bï¼‰ | ~20 tok/s |
| 2g.10gb | 10GB | 28 | ä¸­å‹æ¨¡å‹ï¼ˆ7B-13Bï¼‰ | ~50 tok/s |
| 3g.20gb | 20GB | 42 | å¤§å‹æ¨¡å‹ï¼ˆ13B-70Bï¼‰ | ~100 tok/s |
| 7g.40gb | 40GB | 84 | è¶…å¤§å‹æ¨¡å‹ï¼ˆ70B+ï¼‰ | ~200 tok/s |

#### 2. åŸºäº Time-Slicing çš„åˆ†åŒº

Time-Slicing é€šè¿‡åˆ†å‰² GPU æ—¶é—´æ¥å…è®¸å¤šä¸ª Pod å…±äº«åŒä¸€ä¸ª GPUï¼š

```yaml
# Time-Slicing ResourceSlice å®šä¹‰
apiVersion: gpu.nvidia.com/v1alpha1
kind: ResourceSlice
metadata:
  name: gpu-node-timeslice
  namespace: ai-inference
spec:
  nodeName: gpu-node-01
  devices:
    - id: 0  # GPU 0
      vendor: nvidia
      model: "A100-SXM4-80GB"
      # Time-slicing é…ç½®ï¼šæœ€å¤š 4 ä¸ª Pod å¯å…±äº«åŒä¸€ GPU
      timeSlicing:
        replicas: 4
        # GPU è°ƒåº¦ç­–ç•¥ï¼š"aggressive"ã€"default"ã€"conservative"
        schedulingPolicy: "default"
        # ä¸Šä¸‹æ–‡åˆ‡æ¢å¼€é”€ (ms)
        contextSwitchInterval: 100

---

# Time-Slicing ResourceClass
apiVersion: resource.k8s.io/v1alpha2
kind: ResourceClass
metadata:
  name: gpu.nvidia.com/timeslice
driverName: nvidia.com/gpu
structuredParameters: true

---

# Time-Slicing ResourceClaim ä½¿ç”¨
apiVersion: resource.k8s.io/v1alpha2
kind: ResourceClaim
metadata:
  name: inference-gpu-slice
  namespace: ai-inference
spec:
  resourceClassName: gpu.nvidia.com/timeslice

---

# å¤šä¸ª Pod é€šè¿‡ time-slice å…±äº«åŒä¸€ GPU
apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllm-timeslice-replicas
  namespace: ai-inference
spec:
  replicas: 3  # 3 ä¸ª Pod å…±äº«åŒä¸€ GPU
  selector:
    matchLabels:
      app: vllm-slice
  template:
    metadata:
      labels:
        app: vllm-slice
    spec:
      containers:
        - name: vllm
          image: vllm/vllm-openai:latest
          resources:
            requests:
              memory: "8Gi"
              cpu: "2"
            claims:
              - name: gpu-slice
      resourceClaims:
        - name: gpu-slice
          source:
            resourceClaimTemplateName: timeslice-template
```

**Time-Slicing æ€§èƒ½è€ƒé‡ï¼š**

```mermaid
graph TB
    subgraph "Time-Slicing å¼€é”€"
        A["GPU ä¸Šä¸‹æ–‡åˆ‡æ¢"] -->|~100-500ms| B["L2 Cache åˆ·æ–°"]
        B --> C["åŠ è½½æ–° Kernel"]
        C --> D["å†…å­˜é‡ç»„"]
        D --> E["5-15% æ€§èƒ½ä¸‹é™"]
    end

    F["æ¨èä½¿ç”¨åœºæ™¯"] -->|æ‰¹é‡æ¨ç†| G["ååé‡ä¼˜å…ˆ"]
    F -->|å¼€å‘/æµ‹è¯•| H["æˆæœ¬ä¼˜åŒ–"]
    F -->|ä½ QoS è¦æ±‚| I["éç´§æ€¥ä»»åŠ¡"]

    J["åº”é¿å…çš„åœºæ™¯"] -->|å®æ—¶æ¨ç†| K["ä½å»¶è¿Ÿè¦æ±‚"]
    J -->|é«˜æ€§èƒ½è®­ç»ƒ| L["é«˜ååé‡éœ€æ±‚"]
    J -->|æ•æ„Ÿåº”ç”¨| M["éœ€è¦æ€§èƒ½ä¿è¯"]

    style E fill:#ff6b6b
    style G fill:#76b900
    style K fill:#ff6b6b
```

---

## å‚è€ƒèµ„æ–™

- [Karpenter å®˜æ–¹æ–‡æ¡£](https://karpenter.sh/)
- [NVIDIA DCGM Exporter](https://github.com/NVIDIA/dcgm-exporter)
- [KEDA å®˜æ–¹æ–‡æ¡£](https://keda.sh/)
- [AWS GPU å®ä¾‹æŒ‡å—](https://aws.amazon.com/ec2/instance-types/#Accelerated_Computing)
- [Kubernetes åŠ¨æ€èµ„æºåˆ†é…ï¼ˆDRAï¼‰](https://kubernetes.io/docs/concepts/scheduling-eviction/dynamic-resource-allocation/)
- [NVIDIA GPU Operator æ–‡æ¡£](https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/overview.html)
