---
title: "NeMo æ¡†æ¶"
sidebar_label: "8. NeMo Framework"
description: "ä½¿ç”¨ NVIDIA NeMo æ„å»º LLM å¾®è°ƒå’Œä¼˜åŒ–ç®¡é“"
sidebar_position: 8
tags:
  - nemo
  - nvidia
  - fine-tuning
  - llm
  - training
  - tensorrt
  - genai
last_update:
  date: 2026-02-14
  author: devfloor9
category: "genai-aiml"
---

import { NemoComponents, GPURequirements, CheckpointSharding, MonitoringMetrics, NCCLImportance } from '@site/src/components/NemoTables';

# NeMo æ¡†æ¶

NVIDIA NeMo æ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„æ¡†æ¶ï¼Œç”¨äºè®­ç»ƒã€å¾®è°ƒå’Œä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ã€‚å®ƒæ”¯æŒåœ¨ Kubernetes ç¯å¢ƒä¸­è¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒå’Œé«˜æ•ˆæ¨¡å‹éƒ¨ç½²ã€‚

## æ¦‚è¿°

### ä¸ºä»€ä¹ˆéœ€è¦ NeMo

å½“ Agentic AI å¹³å°éœ€è¦é¢†åŸŸä¸“ç”¨æ¨¡å‹æ—¶ï¼š

- **é¢†åŸŸé€‚é…**ï¼šä¸ºç‰¹å®šè¡Œä¸š/é¢†åŸŸå®šåˆ¶æ¨¡å‹
- **æ€§èƒ½ä¼˜åŒ–**ï¼šé€šè¿‡ TensorRT-LLM åŠ é€Ÿæ¨ç†
- **æˆæœ¬æ•ˆç‡**ï¼šç”¨è¾ƒå°çš„å¾®è°ƒæ¨¡å‹æ›¿ä»£å¤§å‹æ¨¡å‹
- **æ•°æ®éšç§**ï¼šä½¿ç”¨æ•æ„Ÿæ•°æ®è¿›è¡Œæœ¬åœ°è®­ç»ƒ

```mermaid
graph LR
    subgraph "NeMo Pipeline"
        Data["Data Preparation"]
        Pretrain["Pretraining<br/>(Optional)"]
        Finetune["Fine-tuning"]
        Eval["Evaluation"]
        Export["TensorRT Conversion"]
        Deploy["Deployment"]
    end

    Data --> Pretrain
    Pretrain --> Finetune
    Data --> Finetune
    Finetune --> Eval
    Eval --> Export
    Export --> Deploy

    style Finetune fill:#76b900,stroke:#333,stroke-width:2px
    style Export fill:#76b900,stroke:#333,stroke-width:2px
```

### NeMo æ¡†æ¶ç»„ä»¶

<NemoComponents />

## EKS éƒ¨ç½²æ¶æ„

### åˆ†å¸ƒå¼è®­ç»ƒæ¶æ„

```mermaid
graph TB
    subgraph "Control Plane"
        Launcher["NeMo Launcher"]
        Scheduler["Kubernetes Scheduler"]
    end

    subgraph "Worker Nodes"
        subgraph "Node 1"
            W1["Worker Pod"]
            G1["GPU 0-7"]
        end
        subgraph "Node 2"
            W2["Worker Pod"]
            G2["GPU 0-7"]
        end
        subgraph "Node 3"
            W3["Worker Pod"]
            G3["GPU 0-7"]
        end
    end

    subgraph "Storage"
        S3["S3 / FSx"]
        Checkpoint["Checkpoints"]
    end

    subgraph "Communication"
        NCCL["NCCL / EFA"]
    end

    Launcher --> Scheduler
    Scheduler --> W1
    Scheduler --> W2
    Scheduler --> W3

    W1 <--> NCCL
    W2 <--> NCCL
    W3 <--> NCCL

    W1 --> S3
    W2 --> S3
    W3 --> S3

    W1 --> Checkpoint
    W2 --> Checkpoint
    W3 --> Checkpoint

    style Launcher fill:#76b900,stroke:#333
    style NCCL fill:#4285f4,stroke:#333
```

### GPU èŠ‚ç‚¹éœ€æ±‚

<GPURequirements />

## NeMo å®¹å™¨éƒ¨ç½²

### Helm Chart å®‰è£…

```bash
# è®¤è¯ NVIDIA NGC é•œåƒä»“åº“
kubectl create secret docker-registry ngc-secret \
  --docker-server=nvcr.io \
  --docker-username='$oauthtoken' \
  --docker-password=${NGC_API_KEY} \
  --namespace=nemo

# å®‰è£… NeMo Operator
helm repo add nvidia https://helm.ngc.nvidia.com/nvidia
helm repo update

helm install nemo-operator nvidia/nemo-operator \
  --namespace nemo \
  --create-namespace \
  --set operator.image.repository=nvcr.io/nvidia/nemo-operator \
  --set operator.image.tag=24.07
```

### NeMo è®­ç»ƒä»»åŠ¡å®šä¹‰

```yaml
apiVersion: nemo.nvidia.com/v1alpha1
kind: NeMoTraining
metadata:
  name: llama-finetune
  namespace: nemo
spec:
  # æ¨¡å‹é…ç½®
  model:
    name: "meta-llama/Llama-2-7b-hf"
    source: "huggingface"

  # è®­ç»ƒé…ç½®
  training:
    type: "sft"  # ç›‘ç£å¾®è°ƒ
    epochs: 3
    batchSize: 4
    gradientAccumulationSteps: 8
    learningRate: 2e-5

    # åˆ†å¸ƒå¼è®­ç»ƒé…ç½®
    distributed:
      tensorParallelism: 1
      pipelineParallelism: 1
      dataParallelism: 8

  # æ•°æ®é…ç½®
  data:
    trainDataset: "s3://nemo-data/train.jsonl"
    valDataset: "s3://nemo-data/val.jsonl"
    format: "jsonl"

  # èµ„æºé…ç½®
  resources:
    nodes: 1
    gpusPerNode: 8
    gpuType: "nvidia.com/gpu"

  # æ£€æŸ¥ç‚¹é…ç½®
  checkpoint:
    enabled: true
    path: "s3://nemo-checkpoints/llama-finetune"
    saveInterval: 500

  # å®¹å™¨é•œåƒ
  image:
    repository: "nvcr.io/nvidia/nemo"
    tag: "24.07"
    pullSecrets:
      - name: ngc-secret
```

### ä½¿ç”¨ PyTorchJob è¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒ

```yaml
apiVersion: kubeflow.org/v1
kind: PyTorchJob
metadata:
  name: nemo-distributed-training
  namespace: nemo
spec:
  pytorchReplicaSpecs:
    Master:
      replicas: 1
      restartPolicy: OnFailure
      template:
        spec:
          containers:
          - name: pytorch
            image: nvcr.io/nvidia/nemo:24.07
            command:
            - python
            - -m
            - nemo.collections.llm.recipes.finetune
            - --config-path=/config
            - --config-name=llama_finetune
            env:
            - name: NCCL_DEBUG
              value: "INFO"
            - name: NCCL_IB_DISABLE
              value: "0"
            resources:
              limits:
                nvidia.com/gpu: 8
                vpc.amazonaws.com/efa: 4
            volumeMounts:
            - name: config
              mountPath: /config
            - name: data
              mountPath: /data
            - name: shm
              mountPath: /dev/shm
          volumes:
          - name: config
            configMap:
              name: nemo-config
          - name: data
            persistentVolumeClaim:
              claimName: training-data-pvc
          - name: shm
            emptyDir:
              medium: Memory
              sizeLimit: 64Gi
    Worker:
      replicas: 3
      restartPolicy: OnFailure
      template:
        spec:
          containers:
          - name: pytorch
            image: nvcr.io/nvidia/nemo:24.07
            # Worker é…ç½®ä¸ Master ç›¸åŒ
```

## å¾®è°ƒæŒ‡å—

### SFTï¼ˆç›‘ç£å¾®è°ƒï¼‰

```python
# nemo_sft_config.yaml
trainer:
  devices: 8
  num_nodes: 1
  accelerator: gpu
  precision: bf16
  max_epochs: 3
  val_check_interval: 500

model:
  # åŸºç¡€æ¨¡å‹
  restore_from_path: /models/llama-2-7b.nemo

  # LoRA é…ç½®ï¼ˆé«˜æ•ˆå¾®è°ƒï¼‰
  peft:
    peft_scheme: "lora"
    lora_tuning:
      adapter_dim: 32
      alpha: 32
      dropout: 0.1
      target_modules:
        - "q_proj"
        - "v_proj"
        - "k_proj"
        - "o_proj"

  # æ•°æ®é…ç½®
  data:
    train_ds:
      file_path: /data/train.jsonl
      micro_batch_size: 4
      global_batch_size: 32
    validation_ds:
      file_path: /data/val.jsonl
      micro_batch_size: 4

  # ä¼˜åŒ–å™¨é…ç½®
  optim:
    name: fused_adam
    lr: 2e-5
    weight_decay: 0.01
    betas:
      - 0.9
      - 0.98
```

### æ•°æ®æ ¼å¼

```json
{"input": "Answer the following question: What is EKS?", "output": "Amazon EKS (Elastic Kubernetes Service) is a managed Kubernetes service provided by AWS."}
{"input": "Explain the key features of Karpenter.", "output": "Karpenter provides automatic node provisioning, consolidation, and drift detection features for Kubernetes node auto-scaling."}
```

### PEFT/LoRA å¾®è°ƒ

```python
from nemo.collections.llm import finetune
from nemo.collections.llm.peft import LoRA

# LoRA é…ç½®
lora_config = LoRA(
    r=32,
    alpha=32,
    dropout=0.1,
    target_modules=["q_proj", "v_proj", "k_proj", "o_proj"],
)

# è¿è¡Œå¾®è°ƒ
model = finetune(
    model_path="/models/llama-2-7b.nemo",
    data_path="/data/train.jsonl",
    peft_config=lora_config,
    trainer_config={
        "devices": 8,
        "max_epochs": 3,
        "precision": "bf16",
    },
    output_path="/output/llama-2-7b-finetuned",
)
```

## æ£€æŸ¥ç‚¹ç®¡ç†

### S3 æ£€æŸ¥ç‚¹ä¿å­˜

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: nemo-checkpoint-config
  namespace: nemo
data:
  checkpoint.yaml: |
    checkpoint:
      save_dir: "s3://nemo-checkpoints/${JOB_NAME}"
      save_top_k: 3
      save_last: true
      save_interval: 500

      # è‡ªåŠ¨æ¢å¤é…ç½®
      resume:
        enabled: true
        resume_from_checkpoint: "auto"  # ä»æœ€æ–°æ£€æŸ¥ç‚¹è‡ªåŠ¨æ¢å¤
```

### æ£€æŸ¥ç‚¹è½¬æ¢

```bash
# å°† NeMo æ£€æŸ¥ç‚¹è½¬æ¢ä¸º HuggingFace æ ¼å¼
python -m nemo.collections.llm.scripts.convert_nemo_to_hf \
  --input_path /checkpoints/llama-finetuned.nemo \
  --output_path /models/llama-finetuned-hf \
  --model_type llama
```

## TensorRT-LLM è½¬æ¢ä¸ä¼˜åŒ–

### æ¨¡å‹è½¬æ¢ç®¡é“

```mermaid
graph LR
    NeMo["NeMo<br/>Checkpoint"]
    HF["HuggingFace<br/>Format"]
    TRT["TensorRT-LLM<br/>Engine"]
    Triton["Triton<br/>Server"]

    NeMo --> HF
    HF --> TRT
    TRT --> Triton

    style TRT fill:#76b900,stroke:#333,stroke-width:2px
```

### TensorRT-LLM è½¬æ¢è„šæœ¬

```python
# convert_to_trt.py
from tensorrt_llm import LLM, SamplingParams
from tensorrt_llm.builder import BuildConfig

# æ„å»ºé…ç½®
build_config = BuildConfig(
    max_input_len=4096,
    max_output_len=2048,
    max_batch_size=64,

    # é‡åŒ–é…ç½®
    quantization="fp8",  # FP8 é‡åŒ–ä»¥èŠ‚çœå†…å­˜

    # ä¼˜åŒ–é…ç½®
    use_paged_kv_cache=True,
    use_inflight_batching=True,
)

# æ¨¡å‹è½¬æ¢
llm = LLM(
    model="/models/llama-finetuned-hf",
    build_config=build_config,
)

# ä¿å­˜å¼•æ“
llm.save("/engines/llama-finetuned-trt")
```

### ä½¿ç”¨ Kubernetes Job è¿è¡Œè½¬æ¢

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: trt-llm-conversion
  namespace: nemo
spec:
  template:
    spec:
      containers:
      - name: converter
        image: nvcr.io/nvidia/tritonserver:24.07-trtllm-python-py3
        command:
        - python
        - /scripts/convert_to_trt.py
        - --input=/models/llama-finetuned-hf
        - --output=/engines/llama-finetuned-trt
        - --quantization=fp8
        - --max-batch-size=64
        resources:
          limits:
            nvidia.com/gpu: 1
            memory: "80Gi"
        volumeMounts:
        - name: models
          mountPath: /models
        - name: engines
          mountPath: /engines
        - name: scripts
          mountPath: /scripts
      volumes:
      - name: models
        persistentVolumeClaim:
          claimName: models-pvc
      - name: engines
        persistentVolumeClaim:
          claimName: engines-pvc
      - name: scripts
        configMap:
          name: conversion-scripts
      restartPolicy: Never
```

## Triton Inference Server éƒ¨ç½²

### TensorRT-LLM åç«¯é…ç½®

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: triton-trtllm
  namespace: inference
spec:
  replicas: 2
  selector:
    matchLabels:
      app: triton-trtllm
  template:
    metadata:
      labels:
        app: triton-trtllm
    spec:
      containers:
      - name: triton
        image: nvcr.io/nvidia/tritonserver:24.07-trtllm-python-py3
        args:
        - tritonserver
        - --model-repository=/models
        - --http-port=8000
        - --grpc-port=8001
        - --metrics-port=8002
        ports:
        - containerPort: 8000
          name: http
        - containerPort: 8001
          name: grpc
        - containerPort: 8002
          name: metrics
        resources:
          limits:
            nvidia.com/gpu: 1
            memory: "80Gi"
        volumeMounts:
        - name: model-repository
          mountPath: /models
      volumes:
      - name: model-repository
        persistentVolumeClaim:
          claimName: triton-models-pvc
```

### æ¨¡å‹ä»“åº“ç»“æ„

```
/models/
â””â”€â”€ llama-finetuned/
    â”œâ”€â”€ config.pbtxt
    â”œâ”€â”€ 1/
    â”‚   â””â”€â”€ model.plan
    â””â”€â”€ tokenizer/
        â”œâ”€â”€ tokenizer.json
        â””â”€â”€ tokenizer_config.json
```

### config.pbtxt é…ç½®

```protobuf
name: "llama-finetuned"
backend: "tensorrtllm"
max_batch_size: 64

input [
  {
    name: "input_ids"
    data_type: TYPE_INT32
    dims: [-1]
  },
  {
    name: "input_lengths"
    data_type: TYPE_INT32
    dims: [1]
  }
]

output [
  {
    name: "output_ids"
    data_type: TYPE_INT32
    dims: [-1]
  }
]

instance_group [
  {
    count: 1
    kind: KIND_GPU
    gpus: [0]
  }
]

parameters {
  key: "max_tokens_in_paged_kv_cache"
  value: { string_value: "8192" }
}

parameters {
  key: "batch_scheduler_policy"
  value: { string_value: "inflight_fused_batching" }
}
```

## ç›‘æ§ä¸æ—¥å¿—

### è®­ç»ƒæŒ‡æ ‡æ”¶é›†

```yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: nemo-training-monitor
  namespace: nemo
spec:
  selector:
    matchLabels:
      app: nemo-training
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
```

### å…³é”®ç›‘æ§æŒ‡æ ‡

<MonitoringMetrics />

---

## æ·±å…¥äº†è§£ï¼šåˆ†å¸ƒå¼è®­ç»ƒä¸­çš„ NCCL

### NCCL çš„è§’è‰²ä¸é‡è¦æ€§

NCCLï¼ˆ**NVIDIA Collective Communication Library**ï¼‰æ˜¯è´Ÿè´£åˆ†å¸ƒå¼ GPU è®­ç»ƒä¸­**å¤š GPU é—´é«˜é€Ÿé€šä¿¡**çš„æ ¸å¿ƒåº“ã€‚æ·±åº¦å­¦ä¹ æ¨¡å‹çš„æ€§èƒ½ç›´æ¥å—åˆ° NCCL ä¼˜åŒ–ç¨‹åº¦çš„å½±å“ã€‚

```mermaid
graph TB
    subgraph "åˆ†å¸ƒå¼è®­ç»ƒæ€§èƒ½åˆ†æ"
        A["æ€»è®­ç»ƒæ—¶é—´"] --> B["è®¡ç®—æ—¶é—´ 60%"]
        A --> C["é€šä¿¡æ—¶é—´ 40%"]

        C --> D["NCCL ä¼˜åŒ–çš„é¢†åŸŸ"]
        D --> E["é›†åˆæ“ä½œæ—¶é—´"]
        E --> F["åŒæ­¥å¼€é”€"]

        B --> G["GPU è®¡ç®— (Kernels)"]

        style D fill:#326ce5
        style E fill:#76b900
        style F fill:#ff6b6b
    end

    subgraph "NCCL è§£å†³çš„é—®é¢˜"
        H["ç›¸æ¯”åŸå§‹ç½‘ç»œ<br/>æå‡ 3-10 å€"]
        I["æ¶ˆé™¤ CPU å¼€é”€"]
        J["GPU å†…å­˜æ•ˆç‡"]
        K["è‡ªåŠ¨ä½¿ç”¨ NVLink/EFA"]
    end
```

**ä¸ºä»€ä¹ˆ NCCL åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­è‡³å…³é‡è¦ï¼š**

<NCCLImportance />

### æ ¸å¿ƒé›†åˆæ“ä½œ

#### 1. AllReduce - æœ€é‡è¦çš„æ“ä½œ

AllReduce å¯¹æ‰€æœ‰ GPU çš„æ•°æ®æ±‚å’Œå¹¶å°†ç»“æœåˆ†å‘ç»™æ‰€æœ‰ GPUï¼š

```
åˆå§‹çŠ¶æ€ï¼š
GPU 0: [1, 2, 3]
GPU 1: [4, 5, 6]
GPU 2: [7, 8, 9]
GPU 3: [10, 11, 12]

AllReduce åï¼š
GPU 0: [22, 26, 30]  # 1+4+7+10, 2+5+8+11, 3+6+9+12
GPU 1: [22, 26, 30]
GPU 2: [22, 26, 30]
GPU 3: [22, 26, 30]
```

**AllReduce ä½¿ç”¨ç¤ºä¾‹ï¼ˆåˆ†å¸ƒå¼è®­ç»ƒä¸­ï¼‰ï¼š**

```python
import torch
import torch.distributed as dist

# åˆå§‹åŒ–åˆ†å¸ƒå¼è®­ç»ƒ
dist.init_process_group("nccl")
rank = dist.get_rank()
world_size = dist.get_world_size()

# æ¯ä¸ª GPU çš„æ¢¯åº¦ï¼ˆå„ä¸ç›¸åŒï¼‰
gradients = torch.randn(1024, device=f"cuda:{rank}")

# AllReduceï¼šå¯¹æ‰€æœ‰ GPU çš„æ¢¯åº¦æ±‚å’Œå¹¶å–å¹³å‡
dist.all_reduce(gradients, op=dist.ReduceOp.SUM)
gradients /= world_size

# ç°åœ¨æ‰€æœ‰ GPU éƒ½æœ‰ç›¸åŒçš„æ¢¯åº¦
# æ›´æ–°æ—¶æ¨¡å‹æƒé‡ä¿æŒåŒæ­¥
```

#### 2. AllGather - æ”¶é›†æ‰€æœ‰æ•°æ®

AllGather æ”¶é›†æ‰€æœ‰ GPU çš„æ•°æ®å¹¶å°†å®Œæ•´æ•°æ®é›†åˆ†å‘ç»™æ¯ä¸ª GPUï¼š

```
åˆå§‹çŠ¶æ€ï¼š
GPU 0: [1, 2]
GPU 1: [3, 4]
GPU 2: [5, 6]
GPU 3: [7, 8]

AllGather åï¼š
GPU 0: [1, 2, 3, 4, 5, 6, 7, 8]
GPU 1: [1, 2, 3, 4, 5, 6, 7, 8]
GPU 2: [1, 2, 3, 4, 5, 6, 7, 8]
GPU 3: [1, 2, 3, 4, 5, 6, 7, 8]
```

**AllGather ä½¿ç”¨åœºæ™¯ï¼š**

```python
# ç¤ºä¾‹ï¼šåœ¨æ‰¹å½’ä¸€åŒ–ä¸­æ”¶é›†æ‰€æœ‰ GPU çš„ç»Ÿè®¡ä¿¡æ¯
local_batch_stats = compute_batch_stats(local_batch)

# AllGather æ”¶é›†æ‰€æœ‰ GPU çš„ç»Ÿè®¡ä¿¡æ¯
all_batch_stats = [torch.empty_like(local_batch_stats) for _ in range(world_size)]
dist.all_gather(all_batch_stats, local_batch_stats)

# è®¡ç®—å…¨å±€ç»Ÿè®¡ä¿¡æ¯
global_mean = torch.stack(all_batch_stats).mean(dim=0)
global_std = torch.stack(all_batch_stats).std(dim=0)
```

#### 3. ReduceScatter - AllGather çš„é€†æ“ä½œ

ReduceScatter å…ˆå¯¹æ•°æ®æ±‚å’Œï¼Œç„¶ååˆ†åŒºå¹¶åˆ†å‘ç»™æ¯ä¸ª GPUï¼š

```
åˆå§‹çŠ¶æ€ï¼š
GPU 0: [1, 2, 3, 4, 5, 6, 7, 8]
GPU 1: [9, 10, 11, 12, 13, 14, 15, 16]
GPU 2: [17, 18, 19, 20, 21, 22, 23, 24]
GPU 3: [25, 26, 27, 28, 29, 30, 31, 32]

ReduceScatter æ±‚å’Œå¹¶åˆ†åŒºåï¼š
GPU 0: [52, 56]      # (1+9+17+25), (2+10+18+26)
GPU 1: [60, 64]      # (3+11+19+27), (4+12+20+28)
GPU 2: [68, 72]      # (5+13+21+29), (6+14+22+30)
GPU 3: [76, 80]      # (7+15+23+31), (8+16+24+32)
```

**ReduceScatter ä½¿ç”¨åœºæ™¯ï¼ˆæ¨¡å‹å¹¶è¡Œï¼‰ï¼š**

```python
# åœ¨æ¨¡å‹å¹¶è¡Œä¸­å¯¹è®¡ç®—ç»“æœæ±‚å’Œå¹¶åˆ†åŒº
local_output = model_fragment(input_data)

# ReduceScatterï¼šå¯¹æ‰€æœ‰ç‰‡æ®µæ±‚å’Œç„¶ååˆ†åŒºåˆ°æ¯ä¸ª GPU
reduced_output = torch.empty(output_size // world_size, device=local_output.device)
dist.reduce_scatter(reduced_output, [local_output] * world_size)
```

#### 4. Broadcast - æ•°æ®åˆ†å‘

Broadcast å°†ä¸€ä¸ª GPU çš„æ•°æ®å¤åˆ¶åˆ°æ‰€æœ‰ GPUï¼š

```
åˆå§‹çŠ¶æ€ï¼š
GPU 0: [1, 2, 3, 4]
GPU 1: [0, 0, 0, 0]
GPU 2: [0, 0, 0, 0]
GPU 3: [0, 0, 0, 0]

Broadcast åï¼š
GPU 0: [1, 2, 3, 4]
GPU 1: [1, 2, 3, 4]
GPU 2: [1, 2, 3, 4]
GPU 3: [1, 2, 3, 4]
```

**Broadcast ä½¿ç”¨åœºæ™¯ï¼š**

```python
# ä»ä¸» GPU å¹¿æ’­æ¨¡å‹æ£€æŸ¥ç‚¹
model_state = load_checkpoint() if rank == 0 else None

# Broadcastï¼šå°†ä¸» GPU çš„æ¨¡å‹çŠ¶æ€åˆ†å‘ç»™æ‰€æœ‰ GPU
dist.broadcast_object_list([model_state], src=0)
model.load_state_dict(model_state)
```

### ç½‘ç»œæ‹“æ‰‘æ„ŸçŸ¥

NCCL è‡ªåŠ¨æ£€æµ‹ GPU ä¹‹é—´çš„ç‰©ç†è¿æ¥æ‹“æ‰‘å¹¶é€‰æ‹©æœ€ä¼˜è·¯å¾„ï¼š

```mermaid
graph TB
    subgraph "æ‹“æ‰‘å±‚æ¬¡ï¼ˆä»ä¸Šåˆ°ä¸‹é€Ÿåº¦é€’å‡ï¼‰"
        L1["1. NVSwitchï¼ˆåŒä¸€èŠ‚ç‚¹å†…ï¼‰<br/>æœ€é«˜ 600GB/s"]
        L2["2. NVLinkï¼ˆåŒä¸€èŠ‚ç‚¹å†…ï¼‰<br/>æœ€é«˜ 200GB/s"]
        L3["3. EFA/InfiniBandï¼ˆèŠ‚ç‚¹é—´ï¼‰<br/>æœ€é«˜ 100GB/s"]
        L4["4. Ethernetï¼ˆèŠ‚ç‚¹é—´ï¼‰<br/>æœ€é«˜ 10-100GB/s"]
    end

    L1 --> L2 --> L3 --> L4

    subgraph "NCCL è‡ªåŠ¨è·¯å¾„é€‰æ‹©"
        A["æ‹“æ‰‘åˆ†æ"] --> B["æœ€ä¼˜ç®—æ³•é€‰æ‹©"]
        B --> C["é€šé“é…ç½®"]
    end

    style L1 fill:#76b900
    style L2 fill:#76b900
    style L3 fill:#4ecdc4
    style L4 fill:#ff6b6b
```

### NCCL æ€§èƒ½è°ƒä¼˜å‚æ•°

```yaml
# NCCL ç¯å¢ƒå˜é‡å®Œæ•´æŒ‡å—

# 1. ç®—æ³•é€‰æ‹©
export NCCL_ALGO=Ring           # Ringï¼ˆé»˜è®¤ï¼‰ã€Treeã€CollNet
export NCCL_ALGO_ALL=Ring       # æŒ‡å®š AllReduce ç®—æ³•
export NCCL_ALGO_TREE=Tree      # å¼ºåˆ¶ä½¿ç”¨ Tree ç®—æ³•

# 2. åè®®é€‰æ‹©
export NCCL_PROTO=Simple        # Simpleï¼ˆé»˜è®¤ï¼‰æˆ– LLï¼ˆä½å»¶è¿Ÿï¼‰

# 3. é€šé“è®¾ç½®ï¼ˆéå¸¸é‡è¦ï¼‰
export NCCL_MIN_NCHANNELS=4     # æœ€å°é€šé“æ•°ï¼ˆé»˜è®¤ 4ï¼‰
export NCCL_MAX_NCHANNELS=8     # æœ€å¤§é€šé“æ•°ï¼ˆé»˜è®¤ 32ï¼‰

# 4. ç¼“å†²åŒºå¤§å°
export NCCL_BUFFSIZE=2097152    # é»˜è®¤ 2MBï¼Œå»ºè®® 1MB-4MB

# 5. è°ƒè¯•è®¾ç½®
export NCCL_DEBUG=INFO          # TRACEã€DEBUGã€INFOã€WARN
export NCCL_DEBUG_FILE=/var/log/nccl-debug.txt
export NCCL_DEBUG_SUBSYS=ALL    # è¿½è¸ªæ‰€æœ‰å­ç³»ç»Ÿ

# 6. ç½‘ç»œæ¥å£
export NCCL_SOCKET_IFNAME=eth0  # ä½¿ç”¨çš„ç½‘ç»œæ¥å£
export NCCL_IB_DISABLE=0        # ä½¿ç”¨ InfiniBand

# 7. EFA è®¾ç½®ï¼ˆAWSï¼‰
export FI_PROVIDER=efa
export FI_EFA_USE_DEVICE_RDMA=1
export FI_EFA_FORK_SAFE=1

# 8. å†…æ ¸ä¼˜åŒ–
export NCCL_CHECKS_DISABLE=0    # å¯ç”¨å®‰å…¨æ£€æŸ¥ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
export NCCL_COMM_BLOCKING_WAIT=0
export NCCL_ASYNC_ERROR_HANDLING=1

# 9. P2P è®¾ç½®
export NCCL_P2P_DISABLE=0       # å¯ç”¨ GPU P2P é€šä¿¡
export NCCL_P2P_LEVEL=SYS       # P2P çº§åˆ«ï¼šLOCï¼ˆæœ¬åœ°ï¼‰ã€SYSï¼ˆç³»ç»Ÿï¼‰

# 10. è¶…æ—¶è®¾ç½®
export NCCL_COMM_WAIT_TIMEOUT=0 # 0 = æ— é™ç­‰å¾…
```

### Kubernetes é›†æˆè¦ç‚¹

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

> ğŸ“… **æ’°å†™æ—¥æœŸ**: 2026-02-13 | **ä¿®æ”¹æ—¥æœŸ**: 2026-02-14 | â±ï¸ **é˜…è¯»æ—¶é—´**: çº¦ 3 åˆ†é’Ÿ


<Tabs>
<TabItem value="config" label="NCCL Configuration" default>

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: distributed-training
spec:
  containers:
  - name: trainer
    image: nvcr.io/nvidia/pytorch:24.01-py3
    env:
    # NCCL æ ¸å¿ƒè®¾ç½®
    - name: NCCL_DEBUG
      value: "INFO"  # å¯ç”¨ NCCL æ—¥å¿—
    - name: NCCL_DEBUG_SUBSYS
      value: "INIT,GRAPH,ENV"

    # ç½‘ç»œæ¥å£é€‰æ‹©
    - name: NCCL_SOCKET_IFNAME
      value: "eth0"  # ä¸»ç½‘ç»œæ¥å£
    - name: NCCL_IB_DISABLE
      value: "0"  # å¦‚å¯ç”¨åˆ™å¯ç”¨ InfiniBand

    # æ€§èƒ½è°ƒä¼˜
    - name: NCCL_NET_GDR_LEVEL
      value: "5"  # GPUDirect RDMA çº§åˆ«
    - name: NCCL_P2P_LEVEL
      value: "NVL"  # ä½¿ç”¨ NVLink è¿›è¡Œ P2P
    - name: NCCL_CROSS_NIC
      value: "1"  # ä½¿ç”¨å¤šä¸ª NIC

    # EFA ä¸“ç”¨è®¾ç½®ï¼ˆAWSï¼‰
    - name: FI_PROVIDER
      value: "efa"
    - name: FI_EFA_USE_DEVICE_RDMA
      value: "1"
    - name: NCCL_PROTO
      value: "simple"

    resources:
      limits:
        nvidia.com/gpu: 8
```

</TabItem>
<TabItem value="topology" label="Topology Detection">

```yaml
# åŒ…å« NCCL æ‹“æ‰‘ä¿¡æ¯çš„ ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: nccl-topology
data:
  topology.xml: |
    <?xml version="1.0" encoding="UTF-8"?>
    <system version="1">
      <gpu dev="0" numa="0" pci="0000:10:1c.0">
        <nvlink target="1" count="12"/>
        <nvlink target="2" count="12"/>
        <nvlink target="3" count="12"/>
      </gpu>
      <gpu dev="1" numa="0" pci="0000:10:1d.0">
        <nvlink target="0" count="12"/>
        <nvlink target="2" count="12"/>
        <nvlink target="3" count="12"/>
      </gpu>
      <!-- æ›´å¤š GPU... -->
    </system>
---
apiVersion: v1
kind: Pod
metadata:
  name: training-with-topology
spec:
  containers:
  - name: trainer
    volumeMounts:
    - name: nccl-topology
      mountPath: /etc/nccl
    env:
    - name: NCCL_TOPO_FILE
      value: /etc/nccl/topology.xml
  volumes:
  - name: nccl-topology
    configMap:
      name: nccl-topology
```

</TabItem>
<TabItem value="benchmark" label="NCCL Benchmark">

```yaml
# ç”¨äºç½‘ç»œéªŒè¯çš„ NCCL Tests DaemonSet
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: nccl-tests
  namespace: gpu-testing
spec:
  selector:
    matchLabels:
      app: nccl-tests
  template:
    metadata:
      labels:
        app: nccl-tests
    spec:
      hostNetwork: true  # è®¿é—®ä¸»æœºç½‘ç»œ
      containers:
      - name: nccl-test
        image: nvcr.io/nvidia/pytorch:24.01-py3
        command:
        - /bin/bash
        - -c
        - |
          # å®‰è£… NCCL tests
          git clone https://github.com/NVIDIA/nccl-tests.git
          cd nccl-tests
          make MPI=1

          # è¿è¡Œ all-reduce åŸºå‡†æµ‹è¯•
          mpirun --allow-run-as-root \
            -np 8 \
            --hostfile /etc/mpi/hostfile \
            --bind-to none \
            -x NCCL_DEBUG=INFO \
            -x NCCL_SOCKET_IFNAME=eth0 \
            ./build/all_reduce_perf -b 8 -e 4G -f 2 -g 1
        resources:
          limits:
            nvidia.com/gpu: 8
        volumeMounts:
        - name: dshm
          mountPath: /dev/shm
      volumes:
      - name: dshm
        emptyDir:
          medium: Memory
          sizeLimit: 64Gi
```

</TabItem>
</Tabs>

**NCCL æ€§èƒ½å½±å“å› ç´ ï¼š**

1. **ç½‘ç»œå¸¦å®½**ï¼šInfiniBand (200-400 Gbps) > EFA (100 Gbps) > Ethernet (25-100 Gbps)
2. **GPU äº’è¿**ï¼šNVLink (600 GB/s) > PCIe 5.0 (128 GB/s)
3. **æ‹“æ‰‘æ„ŸçŸ¥**ï¼šç›´æ¥è¿æ¥å‡å°‘å»¶è¿Ÿ
4. **åè®®é€‰æ‹©**ï¼š`simple` é€‚ç”¨äºå°æ¶ˆæ¯ï¼Œ`LL128` é€‚ç”¨äºå¤§æ¶ˆæ¯

---

## ç›¸å…³æ–‡æ¡£

- [GPU èµ„æºç®¡ç†](./gpu-resource-management.md)
- [MoE æ¨¡å‹æœåŠ¡](./moe-model-serving.md)
- [æ¨ç†ç½‘å…³](./inference-gateway-routing.md)

:::tip å»ºè®®

- å¾®è°ƒå‰å…ˆç”¨åŸºç¡€æ¨¡å‹æµ‹é‡åŸºçº¿æ€§èƒ½
- LoRA/QLoRA å¯ä»¥åœ¨æœ‰é™ GPU èµ„æºä¸‹å¾®è°ƒå¤§å‹æ¨¡å‹
- TensorRT-LLM è½¬æ¢å¯å°†æ¨ç†æ€§èƒ½æå‡ 2-4 å€
- NCCL è°ƒä¼˜å¯¹åˆ†å¸ƒå¼è®­ç»ƒæ€§èƒ½è‡³å…³é‡è¦ - å…ˆä½¿ç”¨ `NCCL_DEBUG=INFO` äº†è§£é€šä¿¡æ¨¡å¼
:::

:::warning æ³¨æ„äº‹é¡¹

- å¤§è§„æ¨¡è®­ç»ƒä¼šäº§ç”Ÿå¤§é‡ GPU è´¹ç”¨ã€‚è¯·åˆ©ç”¨ Spot å®ä¾‹å’Œæ£€æŸ¥ç‚¹
- åˆ†å¸ƒå¼è®­ç»ƒå†³å®šèŠ‚ç‚¹æ•°é‡æ—¶éœ€è€ƒè™‘ NCCL é€šä¿¡å¼€é”€
- å§‹ç»ˆå°†æ£€æŸ¥ç‚¹ä¿å­˜åˆ° S3 ç­‰æŒä¹…å­˜å‚¨
- NCCL é…ç½®ä¸å½“å¯èƒ½å¯¼è‡´æ€§èƒ½ä¸‹é™ 50% ä»¥ä¸Š - åŠ¡å¿…ä½¿ç”¨ NCCL tests è¿›è¡ŒéªŒè¯
:::
