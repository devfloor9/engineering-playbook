---
title: "EKS Pod å¥åº·æ£€æŸ¥ä¸ç”Ÿå‘½å‘¨æœŸç®¡ç†"
sidebar_label: "5. Pod å¥åº·æ£€æŸ¥ä¸ç”Ÿå‘½å‘¨æœŸ"
description: "Kubernetes Pod å¥åº·æ£€æŸ¥ï¼ˆå­˜æ´»æ¢é’ˆã€å°±ç»ªæ¢é’ˆã€å¯åŠ¨æ¢é’ˆï¼‰å’Œç”Ÿå‘½å‘¨æœŸç®¡ç†ç»¼åˆæŒ‡å—ï¼ŒåŒ…æ‹¬ä¼˜é›…å…³é—­æ¨¡å¼"
sidebar_position: 5
tags: [EKS, Kubernetes, Pod, Health Check, Lifecycle, Probe, Liveness, Readiness, Startup, Graceful Shutdown]
category: "observability-monitoring"
last_update:
  date: 2026-02-14
  author: devfloor9
---

# EKS Pod å¥åº·æ£€æŸ¥ä¸ç”Ÿå‘½å‘¨æœŸç®¡ç†

> ğŸ“… **æ’°å†™æ—¥æœŸ**: 2025-10-15 | **ä¿®æ”¹æ—¥æœŸ**: 2026-02-14 | â±ï¸ **é˜…è¯»æ—¶é—´**: çº¦ 28 åˆ†é’Ÿ

> **ğŸ“Œ å‚è€ƒç¯å¢ƒ**: EKS 1.30+, Kubernetes 1.30+, AWS Load Balancer Controller v2.7+

## 1. æ¦‚è¿°

Pod å¥åº·æ£€æŸ¥ä¸ç”Ÿå‘½å‘¨æœŸç®¡ç†æ˜¯æœåŠ¡ç¨³å®šæ€§å’Œå¯ç”¨æ€§çš„åŸºç¡€ã€‚æ­£ç¡®é…ç½® Probe å¹¶å®ç° Graceful Shutdown å¯ä»¥ç¡®ä¿ä»¥ä¸‹å‡ ç‚¹ï¼š

- **é›¶åœæœºéƒ¨ç½²**: åœ¨æ»šåŠ¨æ›´æ–°æœŸé—´é˜²æ­¢æµé‡ä¸¢å¤±
- **å¿«é€Ÿæ•…éšœæ£€æµ‹**: è‡ªåŠ¨éš”ç¦»å’Œé‡å¯ä¸å¥åº·çš„ Pod
- **èµ„æºä¼˜åŒ–**: é˜²æ­¢å¯åŠ¨ç¼“æ…¢çš„åº”ç”¨è¢«è¿‡æ—©é‡å¯
- **æ•°æ®å®Œæ•´æ€§**: åœ¨å…³é—­æœŸé—´å®‰å…¨å®Œæˆæ­£åœ¨å¤„ç†çš„è¯·æ±‚

æœ¬æ–‡æ¡£æ¶µç›–äº† Pod çš„å®Œæ•´ç”Ÿå‘½å‘¨æœŸï¼Œä» Kubernetes Probe çš„å·¥ä½œåŸç†ï¼Œåˆ°å„è¯­è¨€çš„ Graceful Shutdown å®ç°ã€Init Container çš„ä½¿ç”¨æ–¹æ³•ä»¥åŠå®¹å™¨é•œåƒä¼˜åŒ–ã€‚

:::info ç›¸å…³æ–‡æ¡£
- **Probe è°ƒè¯•**: è¯·å‚é˜… [EKS æ•…éšœæ’æŸ¥ä¸äº‹ä»¶å“åº”æŒ‡å—](/docs/operations-observability/eks-debugging-guide) ä¸­çš„"Probe è°ƒè¯•ä¸æœ€ä½³å®è·µ"ç« èŠ‚
- **é«˜å¯ç”¨è®¾è®¡**: è¯·å‚é˜… [EKS é«˜å¯ç”¨æ¶æ„æŒ‡å—](/docs/operations-observability/eks-resiliency-guide) ä¸­çš„"Graceful Shutdown"ã€"PDB"å’Œ"Pod Readiness Gates"ç« èŠ‚
:::

---

## 2. Kubernetes Probe æ·±å…¥æŒ‡å—

### 2.1 ä¸‰ç§ Probe ç±»å‹åŠå·¥ä½œåŸç†

Kubernetes æä¾›ä¸‰ç§ç±»å‹çš„ Probe æ¥ç›‘æ§ Pod çŠ¶æ€ã€‚

| Probe ç±»å‹ | ç›®çš„ | å¤±è´¥æ—¶çš„è¡Œä¸º | æ¿€æ´»æ—¶æœº |
|-----------|------|-------------|-------------|
| **Startup Probe** | éªŒè¯åº”ç”¨åˆå§‹åŒ–æ˜¯å¦å®Œæˆ | é‡å¯ Podï¼ˆè¾¾åˆ° failureThreshold æ—¶ï¼‰ | Pod å¯åŠ¨åç«‹å³æ‰§è¡Œ |
| **Liveness Probe** | æ£€æµ‹åº”ç”¨æ­»é”/æŒ‚èµ·çŠ¶æ€ | é‡å¯å®¹å™¨ | Startup Probe æˆåŠŸå |
| **Readiness Probe** | éªŒè¯æ˜¯å¦å‡†å¤‡å¥½æ¥æ”¶æµé‡ | ä» Service Endpoints ä¸­ç§»é™¤ï¼ˆä¸é‡å¯ï¼‰ | Startup Probe æˆåŠŸå |

#### Startup Probeï¼šä¿æŠ¤å¯åŠ¨ç¼“æ…¢çš„åº”ç”¨

Startup Probe ä¼šå»¶è¿Ÿ Liveness/Readiness Probe çš„æ‰§è¡Œï¼Œç›´åˆ°åº”ç”¨å®Œå…¨å¯åŠ¨ã€‚å®ƒå¯¹äº Spring Bootã€JVM åº”ç”¨å’Œ ML æ¨¡å‹åŠ è½½ç­‰å¯åŠ¨ç¼“æ…¢çš„åº”ç”¨è‡³å…³é‡è¦ã€‚

**å·¥ä½œåŸç†ï¼š**
- Startup Probe è¿è¡ŒæœŸé—´ï¼ŒLiveness/Readiness Probe è¢«ç¦ç”¨
- Startup Probe æˆåŠŸ â†’ æ¿€æ´» Liveness/Readiness Probe
- Startup Probe å¤±è´¥ï¼ˆè¾¾åˆ° failureThresholdï¼‰ â†’ é‡å¯å®¹å™¨

#### Liveness Probeï¼šæ£€æµ‹æ­»é”

Liveness Probe æ£€æŸ¥åº”ç”¨æ˜¯å¦å­˜æ´»ã€‚å¤±è´¥æ—¶ï¼Œkubelet ä¼šé‡å¯å®¹å™¨ã€‚

**ä½¿ç”¨åœºæ™¯ï¼š**
- æ£€æµ‹æ— é™å¾ªç¯å’Œæ­»é”çŠ¶æ€
- ä¸å¯æ¢å¤çš„åº”ç”¨é”™è¯¯
- ç”±äºå†…å­˜æ³„æ¼å¯¼è‡´çš„æ— å“åº”çŠ¶æ€

**æ³¨æ„äº‹é¡¹ï¼š**
- **ä¸è¦åœ¨ Liveness Probe ä¸­åŒ…å«å¤–éƒ¨ä¾èµ–**ï¼ˆDBã€Redis ç­‰ï¼‰
- å¤–éƒ¨æœåŠ¡æ•…éšœå¯èƒ½å¯¼è‡´æ‰€æœ‰ Pod åŒæ—¶é‡å¯çš„çº§è”æ•…éšœ

#### Readiness Probeï¼šæ§åˆ¶æµé‡æ¥æ”¶

Readiness Probe æ£€æŸ¥ Pod æ˜¯å¦å‡†å¤‡å¥½æ¥æ”¶æµé‡ã€‚å¤±è´¥æ—¶ï¼ŒPod ä» Service çš„ Endpoints ä¸­ç§»é™¤ï¼Œä½†å®¹å™¨ä¸ä¼šé‡å¯ã€‚

**ä½¿ç”¨åœºæ™¯ï¼š**
- éªŒè¯ä¾èµ–æœåŠ¡è¿æ¥ï¼ˆDBã€ç¼“å­˜ï¼‰
- ç¡®è®¤åˆå§‹æ•°æ®åŠ è½½å®Œæˆ
- éƒ¨ç½²æœŸé—´çš„æ¸è¿›å¼æµé‡æ¥æ”¶

```mermaid
flowchart TB
    subgraph "Pod ç”Ÿå‘½å‘¨æœŸä¸ Probe è¡Œä¸º"
        START[Pod åˆ›å»º] --> INIT[Init Container æ‰§è¡Œ]
        INIT --> MAIN[ä¸»å®¹å™¨å¯åŠ¨]
        MAIN --> STARTUP{Startup Probe<br/>è¿è¡Œä¸­}

        STARTUP -->|å¤±è´¥| STARTUP_FAIL[è¾¾åˆ° failureThreshold]
        STARTUP_FAIL --> RESTART[å®¹å™¨é‡å¯]
        RESTART --> MAIN

        STARTUP -->|æˆåŠŸ| PROBES_ACTIVE[Liveness/Readiness<br/>Probe æ¿€æ´»]

        PROBES_ACTIVE --> LIVENESS{Liveness Probe}
        PROBES_ACTIVE --> READINESS{Readiness Probe}

        LIVENESS -->|å¤±è´¥| LIVENESS_FAIL[å®¹å™¨é‡å¯]
        LIVENESS_FAIL --> MAIN
        LIVENESS -->|æˆåŠŸ| RUNNING[æ­£å¸¸è¿è¡Œ]

        READINESS -->|å¤±è´¥| EP_REMOVE[ä» Service Endpoint<br/>ç§»é™¤]
        READINESS -->|æˆåŠŸ| EP_ADD[æ·»åŠ åˆ° Service Endpoint]
        EP_REMOVE -.-> READINESS
        EP_ADD --> RUNNING

        RUNNING --> TERM[Pod ç»ˆæ­¢è¯·æ±‚]
        TERM --> PRESTOP[preStop Hook]
        PRESTOP --> SIGTERM[å‘é€ SIGTERM]
        SIGTERM --> GRACE[Graceful Shutdown]
        GRACE --> STOPPED[å®¹å™¨ç»ˆæ­¢]
    end

    style START fill:#4286f4,stroke:#2a6acf,color:#fff
    style STARTUP fill:#fbbc04,stroke:#c99603,color:#000
    style PROBES_ACTIVE fill:#34a853,stroke:#2a8642,color:#fff
    style RESTART fill:#ff4444,stroke:#cc3636,color:#fff
    style RUNNING fill:#34a853,stroke:#2a8642,color:#fff
    style TERM fill:#ff9900,stroke:#cc7a00,color:#fff
```

### 2.2 Probe æœºåˆ¶

Kubernetes æ”¯æŒå››ç§ Probe æœºåˆ¶ã€‚

| æœºåˆ¶ | æè¿° | ä¼˜ç‚¹ | ç¼ºç‚¹ | æœ€é€‚åˆ |
|----------|------|------|------|------------|
| **httpGet** | HTTP GET è¯·æ±‚ï¼Œæ£€æŸ¥ 200-399 å“åº”ç  | æ ‡å‡†ï¼Œå®ç°ç®€å• | éœ€è¦ HTTP æœåŠ¡å™¨ | REST APIã€Web æœåŠ¡ |
| **tcpSocket** | æ£€æŸ¥ TCP ç«¯å£è¿é€šæ€§ | è½»é‡å¿«é€Ÿ | æ— æ³•éªŒè¯åº”ç”¨é€»è¾‘ | gRPCã€æ•°æ®åº“ |
| **exec** | åœ¨å®¹å™¨å†…æ‰§è¡Œå‘½ä»¤ï¼Œæ£€æŸ¥é€€å‡ºç æ˜¯å¦ä¸º 0 | çµæ´»ï¼Œå¯è‡ªå®šä¹‰é€»è¾‘ | å¼€é”€è¾ƒé«˜ | æ‰¹å¤„ç† Workerã€åŸºäºæ–‡ä»¶çš„æ£€æŸ¥ |
| **grpc** | ä½¿ç”¨ gRPC Health Check Protocolï¼ˆK8s 1.27+ GAï¼‰ | åŸç”Ÿ gRPC æ”¯æŒ | ä»…é€‚ç”¨äº gRPC åº”ç”¨ | gRPC å¾®æœåŠ¡ |

#### httpGet ç¤ºä¾‹

```yaml
livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
    httpHeaders:
    - name: X-Custom-Header
      value: HealthCheck
    scheme: HTTP  # æˆ– HTTPS
  initialDelaySeconds: 30
  periodSeconds: 10
```

#### tcpSocket ç¤ºä¾‹

```yaml
livenessProbe:
  tcpSocket:
    port: 5432  # PostgreSQL
  initialDelaySeconds: 15
  periodSeconds: 10
```

#### exec ç¤ºä¾‹

```yaml
livenessProbe:
  exec:
    command:
    - /bin/sh
    - -c
    - test -f /tmp/healthy
  initialDelaySeconds: 5
  periodSeconds: 5
```

#### grpc ç¤ºä¾‹ï¼ˆKubernetes 1.27+ï¼‰

```yaml
livenessProbe:
  grpc:
    port: 9090
    service: myservice  # å¯é€‰
  initialDelaySeconds: 10
  periodSeconds: 5
```

:::tip gRPC Health Check Protocol
gRPC æœåŠ¡å¿…é¡»å®ç° [gRPC Health Checking Protocol](https://github.com/grpc/grpc/blob/master/doc/health-checking.md)ã€‚Go è¯­è¨€ä½¿ç”¨ `google.golang.org/grpc/health`ï¼ŒJava ä½¿ç”¨ `grpc-health-check` åº“ã€‚
:::

### 2.3 Probe æ—¶é—´è®¾è®¡

Probe æ—¶é—´å‚æ•°å†³å®šäº†æ•…éšœæ£€æµ‹é€Ÿåº¦å’Œç¨³å®šæ€§ä¹‹é—´çš„å¹³è¡¡ã€‚

| å‚æ•° | æè¿° | é»˜è®¤å€¼ | å»ºè®®èŒƒå›´ |
|----------|------|--------|----------|
| `initialDelaySeconds` | å®¹å™¨å¯åŠ¨åˆ°é¦–æ¬¡ Probe çš„ç­‰å¾…æ—¶é—´ | 0 | 10-30sï¼ˆä½¿ç”¨ Startup Probe æ—¶å¯è®¾ä¸º 0ï¼‰ |
| `periodSeconds` | Probe æ‰§è¡Œé—´éš” | 10 | 5-15s |
| `timeoutSeconds` | Probe å“åº”ç­‰å¾…æ—¶é—´ | 1 | 3-10s |
| `failureThreshold` | åˆ¤å®šå¤±è´¥å‰çš„è¿ç»­å¤±è´¥æ¬¡æ•° | 3 | Liveness: 3, Readiness: 1-3, Startup: 30+ |
| `successThreshold` | åˆ¤å®šæˆåŠŸå‰çš„è¿ç»­æˆåŠŸæ¬¡æ•°ï¼ˆä»… Readiness å¯ >1ï¼‰ | 1 | 1-2 |

#### æ—¶é—´è®¾è®¡å…¬å¼

```
æœ€å¤§æ£€æµ‹æ—¶é—´ = failureThreshold Ã— periodSeconds
æœ€çŸ­æ¢å¤æ—¶é—´ = successThreshold Ã— periodSeconds
```

**ç¤ºä¾‹ï¼š**
- `failureThreshold: 3, periodSeconds: 10` â†’ æœ€å¤š 30 ç§’åæ£€æµ‹åˆ°æ•…éšœ
- `successThreshold: 2, periodSeconds: 5` â†’ è‡³å°‘ 10 ç§’ååˆ¤å®šæ¢å¤ï¼ˆä»… Readinessï¼‰

#### æŒ‰å·¥ä½œè´Ÿè½½ç±»å‹çš„å»ºè®®æ—¶é—´

| å·¥ä½œè´Ÿè½½ç±»å‹ | initialDelaySeconds | periodSeconds | failureThreshold | ç†ç”± |
|--------------|-------------------|---------------|-----------------|------|
| Web æœåŠ¡ï¼ˆNode.jsã€Pythonï¼‰ | 10 | 5 | 3 | å¯åŠ¨å¿«ï¼Œéœ€è¦å¿«é€Ÿæ£€æµ‹ |
| JVM åº”ç”¨ï¼ˆSpring Bootï¼‰ | 0ï¼ˆä½¿ç”¨ Startup Probeï¼‰ | 10 | 3 | å¯åŠ¨æ…¢ï¼Œç”± Startup Probe ä¿æŠ¤ |
| æ•°æ®åº“ï¼ˆPostgreSQLï¼‰ | 30 | 10 | 5 | åˆå§‹åŒ–æ—¶é—´é•¿ |
| æ‰¹å¤„ç† Worker | 5 | 15 | 2 | å‘¨æœŸæ€§ä»»åŠ¡ï¼Œæ£€æµ‹è¦æ±‚å®½æ¾ |
| ML æ¨ç†æœåŠ¡ | 0ï¼ˆStartup: 60ï¼‰ | 10 | 3 | æ¨¡å‹åŠ è½½æ—¶é—´é•¿ |

### 2.4 æŒ‰å·¥ä½œè´Ÿè½½çš„ Probe æ¨¡å¼

#### æ¨¡å¼ 1ï¼šWeb æœåŠ¡ï¼ˆREST APIï¼‰

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: rest-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: rest-api
  template:
    metadata:
      labels:
        app: rest-api
    spec:
      containers:
      - name: api
        image: myapp/rest-api:v1.2.3
        ports:
        - containerPort: 8080
          protocol: TCP
        resources:
          requests:
            cpu: 200m
            memory: 256Mi
          limits:
            cpu: 500m
            memory: 512Mi
        # Startup Probeï¼šéªŒè¯åœ¨ 30 ç§’å†…å®Œæˆå¯åŠ¨
        startupProbe:
          httpGet:
            path: /healthz
            port: 8080
          failureThreshold: 6
          periodSeconds: 5
        # Liveness Probeï¼šä»…å†…éƒ¨å¥åº·æ£€æŸ¥ï¼ˆæ’é™¤å¤–éƒ¨ä¾èµ–ï¼‰
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        # Readiness Probeï¼šå¯ä»¥åŒ…å«å¤–éƒ¨ä¾èµ–
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 2
          successThreshold: 1
        lifecycle:
          preStop:
            exec:
              command:
              - /bin/sh
              - -c
              - sleep 5 && kill -TERM 1
      terminationGracePeriodSeconds: 60
```

**å¥åº·æ£€æŸ¥ç«¯ç‚¹å®ç°ï¼ˆNode.js/Expressï¼‰ï¼š**

```javascript
// /healthz - Livenessï¼šä»…æ£€æŸ¥åº”ç”¨è‡ªèº«çŠ¶æ€
app.get('/healthz', (req, res) => {
  // ä»…æ£€æŸ¥å†…éƒ¨çŠ¶æ€ï¼ˆå†…å­˜ã€CPU ç­‰ï¼‰
  const memUsage = process.memoryUsage();
  if (memUsage.heapUsed / memUsage.heapTotal > 0.95) {
    return res.status(500).json({ status: 'unhealthy', reason: 'memory_pressure' });
  }
  res.status(200).json({ status: 'ok' });
});

// /ready - Readinessï¼šåŒ…æ‹¬å¤–éƒ¨ä¾èµ–çš„æ£€æŸ¥
app.get('/ready', async (req, res) => {
  try {
    // éªŒè¯ DB è¿æ¥
    await db.ping();
    // éªŒè¯ Redis è¿æ¥
    await redis.ping();
    res.status(200).json({ status: 'ready' });
  } catch (err) {
    res.status(503).json({ status: 'not_ready', reason: err.message });
  }
});
```

#### æ¨¡å¼ 2ï¼šgRPC æœåŠ¡

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grpc-service
spec:
  replicas: 3
  selector:
    matchLabels:
      app: grpc-service
  template:
    metadata:
      labels:
        app: grpc-service
    spec:
      containers:
      - name: grpc-server
        image: myapp/grpc-service:v2.1.0
        ports:
        - containerPort: 9090
          name: grpc
        resources:
          requests:
            cpu: 300m
            memory: 512Mi
          limits:
            cpu: 1
            memory: 1Gi
        # gRPC åŸç”Ÿæ¢é’ˆï¼ˆK8s 1.27+ï¼‰
        startupProbe:
          grpc:
            port: 9090
            service: myapp.HealthService  # å¯é€‰
          failureThreshold: 30
          periodSeconds: 10
        livenessProbe:
          grpc:
            port: 9090
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        readinessProbe:
          grpc:
            port: 9090
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 2
      terminationGracePeriodSeconds: 45
```

**gRPC å¥åº·æ£€æŸ¥å®ç°ï¼ˆGoï¼‰ï¼š**

```go
package main

import (
    "context"
    "google.golang.org/grpc"
    "google.golang.org/grpc/health"
    "google.golang.org/grpc/health/grpc_health_v1"
)

func main() {
    server := grpc.NewServer()

    // æ³¨å†Œå¥åº·æ£€æŸ¥æœåŠ¡
    healthServer := health.NewServer()
    grpc_health_v1.RegisterHealthServer(server, healthServer)

    // è®¾ç½®æœåŠ¡çŠ¶æ€ä¸º SERVING
    healthServer.SetServingStatus("myapp.HealthService", grpc_health_v1.HealthCheckResponse_SERVING)

    // ä¾èµ–æ£€æŸ¥åå¯ä»¥æ›´æ”¹ä¸º NOT_SERVING
    // healthServer.SetServingStatus("myapp.HealthService", grpc_health_v1.HealthCheckResponse_NOT_SERVING)

    // å¯åŠ¨ gRPC æœåŠ¡å™¨
    lis, _ := net.Listen("tcp", ":9090")
    server.Serve(lis)
}
```

#### æ¨¡å¼ 3ï¼šWorker/æ‰¹å¤„ç†

æ‰¹å¤„ç† Worker æ²¡æœ‰ HTTP æœåŠ¡å™¨ï¼Œå› æ­¤ä½¿ç”¨ `exec` Probeã€‚

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: batch-worker
spec:
  replicas: 2
  selector:
    matchLabels:
      app: batch-worker
  template:
    metadata:
      labels:
        app: batch-worker
    spec:
      containers:
      - name: worker
        image: myapp/batch-worker:v3.0.1
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 2
            memory: 4Gi
        # Startup Probeï¼šéªŒè¯ Worker åˆå§‹åŒ–
        startupProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - test -f /tmp/worker-ready
          failureThreshold: 12
          periodSeconds: 5
        # Liveness Probeï¼šæ£€æŸ¥å¿ƒè·³æ–‡ä»¶
        livenessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - find /tmp/heartbeat -mmin -2 | grep -q heartbeat
          initialDelaySeconds: 10
          periodSeconds: 30
          failureThreshold: 3
        # Readiness Probeï¼šéªŒè¯ä½œä¸šé˜Ÿåˆ—è¿æ¥
        readinessProbe:
          exec:
            command:
            - /app/check-queue-connection.sh
          periodSeconds: 10
          failureThreshold: 3
      terminationGracePeriodSeconds: 120
```

**Worker åº”ç”¨ï¼ˆPythonï¼‰ï¼š**

```python
import os
import time
from pathlib import Path

HEARTBEAT_FILE = Path("/tmp/heartbeat")
READY_FILE = Path("/tmp/worker-ready")

def worker_loop():
    # æ ‡è®°åˆå§‹åŒ–å®Œæˆ
    READY_FILE.touch()

    while True:
        # å®šæœŸæ›´æ–°å¿ƒè·³
        HEARTBEAT_FILE.touch()

        # å¤„ç†ä½œä¸š
        process_jobs()
        time.sleep(5)

def process_jobs():
    # å®é™…ä½œä¸šé€»è¾‘
    pass

if __name__ == "__main__":
    worker_loop()
```

#### æ¨¡å¼ 4ï¼šå¯åŠ¨ç¼“æ…¢çš„åº”ç”¨ï¼ˆSpring Bootã€JVMï¼‰

JVM åº”ç”¨å¯åŠ¨å¯èƒ½éœ€è¦ 30 ç§’æˆ–æ›´é•¿æ—¶é—´ã€‚ä½¿ç”¨ Startup Probe è¿›è¡Œä¿æŠ¤ã€‚

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spring-boot-app
spec:
  replicas: 4
  selector:
    matchLabels:
      app: spring-boot
  template:
    metadata:
      labels:
        app: spring-boot
    spec:
      containers:
      - name: app
        image: myapp/spring-boot:v2.7.0
        ports:
        - containerPort: 8080
        resources:
          requests:
            cpu: 1
            memory: 2Gi
          limits:
            cpu: 2
            memory: 4Gi
        env:
        - name: JAVA_OPTS
          value: "-Xms1g -Xmx3g"
        # Startup Probeï¼šæœ€é•¿ç­‰å¾… 5 åˆ†é’Ÿï¼ˆ30 x 10sï¼‰
        startupProbe:
          httpGet:
            path: /actuator/health/liveness
            port: 8080
          failureThreshold: 30
          periodSeconds: 10
        # Liveness Probeï¼šStartup æˆåŠŸåæ¿€æ´»
        livenessProbe:
          httpGet:
            path: /actuator/health/liveness
            port: 8080
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        # Readiness Probeï¼šåŒ…å«å¤–éƒ¨ä¾èµ–
        readinessProbe:
          httpGet:
            path: /actuator/health/readiness
            port: 8080
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 2
      terminationGracePeriodSeconds: 60
```

**Spring Boot Actuator é…ç½®ï¼š**

```yaml
# application.yml
management:
  endpoints:
    web:
      exposure:
        include: health
  health:
    livenessState:
      enabled: true
    readinessState:
      enabled: true
  endpoint:
    health:
      probes:
        enabled: true
      show-details: when-authorized
```

#### æ¨¡å¼ 5ï¼šSidecar æ¨¡å¼ï¼ˆIstio Proxy + Appï¼‰

åœ¨ Sidecar æ¨¡å¼ä¸­ï¼Œåº”ä¸ºä¸»å®¹å™¨å’Œ Sidecar éƒ½é…ç½® Probeã€‚

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-with-sidecar
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      # ä¸»åº”ç”¨å®¹å™¨
      - name: app
        image: myapp/app:v1.0.0
        ports:
        - containerPort: 8080
        startupProbe:
          httpGet:
            path: /healthz
            port: 8080
          failureThreshold: 10
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8080
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          periodSeconds: 5
      # Istio sidecarï¼ˆIstio åœ¨è‡ªåŠ¨æ³¨å…¥æ—¶ä¼šè‡ªåŠ¨æ·»åŠ  Probeï¼‰
      # æ‰‹åŠ¨é…ç½®ç¤ºä¾‹ï¼š
      - name: istio-proxy
        image: istio/proxyv2:1.22.0
        ports:
        - containerPort: 15090
          name: http-envoy-prom
        startupProbe:
          httpGet:
            path: /healthz/ready
            port: 15021
          failureThreshold: 30
          periodSeconds: 1
        livenessProbe:
          httpGet:
            path: /healthz/ready
            port: 15021
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /healthz/ready
            port: 15021
          periodSeconds: 2
      terminationGracePeriodSeconds: 90
```

:::tip Istio Sidecar æ³¨å…¥
å½“ Istio ä½¿ç”¨è‡ªåŠ¨æ³¨å…¥ï¼ˆ`istio-injection=enabled` æ ‡ç­¾ï¼‰æ—¶ï¼ŒIstio ä¼šè‡ªåŠ¨ä¸º Sidecar æ·»åŠ é€‚å½“çš„ Probeï¼Œæ— éœ€æ‰‹åŠ¨é…ç½®ã€‚
:::

#### 2.4.6 Windows å®¹å™¨ Probe æ³¨æ„äº‹é¡¹

EKS æ”¯æŒåŸºäº Windows Server 2019/2022 çš„ Windows èŠ‚ç‚¹ï¼ŒWindows å®¹å™¨ä¸ Linux å®¹å™¨ç›¸æ¯”å…·æœ‰ä¸åŒçš„ Probe è¡Œä¸ºç‰¹å¾ã€‚

##### Windows ä¸ Linux Probe è¡Œä¸ºå·®å¼‚

| é¡¹ç›® | Linux å®¹å™¨ | Windows å®¹å™¨ | å½±å“ |
|------|---------------|-----------------|------|
| **å®¹å™¨è¿è¡Œæ—¶** | containerd | containerd (1.6+) | ç›¸åŒè¿è¡Œæ—¶ï¼Œä¸åŒ OS å±‚ |
| **exec Probe æ‰§è¡Œ** | `/bin/sh -c` | `cmd.exe /c` æˆ– `powershell.exe` | è„šæœ¬è¯­æ³•å·®å¼‚ |
| **httpGet Probe** | ç›¸åŒ | ç›¸åŒ | æ— å·®å¼‚ |
| **tcpSocket Probe** | ç›¸åŒ | ç›¸åŒ | æ— å·®å¼‚ |
| **å†·å¯åŠ¨æ—¶é—´** | å¿«ï¼ˆå‡ ç§’ï¼‰ | æ…¢ï¼ˆ10-30 ç§’ï¼‰ | éœ€è¦å¢åŠ  Startup Probe failureThreshold |
| **å†…å­˜å¼€é”€** | ä½ï¼ˆ50-100MBï¼‰ | é«˜ï¼ˆ200-500MBï¼‰ | éœ€è¦å¢åŠ  Resource request |
| **Probe è¶…æ—¶** | é€šå¸¸ 1-5 ç§’ | å»ºè®® 3-10 ç§’ | éœ€è€ƒè™‘ Windows I/O å»¶è¿Ÿ |

##### Windows å·¥ä½œè´Ÿè½½ Probe é…ç½®ç¤ºä¾‹

**IIS/.NET Framework åº”ç”¨ï¼š**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: iis-app
  namespace: windows-workloads
spec:
  replicas: 2
  selector:
    matchLabels:
      app: iis-app
  template:
    metadata:
      labels:
        app: iis-app
    spec:
      nodeSelector:
        kubernetes.io/os: windows
        kubernetes.io/arch: amd64
      containers:
      - name: iis
        image: mcr.microsoft.com/windows/servercore/iis:windowsservercore-ltsc2022
        ports:
        - containerPort: 80
        resources:
          requests:
            cpu: 500m
            memory: 512Mi
          limits:
            cpu: 2000m
            memory: 2Gi
        # Startup Probeï¼šè€ƒè™‘ Windows å†·å¯åŠ¨
        startupProbe:
          httpGet:
            path: /
            port: 80
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 5
          timeoutSeconds: 5
          failureThreshold: 12  # æ˜¯ Linux çš„ 2 å€ï¼ˆæœ€é•¿ 60 ç§’ï¼‰
          successThreshold: 1
        # Liveness Probeï¼šIIS è¿›ç¨‹çŠ¶æ€
        livenessProbe:
          httpGet:
            path: /healthz
            port: 80
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        # Readiness Probeï¼šASP.NET åº”ç”¨å°±ç»ª
        readinessProbe:
          httpGet:
            path: /ready
            port: 80
          initialDelaySeconds: 15
          periodSeconds: 5
          timeoutSeconds: 5
          failureThreshold: 3
          successThreshold: 1
      terminationGracePeriodSeconds: 60
```

**ASP.NET Core å¥åº·æ£€æŸ¥ç«¯ç‚¹å®ç°ï¼š**

```csharp
// Program.cs (ASP.NET Core 6+)
using Microsoft.AspNetCore.Diagnostics.HealthChecks;
using Microsoft.Extensions.Diagnostics.HealthChecks;

var builder = WebApplication.CreateBuilder(args);

// æ·»åŠ å¥åº·æ£€æŸ¥
builder.Services.AddHealthChecks()
    .AddCheck("self", () => HealthCheckResult.Healthy())
    .AddSqlServer(
        connectionString: builder.Configuration.GetConnectionString("DefaultConnection"),
        name: "sqlserver",
        tags: new[] { "ready" }
    );

var app = builder.Build();

// /healthz - Livenessï¼šä»…æ£€æŸ¥åº”ç”¨è‡ªèº«
app.MapHealthChecks("/healthz", new HealthCheckOptions
{
    Predicate = check => check.Tags.Contains("self") || check.Tags.Count == 0
});

// /ready - Readinessï¼šåŒ…æ‹¬å¤–éƒ¨ä¾èµ–
app.MapHealthChecks("/ready", new HealthCheckOptions
{
    Predicate = _ => true  // æ‰€æœ‰å¥åº·æ£€æŸ¥
});

app.Run();
```

##### Windows å·¥ä½œè´Ÿè½½ Probe è¶…æ—¶æ³¨æ„äº‹é¡¹

Windows å®¹å™¨å¯èƒ½å‡ºç°è¾ƒé•¿çš„ Probe è¶…æ—¶ï¼ŒåŸå› å¦‚ä¸‹ï¼š

1. **Windows å†…æ ¸å¼€é”€**: è¾ƒé‡çš„ Windows OS å±‚å¯¼è‡´ç³»ç»Ÿè°ƒç”¨å»¶è¿Ÿ
2. **ç£ç›˜ I/O æ€§èƒ½**: NTFS æ–‡ä»¶ç³»ç»Ÿå…ƒæ•°æ®å¼€é”€
3. **.NET Framework é¢„çƒ­**: CLR JIT ç¼–è¯‘å’Œç¨‹åºé›†åŠ è½½æ—¶é—´
4. **Windows Defender**: å®æ—¶æ‰«æå¯¼è‡´è¿›ç¨‹å¯åŠ¨å»¶è¿Ÿ

**å»ºè®®çš„ Probe æ—¶é—´ï¼ˆWindowsï¼‰ï¼š**

```yaml
startupProbe:
  timeoutSeconds: 5-10      # Linux: 3-5s
  periodSeconds: 5
  failureThreshold: 12-20   # Linux: 6-10

livenessProbe:
  timeoutSeconds: 5-10      # Linux: 3-5s
  periodSeconds: 10-15      # Linux: 10s
  failureThreshold: 3

readinessProbe:
  timeoutSeconds: 5-10      # Linux: 3-5s
  periodSeconds: 5-10       # Linux: 5s
  failureThreshold: 3
```

##### CloudWatch Container Insights for Windowsï¼ˆ2025-08ï¼‰

AWS äº 2025 å¹´ 8 æœˆå®£å¸ƒ CloudWatch Container Insights æ”¯æŒ Windows å·¥ä½œè´Ÿè½½ã€‚

**åœ¨ Windows èŠ‚ç‚¹ä¸Šå®‰è£… Container Insightsï¼š**

```bash
# CloudWatch Agent ConfigMapï¼ˆWindowsï¼‰
kubectl apply -f - <<EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: cwagentconfig-windows
  namespace: amazon-cloudwatch
data:
  cwagentconfig.json: |
    {
      "logs": {
        "metrics_collected": {
          "kubernetes": {
            "cluster_name": "my-eks-cluster",
            "metrics_collection_interval": 60
          }
        }
      },
      "metrics": {
        "namespace": "ContainerInsights",
        "metrics_collected": {
          "statsd": {
            "service_address": ":8125"
          }
        }
      }
    }
EOF

# éƒ¨ç½² Windows DaemonSet
kubectl apply -f https://raw.githubusercontent.com/aws-samples/amazon-cloudwatch-container-insights/latest/k8s-deployment-manifest-templates/deployment-mode/daemonset/container-insights-monitoring/cwagent/cwagent-daemonset-windows.yaml
```

**éªŒè¯ Container Insights æŒ‡æ ‡ï¼š**

```bash
# Windows èŠ‚ç‚¹æŒ‡æ ‡
aws cloudwatch get-metric-statistics \
  --namespace ContainerInsights \
  --metric-name node_memory_utilization \
  --dimensions Name=ClusterName,Value=my-eks-cluster Name=NodeName,Value=windows-node-1 \
  --start-time 2026-02-12T00:00:00Z \
  --end-time 2026-02-12T23:59:59Z \
  --period 300 \
  --statistics Average

# Windows Pod æŒ‡æ ‡
aws cloudwatch get-metric-statistics \
  --namespace ContainerInsights \
  --metric-name pod_cpu_utilization \
  --dimensions Name=ClusterName,Value=my-eks-cluster Name=Namespace,Value=windows-workloads \
  --start-time 2026-02-12T00:00:00Z \
  --end-time 2026-02-12T23:59:59Z \
  --period 60 \
  --statistics Average
```

##### æ··åˆé›†ç¾¤ï¼ˆLinux + Windowsï¼‰ç»Ÿä¸€ç›‘æ§ç­–ç•¥

**1. åŸºäº Node Selector çš„åˆ†ç¦»ï¼š**

```yaml
apiVersion: v1
kind: Service
metadata:
  name: unified-app
spec:
  selector:
    app: unified-app  # ä¸ OS æ— å…³
  ports:
  - port: 80
    targetPort: 8080
---
# Linux Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: unified-app-linux
spec:
  replicas: 3
  selector:
    matchLabels:
      app: unified-app
      os: linux
  template:
    metadata:
      labels:
        app: unified-app
        os: linux
    spec:
      nodeSelector:
        kubernetes.io/os: linux
      containers:
      - name: app
        image: myapp:linux-v1
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          periodSeconds: 5
          timeoutSeconds: 3
---
# Windows Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: unified-app-windows
spec:
  replicas: 2
  selector:
    matchLabels:
      app: unified-app
      os: windows
  template:
    metadata:
      labels:
        app: unified-app
        os: windows
    spec:
      nodeSelector:
        kubernetes.io/os: windows
      containers:
      - name: app
        image: myapp:windows-v1
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          periodSeconds: 10      # Windowsï¼šè¾ƒé•¿é—´éš”
          timeoutSeconds: 10     # Windowsï¼šè¾ƒé•¿è¶…æ—¶
```

**2. CloudWatch Logs Insights ç»Ÿä¸€æŸ¥è¯¢ï¼š**

```sql
-- åŒæ—¶æœç´¢ Linux å’Œ Windows Pod æ—¥å¿—
fields @timestamp, kubernetes.namespace_name, kubernetes.pod_name, kubernetes.host, @message
| filter kubernetes.labels.app = "unified-app"
| sort @timestamp desc
| limit 100
```

**3. Grafana Dashboard é›†æˆï¼š**

```yaml
# Prometheus æŸ¥è¯¢ï¼ˆæ··åˆé›†ç¾¤ï¼‰
# Linux + Windows Pod CPU åˆ©ç”¨ç‡
sum(rate(container_cpu_usage_seconds_total{namespace="default", pod=~"unified-app-.*"}[5m])) by (pod, node, os)

# æŒ‰ OS èšåˆ
sum(rate(container_cpu_usage_seconds_total{namespace="default", pod=~"unified-app-.*"}[5m])) by (os)
```

:::warning Windows å®¹å™¨é™åˆ¶
- **é•œåƒå¤§å°**: Windows é•œåƒæœ‰å‡ ä¸ª GBï¼ˆLinux æ˜¯å‡ å MBï¼‰
- **è®¸å¯è¯æˆæœ¬**: é€‚ç”¨ Windows Server è®¸å¯è¯è´¹ç”¨ï¼ˆåŒ…å«åœ¨ EC2 å®ä¾‹è´¹ç”¨ä¸­ï¼‰
- **èŠ‚ç‚¹å¯åŠ¨æ—¶é—´**: Windows èŠ‚ç‚¹å¯åŠ¨è¾ƒæ…¢ï¼ˆ5-10 åˆ†é’Ÿï¼‰
- **ç‰¹æƒå®¹å™¨**: Windows ä¸æ”¯æŒ Linux `privileged` æ¨¡å¼
- **HostProcess å®¹å™¨**: ä» Windows Server 2022ï¼ˆ1.22+ï¼‰å¼€å§‹æ”¯æŒ
:::

:::info å‚è€ƒèµ„æ–™
- [AWS åšå®¢ï¼šCloudWatch Container Insights for Windows](https://aws.amazon.com/blogs/mt/announcing-amazon-cloudwatch-container-insights-for-amazon-eks-windows-workloads-monitoring)
- [EKS Windows å®¹å™¨å®˜æ–¹æ–‡æ¡£](https://docs.aws.amazon.com/eks/latest/userguide/windows-support.html)
- [Kubernetes Windows å®¹å™¨æŒ‡å—](https://kubernetes.io/docs/concepts/windows/)
:::

### 2.5 Probe åæ¨¡å¼ä¸é™·é˜±

#### åæ¨¡å¼ 1ï¼šåœ¨ Liveness Probe ä¸­åŒ…å«å¤–éƒ¨ä¾èµ–

**é—®é¢˜ï¼š**

```yaml
livenessProbe:
  httpGet:
    path: /health  # åŒ…å« DBã€Redis è¿æ¥æ£€æŸ¥
    port: 8080
```

**ç»“æœï¼š**
- DB æ•…éšœæ—¶æ‰€æœ‰ Pod åŒæ—¶é‡å¯ â†’ çº§è”æ•…éšœ
- å³ä½¿æ˜¯ä¸´æ—¶çš„ç½‘ç»œå»¶è¿Ÿä¹Ÿä¼šå¯¼è‡´ Pod é‡å¯

**æ­£ç¡®é…ç½®ï¼š**

```yaml
# Livenessï¼šä»…æ£€æŸ¥åº”ç”¨è‡ªèº«çŠ¶æ€
livenessProbe:
  httpGet:
    path: /healthz  # ä»…æ£€æŸ¥å†…éƒ¨çŠ¶æ€
    port: 8080

# Readinessï¼šåŒ…å«å¤–éƒ¨ä¾èµ–
readinessProbe:
  httpGet:
    path: /ready  # æ£€æŸ¥ DBã€Redis ç­‰
    port: 8080
```

#### åæ¨¡å¼ 2ï¼šä¸ä½¿ç”¨ Startup Probe å´è®¾ç½®è¿‡é«˜çš„ initialDelaySeconds

**é—®é¢˜ï¼š**

```yaml
livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
  initialDelaySeconds: 120  # ç­‰å¾… 2 åˆ†é’Ÿ
  periodSeconds: 10
```

**ç»“æœï¼š**
- å³ä½¿åº”ç”¨åœ¨ 30 ç§’å†…å®Œæˆå¯åŠ¨ï¼Œä¹Ÿæœ‰ 90 ç§’æ²¡æœ‰å¥åº·æ£€æŸ¥
- å¯åŠ¨æœŸé—´çš„å´©æºƒæœ€å¤š 2 åˆ†é’Ÿå†…æ— æ³•æ£€æµ‹

**æ­£ç¡®é…ç½®ï¼š**

```yaml
# ä½¿ç”¨ Startup Probe ä¿æŠ¤å¯åŠ¨
startupProbe:
  httpGet:
    path: /healthz
    port: 8080
  failureThreshold: 12  # æœ€é•¿ç­‰å¾… 120 ç§’
  periodSeconds: 10

# Liveness åœ¨ Startup æˆåŠŸåç«‹å³æ¿€æ´»
livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
  initialDelaySeconds: 0  # Startup æˆåŠŸåç«‹å³å¼€å§‹
  periodSeconds: 10
```

#### åæ¨¡å¼ 3ï¼šLiveness å’Œ Readiness ä½¿ç”¨ç›¸åŒç«¯ç‚¹

**é—®é¢˜ï¼š**

```yaml
livenessProbe:
  httpGet:
    path: /health
    port: 8080

readinessProbe:
  httpGet:
    path: /health  # ç›¸åŒç«¯ç‚¹
    port: 8080
```

**ç»“æœï¼š**
- å¦‚æœ `/health` æ£€æŸ¥å¤–éƒ¨ä¾èµ–ï¼ŒLiveness ä¼šå¤±è´¥å¯¼è‡´ä¸å¿…è¦çš„é‡å¯
- è§’è‰²åˆ†ç¦»æ¨¡ç³Šï¼Œå¢åŠ è°ƒè¯•éš¾åº¦

**æ­£ç¡®é…ç½®ï¼š**

```yaml
livenessProbe:
  httpGet:
    path: /healthz  # ä»…å†…éƒ¨çŠ¶æ€
    port: 8080

readinessProbe:
  httpGet:
    path: /ready  # åŒ…å«å¤–éƒ¨ä¾èµ–
    port: 8080
```

#### åæ¨¡å¼ 4ï¼šè¿‡äºæ¿€è¿›çš„ failureThreshold

**é—®é¢˜ï¼š**

```yaml
livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
  periodSeconds: 5
  failureThreshold: 1  # ä»… 1 æ¬¡å¤±è´¥å°±é‡å¯
```

**ç»“æœï¼š**
- ä¸´æ—¶ç½‘ç»œå»¶è¿Ÿã€GC æš‚åœç­‰ä¼šå¯¼è‡´ä¸å¿…è¦çš„é‡å¯
- å¯èƒ½å‡ºç°é‡å¯å¾ªç¯

**æ­£ç¡®é…ç½®ï¼š**

```yaml
livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
  periodSeconds: 10
  failureThreshold: 3  # 30 ç§’åé‡å¯ï¼ˆ3 x 10sï¼‰
  timeoutSeconds: 5
```

#### åæ¨¡å¼ 5ï¼šè¿‡é•¿çš„ timeoutSeconds

**é—®é¢˜ï¼š**

```yaml
livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
  timeoutSeconds: 30  # ç­‰å¾… 30 ç§’
  periodSeconds: 10
```

**ç»“æœï¼š**
- Probe é˜»å¡ 30 ç§’ï¼Œå»¶è¿Ÿä¸‹ä¸€æ¬¡ Probe æ‰§è¡Œ
- æ•…éšœæ£€æµ‹å˜æ…¢

**æ­£ç¡®é…ç½®ï¼š**

```yaml
livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
  timeoutSeconds: 5  # è¦æ±‚ 5 ç§’å†…å“åº”
  periodSeconds: 10
  failureThreshold: 3
```

### 2.6 ALB/NLB å¥åº·æ£€æŸ¥ä¸ Probe é›†æˆ

ä½¿ç”¨ AWS Load Balancer Controller æ—¶ï¼Œå¿…é¡»åŒæ­¥ ALB/NLB å¥åº·æ£€æŸ¥ä¸ Kubernetes Readiness Probeï¼Œä»¥å®ç°é›¶åœæœºéƒ¨ç½²ã€‚

#### ALB Target Group å¥åº·æ£€æŸ¥ vs Readiness Probe

| ç±»åˆ« | ALB/NLB å¥åº·æ£€æŸ¥ | Kubernetes Readiness Probe |
|------|-----------------|---------------------------|
| **æ‰§è¡Œæ–¹** | AWS Load Balancer | kubelet |
| **æ£€æŸ¥ç›®æ ‡** | Target Group IP:Port | Pod å®¹å™¨ |
| **å¤±è´¥æ—¶çš„è¡Œä¸º** | ä» Target ç§»é™¤ï¼ˆé˜»æ­¢æµé‡ï¼‰ | ä» Service Endpoints ç§»é™¤ |
| **é»˜è®¤é—´éš”** | 30 ç§’ | 10 ç§’ |
| **è¶…æ—¶æ—¶é—´** | 5 ç§’ | 1 ç§’ |

#### å¥åº·æ£€æŸ¥æ—¶é—´åŒæ­¥ç­–ç•¥

åœ¨æ»šåŠ¨æ›´æ–°æœŸé—´ï¼Œä¼šå‘ç”Ÿä»¥ä¸‹åºåˆ—ï¼š

```mermaid
sequenceDiagram
    participant K8s as Kubernetes
    participant Pod as æ–° Pod
    participant LB as ALB/NLB
    participant Old as æ—§ Pod

    K8s->>Pod: åˆ›å»º Pod
    Pod->>Pod: startupProbe æˆåŠŸ
    Pod->>Pod: readinessProbe æˆåŠŸ
    K8s->>K8s: æ·»åŠ åˆ° Service Endpoints
    LB->>Pod: å¼€å§‹å¥åº·æ£€æŸ¥
    Note over LB,Pod: ç­‰å¾…å¥åº·é˜ˆå€¼<br/>ï¼ˆå¦‚è¿ç»­ 2 æ¬¡æˆåŠŸï¼‰
    LB->>LB: æ·»åŠ åˆ° Target Group
    LB->>Pod: å¼€å§‹å‘é€æµé‡

    K8s->>Old: Pod ç»ˆæ­¢è¯·æ±‚
    Old->>Old: preStop Hook
    K8s->>K8s: ä» Service Endpoints ç§»é™¤
    Old->>Old: æ¥æ”¶ SIGTERM
    LB->>Old: æ£€æµ‹åˆ°å¥åº·æ£€æŸ¥å¤±è´¥
    LB->>LB: ä» Target Group ç§»é™¤
    Old->>Old: Graceful Shutdown
    Old->>K8s: ç»ˆæ­¢å®Œæˆ
```

**å»ºè®®é…ç½®ï¼š**

```yaml
apiVersion: v1
kind: Service
metadata:
  name: myapp
  annotations:
    # ALB å¥åº·æ£€æŸ¥é…ç½®
    alb.ingress.kubernetes.io/healthcheck-path: /ready
    alb.ingress.kubernetes.io/healthcheck-interval-seconds: "10"
    alb.ingress.kubernetes.io/healthcheck-timeout-seconds: "5"
    alb.ingress.kubernetes.io/healthy-threshold-count: "2"
    alb.ingress.kubernetes.io/unhealthy-threshold-count: "2"
spec:
  type: NodePort
  ports:
  - port: 80
    targetPort: 8080
  selector:
    app: myapp
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: app
        image: myapp:v1
        ports:
        - containerPort: 8080
        readinessProbe:
          httpGet:
            path: /ready  # ä¸ ALB ç›¸åŒçš„è·¯å¾„
            port: 8080
          periodSeconds: 5  # æ¯” ALB æ›´çŸ­çš„é—´éš”
          failureThreshold: 2
          successThreshold: 1
      terminationGracePeriodSeconds: 60
```

#### Pod Readiness Gatesï¼ˆä¿è¯é›¶åœæœºéƒ¨ç½²ï¼‰

AWS Load Balancer Controller v2.5+ æ”¯æŒ Pod Readiness Gatesï¼Œå®ƒä¼šå»¶è¿Ÿ Pod è½¬æ¢ä¸º `Ready` çŠ¶æ€ï¼Œç›´åˆ° Pod æ³¨å†Œä¸º ALB/NLB ç›®æ ‡å¹¶é€šè¿‡å¥åº·æ£€æŸ¥ã€‚

**å¯ç”¨æ–¹å¼ï¼š**

```yaml
# é€šè¿‡å‘ Namespace æ·»åŠ æ ‡ç­¾å¯ç”¨è‡ªåŠ¨æ³¨å…¥
apiVersion: v1
kind: Namespace
metadata:
  name: production
  labels:
    elbv2.k8s.aws/pod-readiness-gate-inject: enabled
```

**éªŒè¯æ“ä½œï¼š**

```bash
# æ£€æŸ¥ Pod çš„ Readiness Gates
kubectl get pod myapp-xyz -o yaml | grep -A 10 readinessGates

# ç¤ºä¾‹è¾“å‡ºï¼š
# readinessGates:
# - conditionType: target-health.alb.ingress.k8s.aws/my-target-group-hash

# æ£€æŸ¥ Pod Conditions
kubectl get pod myapp-xyz -o jsonpath='{.status.conditions}' | jq
```

**ä¼˜åŠ¿ï¼š**
- åœ¨æ»šåŠ¨æ›´æ–°æœŸé—´ï¼Œæ—§ Pod åœ¨ä» Target ç§»é™¤ä¹‹å‰ä¼šè¢«ä¿ç•™
- æ–° Pod åªæœ‰åœ¨é€šè¿‡ ALB å¥åº·æ£€æŸ¥åæ‰ä¼šæ¥æ”¶æµé‡
- å®Œå…¨é›¶åœæœºéƒ¨ç½²ï¼Œæ— æµé‡æŸå¤±

:::info è¯¦ç»†ä¿¡æ¯
æœ‰å…³ Pod Readiness Gates çš„æ›´å¤šè¯¦æƒ…ï¼Œè¯·å‚é˜… [EKS é«˜å¯ç”¨æ¶æ„æŒ‡å—](/docs/operations-observability/eks-resiliency-guide) ä¸­çš„"Pod Readiness Gates"ç« èŠ‚ã€‚
:::

#### 2.6.4 Gateway API å¥åº·æ£€æŸ¥é›†æˆï¼ˆALB Controller v2.14+ï¼‰

AWS Load Balancer Controller v2.14+ åŸç”Ÿé›†æˆ Kubernetes Gateway API v1.4ï¼Œä¸ Ingress ç›¸æ¯”æä¾›äº†å¢å¼ºçš„æŒ‰è·¯ç”±å¥åº·æ£€æŸ¥æ˜ å°„ã€‚

##### Gateway API vs Ingress å¥åº·æ£€æŸ¥æ¯”è¾ƒ

| ç±»åˆ« | Ingress | Gateway API |
|------|---------|-------------|
| **å¥åº·æ£€æŸ¥é…ç½®ä½ç½®** | Service/Ingress æ³¨è§£ | HealthCheckPolicy CRD |
| **æŒ‰è·¯ç”±å¥åº·æ£€æŸ¥** | æœ‰é™ï¼ˆåŸºäºæ³¨è§£ï¼‰ | åŸç”Ÿæ”¯æŒï¼ˆæŒ‰ HTTPRoute/GRPCRouteï¼‰ |
| **L4/L7 åè®®æ”¯æŒ** | ä»… HTTP/HTTPS | TCP/UDP/TLS/HTTP/GRPC å…¨éƒ¨æ”¯æŒ |
| **å¤šç§Ÿæˆ·è§’è‰²åˆ†ç¦»** | å•ä¸€ Ingress å¯¹è±¡ | Gatewayï¼ˆåŸºç¡€è®¾æ–½ï¼‰/ Routeï¼ˆåº”ç”¨ï¼‰åˆ†ç¦» |
| **åŠ æƒé‡‘ä¸é›€éƒ¨ç½²** | å›°éš¾æˆ–ä¸å¯èƒ½ | HTTPRoute åŸç”Ÿæ”¯æŒ |

##### Gateway API æ¶æ„ä¸å¥åº·æ£€æŸ¥

```mermaid
flowchart TB
    subgraph "Gateway API æ¶æ„"
        Client[å®¢æˆ·ç«¯] --> Gateway[Gateway<br/>ALB/NLB]
        Gateway --> HTTPRoute1[HTTPRoute<br/>/api/v1]
        Gateway --> HTTPRoute2[HTTPRoute<br/>/api/v2]
        Gateway --> GRPCRoute[GRPCRoute<br/>/grpc]

        HTTPRoute1 --> Service1[Service: api-v1]
        HTTPRoute2 --> Service2[Service: api-v2]
        GRPCRoute --> Service3[Service: grpc-svc]

        Service1 --> Pod1[Pods]
        Service2 --> Pod2[Pods]
        Service3 --> Pod3[Pods]

        Policy[HealthCheckPolicy] -.->|åº”ç”¨| HTTPRoute1
        Policy -.->|åº”ç”¨| HTTPRoute2
    end

    style Gateway fill:#ff9900,stroke:#cc7a00,color:#fff
    style Policy fill:#34a853,stroke:#2a8642,color:#fff
```

##### L7 å¥åº·æ£€æŸ¥ï¼šHTTPRoute/GRPCRoute ä¸ ALB

**HealthCheckPolicy CRD ç¤ºä¾‹ï¼š**

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: prod-gateway
  namespace: production
spec:
  gatewayClassName: alb
  listeners:
  - name: http
    protocol: HTTP
    port: 80
---
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: api-v1-route
  namespace: production
spec:
  parentRefs:
  - name: prod-gateway
  hostnames:
  - api.example.com
  rules:
  - matches:
    - path:
        type: PathPrefix
        value: /api/v1
    backendRefs:
    - name: api-v1-service
      port: 8080
---
# HealthCheckPolicyï¼ˆAWS Load Balancer Controller v2.14+ï¼‰
apiVersion: elbv2.k8s.aws/v1beta1
kind: HealthCheckPolicy
metadata:
  name: api-v1-healthcheck
  namespace: production
spec:
  targetGroupARN: arn:aws:elasticloadbalancing:region:account:targetgroup/name/id
  healthCheckConfig:
    protocol: HTTP
    path: /api/v1/healthz  # æŒ‰è·¯ç”±å¥åº·æ£€æŸ¥
    port: 8080
    intervalSeconds: 10
    timeoutSeconds: 5
    healthyThresholdCount: 2
    unhealthyThresholdCount: 2
    matcher:
      httpCode: "200-299"
```

**GRPCRoute å¥åº·æ£€æŸ¥ç¤ºä¾‹ï¼š**

```yaml
apiVersion: gateway.networking.k8s.io/v1alpha2
kind: GRPCRoute
metadata:
  name: grpc-service-route
  namespace: production
spec:
  parentRefs:
  - name: prod-gateway
  hostnames:
  - grpc.example.com
  rules:
  - matches:
    - method:
        service: myservice.v1.MyService
    backendRefs:
    - name: grpc-backend
      port: 9090
---
apiVersion: elbv2.k8s.aws/v1beta1
kind: HealthCheckPolicy
metadata:
  name: grpc-healthcheck
  namespace: production
spec:
  targetGroupARN: arn:aws:elasticloadbalancing:region:account:targetgroup/grpc/id
  healthCheckConfig:
    protocol: HTTP  # gRPC å¥åº·æ£€æŸ¥åŸºäº HTTP/2
    path: /grpc.health.v1.Health/Check
    port: 9090
    intervalSeconds: 10
    timeoutSeconds: 5
    healthyThresholdCount: 2
    unhealthyThresholdCount: 2
    matcher:
      grpcCode: "0"  # gRPC OK çŠ¶æ€
```

##### L4 å¥åº·æ£€æŸ¥ï¼šTCPRoute/UDPRoute ä¸ NLB

```yaml
apiVersion: gateway.networking.k8s.io/v1alpha2
kind: TCPRoute
metadata:
  name: tcp-service-route
  namespace: production
spec:
  parentRefs:
  - name: nlb-gateway
    sectionName: tcp-listener
  rules:
  - backendRefs:
    - name: tcp-backend
      port: 5432
---
apiVersion: elbv2.k8s.aws/v1beta1
kind: HealthCheckPolicy
metadata:
  name: tcp-healthcheck
  namespace: production
spec:
  targetGroupARN: arn:aws:elasticloadbalancing:region:account:targetgroup/tcp/id
  healthCheckConfig:
    protocol: TCP  # ä»… TCP è¿æ¥æ£€æŸ¥
    port: 5432
    intervalSeconds: 30
    timeoutSeconds: 10
    healthyThresholdCount: 3
    unhealthyThresholdCount: 3
```

##### Gateway API Pod Readiness Gates

Gateway API ä»¥ä¸ Ingress ç›¸åŒçš„æ–¹å¼æ”¯æŒ Pod Readiness Gatesï¼š

```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: production
  labels:
    elbv2.k8s.aws/pod-readiness-gate-inject: enabled
```

**éªŒè¯æ“ä½œï¼š**

```bash
# æ£€æŸ¥ Gateway çŠ¶æ€
kubectl get gateway prod-gateway -n production

# æ£€æŸ¥ HTTPRoute çŠ¶æ€
kubectl get httproute api-v1-route -n production -o yaml

# æ£€æŸ¥ Pod çš„ Readiness Gates
kubectl get pod -n production -l app=api-v1 \
  -o jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.status.conditions[?(@.type=="target-health.gateway.networking.k8s.io")].status}{"\n"}{end}'
```

##### å¥åº·æ£€æŸ¥è¿ç§»æ¸…å•ï¼šIngress åˆ° Gateway API

| æ­¥éª¤ | Ingress | Gateway API | éªŒè¯é¡¹ç›® |
|------|---------|-------------|----------|
| 1. å¥åº·æ£€æŸ¥è·¯å¾„æ˜ å°„ | åŸºäºæ³¨è§£ | HealthCheckPolicy CRD | æŒ‰è·¯ç”±ç­–ç•¥åˆ†ç¦» |
| 2. åè®®é…ç½® | ä»… HTTP/HTTPS | HTTP/HTTPS/GRPC/TCP/UDP | éªŒè¯åè®®ç±»å‹ |
| 3. Pod Readiness Gates | Namespace æ ‡ç­¾ | Namespace æ ‡ç­¾ï¼ˆç›¸åŒï¼‰ | é›¶åœæœºéƒ¨ç½²ä¿è¯ |
| 4. å¥åº·æ£€æŸ¥æ—¶é—´ | Service æ³¨è§£ | HealthCheckPolicy | éªŒè¯ interval/timeout |
| 5. å¤šè·¯å¾„å¥åº·æ£€æŸ¥ | ä»…å•ä¸€è·¯å¾„ | æŒ‰è·¯ç”±ç‹¬ç«‹é…ç½® | éªŒè¯æ¯æ¡è·¯ç”± |

**è¿ç§»ç¤ºä¾‹ï¼ˆIngress åˆ° Gateway APIï¼‰ï¼š**

```yaml
# è¿ç§»å‰ï¼ˆIngressï¼‰
apiVersion: v1
kind: Service
metadata:
  name: myapp
  annotations:
    alb.ingress.kubernetes.io/healthcheck-path: /healthz
    alb.ingress.kubernetes.io/healthcheck-interval-seconds: "10"
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: myapp-ingress
spec:
  rules:
  - host: api.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: myapp
            port:
              number: 8080
```

```yaml
# è¿ç§»åï¼ˆGateway APIï¼‰
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: myapp-route
spec:
  parentRefs:
  - name: prod-gateway
  hostnames:
  - api.example.com
  rules:
  - matches:
    - path:
        type: PathPrefix
        value: /
    backendRefs:
    - name: myapp
      port: 8080
---
apiVersion: elbv2.k8s.aws/v1beta1
kind: HealthCheckPolicy
metadata:
  name: myapp-healthcheck
spec:
  targetGroupARN: <auto-discovered-or-explicit>
  healthCheckConfig:
    protocol: HTTP
    path: /healthz
    port: 8080
    intervalSeconds: 10
    timeoutSeconds: 5
    healthyThresholdCount: 2
    unhealthyThresholdCount: 2
```

:::tip Gateway API è¿ç§»ç­–ç•¥
- **æ¸è¿›å¼è¿ç§»**: å¯ä»¥åœ¨åŒä¸€ä¸ª ALB ä¸ŠåŒæ—¶ä½¿ç”¨ Ingress å’Œ Gateway APIï¼ˆä¸åŒçš„ Listenerï¼‰
- **é‡‘ä¸é›€éƒ¨ç½²**: ä½¿ç”¨ HTTPRoute çš„åŸºäºæƒé‡çš„æµé‡åˆ†å‰²è¿›è¡Œå®‰å…¨è¿‡æ¸¡
- **å›æ»šè®¡åˆ’**: è¿ç§»å®Œæˆåä¿ç•™ Ingress å¯¹è±¡ä¸€æ®µæ—¶é—´
:::

:::info å‚è€ƒèµ„æ–™
- [Kubernetes Gateway API v1.4 Release](https://kubernetes.io/blog/2025/11/06/gateway-api-v1-4/)
- [AWS Load Balancer Controller Gateway API æŒ‡å—](https://kubernetes-sigs.github.io/aws-load-balancer-controller/latest/guide/gateway/gateway/)
- [Gateway API è¿ç§»å®è·µæŒ‡å—](https://medium.com/@gudiwada.chaithu/zero-downtime-migration-from-kubernetes-ingress-to-gateway-api-on-aws-eks-642f3432d394)
:::

### 2.7 2025-2026 EKS æ–°ç‰¹æ€§ä¸ Probe é›†æˆ

AWS re:Invent 2025 ä¸Šå‘å¸ƒçš„æ–°çš„å¯è§‚æµ‹æ€§å’Œæ§åˆ¶ç‰¹æ€§è¿›ä¸€æ­¥å¢å¼ºäº†åŸºäº Probe çš„å¥åº·æ£€æŸ¥ã€‚æœ¬èŠ‚ä»‹ç»å¦‚ä½•å°†æœ€æ–°çš„ EKS ç‰¹æ€§ä¸ Probe é›†æˆï¼Œä»¥å®ç°æ›´ç²¾ç¡®å’Œä¸»åŠ¨çš„å¥åº·ç›‘æ§ã€‚

#### 2.7.1 ä½¿ç”¨ Container Network Observability éªŒè¯ Probe è¿é€šæ€§

**æ¦‚è¿°ï¼š**

Container Network Observabilityï¼ˆ2025 å¹´ 11 æœˆå‘å¸ƒï¼‰æä¾›ç»†ç²’åº¦çš„ç½‘ç»œæŒ‡æ ‡ï¼ŒåŒ…æ‹¬ Pod åˆ° Pod çš„é€šä¿¡æ¨¡å¼ã€å»¶è¿Ÿå’Œä¸¢åŒ…ç‡ã€‚å®ƒèƒ½å¤Ÿæ¸…æ™°åŒºåˆ† Probe å¤±è´¥æ˜¯ç”±ç½‘ç»œé—®é¢˜è¿˜æ˜¯åº”ç”¨çº§åˆ«é—®é¢˜å¼•èµ·çš„ã€‚

**ä¸»è¦ç‰¹æ€§ï¼š**
- Pod åˆ° Pod é€šä¿¡è·¯å¾„å¯è§†åŒ–
- ç½‘ç»œå»¶è¿Ÿã€ä¸¢åŒ…ç‡å’Œé‡ä¼ ç‡ç›‘æ§
- å®æ—¶ç½‘ç»œæµé‡å¼‚å¸¸æ£€æµ‹
- ä¸ CloudWatch Container Insights é›†æˆ

**å¯ç”¨æ–¹å¼ï¼š**

```bash
# åœ¨ VPC CNI ä¸­å¯ç”¨ç½‘ç»œå¯è§‚æµ‹æ€§
kubectl set env daemonset aws-node \
  -n kube-system \
  ENABLE_NETWORK_OBSERVABILITY=true

# æˆ–é€šè¿‡ ConfigMap é…ç½®
kubectl apply -f - <<EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: amazon-vpc-cni
  namespace: kube-system
data:
  enable-network-observability: "true"
EOF
```

**Probe è¿é€šæ€§éªŒè¯ç¤ºä¾‹ï¼š**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-gateway
  annotations:
    # å¯ç”¨ç½‘ç»œå¯è§‚æµ‹æ€§æŒ‡æ ‡æ”¶é›†
    network-observability.amazonaws.com/enabled: "true"
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: gateway
        image: myapp/gateway:v2
        ports:
        - containerPort: 8080
        # Readiness Probeï¼šæ£€æŸ¥å¤–éƒ¨ DB è¿æ¥
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          periodSeconds: 5
          failureThreshold: 2
          timeoutSeconds: 3
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8080
          periodSeconds: 10
          failureThreshold: 3
```

**CloudWatch Insights æŸ¥è¯¢ - å…³è” Probe å¤±è´¥ä¸ç½‘ç»œå»¶è¿Ÿï¼š**

```sql
-- æ£€æŸ¥ Probe å¤±è´¥æ—¶çš„ç½‘ç»œå»¶è¿Ÿ
fields @timestamp, pod_name, probe_type, network_latency_ms, packet_loss_percent
| filter namespace = "production"
| filter probe_result = "failed"
| filter network_latency_ms > 100 or packet_loss_percent > 1
| sort @timestamp desc
| limit 100
```

**å‘Šè­¦é…ç½®ç¤ºä¾‹ï¼š**

```yaml
# CloudWatch Alarmï¼šProbe å¤±è´¥ä¸ç½‘ç»œå¼‚å¸¸åŒæ—¶å‘ç”Ÿ
apiVersion: v1
kind: ConfigMap
metadata:
  name: probe-network-alert
  namespace: monitoring
data:
  alarm-config: |
    {
      "AlarmName": "ProbeFailureWithNetworkIssue",
      "MetricName": "ReadinessProbeFailure",
      "Namespace": "ContainerInsights",
      "Statistic": "Sum",
      "Period": 60,
      "EvaluationPeriods": 2,
      "Threshold": 3,
      "ComparisonOperator": "GreaterThanThreshold",
      "Dimensions": [
        {"Name": "ClusterName", "Value": "production-eks"},
        {"Name": "Namespace", "Value": "production"}
      ],
      "AlarmDescription": "Readiness Probe å¤±è´¥æ—¶æ£€æŸ¥ç½‘ç»œå»¶è¿Ÿ"
    }
```

**è¯Šæ–­å·¥ä½œæµï¼š**

```mermaid
flowchart TD
    PROBE_FAIL[æ£€æµ‹åˆ° Readiness Probe å¤±è´¥]
    PROBE_FAIL --> CHECK_NET[æ£€æŸ¥ Network Observability æŒ‡æ ‡]
    CHECK_NET --> NET_OK{ç½‘ç»œ<br/>æ­£å¸¸ï¼Ÿ}

    NET_OK -->|é«˜å»¶è¿Ÿ/ä¸¢åŒ…| NET_ISSUE[ç½‘ç»œé—®é¢˜]
    NET_ISSUE --> CHECK_CNI[æ£€æŸ¥ CNI æ’ä»¶çŠ¶æ€]
    NET_ISSUE --> CHECK_SG[éªŒè¯å®‰å…¨ç»„è§„åˆ™]
    NET_ISSUE --> CHECK_AZ[åˆ†æè·¨ AZ æµé‡æ¨¡å¼]

    NET_OK -->|æ­£å¸¸| APP_ISSUE[åº”ç”¨é—®é¢˜]
    APP_ISSUE --> CHECK_LOGS[åˆ†æ Pod æ—¥å¿—]
    APP_ISSUE --> CHECK_METRICS[æ£€æŸ¥ CPU/å†…å­˜åˆ©ç”¨ç‡]
    APP_ISSUE --> CHECK_DEPS[éªŒè¯å¤–éƒ¨ä¾èµ–çŠ¶æ€]

    style PROBE_FAIL fill:#ff4444,stroke:#cc3636,color:#fff
    style NET_ISSUE fill:#fbbc04,stroke:#c99603,color:#000
    style APP_ISSUE fill:#fbbc04,stroke:#c99603,color:#000
```

:::tip Pod åˆ° Pod è·¯å¾„å¯è§†åŒ–
Container Network Observability ä¸ CloudWatch Logs Insights é›†æˆï¼Œå¯è¿½è¸ª Probe è¯·æ±‚çš„å®Œæ•´ç½‘ç»œè·¯å¾„ã€‚å½“ Readiness Probe æ£€æŸ¥å¤–éƒ¨æ•°æ®åº“æ—¶ï¼Œæ‚¨å¯ä»¥åœ¨ä» Pod åˆ° Service åˆ° Endpoint å†åˆ° DB Pod çš„æ•´ä¸ªè·¯å¾„ä¸­è¯†åˆ«ç“¶é¢ˆæ®µã€‚
:::

---

#### 2.7.2 CloudWatch Observability Operator + Control Plane Metrics

**æ¦‚è¿°ï¼š**

CloudWatch Observability Operatorï¼ˆ2025 å¹´ 12 æœˆå‘å¸ƒï¼‰è‡ªåŠ¨æ”¶é›† EKS Control Plane æŒ‡æ ‡ï¼Œèƒ½å¤Ÿä¸»åŠ¨æ£€æµ‹ API Server æ€§èƒ½ä¸‹é™å¦‚ä½•å½±å“ Probe å“åº”ã€‚

**å®‰è£…ï¼š**

```bash
# å®‰è£… CloudWatch Observability Operator
kubectl apply -f https://raw.githubusercontent.com/aws-observability/aws-cloudwatch-observability-operator/main/bundle.yaml

# å¯ç”¨ EKS Control Plane æŒ‡æ ‡æ”¶é›†
kubectl apply -f - <<EOF
apiVersion: cloudwatch.aws.amazon.com/v1alpha1
kind: EKSControlPlaneMetrics
metadata:
  name: production-control-plane
  namespace: amazon-cloudwatch
spec:
  clusterName: production-eks
  region: ap-northeast-2
  metricsCollectionInterval: 60s
  enabledMetrics:
    - apiserver_request_duration_seconds
    - apiserver_request_total
    - apiserver_storage_objects
    - etcd_request_duration_seconds
    - rest_client_requests_total
EOF
```

**å…³é”® Control Plane æŒ‡æ ‡ï¼š**

| æŒ‡æ ‡ | æè¿° | Probe ç›¸å…³æ€§ | é˜ˆå€¼ç¤ºä¾‹ |
|--------|------|-------------|------------|
| `apiserver_request_duration_seconds` | API Server è¯·æ±‚å»¶è¿Ÿ | Probe è¯·æ±‚å¤„ç†é€Ÿåº¦ | p99 &lt; 1s |
| `apiserver_request_total` (code=5xx) | API Server 5xx é”™è¯¯è®¡æ•° | Probe å¤±è´¥ç‡å¢åŠ  | &lt; 1% |
| `apiserver_storage_objects` | etcd å­˜å‚¨çš„å¯¹è±¡æ•°é‡ | é›†ç¾¤è§„æ¨¡é™åˆ¶ | &lt; 150,000 |
| `etcd_request_duration_seconds` | etcd è¯»å†™å»¶è¿Ÿ | Pod çŠ¶æ€æ›´æ–°å»¶è¿Ÿ | p99 &lt; 100ms |
| `rest_client_requests_total` (code=429) | API Rate Limiting å‘ç”Ÿæ¬¡æ•° | kubelet-apiserver é€šä¿¡èŠ‚æµ | &lt; 10/min |

**Probe è¶…æ—¶é¢„æµ‹å‘Šè­¦ï¼š**

```yaml
apiVersion: cloudwatch.amazonaws.com/v1alpha1
kind: Alarm
metadata:
  name: apiserver-slow-probe-risk
spec:
  alarmName: "EKS-APIServer-SlowProbeRisk"
  metrics:
    - id: m1
      metricStat:
        metric:
          namespace: AWS/EKS
          metricName: apiserver_request_duration_seconds
          dimensions:
            - name: ClusterName
              value: production-eks
            - name: verb
              value: GET
        period: 60
        stat: p99
    - id: e1
      expression: "IF(m1 > 0.5, 1, 0)"
      label: "API Server å“åº”å»¶è¿Ÿ > 500ms"
  evaluationPeriods: 2
  threshold: 1
  comparisonOperator: GreaterThanOrEqualToThreshold
  alarmDescription: "ç”±äº API Server æ€§èƒ½ä¸‹é™å¯¼è‡´ Probe è¶…æ—¶é£é™©"
  alarmActions:
    - arn:aws:sns:ap-northeast-2:123456789012:eks-ops-alerts
```

**å¤§è§„æ¨¡é›†ç¾¤ä¸­ä¿è¯ Probe æ€§èƒ½ï¼š**

```yaml
# 1000+ èŠ‚ç‚¹é›†ç¾¤çš„ Probe é…ç½®ä¼˜åŒ–
apiVersion: apps/v1
kind: Deployment
metadata:
  name: large-scale-api
spec:
  replicas: 100
  template:
    spec:
      containers:
      - name: api
        image: myapp/api:v1
        # Probe æ—¶é—´è°ƒæ•´ï¼šè€ƒè™‘ API Server è´Ÿè½½
        startupProbe:
          httpGet:
            path: /healthz
            port: 8080
          failureThreshold: 30
          periodSeconds: 5  # å…è®¸é¢å¤–å¯åŠ¨æ—¶é—´
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8080
          periodSeconds: 15  # å¤§è§„æ¨¡æ—¶å¢åŠ é—´éš”
          failureThreshold: 3
          timeoutSeconds: 5
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          periodSeconds: 10
          failureThreshold: 2
          timeoutSeconds: 3
```

**CloudWatch Dashboard - Control Plane ä¸ Probe å…³è”åˆ†æï¼š**

```json
{
  "widgets": [
    {
      "type": "metric",
      "properties": {
        "title": "API Server å»¶è¿Ÿ vs Probe å¤±è´¥ç‡",
        "metrics": [
          ["AWS/EKS", "apiserver_request_duration_seconds", {"stat": "p99", "label": "API Server p99 å»¶è¿Ÿ"}],
          ["ContainerInsights", "ReadinessProbeFailure", {"stat": "Sum", "yAxis": "right"}]
        ],
        "period": 60,
        "region": "ap-northeast-2",
        "yAxis": {
          "left": {"label": "å»¶è¿Ÿï¼ˆç§’ï¼‰", "min": 0},
          "right": {"label": "Probe å¤±è´¥æ¬¡æ•°", "min": 0}
        }
      }
    }
  ]
}
```

:::warning å¤§è§„æ¨¡é›†ç¾¤ä¸­çš„ API Server è´Ÿè½½
åœ¨ 1000+ èŠ‚ç‚¹çš„é›†ç¾¤ä¸­ï¼Œæ‰€æœ‰ kubelet çš„ Probe è¯·æ±‚å¯èƒ½é›†ä¸­åœ¨ API Server ä¸Šã€‚å°† `periodSeconds` å¢åŠ åˆ° 10-15 ç§’ï¼Œå¹¶å°† `timeoutSeconds` è®¾ç½®ä¸º 5 ç§’æˆ–æ›´å¤šï¼Œä»¥åˆ†æ•£ API Server è´Ÿè½½ã€‚ä½¿ç”¨ Provisioned Control Planeï¼ˆ2.7.3 èŠ‚ï¼‰å¯ä»¥ä»æ ¹æœ¬ä¸Šè§£å†³æ­¤é—®é¢˜ã€‚
:::

---

#### 2.7.3 ä½¿ç”¨ Provisioned Control Plane ä¿è¯ Probe æ€§èƒ½

**æ¦‚è¿°ï¼š**

Provisioned Control Planeï¼ˆ2025 å¹´ 11 æœˆå‘å¸ƒï¼‰é€šè¿‡é¢„åˆ†é…çš„ Control Plane å®¹é‡ä¿è¯å¯é¢„æµ‹çš„é«˜æ€§èƒ½ Kubernetes æ“ä½œã€‚å®ƒç¡®ä¿å¤§è§„æ¨¡é›†ç¾¤ä¸­çš„ Probe è¯·æ±‚ä¸ä¼šå—åˆ° API Server æ€§èƒ½ä¸‹é™çš„å½±å“ã€‚

**å„ Tier çš„æ€§èƒ½ç‰¹å¾ï¼š**

| Tier | API å¹¶å‘ | Pod è°ƒåº¦é€Ÿåº¦ | æœ€å¤§èŠ‚ç‚¹æ•° | Probe å¤„ç†ä¿è¯ | é€‚åˆçš„å·¥ä½œè´Ÿè½½ |
|------|----------|---------------|------------|--------------|-------------|
| **XL** | é«˜ | ~500 Pods/min | 1,000 | 99.9% &lt; 100ms | AI è®­ç»ƒã€HPC |
| **2XL** | æé«˜ | ~1,000 Pods/min | 2,500 | 99.9% &lt; 80ms | å¤§è§„æ¨¡æ‰¹å¤„ç† |
| **4XL** | è¶…å¿« | ~2,000 Pods/min | 5,000 | 99.9% &lt; 50ms | è¶…å¤§è§„æ¨¡ ML |

**Standard vs Provisioned Control Planeï¼š**

```mermaid
graph LR
    subgraph "Standard Control Plane"
        STD_LOAD[æµé‡å¢åŠ ]
        STD_LOAD --> STD_SCALE[åŠ¨æ€æ‰©å±•]
        STD_SCALE --> STD_DELAY[ä¸´æ—¶å»¶è¿Ÿ]
        STD_DELAY -.-> STD_PROBE_FAIL[å¯èƒ½ Probe è¶…æ—¶]
    end

    subgraph "Provisioned Control Plane"
        PROV_LOAD[æµé‡å¢åŠ ]
        PROV_LOAD --> PROV_READY[é¢„åˆ†é…å®¹é‡]
        PROV_READY --> PROV_FAST[ç«‹å³å¤„ç†]
        PROV_FAST --> PROV_PROBE_OK[ä¿è¯ Probe æ€§èƒ½]
    end

    style STD_PROBE_FAIL fill:#ff4444,stroke:#cc3636,color:#fff
    style PROV_PROBE_OK fill:#34a853,stroke:#2a8642,color:#fff
```

**åˆ›å»º Provisioned Control Planeï¼š**

```bash
# åˆ›å»º Provisioned Control Plane é›†ç¾¤ï¼ˆAWS CLIï¼‰
aws eks create-cluster \
  --name production-provisioned \
  --region ap-northeast-2 \
  --kubernetes-version 1.32 \
  --role-arn arn:aws:iam::123456789012:role/eks-cluster-role \
  --resources-vpc-config subnetIds=subnet-xxx,subnet-yyy,securityGroupIds=sg-zzz \
  --control-plane-type PROVISIONED \
  --control-plane-tier XL
```

**å¤§è§„æ¨¡ Probe ä¼˜åŒ–ç¤ºä¾‹ï¼š**

```yaml
# AI/ML è®­ç»ƒé›†ç¾¤ï¼ˆ1000+ GPU èŠ‚ç‚¹ï¼‰
apiVersion: apps/v1
kind: Deployment
metadata:
  name: training-coordinator
  annotations:
    # é’ˆå¯¹ Provisioned Control Plane ä¼˜åŒ–çš„ Probe é…ç½®
    eks.amazonaws.com/control-plane-tier: "XL"
spec:
  replicas: 50
  template:
    spec:
      containers:
      - name: coordinator
        image: ml-training/coordinator:v3
        resources:
          requests:
            cpu: 4
            memory: 16Gi
        # Provisioned Control Plane å¯ä»¥ä½¿ç”¨æ›´çŸ­çš„é—´éš”
        startupProbe:
          httpGet:
            path: /healthz
            port: 9090
          failureThreshold: 30
          periodSeconds: 3  # å¿«é€Ÿæ£€æµ‹
        livenessProbe:
          httpGet:
            path: /healthz
            port: 9090
          periodSeconds: 5  # æ¯” Standard æ›´çŸ­
          failureThreshold: 2
          timeoutSeconds: 2
        readinessProbe:
          httpGet:
            path: /ready
            port: 9090
          periodSeconds: 3
          failureThreshold: 1
          timeoutSeconds: 2
```

**ä½¿ç”¨æ¡ˆä¾‹ï¼šAI/ML è®­ç»ƒé›†ç¾¤**

- **é—®é¢˜**: åœ¨ 1,000 ä¸ª GPU èŠ‚ç‚¹ä¸ŠåŒæ—¶å¯åŠ¨æ•°ç™¾ä¸ª Training Pod æ—¶ï¼ŒStandard Control Plane å‡ºç° API Server å“åº”å»¶è¿Ÿ
- **è§£å†³æ–¹æ¡ˆ**: ä½¿ç”¨ Provisioned Control Plane XL tier
- **æˆæœ**:
  - Pod è°ƒåº¦æ—¶é—´å‡å°‘ 70%ï¼ˆå¹³å‡ä» 45 ç§’é™è‡³ 13 ç§’ï¼‰
  - Readiness Probe è¶…æ—¶å‡å°‘ 99.8%
  - Training Job å¯åŠ¨å¯é æ€§æå‡

**æˆæœ¬ä¸æ€§èƒ½è€ƒè™‘ï¼š**

```yaml
# Provisioned Control Plane æˆæœ¬ä¼˜åŒ–ç­–ç•¥
# 1. æ—¥å¸¸æ“ä½œï¼šStandard Control Plane
# 2. è®­ç»ƒæœŸé—´ï¼šå‡çº§åˆ° Provisioned Control Plane XL
# ï¼ˆç›®å‰åœ¨é›†ç¾¤åˆ›å»ºæ—¶é€‰æ‹©ï¼›æœªæ¥è®¡åˆ’æ”¯æŒåŠ¨æ€åˆ‡æ¢ï¼‰
```

:::tip HPC å’Œå¤§è§„æ¨¡æ‰¹å¤„ç†å·¥ä½œè´Ÿè½½
Provisioned Control Plane é’ˆå¯¹åœ¨çŸ­æ—¶é—´å†…åŒæ—¶å¯åŠ¨æ•°åƒä¸ª Pod çš„å·¥ä½œè´Ÿè½½è¿›è¡Œäº†ä¼˜åŒ–ã€‚å®ƒä¸º AI/ML è®­ç»ƒã€ç§‘å­¦æ¨¡æ‹Ÿå’Œå¤§è§„æ¨¡æ•°æ®å¤„ç†ä¿è¯ Probe æ€§èƒ½ï¼Œå‡å°‘ Job å¯åŠ¨æ—¶é—´ã€‚
:::

---

#### 2.7.4 GuardDuty Extended Threat Detection é›†æˆ

**æ¦‚è¿°ï¼š**

GuardDuty Extended Threat Detectionï¼ˆEKS æ”¯æŒï¼š2025 å¹´ 6 æœˆï¼‰å¯æ£€æµ‹ Probe ç«¯ç‚¹çš„å¼‚å¸¸è®¿é—®æ¨¡å¼ï¼Œè¯†åˆ«æ¶æ„å·¥ä½œè´Ÿè½½è¯•å›¾ç»•è¿‡æˆ–æ“çºµå¥åº·æ£€æŸ¥çš„æ”»å‡»ã€‚

**ä¸»è¦ç‰¹æ€§ï¼š**
- EKS å®¡è®¡æ—¥å¿— + è¿è¡Œæ—¶è¡Œä¸º + æ¶æ„è½¯ä»¶æ‰§è¡Œ + AWS API æ´»åŠ¨çš„å…³è”åˆ†æ
- åŸºäº AI/ML çš„å¤šé˜¶æ®µæ”»å‡»åºåˆ—æ£€æµ‹
- Probe ç«¯ç‚¹å¼‚å¸¸è®¿é—®æ¨¡å¼è¯†åˆ«
- è‡ªåŠ¨æ£€æµ‹åŠ å¯†æŒ–çŸ¿ç­‰æ¶æ„å·¥ä½œè´Ÿè½½

**å¯ç”¨ï¼š**

```bash
# ä¸º EKS å¯ç”¨ GuardDuty Extended Threat Detectionï¼ˆAWS CLIï¼‰
aws guardduty update-detector \
  --detector-id <detector-id> \
  --features '[
    {
      "Name": "EKS_AUDIT_LOGS",
      "Status": "ENABLED"
    },
    {
      "Name": "EKS_RUNTIME_MONITORING",
      "Status": "ENABLED",
      "AdditionalConfiguration": [
        {
          "Name": "EKS_ADDON_MANAGEMENT",
          "Status": "ENABLED"
        }
      ]
    }
  ]'
```

**Probe ç«¯ç‚¹å®‰å…¨æ¨¡å¼ï¼š**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: secure-api
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: api
        image: myapp/secure-api:v2
        ports:
        - containerPort: 8080
        # å¥åº·æ£€æŸ¥ç«¯ç‚¹
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8080
            httpHeaders:
            - name: X-Health-Check-Token
              value: "SECRET_TOKEN_FROM_ENV"
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
            httpHeaders:
            - name: X-Health-Check-Token
              value: "SECRET_TOKEN_FROM_ENV"
          periodSeconds: 5
        env:
        - name: HEALTH_CHECK_TOKEN
          valueFrom:
            secretKeyRef:
              name: api-secrets
              key: health-token
```

**GuardDuty æ£€æµ‹åœºæ™¯ï¼š**

```mermaid
flowchart TD
    MALICIOUS[æ¶æ„ Pod éƒ¨ç½²]
    MALICIOUS --> PROBE_FAKE[å¥åº·æ£€æŸ¥æ¬ºéª—å°è¯•]
    PROBE_FAKE --> GUARDDUTY[GuardDuty æ£€æµ‹]

    GUARDDUTY --> AUDIT[EKS å®¡è®¡æ—¥å¿—åˆ†æ]
    GUARDDUTY --> RUNTIME[è¿è¡Œæ—¶è¡Œä¸ºåˆ†æ]
    GUARDDUTY --> API[AWS API æ´»åŠ¨åˆ†æ]

    AUDIT --> FINDING[ç”Ÿæˆå¤åˆ Finding]
    RUNTIME --> FINDING
    API --> FINDING

    FINDING --> ALERT[CloudWatch å‘Šè­¦]
    FINDING --> RESPONSE[è‡ªåŠ¨å“åº”]

    RESPONSE --> ISOLATE[Pod éš”ç¦»]
    RESPONSE --> TERMINATE[Pod ç»ˆæ­¢]
    RESPONSE --> NOTIFY[å®‰å…¨å›¢é˜Ÿé€šçŸ¥]

    style MALICIOUS fill:#ff4444,stroke:#cc3636,color:#fff
    style GUARDDUTY fill:#fbbc04,stroke:#c99603,color:#000
    style FINDING fill:#4286f4,stroke:#2a6acf,color:#fff
    style RESPONSE fill:#34a853,stroke:#2a8642,color:#fff
```

**çœŸå®æ£€æµ‹æ¡ˆä¾‹ - åŠ å¯†æŒ–çŸ¿æ”»å‡»ï¼š**

åœ¨ 2025 å¹´ 11 æœˆ 2 æ—¥ GuardDuty æ£€æµ‹åˆ°çš„åŠ å¯†æŒ–çŸ¿æ”»å‡»ä¸­ï¼Œæ”»å‡»è€…æŒ‰ä»¥ä¸‹æ–¹å¼ç»•è¿‡å¥åº·æ£€æŸ¥ï¼š

1. ä¼ªè£…ä¸ºåˆæ³•å®¹å™¨é•œåƒ
2. åœ¨ startupProbe æˆåŠŸåä¸‹è½½æ¶æ„äºŒè¿›åˆ¶æ–‡ä»¶
3. livenessProbe è¿”å›æ­£å¸¸å“åº”ï¼ŒåŒæ—¶åœ¨åå°è¿è¡ŒæŒ–çŸ¿ç¨‹åº
4. GuardDuty æ£€æµ‹åˆ°å¼‚å¸¸ç½‘ç»œæµé‡ + CPU ä½¿ç”¨æ¨¡å¼

**æ£€æµ‹åçš„è‡ªåŠ¨å“åº”ï¼š**

```yaml
# EventBridge Ruleï¼šGuardDuty Finding â†’ Lambda â†’ Pod éš”ç¦»
apiVersion: v1
kind: ConfigMap
metadata:
  name: guardduty-response
  namespace: security
data:
  eventbridge-rule: |
    {
      "source": ["aws.guardduty"],
      "detail-type": ["GuardDuty Finding"],
      "detail": {
        "service": {
          "serviceName": ["EKS"]
        },
        "severity": [7, 8, 9]  # High, Critical
      }
    }
  lambda-action: |
    import boto3
    eks = boto3.client('eks')

    def isolate_pod(cluster_name, namespace, pod_name):
        # ä½¿ç”¨ NetworkPolicy éš”ç¦» Pod
        kubectl_command = f"""
        kubectl apply -f - <<EOF
        apiVersion: networking.k8s.io/v1
        kind: NetworkPolicy
        metadata:
          name: isolate-{pod_name}
          namespace: {namespace}
        spec:
          podSelector:
            matchLabels:
              pod: {pod_name}
          policyTypes:
          - Ingress
          - Egress
        EOF
        """
        # æ‰§è¡Œé€»è¾‘...
```

**å®‰å…¨ç›‘æ§ Dashboardï¼š**

```yaml
# CloudWatch Dashboardï¼šGuardDuty + Probe çŠ¶æ€
apiVersion: cloudwatch.amazonaws.com/v1alpha1
kind: Dashboard
metadata:
  name: security-probe-monitoring
spec:
  widgets:
    - type: metric
      title: "GuardDuty æ£€æµ‹ vs Probe å¤±è´¥"
      metrics:
        - namespace: AWS/GuardDuty
          metricName: FindingCount
          dimensions:
            - name: ClusterName
              value: production-eks
        - namespace: ContainerInsights
          metricName: ProbeFailure
          dimensions:
            - name: Namespace
              value: production
```

:::warning å¥åº·æ£€æŸ¥ç«¯ç‚¹å®‰å…¨
Probe ç«¯ç‚¹ï¼ˆ`/healthz`ã€`/ready`ï¼‰é€šå¸¸åœ¨æ²¡æœ‰èº«ä»½éªŒè¯çš„æƒ…å†µä¸‹å…¬å¼€æš´éœ²ï¼Œè¿™å¯èƒ½æˆä¸ºæ”»å‡»é¢ã€‚å¯ç”¨ GuardDuty Extended Threat Detectionï¼Œå¹¶åœ¨å¯èƒ½çš„æƒ…å†µä¸‹å‘å¥åº·æ£€æŸ¥è¯·æ±‚æ·»åŠ ç®€å•çš„ Token Headerï¼Œä»¥é™åˆ¶æœªæˆæƒè®¿é—®ã€‚
:::

**ç›¸å…³æ–‡æ¡£ï¼š**
- [AWS åšå®¢ï¼šGuardDuty Extended Threat Detection for EKS](https://aws.amazon.com/blogs/aws/amazon-guardduty-expands-extended-threat-detection-coverage-to-amazon-eks-clusters/)
- [AWS åšå®¢ï¼šåŠ å¯†æŒ–çŸ¿æ”»å‡»æ£€æµ‹](https://aws.amazon.com/blogs/security/cryptomining-campaign-targeting-amazon-ec2-and-amazon-ecs/)
- [EKS å®‰å…¨æœ€ä½³å®è·µ](https://docs.aws.amazon.com/eks/latest/best-practices/security.html)

---
## 3. Graceful Shutdown å®Œæ•´æŒ‡å—

Graceful Shutdown æ˜¯ä¸€ç§åœ¨ Pod ç»ˆæ­¢æ—¶å®‰å…¨å®Œæˆæ­£åœ¨å¤„ç†çš„è¯·æ±‚å¹¶åœæ­¢æ¥å—æ–°è¯·æ±‚çš„æ¨¡å¼ã€‚å®ƒå¯¹äºé›¶åœæœºéƒ¨ç½²å’Œæ•°æ®å®Œæ•´æ€§è‡³å…³é‡è¦ã€‚

### 3.1 Pod ç»ˆæ­¢åºåˆ—è¯¦è§£

åœ¨ Kubernetes ä¸­ï¼ŒPod ç»ˆæ­¢æŒ‰ä»¥ä¸‹é¡ºåºè¿›è¡Œã€‚

```mermaid
sequenceDiagram
    participant User as ç”¨æˆ·/ç³»ç»Ÿ
    participant API as API Server
    participant EP as Endpoint Controller
    participant Kubelet as kubelet
    participant Container as å®¹å™¨
    participant App as åº”ç”¨

    User->>API: kubectl delete pod
    API->>API: Pod çŠ¶æ€ â†’ Terminating

    par Endpoint ç§»é™¤ï¼ˆå¼‚æ­¥ï¼‰
        API->>EP: Pod åˆ é™¤äº‹ä»¶
        EP->>EP: ä» Service Endpoints<br/>ç§»é™¤ Pod IP
        Note over EP: kube-proxy æ›´æ–° iptables<br/>ï¼ˆå¯èƒ½éœ€è¦å‡ ç§’ï¼‰
    and preStop Hook æ‰§è¡Œï¼ˆå¼‚æ­¥ï¼‰
        API->>Kubelet: Pod ç»ˆæ­¢è¯·æ±‚
        Kubelet->>Container: æ‰§è¡Œ preStop Hook
        Note over Container: sleep 5<br/>ï¼ˆç­‰å¾… Endpoints ç§»é™¤ï¼‰
    end

    Container->>App: å‘é€ SIGTERM
    App->>App: åœæ­¢æ¥å—æ–°è¯·æ±‚
    App->>App: å®Œæˆæ­£åœ¨å¤„ç†çš„è¯·æ±‚
    Note over App: Graceful Shutdown<br/>ï¼ˆæœ€é•¿ terminationGracePeriodSeconds - preStop æ—¶é•¿ï¼‰

    alt Graceful Shutdown æˆåŠŸ
        App->>Kubelet: exit 0
        Kubelet->>API: Pod ç»ˆæ­¢å®Œæˆ
    else è¶…æ—¶
        Kubelet->>Container: SIGKILLï¼ˆå¼ºåˆ¶ç»ˆæ­¢ï¼‰
        Container->>API: Pod è¢«å¼ºåˆ¶ç»ˆæ­¢
    end

    API->>API: Pod å·²åˆ é™¤
```

**æ—¶é—´è¯¦æƒ…ï¼š**

1. **T+0s**: é€šè¿‡ `kubectl delete pod` æˆ–æ»šåŠ¨æ›´æ–°è¯·æ±‚åˆ é™¤ Pod
2. **T+0s**: API Server å°† Pod çŠ¶æ€æ›´æ”¹ä¸º `Terminating`
3. **T+0s**: ä¸¤ä¸ªæ“ä½œ**å¼‚æ­¥**å¹¶è¡Œå¼€å§‹ï¼š
   - Endpoint Controller ä» Service Endpoints ç§»é™¤ Pod IP
   - kubelet æ‰§è¡Œ preStop Hook
4. **T+0~5s**: preStop Hook æ‰§è¡Œ `sleep 5`ï¼ˆç­‰å¾… Endpoints ç§»é™¤ï¼‰
5. **T+5s**: preStop Hook æ‰§è¡Œ `kill -TERM 1` â†’ å‘é€ SIGTERM
6. **T+5s**: åº”ç”¨æ¥æ”¶ SIGTERMï¼Œå¼€å§‹ Graceful Shutdown
7. **T+5~60s**: åº”ç”¨å®Œæˆæ­£åœ¨å¤„ç†çš„è¯·æ±‚å¹¶æ‰§è¡Œæ¸…ç†ä»»åŠ¡
8. **T+60s**: è¾¾åˆ° `terminationGracePeriodSeconds` æ—¶å‘é€ SIGKILLï¼ˆå¼ºåˆ¶ç»ˆæ­¢ï¼‰

:::tip ä¸ºä»€ä¹ˆéœ€è¦ preStop sleep
Endpoint ç§»é™¤å’Œ preStop Hook æ‰§è¡Œæ˜¯**å¼‚æ­¥**å‘ç”Ÿçš„ã€‚åœ¨ preStop ä¸­æ·»åŠ  5 ç§’çš„ sleep å¯ç¡®ä¿ Endpoint Controller å’Œ kube-proxy æœ‰æ—¶é—´æ›´æ–° iptablesï¼Œä½¿æ–°æµé‡ä¸å†è·¯ç”±åˆ°æ­£åœ¨ç»ˆæ­¢çš„ Podã€‚å¦‚æœæ²¡æœ‰æ­¤æ¨¡å¼ï¼Œæµé‡å¯èƒ½ä¼šç»§ç»­å‘é€åˆ°æ­£åœ¨ç»ˆæ­¢çš„ Podï¼Œå¯¼è‡´ 502/503 é”™è¯¯ã€‚
:::

### 3.2 å„è¯­è¨€çš„ SIGTERM å¤„ç†æ¨¡å¼

#### Node.js (Express)

```javascript
const express = require('express');
const app = express();
const server = app.listen(8080);

// çŠ¶æ€æ ‡å¿—
let isShuttingDown = false;

// å¥åº·æ£€æŸ¥ç«¯ç‚¹
app.get('/healthz', (req, res) => {
  res.status(200).json({ status: 'ok' });
});

app.get('/ready', (req, res) => {
  if (isShuttingDown) {
    return res.status(503).json({ status: 'shutting_down' });
  }
  res.status(200).json({ status: 'ready' });
});

// ä¸šåŠ¡é€»è¾‘
app.get('/api/data', (req, res) => {
  if (isShuttingDown) {
    return res.status(503).send('Service Unavailable');
  }
  // å®é™…é€»è¾‘
  res.json({ data: 'example' });
});

// Graceful Shutdown å¤„ç†å™¨
function gracefulShutdown(signal) {
  console.log(`${signal} received, starting graceful shutdown`);
  isShuttingDown = true;

  // æ‹’ç»æ–°è¿æ¥
  server.close(() => {
    console.log('HTTP server closed');

    // å…³é—­ DB è¿æ¥
    // db.close();

    // é€€å‡ºè¿›ç¨‹
    process.exit(0);
  });

  // è®¾ç½®è¶…æ—¶ï¼ˆåœ¨ SIGKILL ä¹‹å‰å®Œæˆï¼‰
  setTimeout(() => {
    console.error('Graceful shutdown timeout, forcing exit');
    process.exit(1);
  }, 50000); // terminationGracePeriodSeconds - preStop æ—¶é•¿ - 5s ç¼“å†²
}

// å¤„ç† SIGTERMã€SIGINT
process.on('SIGTERM', () => gracefulShutdown('SIGTERM'));
process.on('SIGINT', () => gracefulShutdown('SIGINT'));

console.log('Server started on port 8080');
```

**Deployment é…ç½®ï¼š**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nodejs-app
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: app
        image: myapp/nodejs:v1
        ports:
        - containerPort: 8080
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          periodSeconds: 5
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh", "-c", "sleep 5"]
      terminationGracePeriodSeconds: 60
```

#### Java/Spring Boot

Spring Boot 2.3+ åŸç”Ÿæ”¯æŒ Graceful Shutdownã€‚

**application.ymlï¼š**

```yaml
server:
  shutdown: graceful  # å¯ç”¨ Graceful Shutdown

spring:
  lifecycle:
    timeout-per-shutdown-phase: 50s  # æœ€å¤§ç­‰å¾…æ—¶é—´
management:
  endpoints:
    web:
      exposure:
        include: health
  endpoint:
    health:
      probes:
        enabled: true
  health:
    livenessState:
      enabled: true
    readinessState:
      enabled: true
```

**è‡ªå®šä¹‰å…³é—­é€»è¾‘ï¼ˆå¦‚æœéœ€è¦ï¼‰ï¼š**

```java
import org.springframework.context.event.ContextClosedEvent;
import org.springframework.context.event.EventListener;
import org.springframework.stereotype.Component;

@Component
public class GracefulShutdownListener {

    @EventListener
    public void onApplicationEvent(ContextClosedEvent event) {
        System.out.println("Graceful shutdown initiated");

        // è‡ªå®šä¹‰æ¸…ç†ä»»åŠ¡
        // ä¾‹å¦‚ï¼Œåˆ·æ–°æ¶ˆæ¯é˜Ÿåˆ—ã€ç­‰å¾…æ‰¹å¤„ç†ä½œä¸šå®Œæˆ
        try {
            // æœ€å¤šç­‰å¾… 50 ç§’
            cleanupResources();
        } catch (Exception e) {
            System.err.println("Cleanup error: " + e.getMessage());
        }
    }

    private void cleanupResources() throws InterruptedException {
        // èµ„æºæ¸…ç†é€»è¾‘
        Thread.sleep(5000); // ç¤ºä¾‹ï¼š5 ç§’æ¸…ç†ä»»åŠ¡
        System.out.println("Cleanup completed");
    }
}
```

**Deployment é…ç½®ï¼š**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spring-boot-app
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: app
        image: myapp/spring-boot:v2.7
        ports:
        - containerPort: 8080
        env:
        - name: JAVA_OPTS
          value: "-Xms1g -Xmx2g"
        readinessProbe:
          httpGet:
            path: /actuator/health/readiness
            port: 8080
          periodSeconds: 5
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh", "-c", "sleep 5"]
      terminationGracePeriodSeconds: 60
```

#### Go

```go
package main

import (
    "context"
    "fmt"
    "log"
    "net/http"
    "os"
    "os/signal"
    "syscall"
    "time"
)

var isShuttingDown = false

func main() {
    // HTTP æœåŠ¡å™¨è®¾ç½®
    mux := http.NewServeMux()

    mux.HandleFunc("/healthz", func(w http.ResponseWriter, r *http.Request) {
        w.WriteHeader(http.StatusOK)
        fmt.Fprintln(w, "ok")
    })

    mux.HandleFunc("/ready", func(w http.ResponseWriter, r *http.Request) {
        if isShuttingDown {
            w.WriteHeader(http.StatusServiceUnavailable)
            fmt.Fprintln(w, "shutting down")
            return
        }
        w.WriteHeader(http.StatusOK)
        fmt.Fprintln(w, "ready")
    })

    mux.HandleFunc("/api/data", func(w http.ResponseWriter, r *http.Request) {
        if isShuttingDown {
            w.WriteHeader(http.StatusServiceUnavailable)
            return
        }
        // ä¸šåŠ¡é€»è¾‘
        fmt.Fprintln(w, `{"data":"example"}`)
    })

    server := &http.Server{
        Addr:    ":8080",
        Handler: mux,
    }

    // åœ¨å•ç‹¬çš„ goroutine ä¸­å¯åŠ¨æœåŠ¡å™¨
    go func() {
        log.Println("Server starting on :8080")
        if err := server.ListenAndServe(); err != nil && err != http.ErrServerClosed {
            log.Fatalf("Server error: %v", err)
        }
    }()

    // ç­‰å¾… SIGTERM/SIGINT
    quit := make(chan os.Signal, 1)
    signal.Notify(quit, syscall.SIGTERM, syscall.SIGINT)
    <-quit

    log.Println("Graceful shutdown initiated")
    isShuttingDown = true

    // å¸¦è¶…æ—¶çš„ Graceful Shutdown
    ctx, cancel := context.WithTimeout(context.Background(), 50*time.Second)
    defer cancel()

    if err := server.Shutdown(ctx); err != nil {
        log.Fatalf("Server forced to shutdown: %v", err)
    }

    log.Println("Server exited gracefully")
}
```

**Deployment é…ç½®ï¼š**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: go-app
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: app
        image: myapp/go-app:v1
        ports:
        - containerPort: 8080
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          periodSeconds: 5
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh", "-c", "sleep 5"]
      terminationGracePeriodSeconds: 60
```

#### Python (Flask)

```python
from flask import Flask, jsonify
import signal
import sys
import time
import threading

app = Flask(__name__)
is_shutting_down = False

@app.route('/healthz')
def healthz():
    return jsonify({"status": "ok"}), 200

@app.route('/ready')
def ready():
    if is_shutting_down:
        return jsonify({"status": "shutting_down"}), 503
    return jsonify({"status": "ready"}), 200

@app.route('/api/data')
def api_data():
    if is_shutting_down:
        return jsonify({"error": "service unavailable"}), 503
    return jsonify({"data": "example"}), 200

def graceful_shutdown(signum, frame):
    global is_shutting_down
    print(f"Signal {signum} received, starting graceful shutdown")
    is_shutting_down = True

    # æ¸…ç†ä»»åŠ¡ï¼ˆå¦‚å…³é—­ DB è¿æ¥ï¼‰
    # db.close()

    print("Graceful shutdown completed")
    sys.exit(0)

# æ³¨å†Œ SIGTERM å¤„ç†å™¨
signal.signal(signal.SIGTERM, graceful_shutdown)
signal.signal(signal.SIGINT, graceful_shutdown)

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080)
```

**Deployment é…ç½®ï¼š**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: python-app
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: app
        image: myapp/python-flask:v1
        ports:
        - containerPort: 8080
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          periodSeconds: 5
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh", "-c", "sleep 5"]
      terminationGracePeriodSeconds: 60
```

### 3.3 Connection Draining æ¨¡å¼

Connection Draining æ˜¯ä¸€ç§åœ¨å…³é—­æœŸé—´å®‰å…¨æ¸…ç†ç°æœ‰è¿æ¥çš„æ¨¡å¼ã€‚

#### HTTP Keep-Alive è¿æ¥å¤„ç†

```javascript
// Node.js Express with Connection Draining
const express = require('express');
const app = express();
const server = app.listen(8080);

let isShuttingDown = false;
const activeConnections = new Set();

// è·Ÿè¸ªè¿æ¥
server.on('connection', (conn) => {
  activeConnections.add(conn);
  conn.on('close', () => {
    activeConnections.delete(conn);
  });
});

function gracefulShutdown(signal) {
  console.log(`${signal} received`);
  isShuttingDown = true;

  // æ‹’ç»æ–°è¿æ¥
  server.close(() => {
    console.log('Server closed, no new connections');
  });

  // å…³é—­ç°æœ‰è¿æ¥
  console.log(`Closing ${activeConnections.size} active connections`);
  activeConnections.forEach((conn) => {
    conn.destroy(); // å¼ºåˆ¶å…³é—­ï¼ˆæˆ–ä½¿ç”¨ conn.end() ä¼˜é›…å…³é—­ï¼‰
  });

  // æ¸…ç†åé€€å‡º
  setTimeout(() => {
    console.log('Graceful shutdown complete');
    process.exit(0);
  }, 5000);
}

process.on('SIGTERM', () => gracefulShutdown('SIGTERM'));
```

#### WebSocket è¿æ¥æ¸…ç†

```javascript
// WebSocket graceful shutdown
const WebSocket = require('ws');
const wss = new WebSocket.Server({ port: 8080 });

const clients = new Set();

wss.on('connection', (ws) => {
  clients.add(ws);

  ws.on('close', () => {
    clients.delete(ws);
  });

  ws.on('message', (message) => {
    // å¤„ç†æ¶ˆæ¯
  });
});

function gracefulShutdown() {
  console.log(`Closing ${clients.size} WebSocket connections`);

  clients.forEach((ws) => {
    // é€šçŸ¥å®¢æˆ·ç«¯å…³é—­
    ws.send(JSON.stringify({ type: 'server_shutdown' }));
    ws.close(1001, 'Server shutting down');
  });

  wss.close(() => {
    console.log('WebSocket server closed');
    process.exit(0);
  });
}

process.on('SIGTERM', gracefulShutdown);
```

#### gRPC Graceful Shutdown

```go
package main

import (
    "context"
    "log"
    "net"
    "os"
    "os/signal"
    "syscall"
    "time"

    "google.golang.org/grpc"
    pb "myapp/proto"
)

type server struct {
    pb.UnimplementedMyServiceServer
}

func main() {
    lis, err := net.Listen("tcp", ":9090")
    if err != nil {
        log.Fatalf("Failed to listen: %v", err)
    }

    s := grpc.NewServer()
    pb.RegisterMyServiceServer(s, &server{})

    go func() {
        log.Println("gRPC server starting on :9090")
        if err := s.Serve(lis); err != nil {
            log.Fatalf("Failed to serve: %v", err)
        }
    }()

    // ç­‰å¾… SIGTERM
    quit := make(chan os.Signal, 1)
    signal.Notify(quit, syscall.SIGTERM, syscall.SIGINT)
    <-quit

    log.Println("Graceful shutdown initiated")

    // GracefulStopï¼šç­‰å¾…æ­£åœ¨å¤„ç†çš„ RPC å®Œæˆ
    done := make(chan struct{})
    go func() {
        s.GracefulStop()
        close(done)
    }()

    // å¤„ç†è¶…æ—¶
    select {
    case <-done:
        log.Println("gRPC server stopped gracefully")
    case <-time.After(50 * time.Second):
        log.Println("Graceful stop timeout, forcing stop")
        s.Stop() // å¼ºåˆ¶åœæ­¢
    }
}
```

#### æ•°æ®åº“è¿æ¥æ± æ¸…ç†

```python
# Python with psycopg2 connection pool
import psycopg2
from psycopg2 import pool
import signal
import sys

# è¿æ¥æ± 
db_pool = psycopg2.pool.SimpleConnectionPool(
    minconn=1,
    maxconn=10,
    host='db.example.com',
    database='mydb',
    user='user',
    password='password'
)

def graceful_shutdown(signum, frame):
    print("Closing database connections...")

    # å…³é—­æ‰€æœ‰è¿æ¥
    db_pool.closeall()

    print("Database connections closed")
    sys.exit(0)

signal.signal(signal.SIGTERM, graceful_shutdown)

# åº”ç”¨é€»è¾‘
def query_database():
    conn = db_pool.getconn()
    try:
        cur = conn.cursor()
        cur.execute("SELECT * FROM users")
        return cur.fetchall()
    finally:
        db_pool.putconn(conn)
```

### 3.4 ä¸ Karpenter/Node Drain çš„äº¤äº’

å½“ Karpenter è¿›è¡ŒèŠ‚ç‚¹æ•´åˆæˆ– Spot å®ä¾‹è¢«ç»ˆæ­¢æ—¶ï¼ŒèŠ‚ç‚¹ä¸Šçš„æ‰€æœ‰ Pod å¿…é¡»è¢«å®‰å…¨è¿ç§»ã€‚

#### Karpenter Disruption ä¸ Graceful Shutdown

```mermaid
sequenceDiagram
    participant Karpenter
    participant Node as èŠ‚ç‚¹ï¼ˆæ•´åˆï¼‰
    participant Kubelet as kubelet
    participant Pod as Pod

    Karpenter->>Karpenter: æ£€æµ‹åˆ°éœ€è¦èŠ‚ç‚¹æ•´åˆ<br/>ï¼ˆæœªä½¿ç”¨æˆ–åˆ©ç”¨ç‡ä½ï¼‰
    Karpenter->>Node: Node Cordon
    Karpenter->>Node: å¼€å§‹ Node Drain
    Node->>Kubelet: Pod ç»ˆæ­¢è¯·æ±‚

    Kubelet->>Pod: æ‰§è¡Œ preStop Hook
    Note over Pod: sleep 5

    Kubelet->>Pod: å‘é€ SIGTERM
    Pod->>Pod: Graceful Shutdown<br/>ï¼ˆæœ€é•¿ terminationGracePeriodSecondsï¼‰

    alt Graceful Shutdown æˆåŠŸ
        Pod->>Kubelet: exit 0
        Kubelet->>Karpenter: Pod ç»ˆæ­¢å®Œæˆ
    else è¶…æ—¶
        Kubelet->>Pod: SIGKILL
        Pod->>Kubelet: è¢«å¼ºåˆ¶ç»ˆæ­¢
    end

    Karpenter->>Karpenter: æ‰€æœ‰ Pod å·²è¿ç§»
    Karpenter->>Node: ç»ˆæ­¢èŠ‚ç‚¹
```

**Karpenter NodePool é…ç½®ï¼š**

```yaml
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: default
spec:
  disruption:
    consolidationPolicy: WhenEmptyOrUnderutilized
    consolidateAfter: 5m
    # Disruption é¢„ç®—ï¼šé™åˆ¶å¹¶å‘èŠ‚ç‚¹ä¸­æ–­
    budgets:
    - nodes: "20%"
      schedule: "0 9-17 * * MON-FRI"  # å·¥ä½œæ—¶é—´ 20%
    - nodes: "50%"
      schedule: "0 0-8,18-23 * * *"   # éå·¥ä½œæ—¶é—´ 50%
```

:::warning PDB ä¸ Karpenter çš„äº¤äº’
å¦‚æœ PodDisruptionBudget è¿‡äºä¸¥æ ¼ï¼ˆä¾‹å¦‚ `minAvailable` ç­‰äºå‰¯æœ¬æ•°ï¼‰ï¼ŒKarpenter å°†æ— æ³• Drain èŠ‚ç‚¹ã€‚å°† PDB è®¾ç½®ä¸º `minAvailable: replica - 1` æˆ– `maxUnavailable: 1`ï¼Œä»¥ç¡®ä¿è‡³å°‘ä¸€ä¸ª Pod å¯ä»¥è¢«è¿ç§»ã€‚
:::

#### 3.4.3 ARC + Karpenter é›†æˆ AZ ç–æ•£æ¨¡å¼

**æ¦‚è¿°ï¼š**

AWS Application Recovery Controller (ARC) ä¸ Karpenter çš„é›†æˆï¼ˆ2025 å¹´å‘å¸ƒï¼‰æä¾›äº†ä¸€ç§é«˜å¯ç”¨æ¨¡å¼ï¼Œåœ¨å¯ç”¨åŒº (AZ) æ•…éšœæœŸé—´è‡ªåŠ¨å°†å·¥ä½œè´Ÿè½½è¿ç§»åˆ°ä¸åŒçš„ AZã€‚è¿™ç¡®ä¿äº† AZ æ•…éšœæˆ–ç°è‰²æ•…éšœåœºæ™¯ä¸‹çš„ Graceful Shutdownï¼Œæœ€å¤§ç¨‹åº¦å‡å°‘æœåŠ¡ä¸­æ–­ã€‚

**ä»€ä¹ˆæ˜¯ ARC Zonal Shiftï¼š**

Zonal Shift æ˜¯ä¸€ç§è‡ªåŠ¨å°†æµé‡ä»æ•…éšœæˆ–æ€§èƒ½é™çº§çš„ AZ é‡å®šå‘åˆ°å…¶ä»–å¥åº· AZ çš„èƒ½åŠ›ã€‚å½“ä¸ EKS é›†æˆæ—¶ï¼Œå®ƒè¿˜èƒ½è‡ªåŠ¨åŒ– Pod çš„å®‰å…¨è¿ç§»ã€‚

**æ¶æ„ç»„ä»¶ï¼š**

| ç»„ä»¶ | è§’è‰² | è¡Œä¸º |
|-----------|------|----------|
| **ARC Zonal Autoshift** | è‡ªåŠ¨ AZ æ•…éšœæ£€æµ‹å’Œæµé‡åˆ‡æ¢å†³ç­– | åŸºäº CloudWatch Alarms çš„è‡ªåŠ¨ Shift |
| **Karpenter** | åœ¨æ–° AZ ä¸­é…ç½®èŠ‚ç‚¹ | åŸºäº NodePool é…ç½®åœ¨å¥åº· AZ ä¸­åˆ›å»ºèŠ‚ç‚¹ |
| **AWS Load Balancer** | æµé‡è·¯ç”±æ§åˆ¶ | ç§»é™¤æ•…éšœ AZ ä¸­çš„ Target |
| **PodDisruptionBudget** | ç¡®ä¿ Pod è¿ç§»æœŸé—´çš„å¯ç”¨æ€§ | ç»´æŒæœ€å°å¯ç”¨ Pod æ•° |

**AZ ç–æ•£åºåˆ—ï¼š**

```mermaid
sequenceDiagram
    participant AZ_A as AZ-Aï¼ˆæ•…éšœï¼‰
    participant ARC as ARC Zonal Autoshift
    participant Karpenter
    participant AZ_B as AZ-Bï¼ˆå¥åº·ï¼‰
    participant LB as ALB/NLB
    participant Pod_Old as Pod (AZ-A)
    participant Pod_New as Pod (AZ-B)

    Note over AZ_A: æ£€æµ‹åˆ° AZ æ€§èƒ½é™çº§<br/>ï¼ˆç½‘ç»œå»¶è¿Ÿã€ä¸¢åŒ…ï¼‰

    AZ_A->>ARC: CloudWatch Alarm è§¦å‘
    ARC->>ARC: Zonal Shift å†³ç­–
    ARC->>LB: å¼€å§‹ç§»é™¤ AZ-A Target

    par Karpenter èŠ‚ç‚¹é…ç½®
        ARC->>Karpenter: Cordon AZ-A èŠ‚ç‚¹
        Karpenter->>AZ_B: é…ç½®æ–°èŠ‚ç‚¹
        AZ_B->>Karpenter: Node Ready
    and Pod é‡æ–°è°ƒåº¦
        Karpenter->>Pod_Old: Pod Evictionï¼ˆä¼˜é›…ï¼‰
        Pod_Old->>Pod_Old: æ‰§è¡Œ preStop Hook
        Pod_Old->>Pod_Old: æ¥æ”¶ SIGTERM
        Pod_Old->>Pod_Old: Graceful Shutdown
        Note over Pod_Old: å®Œæˆæ­£åœ¨å¤„ç†çš„è¯·æ±‚<br/>ï¼ˆterminationGracePeriodSecondsï¼‰
    end

    Pod_New->>AZ_B: Pod å¯åŠ¨
    Pod_New->>Pod_New: startupProbe æˆåŠŸ
    Pod_New->>Pod_New: readinessProbe æˆåŠŸ
    LB->>Pod_New: Health Check é€šè¿‡
    LB->>Pod_New: å¼€å§‹å‘é€æµé‡

    Pod_Old->>AZ_A: å®‰å…¨å…³é—­
    Karpenter->>AZ_A: ç»ˆæ­¢ç©ºèŠ‚ç‚¹

    Note over AZ_B: æ‰€æœ‰å·¥ä½œè´Ÿè½½å·²è¿ç§»åˆ° AZ-B
```

**é…ç½®ç¤ºä¾‹ï¼š**

**1. å¯ç”¨ ARC Zonal Autoshiftï¼š**

```bash
# åœ¨ Load Balancer ä¸Šå¯ç”¨ Zonal Autoshift
aws arc-zonal-shift create-autoshift-observer-notification-configuration \
  --resource-identifier arn:aws:elasticloadbalancing:ap-northeast-2:123456789012:loadbalancer/app/production-alb/1234567890abcdef

# é…ç½® Zonal Autoshift
aws arc-zonal-shift update-zonal-autoshift-configuration \
  --resource-identifier arn:aws:elasticloadbalancing:ap-northeast-2:123456789012:loadbalancer/app/production-alb/1234567890abcdef \
  --zonal-autoshift-status ENABLED
```

**2. Karpenter NodePool - AZ æ„ŸçŸ¥é…ç½®ï¼š**

```yaml
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: default
spec:
  disruption:
    consolidationPolicy: WhenEmptyOrUnderutilized
    consolidateAfter: 30s
    # AZ æ•…éšœæ—¶å¿«é€Ÿå“åº”
    budgets:
    - nodes: "100%"
      reasons:
      - "Drifted"  # AZ è¢« Cordon æ—¶ç«‹å³æ›¿æ¢
  template:
    spec:
      requirements:
      - key: "topology.kubernetes.io/zone"
        operator: In
        values:
        - ap-northeast-2a
        - ap-northeast-2b
        - ap-northeast-2c
      - key: karpenter.sh/capacity-type
        operator: In
        values:
        - on-demand  # AZ æ•…éšœå“åº”æ¨èä½¿ç”¨ On-Demand
      nodeClassRef:
        name: default
---
apiVersion: karpenter.k8s.aws/v1
kind: EC2NodeClass
metadata:
  name: default
spec:
  amiFamily: AL2023
  role: "KarpenterNodeRole-production"
  subnetSelectorTerms:
  - tags:
      karpenter.sh/discovery: "production-eks"
  securityGroupSelectorTerms:
  - tags:
      karpenter.sh/discovery: "production-eks"
  # AZ æ•…éšœæ—¶è‡ªåŠ¨æ£€æµ‹
  metadataOptions:
    httpTokens: required
    httpPutResponseHopLimit: 2
```

**3. å¸¦ PDB çš„ Deployment - AZ åˆ†å¸ƒï¼š**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: critical-api
spec:
  replicas: 6
  selector:
    matchLabels:
      app: critical-api
  template:
    metadata:
      labels:
        app: critical-api
    spec:
      # ç¡®ä¿ AZ åˆ†å¸ƒ
      topologySpreadConstraints:
      - maxSkew: 1
        topologyKey: topology.kubernetes.io/zone
        whenUnsatisfiable: DoNotSchedule
        labelSelector:
          matchLabels:
            app: critical-api
      # é˜²æ­¢åŒèŠ‚ç‚¹å…±ç½®
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchLabels:
                  app: critical-api
              topologyKey: kubernetes.io/hostname
      containers:
      - name: api
        image: myapp/critical-api:v3
        ports:
        - containerPort: 8080
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          periodSeconds: 5
          failureThreshold: 2
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8080
          periodSeconds: 10
        lifecycle:
          preStop:
            exec:
              command:
              - /bin/sh
              - -c
              - sleep 5
      terminationGracePeriodSeconds: 60
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: critical-api-pdb
spec:
  minAvailable: 4  # 6 ä¸ªä¸­ä¿æŒè‡³å°‘ 4 ä¸ªï¼ˆAZ æ•…éšœæ—¶ä» 2 ä¸ª AZ è¿è¡Œï¼‰
  selector:
    matchLabels:
      app: critical-api
```

**4. CloudWatch Alarm - AZ æ€§èƒ½é™çº§æ£€æµ‹ï¼š**

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: az-health-monitoring
  namespace: monitoring
data:
  cloudwatch-alarm: |
    {
      "AlarmName": "AZ-A-NetworkLatency-High",
      "MetricName": "NetworkLatency",
      "Namespace": "AWS/EC2",
      "Statistic": "Average",
      "Period": 60,
      "EvaluationPeriods": 3,
      "Threshold": 100,
      "ComparisonOperator": "GreaterThanThreshold",
      "Dimensions": [
        {"Name": "AvailabilityZone", "Value": "ap-northeast-2a"}
      ],
      "AlarmDescription": "AZ-A ç½‘ç»œå»¶è¿Ÿå¢åŠ  - Zonal Shift è§¦å‘",
      "AlarmActions": [
        "arn:aws:arc-zonal-shift:ap-northeast-2:123456789012:autoshift-observer-notification"
      ]
    }
```

**ç»“åˆ Istio Service Mesh çš„ç«¯åˆ°ç«¯ AZ æ¢å¤ï¼š**

ä¸ Istio Service Mesh é›†æˆå¯åœ¨ AZ ç–æ•£æœŸé—´å®ç°æ›´ç²¾ç»†çš„æµé‡æ§åˆ¶ï¼š

```yaml
# Istio DestinationRuleï¼šåŸºäº AZ çš„æµé‡è·¯ç”±
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: critical-api-az-routing
spec:
  host: critical-api.production.svc.cluster.local
  trafficPolicy:
    loadBalancer:
      localityLbSetting:
        enabled: true
        distribute:
        - from: ap-northeast-2a/*
          to:
            "ap-northeast-2b/*": 50
            "ap-northeast-2c/*": 50
        - from: ap-northeast-2b/*
          to:
            "ap-northeast-2a/*": 50
            "ap-northeast-2c/*": 50
        - from: ap-northeast-2c/*
          to:
            "ap-northeast-2a/*": 50
            "ap-northeast-2b/*": 50
    outlierDetection:
      consecutiveErrors: 3
      interval: 10s
      baseEjectionTime: 30s
      maxEjectionPercent: 50
---
# VirtualServiceï¼šAZ æ•…éšœæ—¶çš„è‡ªåŠ¨é‡è·¯ç”±
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: critical-api-failover
spec:
  hosts:
  - critical-api.production.svc.cluster.local
  http:
  - match:
    - sourceLabels:
        topology.kubernetes.io/zone: ap-northeast-2a
    route:
    - destination:
        host: critical-api.production.svc.cluster.local
        subset: az-b
      weight: 50
    - destination:
        host: critical-api.production.svc.cluster.local
        subset: az-c
      weight: 50
    timeout: 3s
    retries:
      attempts: 3
      perTryTimeout: 1s
```

**ç°è‰²æ•…éšœå¤„ç†ç­–ç•¥ï¼š**

ç°è‰²æ•…éšœæ˜¯æ€§èƒ½é™çº§è€Œéå®Œå…¨ä¸­æ–­çš„çŠ¶æ€ï¼Œéš¾ä»¥æ£€æµ‹ã€‚å¯ä»¥ä½¿ç”¨ ARC + Karpenter + Istio ç»„åˆæ¥åº”å¯¹ï¼š

| ç°è‰²æ•…éšœç—‡çŠ¶ | æ£€æµ‹æ–¹æ³• | è‡ªåŠ¨å“åº” |
|---------------------|-----------------|-------------------|
| ç½‘ç»œå»¶è¿Ÿå¢åŠ ï¼ˆ50-200msï¼‰ | Container Network Observability | Istio Outlier Detection â†’ æµé‡ç»•è¡Œ |
| é—´æ­‡æ€§ä¸¢åŒ…ï¼ˆ1-5%ï¼‰ | CloudWatch Network Metrics | ARC Zonal Shift è§¦å‘ |
| ç£ç›˜ I/O é™çº§ | EBS CloudWatch Metrics | Karpenter èŠ‚ç‚¹æ›¿æ¢ |
| API Server å“åº”å»¶è¿Ÿ | Control Plane Metrics | Provisioned Control Plane è‡ªåŠ¨æ‰©å±• |

**æµ‹è¯•ä¸éªŒè¯ï¼š**

```bash
# AZ æ•…éšœæ¨¡æ‹Ÿï¼ˆæ··æ²Œå·¥ç¨‹ï¼‰
kubectl apply -f - <<EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: az-failure-test
  namespace: chaos
data:
  experiment: |
    # 1. ä¸º AZ-A çš„æ‰€æœ‰èŠ‚ç‚¹æ·»åŠ  Taintï¼ˆæ¨¡æ‹Ÿ AZ æ•…éšœï¼‰
    kubectl taint nodes -l topology.kubernetes.io/zone=ap-northeast-2a \
      az-failure=true:NoSchedule

    # 2. éªŒè¯ Karpenter åœ¨ AZ-Bã€AZ-C åˆ›å»ºæ–°èŠ‚ç‚¹
    kubectl get nodes -l topology.kubernetes.io/zone=ap-northeast-2b,ap-northeast-2c

    # 3. ç›‘æ§ Pod è¿ç§»
    kubectl get pods -o wide --watch

    # 4. éªŒè¯ PDB åˆè§„ï¼ˆminAvailable ç»´æŒï¼‰
    kubectl get pdb critical-api-pdb

    # 5. æ£€æŸ¥ Graceful Shutdown æ—¥å¿—
    kubectl logs <pod-name> --previous

    # 6. æ¢å¤ï¼ˆç§»é™¤ Taintï¼‰
    kubectl taint nodes -l topology.kubernetes.io/zone=ap-northeast-2a \
      az-failure-
EOF
```

**ç›‘æ§ Dashboardï¼š**

```yaml
# Grafana Dashboardï¼šAZ å¥åº·å’Œç–æ•£çŠ¶æ€
apiVersion: v1
kind: ConfigMap
metadata:
  name: az-failover-dashboard
  namespace: monitoring
data:
  dashboard.json: |
    {
      "panels": [
        {
          "title": "Pod Distribution by AZ",
          "targets": [
            {
              "expr": "count(kube_pod_info) by (node, zone)"
            }
          ]
        },
        {
          "title": "Network Latency by AZ",
          "targets": [
            {
              "expr": "avg(container_network_latency_ms) by (availability_zone)"
            }
          ]
        },
        {
          "title": "Karpenter Node Provisioning Rate",
          "targets": [
            {
              "expr": "rate(karpenter_nodes_created_total[5m])"
            }
          ]
        },
        {
          "title": "Graceful Shutdown Success Rate",
          "targets": [
            {
              "expr": "rate(pod_termination_graceful_total[5m]) / rate(pod_termination_total[5m])"
            }
          ]
        }
      ]
    }
```

**ç›¸å…³èµ„æºï¼š**
- [AWS åšå®¢ï¼šARC + Karpenter é«˜å¯ç”¨é›†æˆ](https://aws.amazon.com/blogs/containers/enhance-kubernetes-high-availability-with-amazon-application-recovery-controller-and-karpenter-integration/)
- [AWS åšå®¢ï¼šåŸºäº Istio çš„ç«¯åˆ°ç«¯ AZ æ¢å¤](https://aws.amazon.com/blogs/containers/)
- [AWS re:Invent 2025: Supercharge your Karpenter](https://www.youtube.com/watch?v=kUQ4Q11F4iQ)

:::tip è¿ç»´æœ€ä½³å®è·µ
AZ ç–æ•£æ˜¯è‡ªåŠ¨åŒ–çš„ï¼Œä½†éœ€è¦é€šè¿‡å®šæœŸçš„æ··æ²Œå·¥ç¨‹æµ‹è¯•æ¥éªŒè¯ã€‚è‡³å°‘æ¯å­£åº¦è¿›è¡Œä¸€æ¬¡ AZ æ•…éšœæ¨¡æ‹Ÿï¼Œä»¥éªŒè¯ PDBã€Karpenter å’Œ Graceful Shutdown æ˜¯å¦æŒ‰é¢„æœŸå·¥ä½œã€‚ç‰¹åˆ«æ˜¯åœ¨ç”Ÿäº§ç¯å¢ƒä¸­æµ‹é‡ `terminationGracePeriodSeconds` æ˜¯å¦è¶³å¤Ÿé•¿äºå®é™…å…³é—­æ—¶é—´ã€‚
:::

#### Spot å®ä¾‹ 2 åˆ†é’Ÿé¢„è­¦å¤„ç†

AWS Spot å®ä¾‹åœ¨ç»ˆæ­¢å‰æä¾› 2 åˆ†é’Ÿé¢„è­¦ã€‚å¤„ç†æ­¤é¢„è­¦ä»¥ç¡®ä¿ Graceful Shutdownã€‚

**å®‰è£… AWS Node Termination Handlerï¼š**

```bash
helm repo add eks https://aws.github.io/eks-charts
helm repo update

helm install aws-node-termination-handler \
  --namespace kube-system \
  eks/aws-node-termination-handler \
  --set enableSpotInterruptionDraining=true \
  --set enableScheduledEventDraining=true
```

**å·¥ä½œåŸç†ï¼š**
1. æ£€æµ‹ 2 åˆ†é’Ÿ Spot ç»ˆæ­¢é¢„è­¦
2. ç«‹å³ Cordon èŠ‚ç‚¹ï¼ˆé˜»æ­¢æ–° Pod è°ƒåº¦ï¼‰
3. Drain èŠ‚ç‚¹ä¸Šçš„æ‰€æœ‰ Pod
4. åœ¨ Pod çš„ `terminationGracePeriodSeconds` å†…å®Œæˆ Graceful Shutdown

**å»ºè®®çš„ terminationGracePeriodSecondsï¼š**
- ä¸€èˆ¬ Web æœåŠ¡ï¼š30-60 ç§’
- é•¿æ—¶é—´è¿è¡Œçš„ä»»åŠ¡ï¼ˆæ‰¹å¤„ç†ã€ML æ¨ç†ï¼‰ï¼š90-120 ç§’
- æœ€å¤§è®¾ç½®ä¸º 2 åˆ†é’Ÿä»¥å†…ï¼ˆè€ƒè™‘ Spot é¢„è­¦æ—¶é—´ï¼‰

---
### 3.4.4 Node Readiness Controller -- èŠ‚ç‚¹çº§å°±ç»ªç®¡ç†

#### æ¦‚è¿°

Node Readiness Controller (NRC) æ˜¯ 2026 å¹´ 2 æœˆåœ¨ Kubernetes å®˜æ–¹åšå®¢ä¸Šå‘å¸ƒçš„ alpha ç‰¹æ€§ï¼ˆv0.1.1ï¼‰ã€‚å®ƒæ˜¯ä¸€ç§ç”¨äºå£°æ˜å¼ç®¡ç†èŠ‚ç‚¹çº§åŸºç¡€è®¾æ–½å°±ç»ªçŠ¶æ€çš„æ–°æœºåˆ¶ã€‚

ç°æœ‰çš„ Kubernetes èŠ‚ç‚¹ `Ready` æ¡ä»¶ä»…æä¾›ç®€å•çš„äºŒå…ƒçŠ¶æ€ï¼ˆReady/NotReadyï¼‰ï¼Œæ— æ³•å‡†ç¡®åæ˜  CNI æ’ä»¶åˆå§‹åŒ–ã€GPU é©±åŠ¨åŠ è½½å’Œå­˜å‚¨é©±åŠ¨å°±ç»ªç­‰å¤æ‚çš„åŸºç¡€è®¾æ–½ä¾èµ–ã€‚NRC é€šè¿‡æä¾› `NodeReadinessRule` CRD æ¥è§£å†³è¿™äº›é™åˆ¶ï¼Œå…è®¸å£°æ˜å¼å®šä¹‰è‡ªå®šä¹‰å°±ç»ªé—¨æ§ã€‚

**æ ¸å¿ƒä»·å€¼ï¼š**
- **ç»†ç²’åº¦èŠ‚ç‚¹çŠ¶æ€æ§åˆ¶**: æŒ‰åŸºç¡€è®¾æ–½ç»„ä»¶ç‹¬ç«‹ç®¡ç†å°±ç»ªçŠ¶æ€
- **è‡ªåŠ¨åŒ– Taint ç®¡ç†**: æ¡ä»¶ä¸æ»¡è¶³æ—¶è‡ªåŠ¨åº”ç”¨ NoSchedule Taint
- **çµæ´»çš„ç›‘æ§æ¨¡å¼**: æ”¯æŒä»…å¼•å¯¼ã€æŒç»­ç›‘æ§å’Œ dry-run æ¨¡å¼
- **é€‰æ‹©æ€§åº”ç”¨**: ä½¿ç”¨ nodeSelector ä»…å°†è§„åˆ™åº”ç”¨äºç‰¹å®šèŠ‚ç‚¹ç»„

**API ä¿¡æ¯ï¼š**
- API Group: `readiness.node.x-k8s.io/v1alpha1`
- Kind: `NodeReadinessRule`
- å®˜æ–¹æ–‡æ¡£: https://node-readiness-controller.sigs.k8s.io/

#### æ ¸å¿ƒç‰¹æ€§

##### 1. Continuous æ¨¡å¼ - æŒç»­ç›‘æ§

åœ¨æ•´ä¸ªèŠ‚ç‚¹ç”Ÿå‘½å‘¨æœŸä¸­æŒç»­ç›‘æ§æŒ‡å®šæ¡ä»¶ã€‚å¦‚æœåŸºç¡€è®¾æ–½ç»„ä»¶åœ¨è¿è¡Œæ—¶æ•…éšœï¼ˆå¦‚ GPU é©±åŠ¨å´©æºƒï¼‰ï¼Œä¼šç«‹å³åº”ç”¨ Taint ä»¥é˜»æ­¢æ–°çš„ Pod è°ƒåº¦ã€‚

**ä½¿ç”¨åœºæ™¯ï¼š**
- GPU é©±åŠ¨çŠ¶æ€ç›‘æ§
- ç½‘ç»œæ’ä»¶æŒç»­å¥åº·æ£€æŸ¥
- å­˜å‚¨é©±åŠ¨å¯ç”¨æ€§éªŒè¯

##### 2. Bootstrap-only æ¨¡å¼ - ä»…åˆå§‹åŒ–

ä»…åœ¨èŠ‚ç‚¹åˆå§‹åŒ–é˜¶æ®µæ£€æŸ¥æ¡ä»¶ï¼Œæ¡ä»¶æ»¡è¶³ååœæ­¢ç›‘æ§ã€‚å¼•å¯¼å®Œæˆåï¼Œä¸å†å¯¹æ¡ä»¶å˜åŒ–åšå‡ºååº”ã€‚

**ä½¿ç”¨åœºæ™¯ï¼š**
- CNI æ’ä»¶åˆå§‹å¼•å¯¼
- å®¹å™¨é•œåƒé¢„æ‹‰å–å®ŒæˆéªŒè¯
- ç­‰å¾…åˆå§‹å®‰å…¨æ‰«æå®Œæˆ

##### 3. Dry-run æ¨¡å¼ - å®‰å…¨éªŒè¯

æ¨¡æ‹Ÿè§„åˆ™è¡Œä¸ºä½†ä¸å®é™…åº”ç”¨ Taintã€‚é€‚ç”¨äºåœ¨ç”Ÿäº§éƒ¨ç½²å‰éªŒè¯è§„åˆ™ã€‚

**ä½¿ç”¨åœºæ™¯ï¼š**
- æµ‹è¯•æ–°çš„ NodeReadinessRule
- åˆ†ææ¡ä»¶å˜åŒ–çš„å½±å“
- è°ƒè¯•å’Œé—®é¢˜è¯Šæ–­

##### 4. nodeSelector - ç›®æ ‡èŠ‚ç‚¹é€‰æ‹©

åŸºäºæ ‡ç­¾ä»…å°†è§„åˆ™åº”ç”¨äºç‰¹å®šèŠ‚ç‚¹ç»„ã€‚å¯ä»¥å¯¹ GPU èŠ‚ç‚¹å’Œé€šç”¨èŠ‚ç‚¹åº”ç”¨ä¸åŒçš„å°±ç»ªè§„åˆ™ã€‚

#### YAML ç¤ºä¾‹

##### CNI å¼•å¯¼ - Bootstrap-only æ¨¡å¼

```yaml
apiVersion: readiness.node.x-k8s.io/v1alpha1
kind: NodeReadinessRule
metadata:
  name: network-readiness-rule
  namespace: kube-system
spec:
  # è¦æ£€æŸ¥çš„èŠ‚ç‚¹æ¡ä»¶
  conditions:
    - type: "cniplugin.example.net/NetworkReady"
      requiredStatus: "True"

  # æ¡ä»¶ä¸æ»¡è¶³æ—¶åº”ç”¨çš„ Taint
  taint:
    key: "readiness.k8s.io/acme.com/network-unavailable"
    effect: "NoSchedule"
    value: "pending"

  # å¼•å¯¼å®Œæˆååœæ­¢ç›‘æ§
  enforcementMode: "bootstrap-only"

  # ä»…åº”ç”¨äº Worker èŠ‚ç‚¹
  nodeSelector:
    matchLabels:
      node-role.kubernetes.io/worker: ""
```

**è¡Œä¸ºæµç¨‹ï¼š**
1. æ–°èŠ‚ç‚¹åŠ å…¥é›†ç¾¤æ—¶ï¼ŒNRC è‡ªåŠ¨åº”ç”¨ Taint
2. CNI æ’ä»¶å®Œæˆåˆå§‹åŒ–åï¼Œè®¾ç½® `NetworkReady=True` æ¡ä»¶
3. NRC éªŒè¯æ¡ä»¶å¹¶ç§»é™¤ Taint
4. Pod è°ƒåº¦å˜ä¸ºå¯ç”¨ï¼ˆåç»­ CNI çŠ¶æ€å˜åŒ–è¢«å¿½ç•¥ï¼‰

##### GPU èŠ‚ç‚¹æŒç»­ç›‘æ§

```yaml
apiVersion: readiness.node.x-k8s.io/v1alpha1
kind: NodeReadinessRule
metadata:
  name: gpu-driver-readiness
  namespace: kube-system
spec:
  conditions:
    - type: "nvidia.com/gpu-driver-ready"
      requiredStatus: "True"

  taint:
    key: "readiness.k8s.io/gpu-unavailable"
    effect: "NoSchedule"
    value: "driver-not-ready"

  # è¿è¡Œæ—¶æŒç»­ç›‘æ§
  enforcementMode: "continuous"

  # ä»…åº”ç”¨äº GPU èŠ‚ç‚¹
  nodeSelector:
    matchLabels:
      nvidia.com/gpu.present: "true"
```

**è¡Œä¸ºæµç¨‹ï¼š**
1. GPU èŠ‚ç‚¹å¯åŠ¨æ—¶è‡ªåŠ¨åº”ç”¨ Taint
2. NVIDIA é©±åŠ¨å®ˆæŠ¤è¿›ç¨‹åœ¨ GPU åˆå§‹åŒ–å®Œæˆåè®¾ç½®æ¡ä»¶
3. NRC ç§»é™¤ Taintï¼Œå¯ç”¨ AI å·¥ä½œè´Ÿè½½è°ƒåº¦
4. **å¦‚æœè¿è¡Œæ—¶å‘ç”Ÿé©±åŠ¨å´©æºƒï¼š**
   - æ¡ä»¶å˜ä¸º `False`
   - NRC ç«‹å³é‡æ–°åº”ç”¨ Taint
   - ç°æœ‰ Pod ä¿æŒè¿è¡Œï¼Œä½†æ–° Pod è°ƒåº¦è¢«é˜»æ­¢

##### EBS CSI é©±åŠ¨å°±ç»ªæ£€æŸ¥

```yaml
apiVersion: readiness.node.x-k8s.io/v1alpha1
kind: NodeReadinessRule
metadata:
  name: ebs-csi-readiness
  namespace: kube-system
spec:
  conditions:
    - type: "ebs.csi.aws.com/VolumeAttachReady"
      requiredStatus: "True"

  taint:
    key: "readiness.k8s.io/storage-unavailable"
    effect: "NoSchedule"
    value: "csi-not-ready"

  enforcementMode: "bootstrap-only"

  # ä»…åº”ç”¨äºå­˜å‚¨å·¥ä½œè´Ÿè½½ä¸“ç”¨èŠ‚ç‚¹
  nodeSelector:
    matchLabels:
      workload-type: "stateful"
```

##### Dry-run æ¨¡å¼ - æµ‹è¯•è§„åˆ™

```yaml
apiVersion: readiness.node.x-k8s.io/v1alpha1
kind: NodeReadinessRule
metadata:
  name: test-custom-condition
  namespace: kube-system
spec:
  conditions:
    - type: "example.com/CustomHealthCheck"
      requiredStatus: "True"

  taint:
    key: "readiness.k8s.io/test-condition"
    effect: "NoSchedule"
    value: "testing"

  # ä»…è®°å½•è¡Œä¸ºï¼Œä¸å®é™…åº”ç”¨ Taint
  enforcementMode: "dry-run"

  nodeSelector:
    matchLabels:
      environment: "staging"
```

#### EKS åº”ç”¨åœºæ™¯

##### 1. VPC CNI åˆå§‹åŒ–ç­‰å¾…

**é—®é¢˜ï¼š**
å¦‚æœåœ¨èŠ‚ç‚¹åŠ å…¥é›†ç¾¤åã€VPC CNI æ’ä»¶å®Œå…¨åˆå§‹åŒ–ä¹‹å‰å°±è°ƒåº¦ Podï¼Œä¼šå‘ç”Ÿç½‘ç»œè¿æ¥æ•…éšœã€‚

**è§£å†³æ–¹æ¡ˆï¼š**
```yaml
apiVersion: readiness.node.x-k8s.io/v1alpha1
kind: NodeReadinessRule
metadata:
  name: vpc-cni-readiness
  namespace: kube-system
spec:
  conditions:
    - type: "vpc.amazonaws.com/CNIReady"
      requiredStatus: "True"
  taint:
    key: "node.eks.amazonaws.com/network-unavailable"
    effect: "NoSchedule"
    value: "vpc-cni-initializing"
  enforcementMode: "bootstrap-only"
```

**åœ¨ VPC CNI DaemonSet ä¸­è®¾ç½®æ¡ä»¶ï¼š**
```yaml
# aws-node DaemonSet ä¸­çš„ Init å®¹å™¨
initContainers:
- name: set-node-condition
  image: bitnami/kubectl:latest
  command:
  - /bin/sh
  - -c
  - |
    # ç­‰å¾… CNI åˆå§‹åŒ–
    until [ -f /host/etc/cni/net.d/10-aws.conflist ]; do
      echo "Waiting for CNI config..."
      sleep 2
    done

    # è®¾ç½® Node Condition
    kubectl patch node $NODE_NAME --type=json -p='[
      {
        "op": "add",
        "path": "/status/conditions/-",
        "value": {
          "type": "vpc.amazonaws.com/CNIReady",
          "status": "True",
          "lastTransitionTime": "'$(date -u +"%Y-%m-%dT%H:%M:%SZ")'",
          "reason": "CNIInitialized",
          "message": "VPC CNI is ready"
        }
      }
    ]'
  env:
  - name: NODE_NAME
    valueFrom:
      fieldRef:
        fieldPath: spec.nodeName
```

##### 2. GPU èŠ‚ç‚¹ NVIDIA é©±åŠ¨å°±ç»ª

**é—®é¢˜ï¼š**
å¦‚æœåœ¨ NVIDIA é©±åŠ¨åŠ è½½å®Œæˆä¹‹å‰è°ƒåº¦ GPU å·¥ä½œè´Ÿè½½ï¼ŒCUDA åˆå§‹åŒ–å¤±è´¥ï¼ŒPod è¿›å…¥ CrashLoopBackOff çŠ¶æ€ã€‚

**è§£å†³æ–¹æ¡ˆï¼š**
```yaml
apiVersion: readiness.node.x-k8s.io/v1alpha1
kind: NodeReadinessRule
metadata:
  name: nvidia-gpu-readiness
  namespace: kube-system
spec:
  conditions:
    - type: "nvidia.com/gpu-driver-ready"
      requiredStatus: "True"
    - type: "nvidia.com/gpu-device-plugin-ready"
      requiredStatus: "True"
  taint:
    key: "nvidia.com/gpu-not-ready"
    effect: "NoSchedule"
    value: "driver-loading"
  enforcementMode: "continuous"
  nodeSelector:
    matchLabels:
      node.kubernetes.io/instance-type: "g5.xlarge"
```

**åœ¨ NVIDIA Device Plugin ä¸­è®¾ç½®æ¡ä»¶ï¼š**
```go
// NVIDIA Device Plugin ä¸­çš„å¥åº·æ£€æŸ¥é€»è¾‘
func updateNodeCondition(nodeName string) error {
    // æ£€æŸ¥ GPU é©±åŠ¨çŠ¶æ€
    version, err := nvml.SystemGetDriverVersion()
    if err != nil {
        return setCondition(nodeName, "nvidia.com/gpu-driver-ready", "False")
    }

    // æ£€æŸ¥ Device Plugin çŠ¶æ€
    devices, err := nvml.DeviceGetCount()
    if err != nil || devices == 0 {
        return setCondition(nodeName, "nvidia.com/gpu-device-plugin-ready", "False")
    }

    // ä¸€åˆ‡æ­£å¸¸åˆ™è®¾ç½®ä¸º True
    setCondition(nodeName, "nvidia.com/gpu-driver-ready", "True")
    setCondition(nodeName, "nvidia.com/gpu-device-plugin-ready", "True")
    return nil
}
```

##### 3. Node Problem Detector é›†æˆ

**é—®é¢˜ï¼š**
å³ä½¿èŠ‚ç‚¹ä¸Šå‘ç”Ÿç¡¬ä»¶é”™è¯¯ã€å†…æ ¸æ­»é”æˆ–ç½‘ç»œé—®é¢˜ï¼ŒKubernetes ä¹Ÿä¸ä¼šè‡ªåŠ¨é˜»æ­¢ Pod è°ƒåº¦ã€‚

**è§£å†³æ–¹æ¡ˆï¼š**
```yaml
apiVersion: readiness.node.x-k8s.io/v1alpha1
kind: NodeReadinessRule
metadata:
  name: node-problem-detector-readiness
  namespace: kube-system
spec:
  conditions:
    - type: "KernelDeadlock"
      requiredStatus: "False"  # False è¡¨ç¤ºå¥åº·
    - type: "DiskPressure"
      requiredStatus: "False"
    - type: "NetworkUnavailable"
      requiredStatus: "False"
  taint:
    key: "node.kubernetes.io/problem-detected"
    effect: "NoSchedule"
    value: "true"
  enforcementMode: "continuous"
```

#### å·¥ä½œæµå›¾

```mermaid
sequenceDiagram
    participant Node as æ–°èŠ‚ç‚¹
    participant NRC as Node Readiness<br/>Controller
    participant CNI as CNI æ’ä»¶
    participant Scheduler as kube-scheduler
    participant Pod as Pod

    Note over Node: èŠ‚ç‚¹åŠ å…¥é›†ç¾¤

    Node->>NRC: èŠ‚ç‚¹æ³¨å†Œäº‹ä»¶
    NRC->>NRC: æ£€æŸ¥ NodeReadinessRule
    NRC->>Node: è‡ªåŠ¨åº”ç”¨ Taint<br/>(network-unavailable=pending:NoSchedule)

    Note over Node,CNI: åŸºç¡€è®¾æ–½ç»„ä»¶æ­£åœ¨åˆå§‹åŒ–

    CNI->>CNI: VPC CNI åˆå§‹åŒ–å¼€å§‹
    CNI->>CNI: ENI åˆ†é…å®Œæˆ
    CNI->>CNI: IP åœ°å€æ± å°±ç»ª
    CNI->>Node: æ›´æ–° Node Condition<br/>(CNIReady=True)

    NRC->>Node: æ£€æµ‹åˆ° Condition å˜åŒ–
    NRC->>NRC: éªŒè¯ requiredStatus (True == True)
    NRC->>Node: ç§»é™¤ Taint

    Note over Node: èŠ‚ç‚¹å‡†å¤‡å¥½è¿›è¡Œ Pod è°ƒåº¦

    Scheduler->>Node: ç¡®è®¤ Pod è°ƒåº¦å¯ç”¨
    Scheduler->>Pod: å°† Pod åˆ†é…åˆ°èŠ‚ç‚¹
    Pod->>Node: Pod å¯åŠ¨å¹¶ç½‘ç»œè¿æ¥æˆåŠŸ

    Note over Node,Pod: æ­£å¸¸è¿è¡Œ

    alt Continuous æ¨¡å¼
        CNI->>CNI: è¿è¡Œæ—¶é©±åŠ¨å´©æºƒ
        CNI->>Node: Condition å˜åŒ–<br/>(CNIReady=False)
        NRC->>Node: æ£€æµ‹åˆ° Condition å˜åŒ–
        NRC->>Node: é‡æ–°åº”ç”¨ Taint
        Note over Scheduler: æ–° Pod è°ƒåº¦è¢«é˜»æ­¢<br/>ï¼ˆç°æœ‰ Pod ä¿æŒè¿è¡Œï¼‰
    else Bootstrap-only æ¨¡å¼
        Note over NRC: Condition å˜åŒ–è¢«å¿½ç•¥<br/>ï¼ˆç›‘æ§å·²åœæ­¢ï¼‰
    end
```

#### ä¸ Pod Readiness çš„å…³ç³»

Kubernetes Readiness æœºåˆ¶ç°åœ¨å½¢æˆäº†å®Œæ•´çš„ 3 å±‚ç»“æ„ï¼š

| å±‚çº§ | æœºåˆ¶ | èŒƒå›´ | å¤±è´¥è¡Œä¸º | ä½¿ç”¨åœºæ™¯ |
|-------|-----------|-------|-----------------|----------|
| **1. å®¹å™¨** | Readiness Probe | å®¹å™¨å†…éƒ¨å¥åº·æ£€æŸ¥ | ä» Service Endpoint ç§»é™¤ | éªŒè¯åº”ç”¨å°±ç»ª |
| **2. Pod** | Readiness Gate | Pod çº§åˆ«å¤–éƒ¨æ¡ä»¶ | ä» Service Endpoint ç§»é™¤ | ALB/NLB å¥åº·æ£€æŸ¥é›†æˆ |
| **3. èŠ‚ç‚¹** | Node Readiness Controller | èŠ‚ç‚¹åŸºç¡€è®¾æ–½æ¡ä»¶ | é˜»æ­¢ Pod è°ƒåº¦ï¼ˆTaintï¼‰ | CNIã€GPUã€å­˜å‚¨å°±ç»ªéªŒè¯ |

**é›†æˆåœºæ™¯ - å®Œæ•´çš„æµé‡å®‰å…¨ï¼š**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: critical-service
spec:
  replicas: 3
  template:
    spec:
      # åº”ç”¨ 3 å±‚ Readiness
      containers:
      - name: app
        image: myapp:v2
        # ç¬¬ 1 å±‚ï¼šå®¹å™¨ Readiness Probe
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          periodSeconds: 5
          failureThreshold: 2

      # ç¬¬ 2 å±‚ï¼šPod Readiness Gate
      readinessGates:
      - conditionType: "target-health.alb.ingress.k8s.aws/production-alb"

      # ç¬¬ 3 å±‚ï¼šNode Readinessï¼ˆç”± NodeReadinessRule è‡ªåŠ¨å¤„ç†ï¼‰
      # - æ£€æŸ¥èŠ‚ç‚¹ä¸Šçš„ CNIã€GPUã€å­˜å‚¨å°±ç»ªçŠ¶æ€
      # - Pod ä»…è°ƒåº¦åˆ°æ²¡æœ‰ Taint çš„èŠ‚ç‚¹
```

**æµé‡æ¥æ”¶æ£€æŸ¥æ¸…å•ï¼š**

```mermaid
flowchart TD
    START[Pod åˆ›å»º]

    START --> NODE_CHECK{èŠ‚ç‚¹å°±ç»ªï¼Ÿ<br/>Node Readiness}
    NODE_CHECK -->|å­˜åœ¨ Taint| WAIT_NODE[ç­‰å¾…è°ƒåº¦]
    WAIT_NODE --> NODE_CHECK
    NODE_CHECK -->|æ—  Taint| SCHEDULE[Pod è¢«è°ƒåº¦]

    SCHEDULE --> POD_START[Pod å¯åŠ¨]
    POD_START --> CONTAINER_CHECK{å®¹å™¨å°±ç»ªï¼Ÿ<br/>Readiness Probe}
    CONTAINER_CHECK -->|å¤±è´¥| WAIT_CONTAINER[Endpoint æœªæ³¨å†Œ]
    WAIT_CONTAINER --> CONTAINER_CHECK
    CONTAINER_CHECK -->|æˆåŠŸ| GATE_CHECK{Pod Gate é€šè¿‡ï¼Ÿ<br/>Readiness Gate}

    GATE_CHECK -->|å¤±è´¥| WAIT_GATE[Endpoint æœªæ³¨å†Œ]
    WAIT_GATE --> GATE_CHECK
    GATE_CHECK -->|æˆåŠŸ| READY[Service Endpoint å·²æ³¨å†Œ]

    READY --> TRAFFIC[å¼€å§‹æ¥æ”¶æµé‡]

    style NODE_CHECK fill:#fbbc04,stroke:#c99603,color:#000
    style CONTAINER_CHECK fill:#fbbc04,stroke:#c99603,color:#000
    style GATE_CHECK fill:#fbbc04,stroke:#c99603,color:#000
    style READY fill:#34a853,stroke:#2a8642,color:#fff
    style TRAFFIC fill:#4286f4,stroke:#2a6acf,color:#fff
```

#### å®‰è£…å’Œé…ç½®

##### 1. å®‰è£… Node Readiness Controller

```bash
# é€šè¿‡ Helm å®‰è£…
helm repo add node-readiness-controller https://node-readiness-controller.sigs.k8s.io
helm repo update

helm install node-readiness-controller \
  node-readiness-controller/node-readiness-controller \
  --namespace kube-system \
  --create-namespace

# æˆ–é€šè¿‡ Kustomize å®‰è£…
kubectl apply -k https://github.com/kubernetes-sigs/node-readiness-controller/config/default
```

##### 2. éªŒè¯å®‰è£…

```bash
# æ£€æŸ¥ Controller Pod çŠ¶æ€
kubectl get pods -n kube-system -l app=node-readiness-controller

# éªŒè¯ CRD
kubectl get crd nodereadinessrules.readiness.node.x-k8s.io

# åº”ç”¨ç¤ºä¾‹è§„åˆ™
kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/node-readiness-controller/main/examples/basic-rule.yaml

# åˆ—å‡ºè§„åˆ™
kubectl get nodereadinessrules -A
```

##### 3. éªŒè¯èŠ‚ç‚¹çŠ¶æ€

```bash
# æ£€æŸ¥ç‰¹å®šèŠ‚ç‚¹çš„ Condition
kubectl get node <node-name> -o jsonpath='{.status.conditions}' | jq

# è¿‡æ»¤ç‰¹å®š Condition
kubectl get node <node-name> -o jsonpath='{.status.conditions[?(@.type=="CNIReady")]}' | jq

# æ£€æŸ¥æ‰€æœ‰èŠ‚ç‚¹çš„ Taint
kubectl get nodes -o custom-columns=NAME:.metadata.name,TAINTS:.spec.taints
```

#### è°ƒè¯•ä¸æ•…éšœæ’æŸ¥

##### Taint æœªè¢«ç§»é™¤æ—¶

```bash
# 1. æ£€æŸ¥ NodeReadinessRule äº‹ä»¶
kubectl describe nodereadinessrule <rule-name> -n kube-system

# 2. æ£€æŸ¥èŠ‚ç‚¹ Condition çŠ¶æ€
kubectl get node <node-name> -o yaml | grep -A 10 conditions

# 3. æ£€æŸ¥ Controller æ—¥å¿—
kubectl logs -n kube-system -l app=node-readiness-controller --tail=100

# 4. æ‰‹åŠ¨è®¾ç½® Conditionï¼ˆç”¨äºæµ‹è¯•ï¼‰
kubectl patch node <node-name> --type=json -p='[
  {
    "op": "add",
    "path": "/status/conditions/-",
    "value": {
      "type": "CNIReady",
      "status": "True",
      "lastTransitionTime": "'$(date -u +"%Y-%m-%dT%H:%M:%SZ")'",
      "reason": "ManualSet",
      "message": "Manually set for testing"
    }
  }
]'
```

##### ä½¿ç”¨ Dry-run æ¨¡å¼æµ‹è¯•è§„åˆ™

```bash
# å°†ç°æœ‰è§„åˆ™æ›´æ”¹ä¸º dry-run
kubectl patch nodereadinessrule <rule-name> -n kube-system \
  --type=merge \
  -p '{"spec":{"enforcementMode":"dry-run"}}'

# åœ¨ Controller æ—¥å¿—ä¸­éªŒè¯è¡Œä¸º
kubectl logs -n kube-system -l app=node-readiness-controller -f | grep "dry-run"

# æµ‹è¯•åæ¢å¤åŸå§‹æ¨¡å¼
kubectl patch nodereadinessrule <rule-name> -n kube-system \
  --type=merge \
  -p '{"spec":{"enforcementMode":"continuous"}}'
```

:::info Alpha ç‰¹æ€§æé†’
Node Readiness Controller ç›®å‰å¤„äº v0.1.1 alpha é˜¶æ®µã€‚åœ¨åº”ç”¨åˆ°ç”Ÿäº§ç¯å¢ƒä¹‹å‰ï¼š
- åœ¨ Staging ç¯å¢ƒä¸­è¿›è¡Œå……åˆ†æµ‹è¯•
- ä½¿ç”¨ dry-run æ¨¡å¼éªŒè¯è§„åˆ™è¡Œä¸º
- è®¾ç½® Controller æ—¥å¿—ç›‘æ§
- å‡†å¤‡åœ¨å‡ºç°é—®é¢˜æ—¶æ‰‹åŠ¨ç§»é™¤ Taint çš„ç¨‹åº
:::

:::tip è¿ç»´æœ€ä½³å®è·µ
1. **ä¼˜å…ˆä½¿ç”¨ bootstrap-only**: å¤§å¤šæ•°æƒ…å†µä¸‹ bootstrap-only æ¨¡å¼å°±è¶³å¤Ÿäº†ã€‚ä»…å¯¹è¿è¡Œæ—¶é¢‘ç¹æ•…éšœçš„ç»„ä»¶ï¼ˆå¦‚ GPU é©±åŠ¨ï¼‰ä½¿ç”¨ continuous æ¨¡å¼ã€‚
2. **ç§¯æä½¿ç”¨ nodeSelector**: ä¸è¦å°†ç›¸åŒè§„åˆ™åº”ç”¨äºæ‰€æœ‰èŠ‚ç‚¹ï¼›è€Œæ˜¯æŒ‰å·¥ä½œè´Ÿè½½ç±»å‹è¿›è¡Œç»†åˆ†ã€‚
3. **ä¸ Node Problem Detector é›†æˆ**: å°† NRC ä¸ NPD ç»“åˆä½¿ç”¨ï¼Œå¯ä»¥è‡ªåŠ¨å“åº”ç¡¬ä»¶/OS çº§åˆ«çš„é—®é¢˜ã€‚
4. **ç›‘æ§å’Œå‘Šè­¦**: åœ¨ CloudWatch æˆ– Prometheus ä¸­æ”¶é›† Taint åº”ç”¨/ç§»é™¤äº‹ä»¶ï¼Œå¹¶åœ¨ Taint æŒç»­æ—¶é—´è¿‡é•¿æ—¶é…ç½®å‘Šè­¦ã€‚
:::

:::warning æ³¨æ„ PDB å†²çª
å½“ Node Readiness Controller åº”ç”¨ Taint æ—¶ï¼Œä¸ä¼šåœ¨è¯¥èŠ‚ç‚¹ä¸Šåˆ›å»ºæ–°çš„ Podã€‚å¦‚æœåŒæ—¶å¯¹å¤šä¸ªèŠ‚ç‚¹åº”ç”¨ Taint ä¸” PodDisruptionBudget é…ç½®è¿‡äºä¸¥æ ¼ï¼Œå¯èƒ½ä¼šé˜»æ­¢æ•´ä¸ªé›†ç¾¤çš„å·¥ä½œè´Ÿè½½åˆ†é…ã€‚è¯·å°† PDB ç­–ç•¥ä¸è§„åˆ™è®¾è®¡ä¸€èµ·å®¡æŸ¥ã€‚
:::

#### å‚è€ƒèµ„æ–™

- **å®˜æ–¹æ–‡æ¡£**: [Node Readiness Controller](https://node-readiness-controller.sigs.k8s.io/)
- **Kubernetes åšå®¢**: [Introducing Node Readiness Controller](https://kubernetes.io/blog/2026/02/03/introducing-node-readiness-controller/)
- **GitHub ä»“åº“**: [kubernetes-sigs/node-readiness-controller](https://github.com/kubernetes-sigs/node-readiness-controller)

---

### 3.5 Fargate Pod ç”Ÿå‘½å‘¨æœŸç‰¹æ®Šæ³¨æ„äº‹é¡¹

AWS Fargate æ˜¯ä¸€ç§æ— æœåŠ¡å™¨è®¡ç®—å¼•æ“ï¼Œæ— éœ€èŠ‚ç‚¹ç®¡ç†å³å¯è¿è¡Œ Podã€‚Fargate Pod ä¸åŸºäº EC2 çš„ Pod ç›¸æ¯”å…·æœ‰ä¸åŒçš„ç”Ÿå‘½å‘¨æœŸç‰¹å¾ã€‚

#### Fargate vs EC2 vs Auto Mode æ¶æ„æ¯”è¾ƒ

```mermaid
flowchart TB
    subgraph EC2["EC2 Managed Node Group"]
        EC2Node[EC2 å®ä¾‹]
        EC2Kubelet[kubelet]
        EC2Pod1[Pod 1]
        EC2Pod2[Pod 2]
        EC2Pod3[Pod 3]

        EC2Node --> EC2Kubelet
        EC2Kubelet --> EC2Pod1
        EC2Kubelet --> EC2Pod2
        EC2Kubelet --> EC2Pod3
    end

    subgraph Fargate["Fargate"]
        FGPod1[Pod 1<br/>ä¸“ç”¨ MicroVM]
        FGPod2[Pod 2<br/>ä¸“ç”¨ MicroVM]
        FGPod3[Pod 3<br/>ä¸“ç”¨ MicroVM]
    end

    subgraph AutoMode["EKS Auto Mode"]
        AutoNode[AWS æ‰˜ç®¡å®ä¾‹]
        AutoKubelet[kubelet<br/>è‡ªåŠ¨ç®¡ç†]
        AutoPod1[Pod 1]
        AutoPod2[Pod 2]
        AutoPod3[Pod 3]

        AutoNode -.->|AWS æ‹¥æœ‰| AutoKubelet
        AutoKubelet --> AutoPod1
        AutoKubelet --> AutoPod2
        AutoKubelet --> AutoPod3
    end

    style EC2 fill:#ff9900,stroke:#cc7a00
    style Fargate fill:#9b59b6,stroke:#7d3c98
    style AutoMode fill:#34a853,stroke:#2a8642
```

#### Fargate Pod OS è¡¥ä¸è‡ªåŠ¨é©±é€

Fargate ä¼šå®šæœŸè‡ªåŠ¨é©±é€ Pod ä»¥è¿›è¡Œå®‰å…¨è¡¥ä¸ã€‚

**å·¥ä½œåŸç†ï¼š**

1. **è¡¥ä¸å¯ç”¨æ€§æ£€æµ‹**: AWS æ£€æµ‹åˆ°æ–°çš„ OS/è¿è¡Œæ—¶è¡¥ä¸
2. **ä¼˜é›…é©±é€**: Fargate å‘ Pod å‘é€ SIGTERM â†’ åœ¨ `terminationGracePeriodSeconds` å†…ç­‰å¾…å…³é—­
3. **å¼ºåˆ¶ç»ˆæ­¢**: è¶…æ—¶åå‘é€ SIGKILL
4. **é‡æ–°è°ƒåº¦**: Kubernetes é‡æ–°è°ƒåº¦åˆ°æ–°çš„ Fargate Podï¼ˆä½¿ç”¨æ›´æ–°åçš„è¿è¡Œæ—¶ï¼‰

**å…³é”®ç‰¹å¾ï¼š**

- **ä¸å¯é¢„æµ‹çš„æ—¶é—´**: ç”¨æˆ·æ— æ³•æ§åˆ¶ï¼ˆAWS ç®¡ç†ï¼‰
- **æ— æå‰é€šçŸ¥**: ä¸ EC2 Scheduled Events ä¸åŒï¼Œæ²¡æœ‰é¢„å…ˆè­¦å‘Š
- **è‡ªåŠ¨é‡å¯**: å°Šé‡ PodDisruptionBudget (PDB)ï¼Œä½†å®‰å…¨è¡¥ä¸å…·æœ‰æ›´é«˜ä¼˜å…ˆçº§

**ç¼“è§£ç­–ç•¥ï¼š**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: fargate-app
  namespace: fargate-namespace
spec:
  replicas: 3  # å»ºè®®è‡³å°‘ 3 ä¸ªï¼ˆåº”å¯¹è‡ªåŠ¨é©±é€ï¼‰
  selector:
    matchLabels:
      app: fargate-app
  template:
    metadata:
      labels:
        app: fargate-app
    spec:
      containers:
      - name: app
        image: myapp:v1
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
        startupProbe:
          httpGet:
            path: /healthz
            port: 8080
          failureThreshold: 10
          periodSeconds: 5
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8080
          periodSeconds: 10
        lifecycle:
          preStop:
            exec:
              command:
              - /bin/sh
              - -c
              - sleep 10  # Fargate é©±é€æ—¶ç­‰å¾…æ›´é•¿æ—¶é—´
      # Fargate å¯åŠ¨æ—¶é—´å¯èƒ½æ›´é•¿
      terminationGracePeriodSeconds: 60
---
# PDB é™åˆ¶å¹¶å‘é©±é€ï¼ˆå°½åŠ›è€Œä¸ºï¼›å®‰å…¨è¡¥ä¸å¯èƒ½å¿½ç•¥ï¼‰
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: fargate-app-pdb
  namespace: fargate-namespace
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: fargate-app
```

:::warning Fargate PDB é™åˆ¶
Fargate ä»…ä»¥**å°½åŠ›è€Œä¸º**çš„æ–¹å¼å°Šé‡ PDBã€‚å¯¹äºå…³é”®å®‰å…¨è¡¥ä¸ï¼Œå¯èƒ½ä¼šå¿½ç•¥ PDB å¹¶å¼ºåˆ¶é©±é€ã€‚å› æ­¤ï¼Œåœ¨ Fargate ç¯å¢ƒä¸­ï¼Œè¯·ç¡®ä¿ä½¿ç”¨**è‡³å°‘ 3 ä¸ªå‰¯æœ¬**å®ç°é«˜å¯ç”¨æ€§ã€‚
:::

#### Fargate Pod å¯åŠ¨æ—¶é—´ç‰¹å¾

Fargate Pod çš„å¯åŠ¨æ—¶é—´æ¯”åŸºäº EC2 çš„ Pod æ›´é•¿ã€‚

| é˜¶æ®µ | EC2ï¼ˆManaged Nodeï¼‰ | Fargate | åŸå›  |
|-------|-------------------|---------|--------|
| **èŠ‚ç‚¹é…ç½®** | 0sï¼ˆå·²åœ¨è¿è¡Œï¼‰ | 20-40s | MicroVM åˆ›å»º + ENI é™„åŠ  |
| **é•œåƒæ‹‰å–** | 5-30s | 10-60s | æ— å±‚ç¼“å­˜ï¼ˆé¦–æ¬¡è¿è¡Œæ—¶ï¼‰ |
| **å®¹å™¨å¯åŠ¨** | 1-5s | 1-5s | ç›¸åŒ |
| **æ€»å¯åŠ¨æ—¶é—´** | 6-35s | 31-105s | Fargate é¢å¤–å¼€é”€ |

**Startup Probe è°ƒæ•´ç¤ºä¾‹ï¼š**

```yaml
# EC2 Pod
startupProbe:
  httpGet:
    path: /healthz
    port: 8080
  failureThreshold: 6   # 6 x 5s = 30s
  periodSeconds: 5

# Fargate Podï¼ˆå…è®¸æ›´é•¿æ—¶é—´ï¼‰
startupProbe:
  httpGet:
    path: /healthz
    port: 8080
  failureThreshold: 20  # 20 x 5s = 100s
  periodSeconds: 5
```

**é•œåƒæ‹‰å–ä¼˜åŒ–ï¼ˆFargateï¼‰ï¼š**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: fargate-pod
  namespace: fargate-namespace
spec:
  containers:
  - name: app
    image: 123456789012.dkr.ecr.us-east-1.amazonaws.com/myapp:v1
    imagePullPolicy: IfNotPresent  # å»ºè®® IfNotPresent è€Œé Always
  imagePullSecrets:
  - name: ecr-secret
```

:::tip Fargate é•œåƒç¼“å­˜
Fargate åœ¨é‡å¤ä½¿ç”¨ç›¸åŒé•œåƒæ—¶ä¼šè¿›è¡Œå±‚ç¼“å­˜ï¼Œä½†**ç¼“å­˜åœ¨ Pod è¢«é©±é€æ—¶ä¼šä¸¢å¤±**ã€‚ä½¿ç”¨ ECR Image Scanning å’Œ Image Replication æ¥å‡å°‘é•œåƒæ‹‰å–æ—¶é—´ã€‚
:::

#### ç”±äº Fargate DaemonSet é™åˆ¶çš„ Sidecar æ¨¡å¼

Fargate ä¸æ”¯æŒ DaemonSetï¼Œå› æ­¤åœ¨éœ€è¦èŠ‚ç‚¹çº§ä»£ç†æ—¶å¿…é¡»ä½¿ç”¨ Sidecar æ¨¡å¼ã€‚

**EC2 vs Fargate ç›‘æ§æ¨¡å¼æ¯”è¾ƒï¼š**

| åŠŸèƒ½ | EC2ï¼ˆDaemonSetï¼‰ | Fargateï¼ˆSidecarï¼‰ |
|---------|----------------|-------------------|
| **æ—¥å¿—æ”¶é›†** | Fluent Bit DaemonSet | Fluent Bit Sidecar + FireLens |
| **æŒ‡æ ‡æ”¶é›†** | CloudWatch Agent DaemonSet | CloudWatch Agent Sidecar |
| **å®‰å…¨æ‰«æ** | Falco DaemonSet | Fargate ç”± AWS ç®¡ç†ï¼ˆç”¨æˆ·æ— æ³•æ§åˆ¶ï¼‰ |
| **ç½‘ç»œç­–ç•¥** | Calico/Cilium DaemonSet | ä¸æ”¯æŒ NetworkPolicyï¼ˆä½¿ç”¨ Security Groups for Podsï¼‰ |

**Fargate æ—¥å¿—æ¨¡å¼ï¼ˆFireLensï¼‰ï¼š**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: fargate-logging-app
  namespace: fargate-namespace
spec:
  replicas: 2
  selector:
    matchLabels:
      app: logging-app
  template:
    metadata:
      labels:
        app: logging-app
    spec:
      containers:
      # ä¸»åº”ç”¨
      - name: app
        image: myapp:v1
        ports:
        - containerPort: 8080
        resources:
          requests:
            cpu: 500m
            memory: 512Mi
      # FireLens æ—¥å¿—è·¯ç”±å™¨ï¼ˆsidecarï¼‰
      - name: log-router
        image: public.ecr.aws/aws-observability/aws-for-fluent-bit:stable
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 200m
            memory: 256Mi
        env:
        - name: FLB_LOG_LEVEL
          value: "info"
        firelensConfiguration:
          type: fluentbit
          options:
            enable-ecs-log-metadata: "true"
```

:::info Fargate ä¸Šçš„ CloudWatch Container Insights
Fargate **åŸç”Ÿæ”¯æŒ** CloudWatch Container Insightsï¼Œæ— éœ€å•ç‹¬çš„ Sidecar å³å¯è‡ªåŠ¨æ”¶é›†æŒ‡æ ‡ã€‚åˆ›å»º Fargate Profile æ—¶è‡ªåŠ¨å¯ç”¨ã€‚

```bash
aws eks create-fargate-profile \
  --cluster-name my-cluster \
  --fargate-profile-name my-profile \
  --pod-execution-role-arn arn:aws:iam::123456789012:role/FargatePodExecutionRole \
  --selectors namespace=fargate-namespace \
  --tags 'EnableContainerInsights=enabled'
```
:::

#### Fargate Graceful Shutdown æ—¶é—´å»ºè®®

ç”±äºè‡ªåŠ¨é©±é€å’Œè¾ƒé•¿çš„å¯åŠ¨æ—¶é—´ï¼ŒFargate éœ€è¦ä¸ EC2 ä¸åŒçš„ Graceful Shutdown ç­–ç•¥ã€‚

| åœºæ™¯ | terminationGracePeriodSeconds | preStop sleep | åŸå›  |
|----------|------------------------------|---------------|--------|
| **EC2 Pod** | 30-60s | 5s | ç­‰å¾… Endpoints ç§»é™¤ |
| **Fargate Podï¼ˆä¸€èˆ¬ï¼‰** | 60-90s | 10-15s | è¾ƒé•¿çš„ç½‘ç»œä¼ æ’­æ—¶é—´ |
| **Fargate + ALB** | 90-120s | 15-20s | è€ƒè™‘ ALB æ³¨é”€å»¶è¿Ÿ |
| **Fargate é•¿æ—¶é—´è¿è¡Œä»»åŠ¡** | 120-300s | 10s | å…è®¸æ‰¹å¤„ç†ä½œä¸šå®Œæˆ |

**Fargate ä¼˜åŒ–ç¤ºä¾‹ï¼š**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: fargate-web-app
  namespace: fargate-namespace
spec:
  replicas: 3
  selector:
    matchLabels:
      app: web-app
  template:
    metadata:
      labels:
        app: web-app
    spec:
      containers:
      - name: app
        image: myapp:v1
        ports:
        - containerPort: 8080
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          periodSeconds: 5
          failureThreshold: 3
          successThreshold: 1
        lifecycle:
          preStop:
            exec:
              command:
              - /bin/sh
              - -c
              - |
                # Fargate ç½‘ç»œä¼ æ’­å¯èƒ½è¾ƒæ…¢
                echo "PreStop: Waiting for network propagation..."
                sleep 15

                # Readiness å¤±è´¥ä¿¡å·ï¼ˆå¯é€‰ï¼‰
                # curl -X POST http://localhost:8080/shutdown

                echo "PreStop: Graceful shutdown initiated"
      terminationGracePeriodSeconds: 90  # EC2 ä½¿ç”¨ 60sï¼ŒFargate ä½¿ç”¨ 90s
```

#### Fargate vs EC2 vs Auto Mode æ¯”è¾ƒï¼šProbe è§†è§’

| é¡¹ç›® | EC2 Managed Node Group | Fargate | EKS Auto Mode |
|------|------------------------|---------|---------------|
| **èŠ‚ç‚¹ç®¡ç†** | ç”¨æˆ·ç®¡ç† | AWS ç®¡ç† | AWS ç®¡ç† |
| **Pod å¯†åº¦** | é«˜ï¼ˆå¤šä¸ª Pod/èŠ‚ç‚¹ï¼‰ | ä½ï¼ˆ1 Pod = 1 MicroVMï¼‰ | ä¸­ç­‰ï¼ˆAWS ä¼˜åŒ–ï¼‰ |
| **å¯åŠ¨æ—¶é—´** | å¿«ï¼ˆ5-35sï¼‰ | æ…¢ï¼ˆ30-105sï¼‰ | å¿«ï¼ˆ10-40sï¼‰ |
| **Startup Probe failureThreshold** | 6-10 | 15-20 | 8-12 |
| **terminationGracePeriodSeconds** | 30-60s | 60-120s | 30-60s |
| **preStop sleep** | 5s | 10-15s | 5-10s |
| **è‡ªåŠ¨ OS è¡¥ä¸** | æ‰‹åŠ¨ï¼ˆAMI æ›´æ–°ï¼‰ | è‡ªåŠ¨ï¼ˆä¸å¯é¢„æµ‹çš„é©±é€ï¼‰ | è‡ªåŠ¨ï¼ˆè®¡åˆ’æ€§é©±é€ï¼‰ |
| **PDB æ”¯æŒ** | å®Œå…¨æ”¯æŒ | æœ‰é™ï¼ˆå°½åŠ›è€Œä¸ºï¼‰ | å®Œå…¨æ”¯æŒ |
| **DaemonSet æ”¯æŒ** | å®Œå…¨æ”¯æŒ | ä¸æ”¯æŒï¼ˆéœ€è¦ Sidecarï¼‰ | æœ‰é™ï¼ˆAWS ç®¡ç†ï¼‰ |
| **æˆæœ¬æ¨¡å‹** | æŒ‰å®ä¾‹ï¼ˆå§‹ç»ˆè¿è¡Œï¼‰ | æŒ‰ Podï¼ˆä»…è¿è¡Œæ—¶ï¼‰ | æŒ‰ Podï¼ˆä¼˜åŒ–ï¼‰ |
| **Spot æ”¯æŒ** | å®Œå…¨æ”¯æŒï¼ˆTermination Handlerï¼‰ | Fargate Spot æœ‰é™ | è‡ªåŠ¨ä¼˜åŒ– |
| **ç½‘ç»œç­–ç•¥** | Calico/Cilium æ”¯æŒ | ä»… Security Groups for Pods | AWS ç®¡ç†çš„ç½‘ç»œç­–ç•¥ |

**é€‰æ‹©æŒ‡å—ï¼š**

```mermaid
flowchart TD
    Start[åˆ†æå·¥ä½œè´Ÿè½½ç‰¹å¾]

    Start --> Q1{å®Œå…¨å§”æ‰˜<br/>èŠ‚ç‚¹ç®¡ç†ï¼Ÿ}
    Q1 -->|æ˜¯| Q2{æ‰¹å¤„ç†æˆ–<br/>çªå‘å·¥ä½œè´Ÿè½½ï¼Ÿ}
    Q1 -->|å¦| EC2[EC2 Managed<br/>Node Group]

    Q2 -->|æ˜¯| Fargate[Fargate]
    Q2 -->|å¦| Q3{éœ€è¦æœ€æ–° EKS<br/>åŠŸèƒ½ï¼Ÿ}

    Q3 -->|æ˜¯| AutoMode[EKS Auto Mode]
    Q3 -->|å¦| Fargate

    EC2 --> EC2Details[<b>EC2 ç‰¹å¾</b><br/>âœ“ å®Œå…¨æ§åˆ¶<br/>âœ“ DaemonSet æ”¯æŒ<br/>âœ“ æœ€ä½å»¶è¿Ÿ<br/>âœ— è¿ç»´å¼€é”€]

    Fargate --> FargateDetails[<b>Fargate ç‰¹å¾</b><br/>âœ“ æ— éœ€èŠ‚ç‚¹ç®¡ç†<br/>âœ“ éš”ç¦»å®‰å…¨<br/>âœ— å¯åŠ¨æ—¶é—´é•¿<br/>âœ— ä¸æ”¯æŒ DaemonSet]

    AutoMode --> AutoDetails[<b>Auto Mode ç‰¹å¾</b><br/>âœ“ è‡ªåŠ¨ä¼˜åŒ–<br/>âœ“ EC2 çµæ´»æ€§<br/>âœ“ å¯é¢„æµ‹çš„è¡¥ä¸<br/>â—‹ Beta/GA è¿‡æ¸¡]

    style Start fill:#4286f4,stroke:#2a6acf,color:#fff
    style EC2 fill:#ff9900,stroke:#cc7a00,color:#fff
    style Fargate fill:#9b59b6,stroke:#7d3c98,color:#fff
    style AutoMode fill:#34a853,stroke:#2a8642,color:#fff
```

:::tip Fargate ç”Ÿäº§æ£€æŸ¥æ¸…å•
- [ ] **å‰¯æœ¬æ•°**: è‡³å°‘ 3 ä¸ªï¼ˆåº”å¯¹è‡ªåŠ¨é©±é€ï¼‰
- [ ] **Startup Probe**: å°† failureThreshold è®¾ç½®ä¸º 15-20ï¼ˆè€ƒè™‘è¾ƒé•¿çš„å¯åŠ¨æ—¶é—´ï¼‰
- [ ] **terminationGracePeriodSeconds**: è®¾ç½®ä¸º 60-120 ç§’
- [ ] **preStop sleep**: è®¾ç½®ä¸º 10-15 ç§’ï¼ˆç­‰å¾…ç½‘ç»œä¼ æ’­ï¼‰
- [ ] **PDB**: é…ç½® minAvailableï¼ˆå°½åŠ›è€Œä¸ºä½†æ¨èï¼‰
- [ ] **é•œåƒä¼˜åŒ–**: ä½¿ç”¨ ECRï¼Œæœ€å°åŒ–å±‚æ•°
- [ ] **æ—¥å¿—**: FireLens Sidecar æˆ– CloudWatch Logs é›†æˆ
- [ ] **ç›‘æ§**: å¯ç”¨ CloudWatch Container Insights
- [ ] **æˆæœ¬ä¼˜åŒ–**: è€ƒè™‘ Fargate Spotï¼ˆé€‚ç”¨äºå®¹é”™å·¥ä½œè´Ÿè½½ï¼‰
:::

:::info å‚è€ƒèµ„æ–™
- [AWS Fargate on EKS å®˜æ–¹æ–‡æ¡£](https://docs.aws.amazon.com/eks/latest/userguide/fargate.html)
- [Fargate Pod è¡¥ä¸å’Œå®‰å…¨æ›´æ–°](https://docs.aws.amazon.com/eks/latest/userguide/fargate-pod-patching.html)
- [EKS Auto Mode æ¦‚è¿°](https://aws.amazon.com/blogs/aws/streamline-kubernetes-cluster-management-with-new-amazon-eks-auto-mode/)
- [Fargate vs EC2 æ¯”è¾ƒæŒ‡å—](https://aws.amazon.com/blogs/containers/)
:::

---


## 4. Init Container æœ€ä½³å®è·µ

Init Container åœ¨ä¸»å®¹å™¨å¯åŠ¨ä¹‹å‰è¿è¡Œï¼Œæ‰§è¡Œåˆå§‹åŒ–ä»»åŠ¡ã€‚

### 4.1 Init Container å·¥ä½œåŸç†

- Init Container **æŒ‰é¡ºåº**æ‰§è¡Œï¼ˆä¸æ”¯æŒå¹¶å‘æ‰§è¡Œï¼‰
- æ¯ä¸ª Init Container å¿…é¡»æˆåŠŸé€€å‡ºåï¼Œä¸‹ä¸€ä¸ª Init Container æ‰ä¼šå¯åŠ¨
- æ‰€æœ‰ Init Container å¿…é¡»å®Œæˆåï¼Œä¸»å®¹å™¨æ‰ä¼šå¯åŠ¨
- å¦‚æœ Init Container å¤±è´¥ï¼Œå°†æ ¹æ® Pod çš„ `restartPolicy` é‡æ–°å¯åŠ¨

```mermaid
flowchart LR
    START[Pod åˆ›å»º] --> INIT1[Init Container 1]
    INIT1 -->|æˆåŠŸ| INIT2[Init Container 2]
    INIT1 -->|å¤±è´¥| RESTART1[é‡å¯]
    RESTART1 --> INIT1

    INIT2 -->|æˆåŠŸ| MAIN[ä¸»å®¹å™¨å¯åŠ¨]
    INIT2 -->|å¤±è´¥| RESTART2[é‡å¯]
    RESTART2 --> INIT1

    MAIN --> RUNNING[Pod Running]

    style INIT1 fill:#fbbc04,stroke:#c99603,color:#000
    style INIT2 fill:#fbbc04,stroke:#c99603,color:#000
    style MAIN fill:#34a853,stroke:#2a8642,color:#fff
```

### 4.2 Init Container ä½¿ç”¨åœºæ™¯

#### åœºæ™¯ 1ï¼šæ•°æ®åº“è¿ç§»

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-app
spec:
  replicas: 3
  template:
    spec:
      # Init Container: æ•°æ®åº“è¿ç§»
      initContainers:
      - name: db-migration
        image: myapp/migrator:v1
        command:
        - /bin/sh
        - -c
        - |
          echo "Running database migrations..."
          /app/migrate up
          echo "Migrations completed"
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: url
      # ä¸»åº”ç”¨ç¨‹åº
      containers:
      - name: app
        image: myapp/web-app:v1
        ports:
        - containerPort: 8080
```

#### åœºæ™¯ 2ï¼šé…ç½®æ–‡ä»¶ç”Ÿæˆï¼ˆConfigMap è½¬æ¢ï¼‰

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config-template
data:
  config.template: |
    server:
      port: {{ PORT }}
      host: {{ HOST }}
    database:
      url: {{ DB_URL }}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-with-config
spec:
  template:
    spec:
      initContainers:
      - name: config-generator
        image: busybox
        command:
        - /bin/sh
        - -c
        - |
          # ä»æ¨¡æ¿ç”Ÿæˆå®é™…é…ç½®æ–‡ä»¶
          sed -e "s/{{ PORT }}/$PORT/g" \
              -e "s/{{ HOST }}/$HOST/g" \
              -e "s|{{ DB_URL }}|$DB_URL|g" \
              /config-template/config.template > /config/config.yaml
          echo "Config file generated"
          cat /config/config.yaml
        env:
        - name: PORT
          value: "8080"
        - name: HOST
          value: "0.0.0.0"
        - name: DB_URL
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: url
        volumeMounts:
        - name: config-template
          mountPath: /config-template
        - name: config
          mountPath: /config
      containers:
      - name: app
        image: myapp/app:v1
        volumeMounts:
        - name: config
          mountPath: /app/config
      volumes:
      - name: config-template
        configMap:
          name: app-config-template
      - name: config
        emptyDir: {}
```

#### åœºæ™¯ 3ï¼šç­‰å¾…ä¾èµ–æœåŠ¡å°±ç»ª

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend-api
spec:
  template:
    spec:
      initContainers:
      # Init Container 1: ç­‰å¾…æ•°æ®åº“è¿æ¥
      - name: wait-for-db
        image: busybox
        command:
        - /bin/sh
        - -c
        - |
          echo "Waiting for database..."
          until nc -z postgres-service 5432; do
            echo "Database not ready, sleeping..."
            sleep 2
          done
          echo "Database is ready"
      # Init Container 2: ç­‰å¾… Redis è¿æ¥
      - name: wait-for-redis
        image: busybox
        command:
        - /bin/sh
        - -c
        - |
          echo "Waiting for Redis..."
          until nc -z redis-service 6379; do
            echo "Redis not ready, sleeping..."
            sleep 2
          done
          echo "Redis is ready"
      containers:
      - name: api
        image: myapp/backend-api:v1
        ports:
        - containerPort: 8080
```

:::tip æ›´å¥½çš„æ›¿ä»£æ–¹æ¡ˆï¼šreadinessProbe
ç­‰å¾…ä¾èµ–æœåŠ¡å°±ç»ªé€šè¿‡ä¸»å®¹å™¨çš„ Readiness Probe å¤„ç†æ¯”ä½¿ç”¨ Init Container æ›´åŠ çµæ´»ã€‚ç”±äº Init Container åªè¿è¡Œä¸€æ¬¡ï¼Œå¦‚æœä¸»å®¹å™¨è¿è¡ŒæœŸé—´ä¾èµ–æœåŠ¡å®•æœºï¼Œå®ƒæ— æ³•åšå‡ºå“åº”ã€‚
:::

#### åœºæ™¯ 4ï¼šVolume æƒé™è®¾ç½®

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-with-volume
spec:
  template:
    spec:
      securityContext:
        fsGroup: 1000
      initContainers:
      - name: volume-permissions
        image: busybox
        command:
        - /bin/sh
        - -c
        - |
          echo "Setting up volume permissions..."
          chown -R 1000:1000 /data
          chmod -R 755 /data
          echo "Permissions set"
        volumeMounts:
        - name: data
          mountPath: /data
        securityContext:
          runAsUser: 0  # ä»¥ root è¿è¡Œï¼ˆç”¨äºæƒé™å˜æ›´ï¼‰
      containers:
      - name: app
        image: myapp/app:v1
        securityContext:
          runAsUser: 1000
          runAsNonRoot: true
        volumeMounts:
        - name: data
          mountPath: /app/data
      volumes:
      - name: data
        persistentVolumeClaim:
          claimName: app-data-pvc
```

### 4.3 Init Container ä¸ Sidecar Container å¯¹æ¯”ï¼ˆKubernetes 1.29+ï¼‰

Kubernetes 1.29+ å¼•å…¥äº†åŸç”Ÿ Sidecar Containerã€‚

| ç‰¹æ€§ | Init Container | Sidecar Container (1.29+) |
|------|---------------|---------------------------|
| **æ‰§è¡Œæ—¶æœº** | åœ¨ä¸»å®¹å™¨ä¹‹å‰æŒ‰é¡ºåºæ‰§è¡Œ | ä¸ä¸»å®¹å™¨å¹¶å‘æ‰§è¡Œ |
| **ç”Ÿå‘½å‘¨æœŸ** | å®Œæˆåé€€å‡º | ä¸ä¸»å®¹å™¨ä¸€èµ·è¿è¡Œ |
| **é‡å¯** | å¤±è´¥æ—¶æ•´ä¸ª Pod é‡å¯ | å¯å•ç‹¬é‡å¯ |
| **ä½¿ç”¨åœºæ™¯** | ä¸€æ¬¡æ€§åˆå§‹åŒ–ä»»åŠ¡ | æŒç»­æ€§è¾…åŠ©ä»»åŠ¡ï¼ˆæ—¥å¿—æ”¶é›†ã€ä»£ç†ç­‰ï¼‰ |

**Sidecar Container ç¤ºä¾‹ï¼ˆK8s 1.29+ï¼‰ï¼š**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: app-with-sidecar
spec:
  initContainers:
  # åŸç”Ÿ sidecarï¼šå°† restartPolicy è®¾ç½®ä¸º Always
  - name: log-collector
    image: fluent/fluent-bit:2.0
    restartPolicy: Always  # ä½œä¸º sidecar è¿è¡Œ
    volumeMounts:
    - name: logs
      mountPath: /var/log/app
  containers:
  - name: app
    image: myapp/app:v1
    volumeMounts:
    - name: logs
      mountPath: /app/logs
  volumes:
  - name: logs
    emptyDir: {}
```

---
## 5. Pod ç”Ÿå‘½å‘¨æœŸ Hook

Lifecycle Hook åœ¨å®¹å™¨ç”Ÿå‘½å‘¨æœŸçš„ç‰¹å®šæ—¶é—´ç‚¹æ‰§è¡Œè‡ªå®šä¹‰é€»è¾‘ã€‚

### 5.1 PostStart Hook

PostStart Hook åœ¨å®¹å™¨åˆ›å»ºåç«‹å³æ‰§è¡Œã€‚

**ç‰¹æ€§ï¼š**
- ä¸å®¹å™¨çš„ ENTRYPOINT **å¼‚æ­¥**è¿è¡Œ
- å¦‚æœ Hook å¤±è´¥ï¼Œå®¹å™¨å°†è¢«ç»ˆæ­¢
- å®¹å™¨ä¸ä¼šç­‰å¾… Hook å®Œæˆå³è¿›å…¥ `Running` çŠ¶æ€

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: poststart-example
spec:
  containers:
  - name: app
    image: nginx
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/sh
          - -c
          - |
            echo "Container started at $(date)" >> /var/log/lifecycle.log
            # åˆå§‹è®¾ç½®ä»»åŠ¡
            mkdir -p /app/cache
            chown -R nginx:nginx /app/cache
```

**ä½¿ç”¨åœºæ™¯ï¼š**
- å‘é€åº”ç”¨å¯åŠ¨é€šçŸ¥
- åˆå§‹ç¼“å­˜é¢„çƒ­
- è®°å½•å…ƒæ•°æ®

:::warning PostStart Hook æ³¨æ„äº‹é¡¹
PostStart Hook ä¸å®¹å™¨å¯åŠ¨**å¼‚æ­¥**è¿è¡Œï¼Œå› æ­¤åº”ç”¨å¯èƒ½åœ¨ Hook å®Œæˆä¹‹å‰å°±å·²å¯åŠ¨ã€‚å¦‚æœåº”ç”¨ä¾èµ–äº Hook çš„å·¥ä½œç»“æœï¼Œè¯·æ”¹ç”¨ Init Containerã€‚
:::

### 5.2 PreStop Hook

PreStop Hook åœ¨å®¹å™¨æ”¶åˆ°ç»ˆæ­¢è¯·æ±‚æ—¶ã€SIGTERM ä¹‹å‰æ‰§è¡Œã€‚

**ç‰¹æ€§ï¼š**
- **åŒæ­¥**è¿è¡Œï¼ˆSIGTERM çš„å‘é€ä¼šè¢«å»¶è¿Ÿï¼Œç›´åˆ° Hook å®Œæˆï¼‰
- Hook æ‰§è¡Œæ—¶é—´è®¡å…¥ `terminationGracePeriodSeconds`
- æ— è®º Hook æˆåŠŸæˆ–å¤±è´¥ï¼Œéƒ½ä¼šå‘é€ SIGTERM

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: prestop-example
spec:
  containers:
  - name: app
    image: myapp/app:v1
    lifecycle:
      preStop:
        exec:
          command:
          - /bin/sh
          - -c
          - |
            # 1. ç­‰å¾… Endpoint ç§»é™¤
            sleep 5

            # 2. ä¿å­˜åº”ç”¨çŠ¶æ€
            curl -X POST http://localhost:8080/admin/save-state

            # 3. åˆ·æ–°æ—¥å¿—
            kill -USR1 1  # å‘åº”ç”¨å‘é€ USR1 ä¿¡å·

            # 4. å‘é€ SIGTERMï¼ˆPID 1ï¼‰
            kill -TERM 1
  terminationGracePeriodSeconds: 60
```

**ä½¿ç”¨åœºæ™¯ï¼š**
- ç­‰å¾… Endpoint ç§»é™¤ï¼ˆé›¶å®•æœºéƒ¨ç½²ï¼‰
- ä¿å­˜è¿›è¡Œä¸­çš„å·¥ä½œçŠ¶æ€
- é€šçŸ¥å¤–éƒ¨ç³»ç»Ÿå…³é—­
- åˆ·æ–°æ—¥å¿—ç¼“å†²åŒº

### 5.3 Hook æ‰§è¡Œæœºåˆ¶

Kubernetes é€šè¿‡ä¸¤ç§æœºåˆ¶æ‰§è¡Œ Hookã€‚

| æœºåˆ¶ | è¯´æ˜ | ä¼˜ç‚¹ | ç¼ºç‚¹ |
|------|------|------|------|
| **exec** | åœ¨å®¹å™¨å†…éƒ¨æ‰§è¡Œå‘½ä»¤ | å¯è®¿é—®å®¹å™¨æ–‡ä»¶ç³»ç»Ÿ | å¼€é”€è¾ƒå¤§ |
| **httpGet** | å‘é€ HTTP GET è¯·æ±‚ | åŸºäºç½‘ç»œï¼Œè½»é‡çº§ | åº”ç”¨å¿…é¡»æ”¯æŒ HTTP |

#### exec Hook ç¤ºä¾‹

```yaml
lifecycle:
  preStop:
    exec:
      command:
      - /bin/bash
      - -c
      - |
        echo "Shutting down" | tee /var/log/shutdown.log
        /app/cleanup.sh
```

#### httpGet Hook ç¤ºä¾‹

```yaml
lifecycle:
  preStop:
    httpGet:
      path: /shutdown
      port: 8080
      scheme: HTTP
      httpHeaders:
      - name: X-Shutdown-Token
        value: "secret-token"
```

:::warning Hook æ‰§è¡Œä¸º"è‡³å°‘ä¸€æ¬¡"
Kubernetes ä¿è¯ Hook è‡³å°‘æ‰§è¡Œä¸€æ¬¡ï¼Œä½†å¯èƒ½ä¼šæ‰§è¡Œå¤šæ¬¡ã€‚Hook é€»è¾‘å¿…é¡»æ˜¯**å¹‚ç­‰**çš„ã€‚
:::

---

## 6. å®¹å™¨é•œåƒä¼˜åŒ–ä¸å¯åŠ¨æ—¶é—´

å®¹å™¨é•œåƒçš„å¤§å°å’Œç»“æ„ç›´æ¥å½±å“ Pod å¯åŠ¨æ—¶é—´ã€‚

### 6.1 Multi-Stage Build

ä½¿ç”¨ Multi-Stage Build æœ€å°åŒ–æœ€ç»ˆé•œåƒå¤§å°ã€‚

#### Go åº”ç”¨

```dockerfile
# æ„å»ºé˜¶æ®µ
FROM golang:1.22-alpine AS builder

WORKDIR /app
COPY go.mod go.sum ./
RUN go mod download

COPY . .
RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -ldflags="-s -w" -o main .

# è¿è¡Œæ—¶é˜¶æ®µï¼ˆscratchï¼šå°äº 5MBï¼‰
FROM scratch

COPY --from=builder /app/main /main
COPY --from=builder /etc/ssl/certs/ca-certificates.crt /etc/ssl/certs/

USER 65534:65534
ENTRYPOINT ["/main"]
```

**æ•ˆæœï¼š**
- æ„å»ºé•œåƒï¼š300MB+
- æœ€ç»ˆé•œåƒï¼š5-10MB
- å¯åŠ¨æ—¶é—´ï¼š1 ç§’ä»¥å†…

#### Node.js åº”ç”¨

```dockerfile
# æ„å»ºé˜¶æ®µ
FROM node:20-alpine AS builder

WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production

COPY . .

# è¿è¡Œæ—¶é˜¶æ®µ
FROM node:20-alpine

# å®‰å…¨ï¼šé root ç”¨æˆ·
RUN addgroup -g 1001 -S nodejs && \
    adduser -S nodejs -u 1001

WORKDIR /app

# ä»…å¤åˆ¶ç”Ÿäº§ä¾èµ–
COPY --from=builder --chown=nodejs:nodejs /app/node_modules ./node_modules
COPY --chown=nodejs:nodejs . .

USER nodejs

EXPOSE 8080
CMD ["node", "server.js"]
```

**ä¼˜åŒ–å»ºè®®ï¼š**
- ä½¿ç”¨ `npm ci`ï¼ˆæ¯” npm install æ›´å¿«æ›´å¯é ï¼‰
- ä½¿ç”¨ `--only=production` æ’é™¤ devDependencies
- åˆ©ç”¨å±‚ç¼“å­˜ï¼ˆå…ˆ COPY package*.jsonï¼‰

#### Java/Spring Boot åº”ç”¨

```dockerfile
# æ„å»ºé˜¶æ®µ
FROM maven:3.9-eclipse-temurin-21 AS builder

WORKDIR /app
COPY pom.xml .
RUN mvn dependency:go-offline

COPY src ./src
RUN mvn clean package -DskipTests

# è¿è¡Œæ—¶é˜¶æ®µ
FROM eclipse-temurin:21-jre-alpine

RUN addgroup -S spring && adduser -S spring -G spring
USER spring:spring

WORKDIR /app
COPY --from=builder /app/target/*.jar app.jar

EXPOSE 8080
ENTRYPOINT ["java", "-Xms512m", "-Xmx1g", "-jar", "app.jar"]
```

### 6.2 é•œåƒé¢„æ‹‰å–ç­–ç•¥

åœ¨ EKS ä¸­åˆ©ç”¨é•œåƒé¢„æ‹‰å–æ¥ç¼©çŸ­ Pod å¯åŠ¨æ—¶é—´ã€‚

#### Karpenter é•œåƒé¢„æ‹‰å–

```yaml
apiVersion: karpenter.k8s.aws/v1beta1
kind: EC2NodeClass
metadata:
  name: default
spec:
  amiFamily: AL2
  userData: |
    #!/bin/bash
    # é¢„æ‹‰å–å¸¸ç”¨é•œåƒ
    docker pull myapp/backend:v2.1.0
    docker pull myapp/frontend:v1.5.3
    docker pull redis:7-alpine
    docker pull postgres:16-alpine
```

#### ä½¿ç”¨ DaemonSet é¢„æ‹‰å–é•œåƒ

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: image-prepuller
  namespace: kube-system
spec:
  selector:
    matchLabels:
      app: image-prepuller
  template:
    metadata:
      labels:
        app: image-prepuller
    spec:
      initContainers:
      # ä¸ºæ¯ä¸ªéœ€è¦é¢„æ‹‰å–çš„é•œåƒæ·»åŠ ä¸€ä¸ª init container
      - name: prepull-backend
        image: myapp/backend:v2.1.0
        command: ["sh", "-c", "echo 'Image pulled'"]
      - name: prepull-frontend
        image: myapp/frontend:v1.5.3
        command: ["sh", "-c", "echo 'Image pulled'"]
      containers:
      - name: pause
        image: registry.k8s.io/pause:3.9
        resources:
          requests:
            cpu: 1m
            memory: 1Mi
```

### 6.3 Distroless å’Œ Scratch é•œåƒ

Google çš„ Distroless é•œåƒä»…åŒ…å«è¿è¡Œåº”ç”¨æ‰€éœ€çš„æœ€å°‘æ–‡ä»¶ã€‚

#### Distroless ç¤ºä¾‹

```dockerfile
FROM golang:1.22-alpine AS builder
WORKDIR /app
COPY . .
RUN CGO_ENABLED=0 go build -o main .

# distroless åŸºç¡€é•œåƒ
FROM gcr.io/distroless/static-debian12

COPY --from=builder /app/main /main
USER 65534:65534
ENTRYPOINT ["/main"]
```

**Distroless ä¼˜åŠ¿ï¼š**
- æœ€å°æ”»å‡»é¢ï¼ˆæ—  shellã€æ— åŒ…ç®¡ç†å™¨ï¼‰
- é•œåƒä½“ç§¯å°
- å‡å°‘ CVE æ¼æ´

**scratch ä¸ distroless å¯¹æ¯”ï¼š**

| é•œåƒ | å¤§å° | åŒ…å«å†…å®¹ | æœ€é€‚åˆ |
|------|------|---------|--------|
| **scratch** | 0MB | ç©ºæ–‡ä»¶ç³»ç»Ÿ | å®Œå…¨é™æ€é“¾æ¥çš„äºŒè¿›åˆ¶æ–‡ä»¶ï¼ˆGoã€Rustï¼‰ |
| **distroless/static** | ~2MB | CA è¯ä¹¦ã€tzdata | éœ€è¦ TLS/æ—¶åŒºçš„é™æ€äºŒè¿›åˆ¶æ–‡ä»¶ |
| **distroless/base** | ~20MB | glibcã€libssl | åŠ¨æ€é“¾æ¥çš„äºŒè¿›åˆ¶æ–‡ä»¶ |

### 6.4 å¯åŠ¨æ—¶é—´åŸºå‡†æµ‹è¯•

å„ç§é•œåƒç­–ç•¥çš„å¯åŠ¨æ—¶é—´å¯¹æ¯”ï¼ˆEKS 1.30ï¼Œm6i.xlargeï¼‰ï¼š

| åº”ç”¨ | åŸºç¡€é•œåƒ | é•œåƒå¤§å° | æ‹‰å–æ—¶é—´ | å¯åŠ¨æ—¶é—´ | æ€»æ—¶é—´ |
|------|---------|---------|---------|---------|--------|
| Go API | ubuntu:22.04 | 150MB | 8s | 0.5s | **8.5s** |
| Go API | alpine:3.19 | 15MB | 2s | 0.5s | **2.5s** |
| Go API | distroless/static | 5MB | 1s | 0.5s | **1.5s** |
| Go API | scratch | 3MB | 0.8s | 0.5s | **1.3s** |
| Node.js API | node:20 | 350MB | 15s | 2s | **17s** |
| Node.js API | node:20-alpine | 120MB | 6s | 2s | **8s** |
| Spring Boot | eclipse-temurin:21 | 450MB | 20s | 15s | **35s** |
| Spring Boot | eclipse-temurin:21-jre-alpine | 180MB | 10s | 15s | **25s** |
| Python Flask | python:3.12 | 400MB | 18s | 3s | **21s** |
| Python Flask | python:3.12-slim | 130MB | 7s | 3s | **10s** |
| Python Flask | python:3.12-alpine | 50MB | 3s | 3s | **6s** |

**ä¼˜åŒ–å»ºè®®ï¼š**
1. ä½¿ç”¨ **Multi-Stage Build** â€” å‡å°‘ 50-90% çš„é•œåƒå¤§å°
2. é€‰æ‹© **alpine æˆ– distroless** â€” å‡å°‘ 50-80% çš„æ‹‰å–æ—¶é—´
3. å¯ç”¨**é•œåƒç¼“å­˜** â€” é‡æ–°éƒ¨ç½²æ—¶æ‹‰å–æ—¶é—´æ¥è¿‘é›¶
4. é…ç½® **Startup Probe** â€” ä¿æŠ¤å¯åŠ¨ç¼“æ…¢çš„åº”ç”¨


## 7. ç»¼åˆæ£€æŸ¥æ¸…å•ä¸å‚è€ƒèµ„æ–™

### 7.1 ç”Ÿäº§éƒ¨ç½²å‰æ£€æŸ¥æ¸…å•

#### Pod å¥åº·æ£€æŸ¥

| é¡¹ç›® | éªŒè¯å†…å®¹ | ä¼˜å…ˆçº§ |
|------|---------|--------|
| **Startup Probe** | ä¸ºå¯åŠ¨ç¼“æ…¢çš„åº”ç”¨ï¼ˆ30 ç§’ä»¥ä¸Šï¼‰é…ç½® Startup Probe | é«˜ |
| **Liveness Probe** | æ’é™¤å¤–éƒ¨ä¾èµ–ï¼Œä»…æ£€æŸ¥å†…éƒ¨çŠ¶æ€ | å¿…é¡» |
| **Readiness Probe** | åŒ…å«å¤–éƒ¨ä¾èµ–ï¼ŒéªŒè¯æµé‡å°±ç»ªçŠ¶æ€ | å¿…é¡» |
| **Probe æ—¶åº** | éªŒè¯ failureThreshold x periodSeconds æ˜¯å¦åˆé€‚ | ä¸­ |
| **Probe è·¯å¾„** | åˆ†ç¦» `/healthz`ï¼ˆlivenessï¼‰å’Œ `/ready`ï¼ˆreadinessï¼‰ | é«˜ |
| **ALB Health Check** | ç¡®è®¤è·¯å¾„ä¸ Readiness Probe ä¸€è‡´ | é«˜ |
| **Pod Readiness Gates** | ä½¿ç”¨ ALB/NLB æ—¶å¯ç”¨ | ä¸­ |

#### ä¼˜é›…å…³é—­

| é¡¹ç›® | éªŒè¯å†…å®¹ | ä¼˜å…ˆçº§ |
|------|---------|--------|
| **preStop Hook** | æ·»åŠ  `sleep 5` ç­‰å¾… Endpoint ç§»é™¤ | å¿…é¡» |
| **SIGTERM å¤„ç†** | åœ¨åº”ç”¨ä¸­å®ç° SIGTERM å¤„ç†ç¨‹åº | å¿…é¡» |
| **terminationGracePeriodSeconds** | è€ƒè™‘ preStop + å…³é—­æ—¶é—´è¿›è¡Œè®¾ç½®ï¼ˆ30-120 ç§’ï¼‰ | å¿…é¡» |
| **Connection Draining** | HTTP Keep-Aliveã€WebSocket è¿æ¥æ¸…ç†é€»è¾‘ | é«˜ |
| **æ•°æ®æ¸…ç†** | æ¸…ç†æ•°æ®åº“è¿æ¥ã€æ¶ˆæ¯é˜Ÿåˆ—ã€æ–‡ä»¶å¥æŸ„ | é«˜ |
| **Readiness å¤±è´¥** | å…³é—­å¼€å§‹æ—¶è¿”å› Readiness Probe å¤±è´¥ | ä¸­ |

#### èµ„æºä¸é•œåƒ

| é¡¹ç›® | éªŒè¯å†…å®¹ | ä¼˜å…ˆçº§ |
|------|---------|--------|
| **Resource requests/limits** | è®¾ç½® CPU/å†…å­˜ requestsï¼ˆHPAã€VPA çš„åŸºç¡€ï¼‰ | å¿…é¡» |
| **é•œåƒå¤§å°** | é€šè¿‡ Multi-Stage Build æœ€å°åŒ–ï¼ˆç›®æ ‡ 100MB ä»¥ä¸‹ï¼‰ | ä¸­ |
| **é•œåƒæ ‡ç­¾** | ä¸ä½¿ç”¨ `latest` æ ‡ç­¾ï¼Œä½¿ç”¨è¯­ä¹‰åŒ–ç‰ˆæœ¬å· | å¿…é¡» |
| **å®‰å…¨æ‰«æ** | ä½¿ç”¨ Trivyã€Grype è¿›è¡Œ CVE æ‰«æ | é«˜ |
| **é root ç”¨æˆ·** | ä»¥é root ç”¨æˆ·è¿è¡Œå®¹å™¨ | é«˜ |

#### é«˜å¯ç”¨æ€§

| é¡¹ç›® | éªŒè¯å†…å®¹ | ä¼˜å…ˆçº§ |
|------|---------|--------|
| **PodDisruptionBudget** | é…ç½® minAvailable æˆ– maxUnavailable | å¿…é¡» |
| **Topology Spread** | é…ç½® Multi-AZ åˆ†å¸ƒ | é«˜ |
| **å‰¯æœ¬æ•°é‡** | æœ€å°‘ 2 ä¸ªï¼ˆç”Ÿäº§ç¯å¢ƒ 3 ä¸ªä»¥ä¸Šï¼‰ | å¿…é¡» |
| **Affinity/Anti-Affinity** | é˜²æ­¢åœ¨åŒä¸€èŠ‚ç‚¹ä¸Šå…±ç½® | ä¸­ |

### 7.2 ç›¸å…³æ–‡æ¡£

- [EKS æ•…éšœæ’é™¤ä¸äº‹ä»¶å“åº”æŒ‡å—](/docs/operations-observability/eks-debugging-guide) â€” Probe è°ƒè¯•ã€Pod æ•…éšœæ’é™¤
- [EKS é«˜å¯ç”¨æ¶æ„æŒ‡å—](/docs/operations-observability/eks-resiliency-guide) â€” PDBã€ä¼˜é›…å…³é—­ã€Pod Readiness Gates
- [Karpenter è¶…é«˜é€Ÿè‡ªåŠ¨æ‰©ç¼©å®¹](/docs/infrastructure-optimization/karpenter-autoscaling) â€” Karpenter Disruptionã€Spot å®ä¾‹ç®¡ç†

### 7.3 å¤–éƒ¨å‚è€ƒèµ„æ–™

#### Kubernetes å®˜æ–¹æ–‡æ¡£

- [Configure Liveness, Readiness and Startup Probes](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/)
- [Pod Lifecycle](https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/)
- [Init Containers](https://kubernetes.io/docs/concepts/workloads/pods/init-containers/)
- [Container Lifecycle Hooks](https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/)
- [Termination of Pods](https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#pod-termination)

#### AWS å®˜æ–¹æ–‡æ¡£

- [EKS Best Practices - Application Health Checks](https://docs.aws.amazon.com/eks/latest/best-practices/reliability.html)
- [AWS Load Balancer Controller - Pod Readiness Gate](https://kubernetes-sigs.github.io/aws-load-balancer-controller/v2.7/deploy/pod_readiness_gate/)
- [EKS Workshop - Health Checks](https://www.eksworkshop.com/docs/fundamentals/managed-node-groups/health-checks/)

#### Red Hat OpenShift æ–‡æ¡£

- [Monitoring Application Health by Using Health Checks](https://docs.openshift.com/container-platform/4.18/applications/application-health.html) â€” Livenessã€Readinessã€Startup Probe é…ç½®
- [Using Init Containers](https://docs.openshift.com/container-platform/4.18/nodes/containers/nodes-containers-init.html) â€” Init Container æ¨¡å¼ä¸æ“ä½œ
- [Graceful Cluster Shutdown](https://docs.openshift.com/container-platform/4.18/backup_and_restore/graceful-cluster-shutdown.html) â€” ä¼˜é›…å…³é—­æµç¨‹

#### å…¶ä»–å‚è€ƒèµ„æ–™

- [gRPC Health Checking Protocol](https://github.com/grpc/grpc/blob/master/doc/health-checking.md)
- [Google Distroless Images](https://github.com/GoogleContainerTools/distroless)
- [AWS Prescriptive Guidance - Container Image Optimization](https://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/optimize-docker-images-for-eks.html)
- [Learnk8s - Graceful Shutdown](https://learnk8s.io/graceful-shutdown)

### 7.4 EKS Auto Mode ç¯å¢ƒæ£€æŸ¥æ¸…å•

EKS Auto Mode è‡ªåŠ¨åŒ– Kubernetes è¿ç»´ä»¥å‡å°‘åŸºç¡€è®¾æ–½ç®¡ç†å¼€é”€ã€‚ä½†æ˜¯ï¼Œåœ¨ Probe é…ç½®å’Œ Pod ç”Ÿå‘½å‘¨æœŸç®¡ç†æ–¹é¢æœ‰ Auto Mode ç‰¹å®šçš„æ³¨æ„äº‹é¡¹ã€‚

#### ä»€ä¹ˆæ˜¯ EKS Auto Modeï¼Ÿ

EKS Auto Modeï¼ˆ2024 å¹´ 12 æœˆå‘å¸ƒï¼ŒæŒç»­æ”¹è¿›ä¸­ï¼‰è‡ªåŠ¨åŒ–ä»¥ä¸‹å†…å®¹ï¼š
- è®¡ç®—å®ä¾‹é€‰æ‹©ä¸é…ç½®
- åŠ¨æ€èµ„æºæ‰©ç¼©å®¹
- æ“ä½œç³»ç»Ÿè¡¥ä¸å’Œå®‰å…¨æ›´æ–°
- æ ¸å¿ƒæ’ä»¶ç®¡ç†ï¼ˆVPC CNIã€CoreDNSã€kube-proxy ç­‰ï¼‰
- Graviton + Spot ä¼˜åŒ–

#### Auto Mode ç‰¹æ€§å¯¹ Probe çš„å½±å“

| é¡¹ç›® | Auto Mode | æ‰‹åŠ¨ç®¡ç† | Probe é…ç½®å»ºè®® |
|------|----------|---------|---------------|
| **èŠ‚ç‚¹æ›¿æ¢é¢‘ç‡** | é¢‘ç¹ï¼ˆæ“ä½œç³»ç»Ÿè¡¥ä¸ã€ä¼˜åŒ–ï¼‰ | ä»…åœ¨æ˜¾å¼å‡çº§æ—¶ | `terminationGracePeriodSeconds`ï¼š90 ç§’ä»¥ä¸Š |
| **èŠ‚ç‚¹å¤šæ ·æ€§** | è‡ªåŠ¨å®ä¾‹é€‰æ‹©ï¼ˆå¤šç§ç±»å‹ï¼‰ | å›ºå®šç±»å‹ | å°† `startupProbe` failureThreshold è®¾ç½®è¾ƒé«˜ï¼ˆä¸åŒå®ä¾‹ç±»å‹å¯åŠ¨æ—¶é—´ä¸åŒï¼‰ |
| **Spot é›†æˆ** | è‡ªåŠ¨ Spot/On-Demand æ··åˆ | æ‰‹åŠ¨é…ç½® | `preStop` sleep å¯¹äº Spot ä¸­æ–­å¤„ç†æ˜¯å¿…é¡»çš„ |
| **ç½‘ç»œä¼˜åŒ–** | è‡ªåŠ¨ VPC CNI è°ƒä¼˜ | æ‰‹åŠ¨é…ç½® | å»ºè®®å¯ç”¨ Container Network Observability |

#### Auto Mode ç¯å¢ƒ Probe æ£€æŸ¥æ¸…å•

| é¡¹ç›® | éªŒè¯å†…å®¹ | ä¼˜å…ˆçº§ | Auto Mode ç‰¹æœ‰äº‹é¡¹ |
|------|---------|--------|-------------------|
| **Startup Probe failureThreshold** | è®¾ç½®ä¸º 30 æˆ–æ›´é«˜ï¼ˆè€ƒè™‘å®ä¾‹å¤šæ ·æ€§ï¼‰ | é«˜ | Auto Mode è‡ªåŠ¨é€‰æ‹©å®ä¾‹ç±»å‹ï¼Œå¯åŠ¨æ—¶é—´å·®å¼‚æ˜¾è‘— |
| **terminationGracePeriodSeconds** | 90 ç§’ä»¥ä¸Šï¼ˆåº”å¯¹é¢‘ç¹çš„èŠ‚ç‚¹æ›¿æ¢ï¼‰ | å¿…é¡» | æ“ä½œç³»ç»Ÿè¡¥ä¸æœŸé—´è‡ªåŠ¨é©±é€é¢‘ç‡æ›´é«˜ |
| **readinessProbe periodSeconds** | 5 ç§’ï¼ˆå¿«é€Ÿæµé‡åˆ‡æ¢ï¼‰ | é«˜ | èŠ‚ç‚¹æ›¿æ¢æœŸé—´éœ€è¦å¿«é€Ÿçš„ Pod Ready çŠ¶æ€è½¬æ¢ |
| **Container Network Observability** | å¯ç”¨ï¼ˆæ—©æœŸæ£€æµ‹ç½‘ç»œå¼‚å¸¸ï¼‰ | ä¸­ | éªŒè¯ VPC CNI è‡ªåŠ¨è°ƒä¼˜æ•ˆæœ |
| **PodDisruptionBudget** | å¿…é¡»é…ç½®ï¼ˆç¡®ä¿èŠ‚ç‚¹æ›¿æ¢æœŸé—´çš„å¯ç”¨æ€§ï¼‰ | å¿…é¡» | Auto Mode èŠ‚ç‚¹æ›¿æ¢æœŸé—´éµå®ˆ PDB |
| **Topology Spread Constraints** | æ˜ç¡®æŒ‡å®šèŠ‚ç‚¹/AZ åˆ†å¸ƒ | é«˜ | Auto Mode é€‰æ‹©å®ä¾‹ä½†åˆ†å¸ƒæ˜¯ç”¨æˆ·çš„è´£ä»» |

#### Probe é…ç½®å·®å¼‚ï¼šAuto Mode ä¸æ‰‹åŠ¨ç®¡ç†

**æ‰‹åŠ¨ç®¡ç†é›†ç¾¤ï¼š**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-manual-cluster
spec:
  replicas: 3
  template:
    spec:
      nodeSelector:
        node.kubernetes.io/instance-type: m5.xlarge  # å›ºå®šç±»å‹
      containers:
      - name: api
        image: myapp/api:v1
        # å›ºå®šå®ä¾‹ç±»å‹ï¼Œå¯åŠ¨æ—¶é—´å¯é¢„æµ‹
        startupProbe:
          httpGet:
            path: /healthz
            port: 8080
          failureThreshold: 10  # å¯ä»¥è®¾ç½®è¾ƒä½
          periodSeconds: 5
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          periodSeconds: 5
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh", "-c", "sleep 5"]
      terminationGracePeriodSeconds: 60  # æ ‡å‡†è®¾ç½®
```

**Auto Mode é›†ç¾¤ï¼š**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-auto-mode
  annotations:
    # Auto Mode ä¼˜åŒ–æç¤º
    eks.amazonaws.com/compute-type: "auto"
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: api
        # Auto Mode è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜å®ä¾‹
    spec:
      # ä¸è®¾ç½® nodeSelector - Auto Mode è‡ªåŠ¨é€‰æ‹©
      topologySpreadConstraints:
      - maxSkew: 1
        topologyKey: topology.kubernetes.io/zone
        whenUnsatisfiable: DoNotSchedule
        labelSelector:
          matchLabels:
            app: api
      containers:
      - name: api
        image: myapp/api:v1
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          # Auto Mode é€‰æ‹©æœ€ä¼˜å®ä¾‹
        # è€ƒè™‘å®ä¾‹å¤šæ ·æ€§ï¼Œå»¶é•¿å¯åŠ¨æ—¶é—´
        startupProbe:
          httpGet:
            path: /healthz
            port: 8080
          failureThreshold: 30  # è®¾ç½®è¾ƒé«˜ï¼ˆåº”å¯¹å„ç§å®ä¾‹ç±»å‹ï¼‰
          periodSeconds: 5
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          periodSeconds: 5
          failureThreshold: 2
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8080
          periodSeconds: 10
          failureThreshold: 3
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh", "-c", "sleep 10"]  # é¢„ç•™é¢å¤–æ—¶é—´
      terminationGracePeriodSeconds: 90  # åº”å¯¹è‡ªåŠ¨æ“ä½œç³»ç»Ÿè¡¥ä¸é©±é€
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: api-pdb
spec:
  minAvailable: 2  # ç¡®ä¿ Auto Mode èŠ‚ç‚¹æ›¿æ¢æœŸé—´çš„å¯ç”¨æ€§
  selector:
    matchLabels:
      app: api
```

#### å¤„ç† Auto Mode ä¸­çš„è‡ªåŠ¨æ“ä½œç³»ç»Ÿè¡¥ä¸é©±é€

Auto Mode ä¼šå®šæœŸæ›¿æ¢èŠ‚ç‚¹ä»¥è¿›è¡Œæ“ä½œç³»ç»Ÿè¡¥ä¸ã€‚åœ¨æ­¤è¿‡ç¨‹ä¸­ä¼šè‡ªåŠ¨å‘ç”Ÿ Pod é©±é€ã€‚

**æ“ä½œç³»ç»Ÿè¡¥ä¸é©±é€åœºæ™¯ï¼š**

```mermaid
sequenceDiagram
    participant AutoMode as EKS Auto Mode
    participant Node_Old as æ—§èŠ‚ç‚¹
    participant Node_New as æ–°èŠ‚ç‚¹
    participant Pod as Pod

    Note over AutoMode: æ£€æµ‹åˆ°éœ€è¦æ“ä½œç³»ç»Ÿè¡¥ä¸

    AutoMode->>Node_New: é…ç½®æ–°èŠ‚ç‚¹
    Node_New->>AutoMode: èŠ‚ç‚¹å°±ç»ª

    AutoMode->>Node_Old: Cordonï¼ˆé˜»æ­¢è°ƒåº¦ï¼‰
    AutoMode->>Pod: å¼€å§‹ Pod é©±é€

    Pod->>Pod: æ‰§è¡Œ preStop Hook
    Note over Pod: sleep 10<br/>ï¼ˆç­‰å¾…æµé‡æ’ç©ºï¼‰

    Pod->>Pod: æ¥æ”¶ SIGTERM
    Pod->>Pod: ä¼˜é›…å…³é—­
    Note over Pod: terminationGracePeriodSeconds<br/>ï¼ˆæœ€å¤š 90 ç§’ï¼‰

    Pod->>Node_New: åœ¨æ–°èŠ‚ç‚¹ä¸Šé‡æ–°è°ƒåº¦
    Pod->>Pod: startupProbe æˆåŠŸ
    Pod->>Pod: readinessProbe æˆåŠŸ

    AutoMode->>Node_Old: ç»ˆæ­¢èŠ‚ç‚¹

    Note over AutoMode: æ“ä½œç³»ç»Ÿè¡¥ä¸å®Œæˆ
```

**ç›‘æ§ç¤ºä¾‹ï¼š**

```bash
# è·Ÿè¸ª Auto Mode èŠ‚ç‚¹æ›¿æ¢äº‹ä»¶
kubectl get events --field-selector reason=Evicted --watch

# æ£€æŸ¥æ¯ä¸ªèŠ‚ç‚¹çš„æ“ä½œç³»ç»Ÿç‰ˆæœ¬
kubectl get nodes -o custom-columns=\
NAME:.metadata.name,\
OS_IMAGE:.status.nodeInfo.osImage,\
KERNEL:.status.nodeInfo.kernelVersion

# æ£€æŸ¥ Auto Mode ç®¡ç†çŠ¶æ€
kubectl get nodes -L eks.amazonaws.com/compute-type
```

:::tip Auto Mode èŠ‚ç‚¹æ›¿æ¢é¢‘ç‡
Auto Mode ä¸ºäº†å®‰å…¨è¡¥ä¸ã€æ€§èƒ½ä¼˜åŒ–å’Œæˆæœ¬é™ä½ï¼Œæ¯”æ‰‹åŠ¨ç®¡ç†æ›´é¢‘ç¹åœ°æ›¿æ¢èŠ‚ç‚¹ï¼ˆå¹³å‡æ¯ä¸¤å‘¨ä¸€æ¬¡ï¼‰ã€‚å°† `terminationGracePeriodSeconds` è®¾ç½®ä¸º 90 ç§’ä»¥ä¸Šï¼Œå¹¶å§‹ç»ˆé…ç½® PDBï¼Œä»¥ç¡®ä¿åœ¨ä¸ä¸­æ–­æœåŠ¡çš„æƒ…å†µä¸‹è¿›è¡ŒèŠ‚ç‚¹æ›¿æ¢ã€‚
:::

#### éªŒè¯ Auto Mode æ˜¯å¦å·²å¯ç”¨

```bash
# æ£€æŸ¥é›†ç¾¤æ˜¯å¦å¤„äº Auto Mode
aws eks describe-cluster --name production-eks \
  --query 'cluster.computeConfig.enabled' \
  --output text

# æ£€æŸ¥ Auto Mode èŠ‚ç‚¹
kubectl get nodes -L eks.amazonaws.com/compute-type
# ç¤ºä¾‹è¾“å‡ºï¼š
# NAME                    COMPUTE-TYPE
# ip-10-0-1-100.ec2.internal   auto
# ip-10-0-2-200.ec2.internal   auto
```

**ç›¸å…³æ–‡æ¡£ï¼š**
- [AWS Blog: Getting started with EKS Auto Mode](https://aws.amazon.com/blogs/containers/getting-started-with-amazon-eks-auto-mode)
- [AWS Blog: How to build highly available Kubernetes applications with EKS Auto Mode](https://aws.amazon.com/blogs/containers/how-to-build-highly-available-kubernetes-applications-with-amazon-eks-auto-mode/)
- [AWS Blog: Maximize EKS efficiency - Auto Mode, Graviton, and Spot](https://aws.amazon.com/blogs/containers/maximize-amazon-eks-efficiency-how-auto-mode-graviton-and-spot-work-together/)

---

### 7.5 åŸºäº AI/Agentic çš„ Probe ä¼˜åŒ–

æœ¬èŠ‚ä»‹ç»å¦‚ä½•åˆ©ç”¨ AWS re:Invent 2025 CNS421 ä¼šè®®ä¸­ä»‹ç»çš„åŸºäº Agentic AI çš„ EKS è¿ç»´æ¨¡å¼ï¼Œè‡ªåŠ¨ä¼˜åŒ– Probe é…ç½®å¹¶è¯Šæ–­æ•…éšœã€‚

#### CNS421 ä¼šè®®è¦ç‚¹ - Agentic AI ç”¨äº EKS è¿ç»´

**ä¼šè®®æ¦‚è¿°ï¼š**

"Streamline Amazon EKS Operations with Agentic AI" ä¼šè®®é€šè¿‡ç°åœºä»£ç æ¼”ç¤ºå±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ Model Context Protocolï¼ˆMCPï¼‰å’Œ AI ä»£ç†è‡ªåŠ¨åŒ– EKS é›†ç¾¤ç®¡ç†ã€‚

**æ ¸å¿ƒèƒ½åŠ›ï¼š**
- å®æ—¶é—®é¢˜è¯Šæ–­ï¼ˆè‡ªåŠ¨ Probe æ•…éšœæ ¹å› åˆ†æï¼‰
- å¼•å¯¼ä¿®å¤ï¼ˆé€æ­¥è§£å†³æŒ‡å—ï¼‰
- Tribal Knowledge åˆ©ç”¨ï¼ˆä»è¿‡å¾€é—®é¢˜æ¨¡å¼ä¸­å­¦ä¹ ï¼‰
- è‡ªåŠ¨ä¿®å¤ï¼ˆè‡ªåŠ¨è§£å†³ç®€å•é—®é¢˜ï¼‰

**æ¶æ„ï¼š**

```mermaid
flowchart LR
    PROBE_FAIL[æ£€æµ‹åˆ° Probe æ•…éšœ]
    PROBE_FAIL --> MCP[EKS MCP Server]

    MCP --> CONTEXT[ä¸Šä¸‹æ–‡æ”¶é›†]
    CONTEXT --> LOGS[Pod æ—¥å¿—]
    CONTEXT --> METRICS[CloudWatch æŒ‡æ ‡]
    CONTEXT --> EVENTS[Kubernetes Events]
    CONTEXT --> NETWORK[Network Observability]

    CONTEXT --> AI[Agentic AI<br/>Amazon Bedrock]
    AI --> ANALYZE[æ ¹å› åˆ†æ]

    ANALYZE --> DECISION{å¯è‡ªåŠ¨ä¿®å¤ï¼Ÿ}

    DECISION -->|æ˜¯| AUTO[è‡ªåŠ¨ä¿®å¤]
    AUTO --> FIX_PROBE[è°ƒæ•´ Probe è®¾ç½®]
    AUTO --> FIX_APP[é‡å¯åº”ç”¨]
    AUTO --> FIX_NETWORK[ä¿®æ”¹ç½‘ç»œç­–ç•¥]

    DECISION -->|å¦| GUIDE[æä¾›ä¿®å¤æŒ‡å—]
    GUIDE --> HUMAN[è¿ç»´äººå‘˜ä»‹å…¥]

    HUMAN --> LEARN[å­¦ä¹ ä¿®å¤æ¨¡å¼]
    LEARN --> TRIBAL[Tribal Knowledge<br/>æ›´æ–°]

    style PROBE_FAIL fill:#ff4444,stroke:#cc3636,color:#fff
    style AI fill:#4286f4,stroke:#2a6acf,color:#fff
    style AUTO fill:#34a853,stroke:#2a8642,color:#fff
```

#### ä½¿ç”¨ Kiro + EKS MCP è‡ªåŠ¨ä¼˜åŒ– Probe

**ä»€ä¹ˆæ˜¯ Kiroï¼š**

Kiro æ˜¯ä¸€ä¸ªç”± AWS AI é©±åŠ¨çš„è¿ç»´å·¥å…·ï¼Œé€šè¿‡ MCPï¼ˆModel Context Protocolï¼‰æœåŠ¡å™¨ä¸ AWS èµ„æºè¿›è¡Œäº¤äº’ã€‚

**å®‰è£…å’Œè®¾ç½®ï¼š**

```bash
# å®‰è£… Kiro CLIï¼ˆmacOSï¼‰
brew install aws/tap/kiro

# é…ç½® EKS MCP Server
kiro mcp add eks \
  --server-type eks \
  --cluster-name production-eks \
  --region ap-northeast-2

# å¯ç”¨ Probe ä¼˜åŒ–ä»£ç†
kiro agent create probe-optimizer \
  --type eks-health-check \
  --auto-remediate true
```

**Probe æ•…éšœè‡ªåŠ¨è¯Šæ–­å·¥ä½œæµï¼š**

```yaml
# Kiro Agent é…ç½® - è‡ªåŠ¨ Probe æ•…éšœå“åº”
apiVersion: kiro.aws/v1alpha1
kind: Agent
metadata:
  name: probe-failure-analyzer
spec:
  cluster: production-eks
  triggers:
    - type: ProbeFailure
      conditions:
        - probeType: readiness
          failureThreshold: 3
          duration: 5m
  actions:
    - name: collect-context
      steps:
        - getPodLogs:
            namespace: ${event.namespace}
            podName: ${event.podName}
            tailLines: 500
        - getCloudWatchMetrics:
            namespace: ContainerInsights
            metricName: pod_cpu_utilization
            dimensions:
              - name: PodName
                value: ${event.podName}
            period: 300
        - getNetworkObservability:
            podName: ${event.podName}
            metrics:
              - latency
              - packetLoss
              - connectionErrors
        - getKubernetesEvents:
            namespace: ${event.namespace}
            fieldSelector: involvedObject.name=${event.podName}

    - name: analyze-root-cause
      llm:
        model: anthropic.claude-3-5-sonnet-20241022-v2:0
        prompt: |
          Analyze the following Kubernetes Readiness Probe failure:

          Pod: ${event.podName}
          Namespace: ${event.namespace}
          Probe Config:
          ${context.probeConfig}

          Pod Logs (last 500 lines):
          ${context.podLogs}

          CloudWatch Metrics (last 5 minutes):
          ${context.metrics}

          Network Observability:
          ${context.networkMetrics}

          Kubernetes Events:
          ${context.events}

          Determine the root cause and suggest:
          1. Is this a network issue, application issue, or configuration issue?
          2. Recommended Probe settings (periodSeconds, failureThreshold, timeoutSeconds)
          3. Auto-remediation actions if applicable

    - name: auto-remediate
      conditions:
        - type: RootCauseIdentified
          confidence: ">0.8"
      steps:
        - applyProbeOptimization:
            when: ${analysis.recommendedAction == "adjust_probe_settings"}
            patchDeployment:
              name: ${event.deploymentName}
              namespace: ${event.namespace}
              patch:
                spec:
                  template:
                    spec:
                      containers:
                        - name: ${event.containerName}
                          readinessProbe:
                            periodSeconds: ${analysis.recommendedPeriod}
                            failureThreshold: ${analysis.recommendedThreshold}
                            timeoutSeconds: ${analysis.recommendedTimeout}

        - restartPod:
            when: ${analysis.recommendedAction == "restart_pod"}
            namespace: ${event.namespace}
            podName: ${event.podName}

        - notifySlack:
            channel: "#eks-ops"
            message: |
              ğŸ¤– Probe Failure Auto-Remediated

              Pod: ${event.podName}
              Root Cause: ${analysis.rootCause}
              Action Taken: ${analysis.appliedAction}
              Confidence: ${analysis.confidence}

              Details: ${analysis.explanation}

    - name: manual-guide
      conditions:
        - type: RootCauseIdentified
          confidence: "<0.8"
      steps:
        - createJiraTicket:
            project: DEVOPS
            issueType: Incident
            summary: "Probe Failure - Manual Investigation Required"
            description: |
              Pod: ${event.podName}
              Potential Causes: ${analysis.possibleCauses}
              Investigation Steps: ${analysis.investigationSteps}
              Context: ${context}
```

**å®é™…ç¤ºä¾‹ - è‡ªåŠ¨ä¼˜åŒ– Probe è¶…æ—¶ï¼š**

```bash
# é€šè¿‡ Kiro è¿›è¡Œäº¤äº’å¼ Probe ä¼˜åŒ–
$ kiro chat --agent probe-optimizer

User: My readiness probe is failing intermittently on pod api-gateway-xyz.
      Can you diagnose and fix it?

Kiro: ğŸ” Analyzing probe failures for pod api-gateway-xyz...

      âœ… Root Cause Identified (Confidence: 92%)
      - Issue: Network latency spikes to external database
      - Current Probe: periodSeconds=5, timeoutSeconds=3, failureThreshold=2
      - Network metrics show p99 latency: 2.8 seconds

      ğŸ“Š Recommendation:
      1. Increase timeoutSeconds from 3 to 5 seconds
      2. Increase failureThreshold from 2 to 3
      3. Enable Container Network Observability for ongoing monitoring

      ğŸ¤– Auto-Remediation Available
      Shall I apply these changes? (yes/no)

User: yes

Kiro: âœ… Applied Probe Optimization
      - Updated Deployment: api-gateway
      - New Probe Config:
        * periodSeconds: 5
        * timeoutSeconds: 5 (increased)
        * failureThreshold: 3 (increased)

      ğŸ“ˆ Monitoring for 5 minutes to verify stability...

      âœ… Verification Complete
      - Probe failures reduced from 12/hour to 0/hour
      - Network latency p99: 2.8s (within new 5s timeout)
      - Recommendation recorded in tribal knowledge

      ğŸ’¡ Suggestion: Consider moving database to same VPC
          to reduce network latency permanently.
```

#### ä½¿ç”¨ Amazon Q Developer è°ƒè¯• Probe é—®é¢˜

Amazon Q Developer æ˜¯ä¸€ä¸ª IDE é›†æˆçš„ AI åŠ©æ‰‹ï¼Œæ”¯æŒ Probe é…ç½®ä»£ç å®¡æŸ¥å’Œå®æ—¶è°ƒè¯•ã€‚

**VS Code é›†æˆç¤ºä¾‹ï¼š**

```yaml
# å¼€å‘è€…æ­£åœ¨ç¼–å†™çš„ Deployment YAML
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  template:
    spec:
      containers:
      - name: app
        image: myapp:v1
        readinessProbe:
          httpGet:
            path: /health  # âš ï¸ Q Developer è­¦å‘Š
            port: 8080
          periodSeconds: 10
          timeoutSeconds: 1  # âš ï¸ Q Developer è­¦å‘Š
```

**Q Developer å»ºè®®ï¼š**

```
ğŸ’¡ Amazon Q Developer å»ºè®®

é—®é¢˜ 1ï¼šLiveness å’Œ Readiness ä½¿ç”¨ç›¸åŒçš„ç«¯ç‚¹ã€‚
å»ºè®®ï¼š
- Liveness Probeï¼š/healthzï¼ˆä»…æ£€æŸ¥å†…éƒ¨çŠ¶æ€ï¼‰
- Readiness Probeï¼š/readyï¼ˆåŒ…å«å¤–éƒ¨ä¾èµ–ï¼‰

é—®é¢˜ 2ï¼štimeoutSeconds è®¾ç½®è¿‡çŸ­ã€‚
å»ºè®®ï¼š
- å°† timeoutSeconds å¢åŠ åˆ° 3-5 ç§’
- åœ¨ EKS ç¯å¢ƒä¸­ 1 ç§’å¯èƒ½å› ç½‘ç»œå»¶è¿Ÿè€Œè¶…æ—¶

é—®é¢˜ 3ï¼šç¼ºå°‘ Startup Probeã€‚
å»ºè®®ï¼š
- å¦‚æœåº”ç”¨å¯åŠ¨æ—¶é—´è¶…è¿‡ 30 ç§’ï¼Œæ·»åŠ  Startup Probe
- failureThreshold: 30ï¼ŒperiodSeconds: 10

åº”ç”¨å»ºè®®ï¼Ÿ[æ˜¯] [å¦] [è¯¦ç»†è¯´æ˜]
```

**å®æ—¶ä»£ç æ‰§è¡ŒéªŒè¯ï¼ˆAmazon Q Developerï¼‰ï¼š**

```bash
# Q Developer åœ¨æœ¬åœ°éªŒè¯ Probe é…ç½®
$ q-dev validate deployment.yaml --cluster production-eks

âœ… è¯­æ³•æœ‰æ•ˆ
âš ï¸  æœ€ä½³å®è·µæ£€æŸ¥ï¼š
    - å¯åŠ¨ç¼“æ…¢çš„åº”ç”¨ç¼ºå°‘ Startup Probeï¼ˆ15 ä¸ªè­¦å‘Šï¼‰
    - Liveness Probe åŒ…å«å¤–éƒ¨ä¾èµ–ï¼ˆä¸¥é‡ï¼‰
    - terminationGracePeriodSeconds åº”è‡³å°‘ä¸º 60 ç§’ï¼ˆè­¦å‘Šï¼‰

ğŸ§ª æ¨¡æ‹Ÿç»“æœï¼š
    - Probe æˆåŠŸç‡ï¼š94%ï¼ˆç›®æ ‡ï¼š>99%ï¼‰
    - é¢„è®¡ Pod å¯åŠ¨æ—¶é—´ï¼š45 ç§’
    - é¢„è®¡ä¼˜é›…å…³é—­æ—¶é—´ï¼š25 ç§’

ğŸ“Š å»ºè®®ï¼š
    åº”ç”¨ Q Developer å»ºè®®çš„é…ç½®ï¼Ÿ(Y/n)
```

#### åŸºäº Tribal Knowledge çš„ Probe æ¨¡å¼å­¦ä¹ 

Agentic AI ä»è¿‡å»çš„ Probe é—®é¢˜è§£å†³æ¨¡å¼ä¸­å­¦ä¹ ï¼Œåœ¨ç±»ä¼¼æƒ…å†µä¸‹ç«‹å³å“åº”ã€‚

**Tribal Knowledge ç¤ºä¾‹ï¼š**

```yaml
# ç»„ç»‡çš„ Probe è§£å†³æ¨¡å¼åº“
apiVersion: kiro.aws/v1alpha1
kind: TribalKnowledge
metadata:
  name: probe-failure-patterns
spec:
  patterns:
    - id: pattern-001
      name: "Database Connection Timeout"
      symptoms:
        - probeType: readiness
          errorPattern: "connection timeout"
          frequency: intermittent
      rootCause: "æ•°æ®åº“åœ¨ä¸åŒ AZ å¯¼è‡´é«˜å»¶è¿Ÿ"
      solution:
        - action: increaseTimeout
          from: 3
          to: 5
        - action: addRetry
          retries: 2
      confidence: 0.95
      resolvedCount: 47
      lastSeen: "2026-02-10"

    - id: pattern-002
      name: "Slow JVM Startup"
      symptoms:
        - probeType: startup
          errorPattern: "probe failed"
          timing: "first 60 seconds"
      rootCause: "JVM åˆå§‹åŒ–è€—æ—¶è¶…è¿‡ 30 ç§’"
      solution:
        - action: addStartupProbe
          failureThreshold: 30
          periodSeconds: 10
      confidence: 0.98
      resolvedCount: 123
      lastSeen: "2026-02-11"

    - id: pattern-003
      name: "Network Policy Blocking Health Check"
      symptoms:
        - probeType: liveness
          errorPattern: "connection refused"
          timing: "after deployment"
      rootCause: "NetworkPolicy æœªå…è®¸ kubelet è®¿é—®"
      solution:
        - action: updateNetworkPolicy
          allowFrom:
            - podSelector: {}  # å…è®¸å‘½åç©ºé—´å†…æ‰€æœ‰ Pod
            - namespaceSelector:
                matchLabels:
                  name: kube-system
      confidence: 0.92
      resolvedCount: 34
      lastSeen: "2026-02-08"
```

**è‡ªåŠ¨æ¨¡å¼åŒ¹é…ï¼š**

```bash
# æ–° Probe æ•…éšœå‘ç”Ÿæ—¶è‡ªåŠ¨åŒ¹é…
$ kiro diagnose probe-failure \
  --pod api-backend-abc \
  --namespace production

ğŸ” æ­£åœ¨åˆ†æ Probe æ•…éšœ...

âœ… æ¨¡å¼åŒ¹é…ï¼š"Database Connection Timeout"ï¼ˆpattern-001ï¼‰
   ç½®ä¿¡åº¦ï¼š89%
   æ­¤æ¨¡å¼å·²æˆåŠŸè§£å†³ 47 æ¬¡

ğŸ“‹ å»ºè®®æ“ä½œï¼ˆæ¥è‡ª Tribal Knowledgeï¼‰ï¼š
   1. å°† readinessProbe.timeoutSeconds ä» 3 å¢åŠ åˆ° 5
   2. æ·»åŠ  2 æ¬¡é‡è¯•é€»è¾‘
   3. è€ƒè™‘å°†æ•°æ®åº“æ”¾ç½®åœ¨åŒä¸€ AZ

ğŸ¤– è‡ªåŠ¨åº”ç”¨ï¼Ÿ(yes/no)
```

#### Probe ä¼˜åŒ–é›†æˆä»ªè¡¨æ¿

```yaml
# Grafana Dashboard - AI é©±åŠ¨çš„ Probe ä¼˜åŒ–çŠ¶æ€
apiVersion: v1
kind: ConfigMap
metadata:
  name: ai-probe-optimization-dashboard
  namespace: monitoring
data:
  dashboard.json: |
    {
      "title": "AI-Driven Probe Optimization",
      "panels": [
        {
          "title": "Auto-Remediation Success Rate",
          "targets": [{
            "expr": "rate(kiro_auto_remediation_success[1h]) / rate(kiro_auto_remediation_total[1h])"
          }]
        },
        {
          "title": "Tribal Knowledge Pattern Matching",
          "targets": [{
            "expr": "kiro_pattern_match_count"
          }]
        },
        {
          "title": "Probe Failure Rate Trend (Before/After AI)",
          "targets": [
            {"expr": "rate(probe_failures_total[1h])", "legendFormat": "Before AI"},
            {"expr": "rate(probe_failures_ai_optimized_total[1h])", "legendFormat": "After AI"}
          ]
        },
        {
          "title": "Mean Time to Resolution (MTTR)",
          "targets": [{
            "expr": "avg(kiro_remediation_duration_seconds)"
          }]
        }
      ]
    }
```

**ROI è¡¡é‡ç¤ºä¾‹ï¼š**

| æŒ‡æ ‡ | AI å¼•å…¥å‰ | AI å¼•å…¥å | æ”¹å–„å¹…åº¦ |
|------|----------|----------|---------|
| Probe æ•…éšœæ¬¡æ•° | 120 æ¬¡/å‘¨ | 12 æ¬¡/å‘¨ | å‡å°‘ 90% |
| å¹³å‡è§£å†³æ—¶é—´ï¼ˆMTTRï¼‰ | 45 åˆ†é’Ÿ | 3 åˆ†é’Ÿ | å‡å°‘ 93% |
| éœ€è¦è¿ç»´äººå‘˜ä»‹å…¥çš„æ¡ˆä¾‹ | 120 æ¬¡/å‘¨ | 12 æ¬¡/å‘¨ | å‡å°‘ 90% |
| Probe é…ç½®ä¼˜åŒ–æ—¶é—´ | 2 å°æ—¶/æ¡ˆä¾‹ | 5 åˆ†é’Ÿ/æ¡ˆä¾‹ | å‡å°‘ 96% |

:::tip é‡‡ç”¨ Agentic AI çš„æœ€ä½³å®è·µ
ä¸è¦ä»ä¸€å¼€å§‹å°±è¿½æ±‚ Agentic AI çš„ 100% è‡ªåŠ¨åŒ–ã€‚åœ¨å‰ 3 ä¸ªæœˆä»¥"å»ºè®®æ¨¡å¼"è¿è¡Œï¼Œç”±è¿ç»´äººå‘˜å®¡æŸ¥å’Œæ‰¹å‡† AI å»ºè®®ã€‚å½“ Tribal Knowledge ç§¯ç´¯å……åˆ†ä¸”ç½®ä¿¡åº¦è¾¾åˆ° 90% ä»¥ä¸Šæ—¶ï¼Œå†è½¬æ¢ä¸º"è‡ªåŠ¨ä¿®å¤æ¨¡å¼"ã€‚
:::

**ç›¸å…³èµ„æºï¼š**
- [YouTube: CNS421 - Streamline Amazon EKS operations with Agentic AI](https://www.youtube.com/watch?v=4s-a0jY4kSE)
- [AWS Blog: Agentic Cloud Modernization with Kiro](https://aws.amazon.com/blogs/migration-and-modernization/agentic-cloud-modernization-accelerating-modernization-with-aws-mcps-and-kiro/)
- [AWS Blog: AWS IaC MCP Server](https://aws.amazon.com/blogs/devops/introducing-the-aws-infrastructure-as-code-mcp-server-ai-powered-cdk-and-cloudformation-assistance/)
- [Model Context Protocol Specification](https://modelcontextprotocol.io/)

---

**æ–‡æ¡£è´¡çŒ®**ï¼šæ¬¢è¿é€šè¿‡ GitHub Issues æäº¤å¯¹æœ¬æ–‡æ¡£çš„åé¦ˆã€é”™è¯¯æŠ¥å‘Šå’Œæ”¹è¿›å»ºè®®ã€‚
